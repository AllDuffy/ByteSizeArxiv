{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import urllib.request as libreq\n",
    "import feedparser\n",
    "import pdfminer.layout\n",
    "import pdfminer.high_level\n",
    "from io import StringIO\n",
    "from pdfminer.layout import LAParams\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import nltk\n",
    "import re\n",
    "import heapq\n",
    "import boto3\n",
    "import pdfminer3\n",
    "import os\n",
    "from pycontractions import Contractions\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader #for deleting all images\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer \n",
    "import numpy as np  \n",
    "import pandas as pd   \n",
    "#from keras.preprocessing.text import Tokenizer \n",
    "#from keras.preprocessing.sequence import pad_sequences  \n",
    "#from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#import warnings\n",
    "ps = PorterStemmer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed title: ArXiv Query: search_query=cat:cs.LG&id_list=&start=0&max_results=5\n",
      "Feed last updated: 2020-05-16T00:00:00-04:00\n",
      "totalResults for this query: 55391\n",
      "itemsPerPage for this query: 5\n",
      "startIndex for this query: 0\n",
      "e-print metadata\n",
      "arxiv-id: cs/9905014v1\n",
      "Published: 1999-05-21T14:26:07Z\n",
      "Title:  Hierarchical Reinforcement Learning with the MAXQ Value Function\n",
      "  Decomposition\n",
      "Last Author:  Thomas G. Dietterich\n",
      "Authors:  Thomas G. Dietterich\n",
      "abs page link: http://arxiv.org/abs/cs/9905014v1\n",
      "pdf link: http://arxiv.org/pdf/cs/9905014v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: 63 pages, 15 figures\n",
      "Primary Category: cs.LG\n",
      "All Categories: cs.LG, I.2.6\n",
      "Abstract: This paper presents the MAXQ approach to hierarchical reinforcement learning\n",
      "based on decomposing the target Markov decision process (MDP) into a hierarchy\n",
      "of smaller MDPs and decomposing the value function of the target MDP into an\n",
      "additive combination of the value functions of the smaller MDPs. The paper\n",
      "defines the MAXQ hierarchy, proves formal results on its representational\n",
      "power, and establishes five conditions for the safe use of state abstractions.\n",
      "The paper presents an online model-free learning algorithm, MAXQ-Q, and proves\n",
      "that it converges wih probability 1 to a kind of locally-optimal policy known\n",
      "as a recursively optimal policy, even in the presence of the five kinds of\n",
      "state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\n",
      "through a series of experiments in three domains and shows experimentally that\n",
      "MAXQ-Q (with state abstractions) converges to a recursively optimal policy much\n",
      "faster than flat Q learning. The fact that MAXQ learns a representation of the\n",
      "value function has an important benefit: it makes it possible to compute and\n",
      "execute an improved, non-hierarchical policy via a procedure similar to the\n",
      "policy improvement step of policy iteration. The paper demonstrates the\n",
      "effectiveness of this non-hierarchical execution experimentally. Finally, the\n",
      "paper concludes with a comparison to related work and a discussion of the\n",
      "design tradeoffs in hierarchical reinforcement learning.\n",
      "e-print metadata\n",
      "arxiv-id: cs/9905015v1\n",
      "Published: 1999-05-21T14:49:39Z\n",
      "Title:  State Abstraction in MAXQ Hierarchical Reinforcement Learning\n",
      "Last Author:  Thomas G. Dietterich\n",
      "Authors:  Thomas G. Dietterich\n",
      "abs page link: http://arxiv.org/abs/cs/9905015v1\n",
      "pdf link: http://arxiv.org/pdf/cs/9905015v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: 7 pages, 2 figures\n",
      "Primary Category: cs.LG\n",
      "All Categories: cs.LG, I.2.6\n",
      "Abstract: Many researchers have explored methods for hierarchical reinforcement\n",
      "learning (RL) with temporal abstractions, in which abstract actions are defined\n",
      "that can perform many primitive actions before terminating. However, little is\n",
      "known about learning with state abstractions, in which aspects of the state\n",
      "space are ignored. In previous work, we developed the MAXQ method for\n",
      "hierarchical RL. In this paper, we define five conditions under which state\n",
      "abstraction can be combined with the MAXQ value function decomposition. We\n",
      "prove that the MAXQ-Q learning algorithm converges under these conditions and\n",
      "show experimentally that state abstraction is important for the successful\n",
      "application of MAXQ-Q learning.\n",
      "e-print metadata\n",
      "arxiv-id: cs/0001004v1\n",
      "Published: 2000-01-07T06:20:53Z\n",
      "Title:  Multiplicative Algorithm for Orthgonal Groups and Independent Component\n",
      "  Analysis\n",
      "Last Author:  Toshinao Akuzawa (RIKEN BSI)\n",
      "Authors:  Toshinao Akuzawa\n",
      "abs page link: http://arxiv.org/abs/cs/0001004v1\n",
      "pdf link: http://arxiv.org/pdf/cs/0001004v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: 11 pages, 2 figures\n",
      "Primary Category: cs.LG\n",
      "All Categories: cs.LG, G.1.6\n",
      "Abstract: The multiplicative Newton-like method developed by the author et al. is\n",
      "extended to the situation where the dynamics is restricted to the orthogonal\n",
      "group. A general framework is constructed without specifying the cost function.\n",
      "Though the restriction to the orthogonal groups makes the problem somewhat\n",
      "complicated, an explicit expression for the amount of individual jumps is\n",
      "obtained. This algorithm is exactly second-order-convergent. The global\n",
      "instability inherent in the Newton method is remedied by a\n",
      "Levenberg-Marquardt-type variation. The method thus constructed can readily be\n",
      "applied to the independent component analysis. Its remarkable performance is\n",
      "illustrated by a numerical simulation.\n",
      "e-print metadata\n",
      "arxiv-id: cs/0002006v1\n",
      "Published: 2000-02-09T06:44:28Z\n",
      "Title:  Multiplicative Nonholonomic/Newton -like Algorithm\n",
      "Last Author:  Noboru Murata (RIKEN BSI)\n",
      "Authors:  Toshinao Akuzawa, Noboru Murata\n",
      "abs page link: http://arxiv.org/abs/cs/0002006v1\n",
      "pdf link: http://arxiv.org/pdf/cs/0002006v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: 12 pages\n",
      "Primary Category: cs.LG\n",
      "All Categories: cs.LG, G.1.6\n",
      "Abstract: We construct new algorithms from scratch, which use the fourth order cumulant\n",
      "of stochastic variables for the cost function. The multiplicative updating rule\n",
      "here constructed is natural from the homogeneous nature of the Lie group and\n",
      "has numerous merits for the rigorous treatment of the dynamics. As one\n",
      "consequence, the second order convergence is shown. For the cost function,\n",
      "functions invariant under the componentwise scaling are choosen. By identifying\n",
      "points which can be transformed to each other by the scaling, we assume that\n",
      "the dynamics is in a coset space. In our method, a point can move toward any\n",
      "direction in this coset. Thus, no prewhitening is required.\n",
      "e-print metadata\n",
      "arxiv-id: cs/0009001v3\n",
      "Published: 2000-09-05T18:54:58Z\n",
      "Title:  Complexity analysis for algorithmically simple strings\n",
      "Last Author:  Andrei N. Soklakov (Royal Holloway, University of London)\n",
      "Authors:  Andrei N. Soklakov\n",
      "abs page link: http://arxiv.org/abs/cs/0009001v3\n",
      "pdf link: http://arxiv.org/pdf/cs/0009001v3\n",
      "Journal reference: No journal ref found\n",
      "Comments: 10 pages\n",
      "Primary Category: cs.LG\n",
      "All Categories: cs.LG, E.4; F.2; I.2\n",
      "Abstract: Given a reference computer, Kolmogorov complexity is a well defined function\n",
      "on all binary strings. In the standard approach, however, only the asymptotic\n",
      "properties of such functions are considered because they do not depend on the\n",
      "reference computer. We argue that this approach can be more useful if it is\n",
      "refined to include an important practical case of simple binary strings.\n",
      "Kolmogorov complexity calculus may be developed for this case if we restrict\n",
      "the class of available reference computers. The interesting problem is to\n",
      "define a class of computers which is restricted in a {\\it natural} way modeling\n",
      "the real-life situation where only a limited class of computers is physically\n",
      "available to us. We give an example of what such a natural restriction might\n",
      "look like mathematically, and show that under such restrictions some error\n",
      "terms, even logarithmic in complexity, can disappear from the standard\n",
      "complexity calculus.\n",
      "  Keywords: Kolmogorov complexity; Algorithmic information theory.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "python_arXiv_parsing_example.py\n",
    "\n",
    "This sample script illustrates a basic arXiv api call\n",
    "followed by parsing of the results using the \n",
    "feedparser python module.\n",
    "\n",
    "Please see the documentation at \n",
    "http://export.arxiv.org/api_help/docs/user-manual.html\n",
    "for more information, or email the arXiv api \n",
    "mailing list at arxiv-api@googlegroups.com.\n",
    "\n",
    "urllib is included in the standard python library.\n",
    "feedparser can be downloaded from http://feedparser.org/ .\n",
    "\n",
    "Author: Julius B. Lucks\n",
    "\n",
    "This is free software.  Feel free to do what you want\n",
    "with it, but please play nice with the arXiv API!\n",
    "\"\"\"\n",
    "\n",
    "# Base api query url\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "\n",
    "# Search parameters\n",
    "search_query = 'cat:cs.LG' # search in the machine learning category\n",
    "start = 0                    # retreive the first 5 results\n",
    "max_results = 5\n",
    "\n",
    "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)\n",
    "#List of paper entries with all info\n",
    "corpusEntry=[]\n",
    "#Corresponding list of pdf download links \n",
    "corpusPDF=[]\n",
    "#Corresponding list of Paper ID's\n",
    "corpusID = []\n",
    "#Corresponding list of Paper Abstracts\n",
    "corpusAbstract = []\n",
    "# Opensearch metadata such as totalResults, startIndex, \n",
    "# and itemsPerPage live in the opensearch namespase.\n",
    "# Some entry metadata lives in the arXiv namespace.\n",
    "# This is a hack to expose both of these namespaces in\n",
    "# feedparser v4.1\n",
    "feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "with libreq.urlopen(base_url+query) as url:\n",
    "    response = url.read()\n",
    "\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response)\n",
    "\n",
    "# print out feed information\n",
    "print ('Feed title: %s' % feed.feed.title)\n",
    "print ('Feed last updated: %s' % feed.feed.updated)\n",
    "\n",
    "# print opensearch metadata\n",
    "print ('totalResults for this query: %s' % feed.feed.opensearch_totalresults)\n",
    "print ('itemsPerPage for this query: %s' % feed.feed.opensearch_itemsperpage)\n",
    "print ('startIndex for this query: %s'   % feed.feed.opensearch_startindex)\n",
    "\n",
    "# Run through each entry, and print out information\n",
    "for entry in feed.entries:\n",
    "    corpusEntry.append(entry)\n",
    "    print ('e-print metadata')\n",
    "    print ('arxiv-id: %s' % entry.id.split('/abs/')[-1])\n",
    "    corpusID.append(entry.id.split('/abs/')[-1])\n",
    "    print ('Published: %s' % entry.published)\n",
    "    print ('Title:  %s' % entry.title)\n",
    "    \n",
    "    # feedparser v4.1 only grabs the first author\n",
    "    author_string = entry.author\n",
    "    \n",
    "    # grab the affiliation in <arxiv:affiliation> if present\n",
    "    # - this will only grab the first affiliation encountered\n",
    "    #   (the first affiliation for the first author)\n",
    "    # Please email the list with a way to get all of this information!\n",
    "    try:\n",
    "        author_string += ' (%s)' % entry.arxiv_affiliation\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    print ('Last Author:  %s' % author_string)\n",
    "    \n",
    "    # feedparser v5.0.1 correctly handles multiple authors, print them all\n",
    "    try:\n",
    "        print ('Authors:  %s' % ', '.join(author.name for author in entry.authors))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # get the links to the abs page and pdf for this e-print\n",
    "    for link in entry.links:\n",
    "        if link.rel == 'alternate':\n",
    "            print ('abs page link: %s' % link.href)\n",
    "        elif link.title == 'pdf':\n",
    "            \n",
    "            corpusPDF.append({\"pdf_url\": link.href})\n",
    "            print ('pdf link: %s' % link.href)\n",
    "    \n",
    "    # The journal reference, comments and primary_category sections live under \n",
    "    # the arxiv namespace\n",
    "    try:\n",
    "        journal_ref = entry.arxiv_journal_ref\n",
    "    except AttributeError:\n",
    "        journal_ref = 'No journal ref found'\n",
    "    print ('Journal reference: %s' % journal_ref)\n",
    "    \n",
    "    try:\n",
    "        comment = entry.arxiv_comment\n",
    "    except AttributeError:\n",
    "        comment = 'No comment found'\n",
    "    print ('Comments: %s' % comment)\n",
    "    \n",
    "    # Since the <arxiv:primary_category> element has no data, only\n",
    "    # attributes, feedparser does not store anything inside\n",
    "    # entry.arxiv_primary_category\n",
    "    # This is a dirty hack to get the primary_category, just take the\n",
    "    # first element in entry.tags.  If anyone knows a better way to do\n",
    "    # this, please email the list!\n",
    "    print ('Primary Category: %s' % entry.tags[0]['term'])\n",
    "    \n",
    "    # Lets get all the categories\n",
    "    all_categories = [t['term'] for t in entry.tags]\n",
    "    print ('All Categories: %s' % (', ').join(all_categories))\n",
    "    \n",
    "    # The abstract is in the <summary> element\n",
    "    print ('Abstract: %s' %  entry.summary)\n",
    "    corpusAbstract.append(entry.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/cs/9905014v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/cs/9905014v1',\n",
       "  'updated': '1999-05-21T14:26:07Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=1999, tm_mon=5, tm_mday=21, tm_hour=14, tm_min=26, tm_sec=7, tm_wday=4, tm_yday=141, tm_isdst=0),\n",
       "  'published': '1999-05-21T14:26:07Z',\n",
       "  'published_parsed': time.struct_time(tm_year=1999, tm_mon=5, tm_mday=21, tm_hour=14, tm_min=26, tm_sec=7, tm_wday=4, tm_yday=141, tm_isdst=0),\n",
       "  'title': 'Hierarchical Reinforcement Learning with the MAXQ Value Function\\n  Decomposition',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Hierarchical Reinforcement Learning with the MAXQ Value Function\\n  Decomposition'},\n",
       "  'summary': 'This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.'},\n",
       "  'authors': [{'name': 'Thomas G. Dietterich'}],\n",
       "  'author_detail': {'name': 'Thomas G. Dietterich'},\n",
       "  'author': 'Thomas G. Dietterich',\n",
       "  'arxiv_comment': '63 pages, 15 figures',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/cs/9905014v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/cs/9905014v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'I.2.6',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]},\n",
       " {'id': 'http://arxiv.org/abs/cs/9905015v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/cs/9905015v1',\n",
       "  'updated': '1999-05-21T14:49:39Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=1999, tm_mon=5, tm_mday=21, tm_hour=14, tm_min=49, tm_sec=39, tm_wday=4, tm_yday=141, tm_isdst=0),\n",
       "  'published': '1999-05-21T14:49:39Z',\n",
       "  'published_parsed': time.struct_time(tm_year=1999, tm_mon=5, tm_mday=21, tm_hour=14, tm_min=49, tm_sec=39, tm_wday=4, tm_yday=141, tm_isdst=0),\n",
       "  'title': 'State Abstraction in MAXQ Hierarchical Reinforcement Learning',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'State Abstraction in MAXQ Hierarchical Reinforcement Learning'},\n",
       "  'summary': 'Many researchers have explored methods for hierarchical reinforcement\\nlearning (RL) with temporal abstractions, in which abstract actions are defined\\nthat can perform many primitive actions before terminating. However, little is\\nknown about learning with state abstractions, in which aspects of the state\\nspace are ignored. In previous work, we developed the MAXQ method for\\nhierarchical RL. In this paper, we define five conditions under which state\\nabstraction can be combined with the MAXQ value function decomposition. We\\nprove that the MAXQ-Q learning algorithm converges under these conditions and\\nshow experimentally that state abstraction is important for the successful\\napplication of MAXQ-Q learning.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Many researchers have explored methods for hierarchical reinforcement\\nlearning (RL) with temporal abstractions, in which abstract actions are defined\\nthat can perform many primitive actions before terminating. However, little is\\nknown about learning with state abstractions, in which aspects of the state\\nspace are ignored. In previous work, we developed the MAXQ method for\\nhierarchical RL. In this paper, we define five conditions under which state\\nabstraction can be combined with the MAXQ value function decomposition. We\\nprove that the MAXQ-Q learning algorithm converges under these conditions and\\nshow experimentally that state abstraction is important for the successful\\napplication of MAXQ-Q learning.'},\n",
       "  'authors': [{'name': 'Thomas G. Dietterich'}],\n",
       "  'author_detail': {'name': 'Thomas G. Dietterich'},\n",
       "  'author': 'Thomas G. Dietterich',\n",
       "  'arxiv_comment': '7 pages, 2 figures',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/cs/9905015v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/cs/9905015v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'I.2.6',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]},\n",
       " {'id': 'http://arxiv.org/abs/cs/0001004v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/cs/0001004v1',\n",
       "  'updated': '2000-01-07T06:20:53Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2000, tm_mon=1, tm_mday=7, tm_hour=6, tm_min=20, tm_sec=53, tm_wday=4, tm_yday=7, tm_isdst=0),\n",
       "  'published': '2000-01-07T06:20:53Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2000, tm_mon=1, tm_mday=7, tm_hour=6, tm_min=20, tm_sec=53, tm_wday=4, tm_yday=7, tm_isdst=0),\n",
       "  'title': 'Multiplicative Algorithm for Orthgonal Groups and Independent Component\\n  Analysis',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Multiplicative Algorithm for Orthgonal Groups and Independent Component\\n  Analysis'},\n",
       "  'summary': 'The multiplicative Newton-like method developed by the author et al. is\\nextended to the situation where the dynamics is restricted to the orthogonal\\ngroup. A general framework is constructed without specifying the cost function.\\nThough the restriction to the orthogonal groups makes the problem somewhat\\ncomplicated, an explicit expression for the amount of individual jumps is\\nobtained. This algorithm is exactly second-order-convergent. The global\\ninstability inherent in the Newton method is remedied by a\\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\\napplied to the independent component analysis. Its remarkable performance is\\nillustrated by a numerical simulation.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'The multiplicative Newton-like method developed by the author et al. is\\nextended to the situation where the dynamics is restricted to the orthogonal\\ngroup. A general framework is constructed without specifying the cost function.\\nThough the restriction to the orthogonal groups makes the problem somewhat\\ncomplicated, an explicit expression for the amount of individual jumps is\\nobtained. This algorithm is exactly second-order-convergent. The global\\ninstability inherent in the Newton method is remedied by a\\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\\napplied to the independent component analysis. Its remarkable performance is\\nillustrated by a numerical simulation.'},\n",
       "  'authors': [{'name': 'Toshinao Akuzawa'}],\n",
       "  'author_detail': {'name': 'Toshinao Akuzawa'},\n",
       "  'arxiv_affiliation': 'RIKEN BSI',\n",
       "  'author': 'Toshinao Akuzawa',\n",
       "  'arxiv_comment': '11 pages, 2 figures',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/cs/0001004v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/cs/0001004v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'G.1.6',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]},\n",
       " {'id': 'http://arxiv.org/abs/cs/0002006v1',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/cs/0002006v1',\n",
       "  'updated': '2000-02-09T06:44:28Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2000, tm_mon=2, tm_mday=9, tm_hour=6, tm_min=44, tm_sec=28, tm_wday=2, tm_yday=40, tm_isdst=0),\n",
       "  'published': '2000-02-09T06:44:28Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2000, tm_mon=2, tm_mday=9, tm_hour=6, tm_min=44, tm_sec=28, tm_wday=2, tm_yday=40, tm_isdst=0),\n",
       "  'title': 'Multiplicative Nonholonomic/Newton -like Algorithm',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Multiplicative Nonholonomic/Newton -like Algorithm'},\n",
       "  'summary': 'We construct new algorithms from scratch, which use the fourth order cumulant\\nof stochastic variables for the cost function. The multiplicative updating rule\\nhere constructed is natural from the homogeneous nature of the Lie group and\\nhas numerous merits for the rigorous treatment of the dynamics. As one\\nconsequence, the second order convergence is shown. For the cost function,\\nfunctions invariant under the componentwise scaling are choosen. By identifying\\npoints which can be transformed to each other by the scaling, we assume that\\nthe dynamics is in a coset space. In our method, a point can move toward any\\ndirection in this coset. Thus, no prewhitening is required.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'We construct new algorithms from scratch, which use the fourth order cumulant\\nof stochastic variables for the cost function. The multiplicative updating rule\\nhere constructed is natural from the homogeneous nature of the Lie group and\\nhas numerous merits for the rigorous treatment of the dynamics. As one\\nconsequence, the second order convergence is shown. For the cost function,\\nfunctions invariant under the componentwise scaling are choosen. By identifying\\npoints which can be transformed to each other by the scaling, we assume that\\nthe dynamics is in a coset space. In our method, a point can move toward any\\ndirection in this coset. Thus, no prewhitening is required.'},\n",
       "  'authors': [{'name': 'Toshinao Akuzawa'}, {'name': 'Noboru Murata'}],\n",
       "  'author_detail': {'name': 'Noboru Murata'},\n",
       "  'arxiv_affiliation': 'RIKEN BSI',\n",
       "  'author': 'Noboru Murata',\n",
       "  'arxiv_doi': '10.1016/S0960-0779(00)00077-1',\n",
       "  'links': [{'title': 'doi',\n",
       "    'href': 'http://dx.doi.org/10.1016/S0960-0779(00)00077-1',\n",
       "    'rel': 'related',\n",
       "    'type': 'text/html'},\n",
       "   {'href': 'http://arxiv.org/abs/cs/0002006v1',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/cs/0002006v1',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_comment': '12 pages',\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'G.1.6',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]},\n",
       " {'id': 'http://arxiv.org/abs/cs/0009001v3',\n",
       "  'guidislink': True,\n",
       "  'link': 'http://arxiv.org/abs/cs/0009001v3',\n",
       "  'updated': '2002-02-26T01:51:09Z',\n",
       "  'updated_parsed': time.struct_time(tm_year=2002, tm_mon=2, tm_mday=26, tm_hour=1, tm_min=51, tm_sec=9, tm_wday=1, tm_yday=57, tm_isdst=0),\n",
       "  'published': '2000-09-05T18:54:58Z',\n",
       "  'published_parsed': time.struct_time(tm_year=2000, tm_mon=9, tm_mday=5, tm_hour=18, tm_min=54, tm_sec=58, tm_wday=1, tm_yday=249, tm_isdst=0),\n",
       "  'title': 'Complexity analysis for algorithmically simple strings',\n",
       "  'title_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Complexity analysis for algorithmically simple strings'},\n",
       "  'summary': 'Given a reference computer, Kolmogorov complexity is a well defined function\\non all binary strings. In the standard approach, however, only the asymptotic\\nproperties of such functions are considered because they do not depend on the\\nreference computer. We argue that this approach can be more useful if it is\\nrefined to include an important practical case of simple binary strings.\\nKolmogorov complexity calculus may be developed for this case if we restrict\\nthe class of available reference computers. The interesting problem is to\\ndefine a class of computers which is restricted in a {\\\\it natural} way modeling\\nthe real-life situation where only a limited class of computers is physically\\navailable to us. We give an example of what such a natural restriction might\\nlook like mathematically, and show that under such restrictions some error\\nterms, even logarithmic in complexity, can disappear from the standard\\ncomplexity calculus.\\n  Keywords: Kolmogorov complexity; Algorithmic information theory.',\n",
       "  'summary_detail': {'type': 'text/plain',\n",
       "   'language': None,\n",
       "   'base': '',\n",
       "   'value': 'Given a reference computer, Kolmogorov complexity is a well defined function\\non all binary strings. In the standard approach, however, only the asymptotic\\nproperties of such functions are considered because they do not depend on the\\nreference computer. We argue that this approach can be more useful if it is\\nrefined to include an important practical case of simple binary strings.\\nKolmogorov complexity calculus may be developed for this case if we restrict\\nthe class of available reference computers. The interesting problem is to\\ndefine a class of computers which is restricted in a {\\\\it natural} way modeling\\nthe real-life situation where only a limited class of computers is physically\\navailable to us. We give an example of what such a natural restriction might\\nlook like mathematically, and show that under such restrictions some error\\nterms, even logarithmic in complexity, can disappear from the standard\\ncomplexity calculus.\\n  Keywords: Kolmogorov complexity; Algorithmic information theory.'},\n",
       "  'authors': [{'name': 'Andrei N. Soklakov'}],\n",
       "  'author_detail': {'name': 'Andrei N. Soklakov'},\n",
       "  'arxiv_affiliation': 'Royal Holloway, University of London',\n",
       "  'author': 'Andrei N. Soklakov',\n",
       "  'arxiv_comment': '10 pages',\n",
       "  'links': [{'href': 'http://arxiv.org/abs/cs/0009001v3',\n",
       "    'rel': 'alternate',\n",
       "    'type': 'text/html'},\n",
       "   {'title': 'pdf',\n",
       "    'href': 'http://arxiv.org/pdf/cs/0009001v3',\n",
       "    'rel': 'related',\n",
       "    'type': 'application/pdf'}],\n",
       "  'arxiv_primary_category': {'term': 'cs.LG',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom'},\n",
       "  'tags': [{'term': 'cs.LG',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None},\n",
       "   {'term': 'E.4; F.2; I.2',\n",
       "    'scheme': 'http://arxiv.org/schemas/atom',\n",
       "    'label': None}]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusEntry #This is the full entry, can access id, link, when updated etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pdf_url': 'http://arxiv.org/pdf/cs/9905014v1'},\n",
       " {'pdf_url': 'http://arxiv.org/pdf/cs/9905015v1'},\n",
       " {'pdf_url': 'http://arxiv.org/pdf/cs/0001004v1'},\n",
       " {'pdf_url': 'http://arxiv.org/pdf/cs/0002006v1'},\n",
       " {'pdf_url': 'http://arxiv.org/pdf/cs/0009001v3'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusPDF #This is the forced PDF link as a pdf_url item for the download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://arxiv.org/pdf/cs/9905015v1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusPDF[1]['pdf_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Al\\\\Documents\\\\ByteSizeArxiv\\\\library/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = r'C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Override the default filename format by defining a slugify function. So can force pdf link for all even without listed\n",
    "activePDF = arxiv.download(corpusPDF[0],library, slugify=lambda x: corpusEntry[0].get('id').split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Al\\\\Documents\\\\ByteSizeArxiv\\\\library/9905014v1.pdf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activePDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "activePDF = 'C:\\\\Users\\\\Al\\\\Documents\\\\ByteSizeArxiv\\\\library/0608033v1.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs/9905014v1\n",
      "\n",
      "/cs/9905015v1\n"
     ]
    }
   ],
   "source": [
    "with open(r'C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library/library.txt') as f:\n",
    "   for line in f:\n",
    "       # For Python3, use print(line)\n",
    "       print (line[-13:])\n",
    "       if 'str' in line:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryDir = 'C:\\\\Users\\\\Al\\\\Documents\\\\ByteSizeArxiv\\\\library/'\n",
    "pdf = libraryDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=pdfminer.high_level.extract_text(activePDF, codec='utf-8', laparams=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusAbstract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE\\n\\nA Study on Learnability for Rigid Lambek Grammars\\n\\n6\\n0\\n0\\n2\\n \\ng\\nu\\nA\\n \\n6\\n \\n \\n]\\n\\nG\\nL\\n.\\ns\\nc\\n[\\n \\n \\n1\\nv\\n3\\n3\\n0\\n8\\n0\\n6\\n0\\n/\\ns\\nc\\n:\\nv\\ni\\nX\\nr\\na\\n\\n9\\n9\\n3\\n6\\n-\\n9\\n4\\n2\\n0\\n \\nN\\nS\\n\\nS\\n\\nI\\n\\nRoberto Bonato\\n\\nN° ????\\n\\nJuin 2006\\n\\nThème SYM\\n\\na p p o r t  (cid:13)\\n(cid:13) d e  r e c h e r c h e (cid:13)\\n\\n\\x0c\\x0cA Study on Learnability for Rigid Lambek Grammars\\n\\nRoberto Bonato\\n\\nThème SYM (cid:22) Systèmes symboliques\\n\\nPro jet SIGNES\\n\\nRapport de re\\rher\\rhe n° ???? (cid:22) Juin 2006 (cid:22) 83 pages\\n\\nAbstra\\rt: We present basi\\r notions of Gold\\'s learnability in the limit paradigm, (cid:28)rst pre-\\n\\nsented in 1967, a formalization of the \\rognitive pro\\ress by whi\\rh a native speaker gets to\\n\\ngrasp the underlying grammar of his/her own native language by being exposed to well\\n\\nformed senten\\res generated by that grammar. Then we present Lambek grammars, a for-\\n\\nmalism issued from \\rategorial grammars whi\\rh, although not as expressive as needed for\\n\\na full formalization of natural languages, is parti\\rularly suited to easily implement a nat-\\n\\nural interfa\\re between syntax and semanti\\rs. In hte last part of this work, we present a\\n\\nlearnability result for Rigid Lambek grammars from stru\\rtured examples.\\n\\nKey-words: Formal Learning Theory, ma\\rhine learning, Lambek \\ral\\rulus, \\romputational\\n\\nlinguisti\\rs, formal grammars\\n\\nUnité de recherche INRIA Futurs\\nParc Club Orsay Université, ZAC des Vignes,\\n4, rue Jacques Monod, 91893 ORSAY Cedex (France)\\n\\nTéléphone : +33 1 72 92 59 00 — Télécopie : +33 1 72 92 59 ??\\n\\n\\x0cUne étude sur l\\'apprenabilité\\n\\ndes Grammaires de Lambek Rigides\\n\\nRésumé : On présente les notions basiques du paradigme d\\'apprenabilité à la limite pour\\n\\nune \\rlasse de grammaires formelles de(cid:28)ni par Gold en 1967, \\romme possible formalisation\\n\\ndu pro\\ressus \\rognitif qui permet l\\'apprentissage d\\'une langue naturelle à partir d\\'exemples\\n\\nd\\'énon\\rés bien formés. Ensuite, nous presentons les grammaires de Lambek, un formalisme\\n\\nissu des grammaires \\ratégorielles que, bien que en\\rore insu(cid:30)sant à rendre \\rompte de nombre\\n\\nde phenomenes linguistiques, a des qualités intéréssantes par rapport à l\\'interfa\\re syntaxe-\\n\\nsémantique. En(cid:28)n, nous présentons un résultat d\\'apprenabilité pour les grammaires de\\n\\nLambek Rigides dans le modèle d\\'apprentissage de Gold à partir d\\'exemples stru\\rturés.\\n\\nMots-\\rlés : Théorie formelle de l\\'apprentissage, apprentissage automatique, \\ral\\rul de\\n\\nLambek, linguistique \\romputationnelle, grammaires formelles\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n3\\n\\n1 Introdu\\rtion\\n\\nHow \\romes it that human beings, whose \\ronta\\rts with the world are brief and\\n\\npersonal and limited, are nevertheless able to know as mu\\rh as they do know?\\n\\nSir Bertrand Russell (\\ritato da Noam Chomsky in [Cho75℄).\\n\\nFormal Learning Theory was (cid:28)rst de(cid:28)ned in an arti\\rle by E. M. Gold in 1967 (see [Gol67℄)\\n\\nas a (cid:28)rst e(cid:27)ort to provide a rigurous formalization of grammati\\ral inferen\\re, that is the\\n\\npro\\ress by whi\\rh a learner, presented with a \\rertain given subset of well-formed senten\\res of\\n\\na given language, gets to infer the grammar that generates it. The typi\\ral example of su\\rh\\n\\na pro\\ress is given by a \\rhild whi gets to master, in a \\rompletely spontaneous way and on\\n\\nthe basis of the relatively small amount of information provided by senten\\res uttered in its\\n\\n\\rultural environment, the higly \\romplex and subtle rules of her mother tongue, to the point\\n\\nthat she \\ran utter \\rorre\\rt and original senten\\res before her third year of life. In [OWdJM97℄\\n\\nsu\\rh a formal framework is used in the broder \\rontext of the mathemati\\ral formalization of\\n\\nany kind of indu\\rtive reasoning. In this \\rase the learner is (cid:16)the s\\rientist(cid:17) who, on the basis\\n\\nof (cid:28)nite amount of empiri\\ral eviden\\res provided by natural phenomena, formulates s\\rienti(cid:28)\\r\\n\\nhypotheses would \\rould intensionally a\\r\\runt for them.\\n\\nAfter an initial skepti\\rism about the grammars that \\rould be a\\rtually learnt in Gold\\'s\\n\\nparadigm (a skepti\\rism shared and in a way enouraged by Gold himself, who proves the non-\\n\\nlearnability in its model of the four \\rlasses of grammars of Chomsky\\'s hierar\\rhy), re\\rently\\n\\nthere has been a renewal of interest toward this \\romputational model of learning. One of\\n\\nthe most re\\rent results is Shinohara\\'s (see [Shi90℄), who proves that as soon as we bound\\n\\nthe number of rules in a \\rontext-sensitive grammar, it be\\romes learnable in Gold\\'s paradigm.\\n\\nLambek Grammars have re\\rently known a renewed interest as a mathemati\\ral tool for\\n\\nthe des\\rription of \\rertain linguisti\\rs phenomena, after having being long negle\\rted after\\n\\ntheir (cid:28)rst de(cid:28)nition in [Lam58℄. Van Benthem was among the (cid:28)rst who stressed the singu-\\n\\nlar \\rorresponden\\re between Montague Semanti\\rs (see [Mon97℄) and the notion of stru\\rture\\n\\nasso\\riated to a senten\\re of a Lambek grammar. In parti\\rular, a re\\rent work by Hans-Jorg\\n\\nTiede (see [Tie99℄) has made \\rlearer the notion of stru\\rture of a senten\\re in a Lambek gram-\\n\\nmar, in \\rontrast with a previsous de(cid:28)nition given by Buszkowski (see [Bus86℄). In doing\\n\\nso, he gets to prove a meaningful result about Lambek Grammars, that is that the \\rlass of\\n\\ntree languages generated by Lambek grammars stri\\rtly \\rontains the \\rlass of tree languages\\n\\ngenerated by \\rontext-free grammars.\\n\\nSe\\rtion 2 introdu\\res the basi\\r notions of Learning Theory by Gold and provides a short\\n\\nreview of most important known fa\\rt and results about it. Se\\rtion 3 is a short introdu\\rtion\\n\\nfo Lambek Grammars: we give their de(cid:28)nition and we present the features whi\\rh make them\\n\\nattra\\rtive from a \\romputational linguisti\\rs point of view. Se\\rtion 4 brie(cid:29)y presents the \\rlass\\n\\nof rigid Lambek Grammars, whi\\rh is the ob je\\rt of our lerning algorithm, along with some\\n\\nbasi\\r properties and open questions. In Se\\rtion 5 we present a learning algorithm for rigid\\n\\nRR n° 0123456789\\n\\n\\x0c4\\n\\nBonato\\n\\nLambek grammars from a stru\\rtured input: the algorithm takes as its input a (cid:28)nite set of\\n\\nwhat has been de(cid:28)ned in \\rhapter 3 as proof tree stru\\rtures. It is proved \\ronvergen\\re for the\\n\\nalgorithm and so the lernability for the \\rlass of rigid Lambek grammars.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n5\\n\\n2 Grammati\\ral Inferen\\re\\n\\n2.1 Child\\'s First Language A\\rquisition\\n\\nOne of the most \\rhallenging goals for modern \\rognitive s\\rien\\res is providing a sound theory\\n\\na\\r\\rounting for the pro\\ress by whi\\rh any human being gets to master the highly \\romplex\\n\\nand arti\\rulated grammati\\ral stru\\rture of her mother tongue in a relatively small amount of\\n\\ntime. Between the age of 3 and 5 we witness in \\rhildren a linguisti\\r explosion, at the end\\n\\nof whi\\rh we \\ran say that the \\rhild masters all the grammati\\ral rules of her mother tongue,\\n\\nand subsequent learning is not but lexi\\ron a\\rquisition. Moreover, \\rognitive psy\\rhologists\\n\\nagree (see [OGL95℄) in stating that the learning pro\\ress is almost \\rompletely based on\\n\\npositive eviden\\re provided by the \\rultural environment wherein the \\rhild is grown up: that\\n\\nis, \\rorre\\rt statements belonging to her mother tongue. Negative eviden\\re (any information\\n\\nor feedba\\rk given to the \\rhild to identify not-well-formed senten\\res), is almost \\rompletely\\n\\nabsent and, in any \\rase, doesn\\'t seem to play any signi(cid:28)\\rant role in the pro\\ress of learning\\n\\n(see [Pin94℄). Simply stated, the \\rhild a\\rquires a language due to the exposition to \\rorre\\rt\\n\\nsenten\\res \\roming from her linguisti\\r environment and not to the negative feedba\\rk she gets\\n\\nwhen she utters a wrong senten\\re.\\n\\nProviding a formal framework wherein to ins\\rribe su\\rh an astounding ability to extra\\rt\\n\\nhighly arti\\rulated knowledge (i.e. the grammar of a human language) from a relatively small\\n\\namount of (cid:16)raw(cid:17) data (i.e. the statements of the language the \\rhild is exposed to during\\n\\nher early \\rhildhood) was one of the ma jor for\\res that led to the the de(cid:28)nition of a formal\\n\\nlearning theory as the one we are going to des\\rribe in the following se\\rtions.\\n\\n2.2 Gold\\'s Model\\n\\nThe pro\\ress of a \\rhild\\'s (cid:28)rst language a\\rquisition \\ran be seen as an instan\\re of the more\\n\\ngeneral problem of grammati\\ral inferen\\re.\\n\\nIn parti\\rular we will restri\\rt our attention to\\n\\nthe pro\\ress of inferen\\re from positive data only. Simply stated, it\\'s the pro\\ress by whi\\rh a\\n\\nlearner \\ran a\\rquire the whole grammati\\ral stru\\rture of a formal language on the basis of\\n\\nwell-formed senten\\res belonging to the target language.\\n\\nIn 1967 Gold de(cid:28)ned (see [Gol67℄) the formal model for the pro\\ress of grammati\\ral\\n\\ninferen\\re from positive data that will be adopted in the present work. In Gold\\'s model,\\n\\ngrammati\\ral inferen\\re is \\ron\\reived as an in(cid:28)nite pro\\ress during whi\\rh a learner is presented\\n\\nwith an in(cid:28)nite stream of senten\\res s0, s1, . . . , sn . . ., belonging to language whi\\rh has to be\\nlearnt, one senten\\re at a time. Ea\\rh time the learner is presented with a new senten\\re si ,\\nshe formulates a new hypothesis Gi on the nature of the underlying grammar that \\rould\\n\\ngenerate the language the senten\\res she has seen so far belong to: sin\\re she is exposed to\\n\\nan in(cid:28)nite number of senten\\res, she will \\ronje\\rture an in(cid:28)nite number of (not ne\\ressarily\\n\\ndi(cid:27)erent) grammars G0, G1, . . . , Gn . . ..\\n\\nRR n° 0123456789\\n\\n\\x0c6\\n\\nBonato\\n\\ns0\\n\\n, s1\\n\\n, . . . , sn\\n\\n, . . .\\n\\nG0\\n|{z}\\nG1\\n| {z }\\nGn\\n\\n|\\n\\n|\\n\\n.\\n\\n{z\\n\\n.\\n\\n.\\n\\n}\\n\\nG\\n{z\\n\\n}\\n\\nTwo basi\\r assumptions are made about the stream of senten\\res she is presented with:\\n\\n(i) only grammati\\ral senten\\res (i.e. belonging to the target language) appear in the stream,\\n\\n\\roherently with our \\rommitment to the pro\\ress of grammar indu\\rtion from positive data\\n\\nonly; (ii) every possible senten\\re of the language must appear in the stream (whi\\rh must be\\n\\ntherefore an enumeration of the elements of the language).\\n\\nThe learning pro\\ress is \\ronsidered su\\r\\ressful when, from a given point onward, the gram-\\n\\nmar \\ronje\\rtured by the learner doesn\\'t \\rhange anymore and it \\roin\\rides with the grammar\\n\\nthat a\\rtually generates the target language.\\n\\nIt is important to stress the fa\\rt that one\\n\\n\\ran never know at any (cid:28)nite stage whether the learning has been su\\r\\ressful or not due to\\n\\nthe in(cid:28)nite nature of the learning pro\\ress itself: at ea\\rh (cid:28)nite stage, no one \\ran predi\\rt\\n\\nwhether next senten\\re will \\rhange or not the \\rurrent hypothesis. The goal of the theory\\n\\nlies in devising a su\\r\\ressful strategy for making guesses, that is, one whi\\rh \\ran be proved to\\n\\n\\ronverge to the \\rorre\\rt grammar after a (cid:28)nite (but unknown) amount of time (or positive\\n\\neviden\\re, whi\\rh is the same in our model). Gold \\ralled this \\rriterion of su\\r\\ressful learning\\n\\nidenti(cid:28)\\ration in the limit.\\n\\nA\\r\\rording to this \\rriterion, a \\rlass of grammars is said to be learnable when, for any\\n\\nlanguage generated by a grammar belonging to the \\rlass, and for any enumeration of its\\n\\nsenten\\res, there is a learner that su\\r\\ressfully identi(cid:28)es the \\rorre\\rt grammar that generates\\n\\nthe language. A good deal of \\rurrent resear\\rh on formal learning theory is devoted to\\n\\nidentifying non-trivial \\rlasses of languages whi\\rh are learnable in Gold\\'s model or useful\\n\\n\\rriterions to dedu\\re (un)learnability for a \\rlass of languages on the basis of some stru\\rtural\\n\\nproperty of the language.\\n\\nAs it will be made \\rlear in the following se\\rtions, a\\r\\repting this \\rriterion for su\\r\\ressful\\n\\nlearning means that we are not interested in when the learning has taken pla\\re: in fa\\rt there\\'s\\n\\nno e(cid:27)e\\rtive way to de\\ride if it has or not at any (cid:28)nite stage. Our aim is to devise e(cid:27)e\\rtive\\n\\npro\\redures su\\rh that, if applied to the in(cid:28)nite input stream of senten\\res, are guaranteed to\\n\\n\\ronverge to the grammar we are looking for, if it exists.\\n\\n3 Basi\\r Notions\\n\\nWe present here a short review of (Formal) Learning Theory as des\\rribed in [Kan98℄, when\\re\\n\\nwe take the prin\\ripal de(cid:28)nitions and notation \\ronventions.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n7\\n\\n3.1 Grammar Systems\\n\\nThe (cid:28)st step in the formalization of the learning pro\\ress is the formal de(cid:28)nition of both\\n\\nthe (cid:16)\\rultural environment(cid:17) wherein this pro\\ress takes pla\\re and the (cid:16)positive eviden\\res(cid:17) the\\n\\nlearner is exposed to. To do this, we introdu\\re the notion of grammar system.\\n\\nDe(cid:28)nition 3.1 (Grammar System) A grammar system is a triple hΩ, S, Li, where\\n\\nˆ Ω is a \\rertain re\\rursive set of (cid:28)nitary obje\\rts on whi\\rh me\\rhani\\ral \\romputations \\ran\\n\\nbe \\rarried out;\\n\\nˆ S is a \\rertain re\\rursive subset of Σ∗\\n\\n, where Σ is a given (cid:28)nite alphabet;\\n\\nˆ L is a fun\\rtion that maps elements of Ω to subsets of S , i.e. L : Ω → ℘(S).\\n\\nWe \\ran think of Ω as the (cid:16)hypothesis spa\\re(cid:17), when\\re the learner takes her grammati\\ral\\n\\n\\ronje\\rtures, a\\r\\rording to the positive examples she has been exposed to up to a \\rertain (cid:28)nite\\n\\nstage of the learning pro\\ress. Elements of Ω are \\ralled grammars.\\n\\nPositive examples presented to the learner belong to the set S (often we simply have\\n\\nS = Σ∗\\nbe made \\rlear in the following se\\rtions, the nature of elements in S strongly in(cid:29)uen\\res the\\n\\n); its elements are \\ralled senten\\res, while its subsets are \\ralled languages. As it will\\n\\npro\\ress of learning: intuitively, we \\ran guess that the more information they bear, the easier\\n\\nthe learning pro\\ress is, if it is possible at all.\\n\\nThe fun\\rtion L maps ea\\rh grammar G belonging to Ω into a subset of S whi\\rh is desig-\\nnated as the language generated by G. That\\'s why we often refer to L as the naming fun\\rtion.\\nThe question of whether s ∈ L(G) holds between any s ∈ S and G ∈ Ω is addressed to as\\n\\nthe universal membership problem.\\n\\nExample 3.2 Let Σ be any (cid:28)nite alphabet and let DF A be the set of deterministi\\r (cid:28)nite\\nautomata whose input alphabet is Σ. For every M ∈ DF A, let L(M ) be the set of strings\\nover Σ a\\r\\repted by M . Then hDF A, Σ∗, Li is a grammar system.\\n\\nExample 3.3 Let Σ be any (cid:28)nite alphabet and let RegExpr be the set of regular expressions\\nover Σ. For every r ∈ RegExpr, let L(r) be the regular language represented by r. Then\\nhRegExpr, Σ∗, Li is a grammar system.\\n\\nExample 3.4 (Angluin, 1980) Let Σ any (cid:28)nite alphabet, and let V ar be a \\rountably in-\\n(cid:28)nite set of variables, disjoint from Σ. A pattern over Σ is any element of (Σ ∪ V ar)+\\nP at be the set of patterns over Σ. For every p ∈ P at, let L(p) be the set of strings that\\n\\ran be obtained from p by uniformly repla\\ring ea\\rh variable x o\\r\\rurring in p by some string\\nw ∈ Σ+\\n\\n. The triple hP at, Σ+, Li is a grammar system.\\n\\n: let\\n\\nRR n° 0123456789\\n\\n\\x0c8\\n\\nBonato\\n\\nΩ\\n\\nG\\n\\nG\\n\\nφ (l  )\\n1\\n\\nφ (l  )\\n2\\n\\nφ (l  )\\nn\\n\\nS\\n\\nL(G)\\n\\nl1\\n\\nl 2\\n\\nl n\\n\\nFigure 1: Grammati\\ral Inferen\\re\\n\\n3.2 Learning Fun\\rtions, Convergen\\re, Learnability\\n\\nOn\\re formally de(cid:28)ned both the set of possible (cid:16)guesses(cid:17) the learner \\ran make and the set\\n\\nof the positive examples she is exposed to, we need a formal notion for the me\\rhanism by\\n\\nwhi\\rh the learner formulates hypotheses, on the basis (cid:28)nite sets of well-formed senten\\res of\\n\\na given language, about the grammar that generates them.\\n\\nDe(cid:28)nition 3.5 (Learning Fun\\rtion) Let hΩ, S, Li be a grammar system. A learning\\n\\nfun\\rtion is a partial fun\\rtion that maps (cid:28)nite sets of senten\\res to grammars,\\n\\nϕ :\\n\\nSk ⇀ Ω\\n\\n[k≥1\\n\\nwhere Sk\\n\\ndenotes the set of k-ary sequen\\res of senten\\res.\\n\\nA learning fun\\rtion \\ran be seen as a formal model of the \\rognitive pro\\ress by whi\\rh a learner\\n\\n\\ronje\\rtures that a given (cid:28)nite set of senten\\res belongs to the language generated by a \\rertain\\n\\ngrammar. Sin\\re it\\'s partial, possibly the learner \\rannot infer any grammar from the stream\\n\\nof senten\\res she has seen so far.\\n\\nA\\r\\rording to the informal model outlined in se\\rtion 2.2, in a su\\r\\ressful learning pro\\ress,\\n\\nwe require the guesses made by the learner to remain the same from a \\rertain point onward\\n\\nin the in(cid:28)nite pro\\ress of learning. That is to say, there must be a (cid:28)nite stage (even if we\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n9\\n\\ndon\\'t know whi\\rh one) after whi\\rh the grammar inferred on the basis of all the positive\\n\\nexamples the learner has seen so far is always the same. This informal idea \\ran be made\\n\\npre\\rise by introdu\\ring the notion of \\ronvergen\\re for a learning fun\\rtion:\\n\\nDe(cid:28)nition 3.6 (Convergen\\re) Let hΩ, S, Li be a grammar system, ϕ a learning fun\\rtion,\\n\\nan in(cid:28)nite sequen\\re of senten\\res belonging to S , and let\\n\\nhsiii∈N = hs0, s1, . . .i\\n\\nGi = ϕ(hs0, . . . , sii)\\n\\nfor any i ∈ N su\\rh that ϕ is de(cid:28)ned on the (cid:28)nite sequen\\re hs0, . . . , sii. ϕ is said to \\ronverge\\nto G on hsiii∈N if there exists n ∈ N su\\rh that, for ea\\rh i ≥ n, Gi is de(cid:28)ned and Gi = G\\n(equivalently, if Gi = G for al l but (cid:28)nitely many i ∈ N).\\n\\nAs we\\'ve already pointed out, one \\ran never say exa\\rtly if and when \\ronvergen\\re of a\\n\\nlearning fun\\rtion to a \\rertain grammar has taken pla\\re: this is due to the in(cid:28)nite nature of\\n\\nthe pro\\ress by whi\\rh a learner gets to learn a given language in Gold\\'s model. At any (cid:28)nite\\n\\nstage of the learning pro\\ress there\\'s no way to know whether the next senten\\re the learner\\n\\nwill see \\rauses the \\rurrent hypothesis to \\rhange or not.\\n\\nWe will say that a \\rlass of grammars is learnable when for ea\\rh language generated\\n\\nby its grammars there exists a learning fun\\rtion whi\\rh \\ronverges to the \\rorre\\rt underlying\\n\\ngrammar on the basis of any enumeration of the senten\\res of the language. Formally:\\n\\nDe(cid:28)nition 3.7 (Learning G ) Let hΩ, S, Li be a grammar system, and G ⊆ Ω a given set\\nof grammars. The learning fun\\rtion ϕ is said to learn G if the fol lowing \\rondition holds:\\n\\nˆ for every language L ∈ L(G) = {L(G) | G ∈ G},\\n\\nˆ and for every in(cid:28)nite sequen\\re hsiii∈N that enumerates L (i.e., {si | i ∈ N} = L)\\n\\nthere exists a G ∈ G su\\rh that L(G) = L, su\\rh that ϕ \\ronverges to G on hsiii∈N .\\n\\nSo we will say that a given learning fun\\rtion \\ronverges to a single grammar, but that it\\n\\nlearns a \\rlass of grammars. The learning for a single grammar, indeed, \\rould be trivially\\n\\nimplemented by a learning fun\\rtion that, for any given sequen\\re of senten\\res as input, always\\n\\nreturns that grammar.\\n\\nDe(cid:28)nition 3.8 (Learnability of a Class of Grammars) A \\rlass G of grammars is \\ral led\\nlearnable if and only if there exists a learning fun\\rtion that learns G . It is \\ral led e(cid:27)e\\rtively\\nlearnable if and only if there is a \\romputable learning fun\\rtion that learns G .\\n\\nObviously e(cid:27)e\\rtive learnability implies learnability.\\n\\nRR n° 0123456789\\n\\n\\x0c10\\n\\nBonato\\n\\nExample 3.9 Let hΩ, S, Li be any grammar system and let G = {G0, G1, G2} ⊆ Ω and\\nsuppose there are elements w1, w2 ∈ S su\\rh that w1 ∈ L(G1) − L(G0) and w2 ∈ L(G2) −\\n(L(G1) ∪ L(G0)). Then it\\'s easy to verify that the fol lowing learning fun\\rtion learns G :\\n\\nϕ(hs0, . . . , sii) = \\uf8f1\\n\\uf8f2\\n\\notherwise.\\n\\nif w2 ∈ {s0, . . . , si},\\nif w1 ∈ {s0, . . . , si} and w2 6∈ {s0, . . . , si},\\n\\nG2\\nG1\\nG0\\n\\n\\uf8f3\\n\\nExample 3.10 Let\\'s \\ronsider the grammar system hCF G, Σ∗, Li of \\rontext-free grammars\\nover the alphabet Σ. Let G be the sub\\rlass of CF G \\ronsisting of grammars whose rules are\\n\\nal l of the form\\n\\nS → w,\\n\\nwhere w ∈ Σ∗\\nLet\\'s de(cid:28)ne the learning fun\\rtion ϕ as\\n\\n. We \\ran easily see that L(G) is exa\\rtly the \\rlass of (cid:28)nite languages over Σ.\\n\\nϕ(hs0, . . . , sii) = hΣ, {S}, S, P i,\\n\\nP = {S → s0, . . . , S → si}.\\n\\nwhere\\n\\nThen ϕ learns G .\\n\\n3.3 Stru\\rtural Conditions for (Un)Learnability\\n\\nOne of the (cid:28)rst important results in learnability theory presented in [Gol67℄ was a su(cid:30)\\rient\\n\\n\\rondition to dedu\\re the unlearnability of a \\rlass G of grammars on the basis of some formal\\nproperties of the \\rlass of languages L = L(G) (see theorem 3.14). We present here some\\n\\nstru\\rtural \\ronditions su(cid:30)\\rient to dedu\\re (un)learnability for a \\rlass of grammars. Su\\rh\\n\\nresults are useful to get a deeper understanding to the general problem of learnability for a\\n\\n\\rlass of grammars.\\n\\n3.3.1 Existen\\re of a Limit Point\\n\\nLet\\'s de(cid:28)ne the notion of limit point for a \\rlass of languages:\\n\\nDe(cid:28)nition 3.11 (Limit Point) A \\rlass L of languages has a limit point if there exists an\\nin(cid:28)nite sequen\\re hLnin∈N of languages in L su\\rh that\\n\\nand there exists another language L ∈ L su\\rh that\\n\\nL0 ⊂ L1 ⊂ · · · ⊂ Ln ⊂ · · ·\\n\\nThe language L is \\ral led limit point of L.\\n\\nL =\\n\\nLn\\n\\n[n∈N\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n11\\n\\nL0\\n\\nL1\\n\\nL2\\n\\nLn\\n\\nL\\n\\nFigure 2: A limit point for a \\rlass of languages.\\n\\nLemma 3.12 (Blum and Blum\\'s lo\\rking sequen\\re lemma, 1975)\\n\\nSuppose that a learning fun\\rtion ϕ \\ronverges on every in(cid:28)nite sequen\\re that enumerates a\\nlanguage L. Then there is a (cid:28)nite sequen\\re hw0, . . . , wli (\\ral led a lo\\rking sequen\\re for ϕ\\n\\nand L) with the fol lowing properties:\\n\\n(i) {w0, . . . , wl} ⊆ L,\\n\\n(ii) for every (cid:28)nite sequen\\re hv0, . . . , vmi, if {v0, . . . , vm} ⊆ L, then ϕ(hw0, . . . , wli) =\\n\\nϕ(hw0, . . . , wl, v0, . . . , vmi).\\n\\nIntuitively enough, the previous lemma (see [BB75℄) states that if a learning fun\\rtion \\ron-\\n\\nverges, then there must exist a (cid:28)nite subsequen\\re of input senten\\res that (cid:16)lo\\rks(cid:17) the guess\\n\\nmade by the learner on the grammar the learning fun\\rtion \\ronverges to: that is to say,\\n\\nthe learning fun\\rtion returns always the same grammar for any input stream of senten\\res\\n\\n\\rontaining that (cid:28)nite sequen\\re.\\n\\nlearnability framework:\\n\\nThe lo\\rking sequen\\re lemma proves one of the (cid:28)rst unlearnability \\rriterions in Gold\\'s\\n\\nTheorem 3.13 If L(G) has a limit point, then G is not learnable.\\n\\nAn easy \\ronsequen\\re of the previous theorem is the following\\n\\nTheorem 3.14 (Gold, 1967) For any grammar system, a \\rlass G of grammars is not\\nlearnable if L(G) \\rontains al l (cid:28)nite languages and at least one in(cid:28)nite language.\\n\\n∞\\nProof sket\\rh. Let L1 ⊂ L2 ⊂ . . . be a sequen\\re of (cid:28)nite languages and let L∞ =\\ni=1 Li .\\nSuppose there were a learning fun\\rtion ϕ that learns the \\rlass {L | L is (cid:28)nite}∪{L∞}. Then\\nϕ must identify any (cid:28)nite language in a (cid:28)nite amount of time. But then we \\ran build an\\nin(cid:28)nite sequen\\re of senten\\res that for\\res ϕ to make an in(cid:28)nite number of mistakes: we (cid:28)rst\\npresent ϕ with enough examples from L1 to make it guess L1 ; then with enough examples\\nfrom L2 to make it guess L2 , and so on. Note that all our examples belong to L∞ .\\n\\nS\\n\\nRR n° 0123456789\\n\\n\\x0c12\\n\\nBonato\\n\\n3.3.2 (In)Finite Elasti\\rity\\n\\nAs we\\'ve seen in the previous se\\rtion, the existen\\re of a limit point for a \\rlass of languages\\n\\nimplies the existen\\re of an (cid:16)in(cid:28)nite as\\rending \\rhain(cid:17) of languages like the one des\\rribed by\\n\\nthe following, weaker \\rondition:\\n\\nDe(cid:28)nition 3.15 (In(cid:28)nite Elasti\\rity) A \\rlass L of languages is said to have in(cid:28)nite elas-\\nti\\rity if there exists an in(cid:28)nite sequen\\re hsnin∈N of senten\\res and an in(cid:28)nite sequen\\re\\nhLnin∈N of languages su\\rh that for every n ∈ N,\\n\\nand\\n\\nsn /∈ Ln,\\n\\n{s0, . . . , sn} ⊆ Ln+1.\\n\\nThe following de(cid:28)nition, although trivial, identi(cid:28)es an extremely useful \\rriterion to dedu\\re\\n\\nlearnability for a \\rlass of grammars:\\n\\nDe(cid:28)nition 3.16 (Finite Elasti\\rity) A \\rlass L of languages is said to have (cid:28)nite elasti\\rity\\n\\nif it doesn\\'t have in(cid:28)nite elasti\\rity.\\n\\nDana Angluin proposed in [Ang80℄ a \\rhara\\rterization of the notion of learnability in\\n\\na (cid:16)restri\\rtive setting(cid:17) whi\\rh is of paramount importan\\re in formal learning theory. Su\\rh\\n\\nrestri\\rtions are about the membership problem and the re\\rursive enumerability for the \\rlass\\n\\nof grammars whose learnability is at issue. Let hΩ, S, Li be a grammar system and G ⊆ Ω\\n\\na \\rlass of grammars, let\\'s de(cid:28)ne:\\n\\nCondition 3.17 There is an algorithm that, given s ∈ S and G ∈ G , determines whether\\ns ∈ L(G).\\n\\nCondition 3.18 G is a re\\rursively enumerable \\rlass of grammars.\\n\\nCondition 3.17 is usually referred to as de\\ridability for the universal membership problem,\\n\\nand \\rondition 3.18 as the re\\rursive enumerability \\rondition. Su\\rh restri\\rtions are not unusual\\n\\nin \\ron\\rrete situations where learnability is at issue, so they don\\'t signi(cid:28)\\rantly a(cid:27)e\\rt the\\n\\nusefulness of the following \\rhara\\rterization of the notion learnability under su\\rh restri\\rtive\\n\\n\\ronditions.\\n\\nTheorem 3.19 (Angluin 1980) Let hΩ, S, Li be a grammar system for whi\\rh both \\ron-\\nditions 3.17 and 3.18 hold, and let G be a re\\rursively enumerable subset of Ω. Then G is\\nlearnable if and only if there exists a \\romputable partial fun\\rtion ψ : Ω × N ⇀ S su\\rh that:\\n\\n(i) for al l n ∈ N, ψ(G, n) is de(cid:28)ned if and only if G ∈ G and L(G) 6= ∅;\\n\\n(ii) for al l G ∈ G, TG = {ψ(G, n) | n ∈ N} is a (cid:28)nite subset of L(G);\\n\\n(iii) for al l G, G′ ∈ G , if TG ⊆ L(G′), then L(G′) 6⊂ L(G).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n13\\n\\nNote: From this point onward, unless otherwise stated, we will restri\\rt our attention to\\n\\n\\rlasses of grammars that ful(cid:28)ll both \\rondition 3.17 and \\rondition 3.18.\\n\\nAngluin\\'s theorem introdu\\res the notion of TG as the tel l-tale set for a given language.\\n\\nLearnability in the restri\\rted environment is \\rhara\\rterized by the existen\\re of a me\\rhanism\\n\\n(the fun\\rtion ψ) to enumerate all the senten\\res belonging to su\\rh a (cid:28)nite subset of the target\\nlanguage. Even more, a tell-tale set for a given grammar G is su\\rh that if it is in\\rluded in\\nthe language generated by another grammar G′\\n\\n, then\\n\\nˆ either L(G) is in\\rluded in L(G′),\\n\\nˆ or L(G′) \\rontains other senten\\res as well as those belonging to L(G).\\n\\nOtherwise stated, it is never the \\rase that TG ⊆ L(G′) ⊆ L(G). The point of the tell-tale\\n\\nsubset is that on\\re the strings of that subset have appeared among the sample strings, we\\n\\nneed not fear overgeneralization in guessing a grammar G. This is be\\rause the true answer,\\neven if it is not L(G), \\rannot be a proper subset of L(G). This means that a learner who\\nhas seen only the senten\\res belonging to the tell-tale set for a given grammar G, is justi(cid:28)ed\\nin \\ronje\\rturing G as the underlying grammar, sin\\re doing so never results in overshooting\\n\\nor in\\ronsisten\\ry.\\n\\nTG\\n\\nL(\\n\\n)G\\n\\nL(\\n\\n)G´\\n\\nL(\\n\\n´´)G\\n\\nFigure 3: A tell-tale set for L(G).\\n\\nAs a \\ronsequen\\re of Angluin\\'s theorem, Wright proved in [Wri89℄ the following\\n\\nTheorem 3.20 (Wright, 1989) Let hΩ, S, Li and G be as in theorem 3.19. If L(G) has\\n(cid:28)nite elasti\\rity, then G is learnable.\\n\\nIn su\\rh a restri\\rted framework, therefore, the task of proving learnability for a \\rertain \\rlass\\n\\nof grammars \\ran be redu\\red to the usually simpler task of proving its (cid:28)nite elasti\\rity.\\n\\nRR n° 0123456789\\n\\n\\x0c14\\n\\nBonato\\n\\nDue to Wright\\'s theorem we \\ran establish the following useful impli\\rations\\n\\nL(G) has (cid:28)nite elasti\\rity\\n\\n†\\n⇒ G is learnable\\n\\nL(G) has a limit point ⇒ G is unlearnable\\n\\nG is unlearnable\\n\\n†\\n⇒ L(G) has in(cid:28)nite elasti\\rity\\n\\nThe impli\\rations indi\\rated by\\n\\n†\\n⇒ depend on the de\\ridability of universal membership and\\n\\nre\\rursive enumerability of the \\rlass of grammars at issue, as de(cid:28)ned in \\ronditions 3.17 and\\n\\n3.18.\\n\\n3.3.3 Kanazawa\\'s Theorem\\n\\nThe following theorem (see [Kan98℄), whi\\rh is a generalization of a previous theorem by\\n\\nWright, provides a su(cid:30)\\rient \\rondition for a \\rlass of grammars to have (cid:28)nite elasti\\rity, and\\n\\ntherefore to be learnable. A relation R ⊆ Σ∗ × Υ∗\\nfor every s ∈ Σ∗\\n\\n, the set {u ∈ Υ∗ | sRu} is (cid:28)nite.\\n\\nis said to be (cid:28)nite-valued if and only if\\n\\nTheorem 3.21 Let M be a \\rlass of languages over Υ that has (cid:28)nite elasti\\rity, and let\\nbe a (cid:28)nite-valued relation. Then L = {R−1[M ] | M ∈ M} also has (cid:28)nite\\nR ⊆ Σ∗ × Υ∗\\n\\nelasti\\rity.\\n\\nelasti\\rity.\\n\\nThis theorem is a powerful tool to prove (cid:28)nite elasti\\rity (and therefore learnability) for\\n\\n\\rlasses of grammars. On\\re we prove the (cid:28)nite elasti\\rity for a \\rertain \\rlass of grammars\\n\\nin the (cid:16)straight(cid:17) way, we \\ran get a proof for (cid:28)nite elasti\\rity of other \\rlasses of grammars,\\n\\ndue to the relatively loose requirements of the theorem. All we have to do is to devise a\\n\\n(cid:16)smart(cid:17) (cid:28)nite-valued relation between the (cid:28)rst \\rlass and a new \\rlass of grammars su\\rh that\\n\\nthe anti-image of the latter under this relation is the \\rlass for whi\\rh we want to prove (cid:28)nite\\n\\nR\\n\\nΣ*\\n\\nΥ *\\n\\nR  [-1\\n\\nM]\\n\\nM\\n\\nFigure 4: Kanazawa\\'s theorem.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n15\\n\\n3.4 Constraints on Learning Fun\\rtions\\n\\nIn the de(cid:28)nition of learnability nothing is said about the behaviour of learning fun\\rtions\\n\\napart from \\ronvergen\\re to a \\rorre\\rt grammar. Further \\ronstraints \\ran be imposed: one \\ran\\n\\n\\rhoose a \\rertain learning strategy. Intuitively, a strategy refers to a poli\\ry, or preferen\\re,\\n\\nfor \\rhoosing hypotheses. Formally, a strategy \\ran be analyzed as merely pi\\rking a subset of\\n\\npossible learning fun\\rtions. Strategies \\ran be grouped by numerous properties. We \\rhoose\\n\\nto group them by restri\\rtiveness, de(cid:28)ned as follows:\\n\\nDe(cid:28)nition 3.22 (Restri\\rtiveness) If a strategy \\ronstrains the \\rlass of learnable languages\\n\\nit is said to be restri\\rtive.\\n\\nFor example, strategies are grouped as \\romputational \\ronstraints (\\romputability, time\\n\\n\\romplexity), \\ronstraints on potential \\ronje\\rtures (\\ronsisten\\ry), \\ronstraints on the relation\\n\\nbetween \\ronje\\rtures (\\ronservatism), et\\r. Sin\\re the \\rlasses we will be dis\\russing are all \\rlasses\\n\\nof re\\rursive languages, (cid:16)restri\\rtive(cid:17) will be taken to mean (cid:16)restri\\rtive for \\rlasses of re\\rursive\\n\\nlanguages(cid:17).\\n\\n3.4.1 Non-restri\\rtive Constraints\\n\\nThe proof of theorem 3.19 implies that in a grammar system where universal membership\\n\\nis de\\ridable, a re\\rursively enumerable \\rlass of grammars is learnable if and only if there is a\\n\\n\\romputable learning fun\\rtion that learns it order-independently, prudently, and is responsive\\n\\nand \\ronsistent on this \\rlass.\\n\\nDe(cid:28)nition 3.23 (Order-independent Learning) A learning fun\\rtion ϕ learns G order-\\nindependently if for al l L ∈ L(G), there exists G ∈ G su\\rh that L(G) = L and for al l in(cid:28)nite\\nsequen\\res hsiii∈N that enumerate L, ϕ \\ronverges on hsiii∈N to G.\\n\\nIntuitively this seems a reasonable strategy. There does not seem to be an a priori reason\\n\\nwhy either the order of presentation should in(cid:29)uen\\re the (cid:28)nal \\rhoi\\re of hypothesis. On the\\n\\nother hand, it has already been proved (see [JORS99℄) that in any grammar system, a \\rlass\\n\\nof grammars is learnable if and only if there is a \\romputable learning fun\\rtion that learns\\n\\nit order-independently.\\n\\nDe(cid:28)nition 3.24 (Exa\\rt Learning) A learning fun\\rtion ϕ learns G exa\\rtly if for al l G′\\nsu\\rh that ϕ learns G′\\n\\n, L(G′) ⊆ L(G).\\n\\nIn other words, the learning fun\\rtion will not hypothesize grammars that are outside its\\n\\n\\rlass. This is not really a \\ronstraint on learning fun\\rtions, but on the relation between a\\n\\n\\rlass of languages and a learning fun\\rtion. For every learning fun\\rtion there exists a \\rlass\\n\\nthat it learns exa\\rtly. The reason for this \\ronstraint is the idea that \\rhildren only learn\\n\\nlanguages that have at least a \\rertain minimal expressiveness. If we want to model language\\n\\nlearning, we want learning fun\\rtions to learn a \\rhosen \\rlass exa\\rtly. There seems to be\\n\\nempiri\\ral support for this idea. Some of it \\romes from studies of \\rhildren raised in pidgin\\n\\ndiale\\rts, some from studies of sensory deprived \\rhildren (see [Pin94℄).\\n\\nRR n° 0123456789\\n\\n\\x0c16\\n\\nBonato\\n\\nDe(cid:28)nition 3.25 (Prudent Learning) A learning fun\\rtion ϕ learns G prudently if ϕ learns\\nG and range(ϕ) ⊆ G .\\n\\nNote that prudent learning implies exa\\rt learning. This redu\\res to the \\rondition that a\\n\\nlearning fun\\rtion should only produ\\re a hypothesis if the learning fun\\rtion \\ran ba\\rk up its\\n\\nhypotheses, i.e. if the hypothesis is \\ron(cid:28)rmed by the input, the learning fun\\rtion is able to\\n\\nidentify the language.\\n\\nDe(cid:28)nition 3.26 (Responsive Learning) A learning fun\\rtion ϕ is responsive on G if for\\nany L ∈ L(G) and for any (cid:28)nite sequen\\re hs0, . . . , sii of elements of L ({hs0, . . . , sii} ⊆ L),\\nϕ(hs0, . . . , sii) is de(cid:28)ned.\\n\\nThis \\ronstraint \\ran be regarded as the \\romplement of prudent learning:\\n\\nif all senten\\res\\n\\nfound in the input are in a language in the \\rlass of languages learned, the learning fun\\rtion\\n\\nshould always produ\\re a hypothesis.\\n\\nDe(cid:28)nition 3.27 (Consistent Learning) A learning fun\\rtion ϕ is \\ronsistent on G if for\\nany L ∈ L(G) and for any (cid:28)nite sequen\\re hs0, . . . , sii of elements of L, either ϕ(hs0, . . . , sii)\\nis unde(cid:28)ned or {s0, . . . , si} ⊆ L(ϕ(hs0, . . . , sii)).\\n\\nThe idea behind this \\ronstraint is that all the data given should be explained by the \\rhosen\\n\\nhypothesis. It should be self-evident that this is a desirable property. Indeed, one would\\n\\nalmost expe\\rt it to be part of the de(cid:28)nition of learning. However, learning fun\\rtions that\\n\\nare not \\ronsistent are not ne\\ressarily trivial. If, for example, the input is noisy, it would not\\n\\nbe unreasonable for a learning fun\\rtion to ignore \\rertain data be\\rause it \\ronsiders them as\\n\\nunreliable. Also, it is a well known fa\\rt that \\rhildren do not learn languages \\ronsistently.\\n\\n3.4.2 Restri\\rtive Constraints\\n\\nDe(cid:28)nition 3.28 (Set-Drivenness) A learning fun\\rtion ϕ learns G set-driven if ϕ(hs0, . . . , sii)\\nis determined by {s0, . . . , si} or, more pre\\risely, if the fol lowing holds: whenever {s0, . . . , si} =\\n{u0, . . . , uj}, ϕ(hs0, . . . , sii) is de(cid:28)ned if and only if ϕ(hu0, . . . , uji) is de(cid:28)ned, and if they\\n\\nare de(cid:28)ned, they are equal.\\n\\nIt is easy to see that set-drivenness implies order-independen\\re. Set-driven learning \\rould be\\n\\nvery loosely des\\rribed as order-independent learning with the addition of ignoring (cid:16)doubles(cid:17)\\n\\nin the input.\\n\\nIt is obvious that this is a ni\\re property for a learning fun\\rtion to have:\\n\\none would not expe\\rt the \\rhoi\\re of hypothesis to be in(cid:29)uen\\red by repeated presentation of\\n\\nthe same data. The assumption here is that the order of presentation and the number of\\n\\nrepetitions are essentially arbitrary, i.e. they \\rarry no information that is of any use to the\\n\\nlearning fun\\rtion. One \\ran devise situations where this is not the \\rase.\\n\\nDe(cid:28)nition 3.29 (Conservative Learning) A learning fun\\rtion ϕ is \\ronservative if for\\nany (cid:28)nite sequen\\re hs0, . . . , sii of senten\\res and for any senten\\re si+1 , whenever ϕ(hs0, . . . , sii)\\nis de(cid:28)ned and si+1 ∈ L(ϕ(hs0, . . . , sii)), ϕ(hs0, . . . , si, si+1i) is also de(cid:28)ned and ϕ(hs0, . . . , sii) =\\nϕ(hs0, . . . , si, si+1i).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n17\\n\\nAt (cid:28)rst glan\\re \\ronservatism may seem a desirable property. Why \\rhange your hypothesis\\n\\nif there is no dire\\rt need for it? One \\rould imagine \\rases, however, where it would not\\n\\nbe unreasonable for a learning fun\\rtion to \\rhange its mind, even though the new data (cid:28)ts\\n\\nin the \\rurrent hypothesis. Su\\rh a fun\\rtion \\rould for example make reasonable but (cid:16)wild(cid:17)\\n\\nguesses whi\\rh it \\rould later retra\\rt. The fun\\rtion \\rould (cid:16)note(cid:17) after a while that the inputs\\n\\n\\rover only a proper subset of its \\ronje\\rtured language. While su\\rh behaviour will sometimes\\n\\nresult in temporarily overshooting, su\\rh a fun\\rtion \\rould still be guaranteed to \\ronverge to\\n\\nthe \\rorre\\rt hypothesis in the limit.\\n\\nIt is a \\rommon assumption in \\rognitive s\\rien\\re that human \\rognitive pro\\resses \\ran be\\n\\nsimulated by \\romputer. This would lead one to believe that \\rhildren\\'s learning fun\\rtions\\n\\nare \\romputable. The \\rorresponding strategy is the set of all partial and total re\\rursive\\n\\nfun\\rtions. Sin\\re this is only a subset of all possible fun\\rtions, the \\romputability strategy is\\n\\na non trivial hypothesis, but not ne\\ressarily a restri\\rtive one.\\n\\nThe \\romputability \\ronstraint intera\\rts with \\ronsisten\\ry (see [Ful88℄):\\n\\nProposition 3.30 There is a \\rol le\\rtion of languages that is identi(cid:28)able by a \\romputable\\n\\nlearning fun\\rtion but by no \\ronsistent, \\romputable learning fun\\rtion.\\n\\nThe \\romputability \\ronstraint also intera\\rts with \\ronservative learning (see [Ang80℄):\\n\\nProposition 3.31 (Angluin, 1980) There is a \\rol le\\rtion of languages that is identi(cid:28)able\\n\\nby a \\romputable learning fun\\rtion but by no \\ronservative, \\romputable learning fun\\rtion.\\n\\nDe(cid:28)nition 3.32 (Monotoni\\rity) The learning fun\\rtion ϕ is monotone in\\rreasing if for al l\\n(cid:28)nite sequen\\res hs0, . . . , sni and hs0, . . . , sn+mi, whenever ϕ(hs0, . . . , sni) and ϕ(hs0, . . . , sn+mi)\\n\\nare de(cid:28)ned,\\n\\nL(ϕ(hs0, . . . , sni)) ⊆ L(ϕ(hs0, . . . , sn+mi)).\\n\\nWhen a learning fun\\rtion that is monotone in\\rreasing \\rhanges its hypothesis, the language\\n\\nasso\\riated with the previous hypothesis will be (properly) in\\rluded in the language asso\\ri-\\n\\nated with the new hypothesis. There seems to be little or no empiri\\ral support for su\\rh a\\n\\n\\ronstraint.\\n\\nDe(cid:28)nition 3.33 (In\\rrementality, Kanazawa 1998) The learning fun\\rtion ϕ is in\\rre-\\nmental if there exists a \\romputable fun\\rtion ψ su\\rh that\\n\\nϕ(hs0, . . . , sn+1i) ≃ ψ(ϕ(hs0, . . . , sni), sn+1).\\n\\nAn in\\rremental learning fun\\rtion does not need to store previous data. All it needs is \\rurrent\\n\\ninput, sn , and its previous hypothesis. A generalized form of this \\ronstraint, \\ralled memory\\nlimitation, limits a\\r\\ress for a learning fun\\rtion to only n previous elements of the input\\n\\nsequen\\re. This seems reasonable from an empiri\\ral point of view; it seems improbable that\\n\\n\\rhildren (un\\rons\\riously) store all utteran\\res they en\\rounter.\\n\\nRR n° 0123456789\\n\\n\\x0c18\\n\\nBonato\\n\\nNote that, on an in(cid:28)nite sequen\\re enumerating language L in L(G), a \\ronservative learn-\\ning fun\\rtion ϕ learning G never outputs any grammar that generates a proper superset of L.\\n\\nLet ϕ be a \\ronservative and \\romputable learning fun\\rtion that is responsive and \\ronsis-\\ntent on G , and learns G prudently. Then, whenever {s0, . . . , sn} ⊆ L for some L ∈ L(G),\\nL(ϕ(hs0, . . . , sni)) must be a minimal element of the set {L ∈ L(G) | {s0, . . . , sn} ⊆ L}. This\\n\\nimplies the following \\rondition:\\n\\nCondition 3.34 There is a \\romputable partial fun\\rtion ψ that takes any (cid:28)nite set D of\\nsenten\\res and maps it to a grammar ψ(D) ∈ G su\\rh that L(ψ(D)) is a minimal element of\\n{L ∈ L(G) | D ⊆ L} whenever the latter set is non-empty.\\n\\nDe(cid:28)nition 3.35 Let ψ a \\romputable fun\\rtion satisfying \\rondition 3.34. De(cid:28)ne a learning\\nfun\\rtion ϕ as fol lows\\n\\nϕ(hs0i) ≃ ψ({s0}),\\n\\nϕ(hs0, . . . , si + 1i) ≃\\n\\nϕ(hs0, . . . , sii)\\n\\nif si+1 ∈ L(ϕ(hs0, . . . , sii)),\\n\\n(cid:26)\\n\\nψ({s0, . . . , si+1}) otherwise.\\n\\nUnder \\rertain \\ronditions the fun\\rtion just de(cid:28)ned is guaranteed to learn G , one su\\rh \\rase is\\nwhere L(G has (cid:28)nite elasti\\rity.\\n\\nProposition 3.36 Let G be a \\rlass of grammars su\\rh that L(G) has (cid:28)nite elasti\\rity, and a\\n\\romputable fun\\rtion ψ satisfying \\rondition 3.34 exists. Then the learning fun\\rtion ϕ de(cid:28)ned\\nin de(cid:28)nition 3.35 learns G .\\n\\n4 Is Learning Theory Powerful Enough?\\n\\n4.1 First Negative Results\\n\\nOne of the main and apparently dis\\rouraging \\ronsequen\\res of the theorem 3.14 proved by\\n\\nGold in the original arti\\rle wherein he laid the foundations of Formal Learning Theory was\\n\\nthat none of the four \\rlasses of Chomsky\\'s Hierar\\rhy is learnable under the \\rriterion of\\n\\nidenti(cid:28)\\ration in the limit. Su\\rh a (cid:28)rst negative result has been taken for a long time as\\n\\na proof that identifying languages from positive data a\\r\\rording to his identi(cid:28)\\ration in the\\n\\nlimit \\rriterion was too hard a task. Gold himself looks quite pessimisti\\r about the future of\\n\\nthe theory he has just de(cid:28)ned along its main dire\\rtions:\\n\\nHowever, the results presented in the last se\\rtion show that only the most trivial\\n\\n\\rlass of languages \\ronsidered is learnable... [Gol67℄\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n19\\n\\n4.2 Angluin\\'s Results\\n\\nThe (cid:28)rst example of non-trivial \\rlass of learnable grammars was dis\\rovered by Dana Angluin\\n\\n(see [Ang80℄).\\n\\nIf P at is de(cid:28)ned like in example 3.4, we \\ran prove that the \\rlass of all\\n\\npattern languages has (cid:28)nite elasti\\rity and, therefore, it is learnable. Furthermore, su\\rh a\\n\\nlearnable \\rlass of grammars was also the (cid:28)rst example of an interesting \\rlass of grammars\\n\\nthat \\rross-\\ruts Chomsky Hierar\\rhy, therefore showing that Chomsky\\'s is not but one of\\n\\nmany meaningful possible \\rlassi(cid:28)\\rations for formal grammars.\\n\\n4.3 Shinohara\\'s Results\\n\\nInitial pessimism about e(cid:27)e\\rtive usefulness of Gold\\'s notion of identi(cid:28)\\ration in the limit was\\n\\nde(cid:28)nitely abandoned after an impressive result by Shinohara who proves (see [Shi90℄), that\\n\\nk-rigid \\rontext sensitive grammars (\\rontext-sensitive grammars over a (cid:28)nite alphabet Σ with\\nat most k rules), have (cid:28)nite elasti\\rity for any k . Sin\\re the universal membership problem\\n\\nfor \\rontext-sensitive grammars is de\\ridable, that \\rlass of grammars is learnable. This is a\\n\\nparti\\rular \\rase of his more general result about (cid:28)nite elasti\\rity for what he \\ralls monotoni\\r\\n\\nformal system.\\n\\n4.4 Kanazawa\\'s Results\\n\\nMakoto Kanazawa in [Kan98℄ makes another de\\risive step toward bridging the existing\\n\\ngap between Formal Learning Theory and \\romputational linguisti\\rs. Indeed, he gets some\\n\\nimportant results on the learnability for some non-trivial sub\\rlasses of Classi\\ral Categorial\\n\\nGrammars (also known as AB Grammars). Analogously to what is done in [Shi90℄ he proves\\n\\nthat as soon as we bound the maximum number of types a \\rlassi\\ral \\rategorial grammar\\n\\nassigns to a word, we get sub\\rlasses whi\\rh \\ran be e(cid:27)e\\rtively learnable:\\n\\nin parti\\rular, he\\n\\nproves e(cid:27)e\\rtive learnability for the \\rlass of k-valued Classi\\ral Categorial Grammars, both\\n\\nfrom stru\\rtures and from strings.\\n\\nIn the (cid:28)rst \\rase, ea\\rh string of the language the learner is presented to \\romes with\\n\\nadditional information about the underlying stru\\rture indu\\red by the grammar formalism\\n\\nthat generates the language. The availability of su\\rh additional information for ea\\rh string\\n\\nis somewhat in \\rontrast with Gold\\'s model of learning and gives rise to weaker results.\\n\\nOn the other hand, psy\\rhologi\\ral plausibility of the pro\\ress is preserved by the fa\\rt that\\n\\nsu\\rh an underlying stru\\rture \\ran be seen as some kind of semanti\\r information that \\rould\\n\\nbe available to the \\rhild learning the language from the very early stages of her \\rognitive\\n\\nThe present work pushes Kanazawa\\'s results a little further in the dire\\rtion of proving the\\n\\ne(cid:27)e\\rtive learnability for more and more powerful and expressive \\rlasses of formal languages.\\n\\nIn parti\\rular, we will be able to prove learnability for the \\rlass of Rigid Lambek Grammars\\n\\ndevelopment.\\n\\n4.5 Our Results\\n\\nRR n° 0123456789\\n\\n\\x0c20\\n\\nBonato\\n\\n(see \\rhapter 9) and to show an e(cid:27)e\\rtive algorithm to learn them on the basis of a stru\\rtured\\n\\ninput. Mu\\rh is left to be done along this dire\\rtion of resear\\rh, sin\\re even a formal theory\\n\\nfor Rigid Lambek Grammars is still under-developed. However, our results \\ron(cid:28)rm on\\re\\n\\nagain that initial pessimism toward this paradigm of learning was largely unjusti(cid:28)ed, and\\n\\nthat even quite a \\romplex and linguisti\\rally motivated formalism like Lambek Grammars\\n\\n\\ran be learnt a\\r\\rording to it.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n21\\n\\n5 Lambek Grammars\\n\\nIn 1958 Joa\\rhim Lambek proposed (see [Lam58℄) to extend the formalism of Classi\\ral Cate-\\n\\ngorial Grammars (sometimes referred to also as Basi\\r Categorial Grammars or BCGs) by a\\n\\ndedu\\rtive system to derive type-\\rhange rules. A BCG is basi\\rally as a (cid:28)nite relation between\\n\\nthe (cid:28)nite set of symbols of the alphabet (usually referred to as words) and a (cid:28)nite set of\\n\\ntypes. Combinatory properties of ea\\rh word are \\rompletely determined by the shape of its\\n\\ntypes, whi\\rh \\ran be \\rombined a\\r\\rording to a small set of rules, (cid:28)xed on\\re and for all BCGs.\\n\\nLambek\\'s proposal marked the irruption of logi\\rs into grammars: Lambek grammars \\rome\\n\\nwith a whole dedu\\rtive system that allows the type of a symbol to be repla\\red with a weaker\\n\\ntype.\\n\\nIt was (cid:28)rst realized by van Benthem (in [vB87℄) that the proofs of these type \\rhanges\\n\\nprin\\riples \\rarry important information about their semanti\\r interpretation, following the\\n\\nCurry-Howard isomorphism. Thus, the notion of a proof theoreti\\ral grammar was proposed\\n\\nthat repla\\res formal grammars (see [Cho56℄) with dedu\\rtive systems and that in\\rludes a\\n\\nsystemati\\r semanti\\rs for natural languages based on the relationship between proof theory\\n\\nand type theory. Thus, rather than \\ronsidering grammati\\ral \\rategories as unanalyzed prim-\\n\\nitives, they are taken to be formulas \\ronstru\\rted from atoms and \\ronne\\rtives, and rather\\n\\nthan de(cid:28)ning grammars with respe\\rt to rewrite rules, grammars are de(cid:28)ned by the rules of\\n\\ninferen\\re governing the \\ronne\\rtives used in the synta\\rti\\r \\rategories.\\n\\nDue to the renewed interest in \\rategorial grammars in the (cid:28)eld of \\romputational lin-\\n\\nguisti\\rs, Lambek (Categorial) Grammars (LCGs) are \\rurrently \\ronsidered as a promising\\n\\nformalism. They enjoy the relative simpli\\rity of a tightly \\ronstrained formalism as that for\\n\\nBCGs, together with the linguisti\\rally attra\\rtive feature of full lexi\\ralization.\\n\\nBesides, although Pentus proved (in [Pen97℄) that Lambek grammars generate exa\\rtly\\n\\n\\rontext-free (string) languages, in [Tie99℄ it has been shown that their strong generative\\n\\n\\rapa\\rity is greater than that of \\rontext-free grammars. These features make them an in-\\n\\nteresting sub je\\rt for our inquiry about their properties with respe\\rt to Gold\\'s Learnability\\n\\nTheory.\\n\\n5.1 Classi\\ral Categorial Grammars\\n\\nThe main idea whi\\rh lies behind the theory of Categorial Grammars is to \\ron\\reive a grammar\\n\\ninstead as a set of rules whi\\rh generate any string of the language, as a system whi\\rh assigns\\n\\nto ea\\rh symbol of the alphabet a set of types whi\\rh \\ran be \\rombined a\\r\\rording to a small\\n\\nset of rules, (cid:28)xed for the whole \\rlass of Classi\\ral Categorial Grammars.\\n\\nA \\rontext-free grammar á la Chomsky is made of a set of rules that generate all the strings\\n\\nof a given language in a (cid:16)top-down(cid:17) fashion, starting from an initial symbol whi\\rh identi(cid:28)es\\n\\nall the well-formed strings. On the \\rontrary, a \\rategorial grammar a\\r\\repts a sequen\\re of\\n\\nsymbols of the alphabet as a well-formed string if and only if a sequen\\re of types assigned to\\n\\nthem redu\\res (in a (cid:16)bottom-up(cid:17) fashion) a\\r\\rording to a (cid:28)xed set of rules, to a distinguished\\n\\ntype whi\\rh designates well-formed strings.\\n\\nRR n° 0123456789\\n\\n\\x0c22\\n\\nBonato\\n\\nDe(cid:28)nition 5.1 (Classi\\ral Categorial Grammar)\\n\\nA Classi\\ral Categorial Grammar (hen\\reforth CCG) is a quadruple hΣ, P r, F, si, su\\rh that\\n\\nˆ Σ is a (cid:28)nite set (the terminal symbols or vo\\rabulary),\\n\\nˆ Pr is a (cid:28)nite set (the non-terminal symbols or atomi\\r \\rategories),\\n\\nˆ F is a fun\\rtion from Σ to (cid:28)nite subsets of Tp, where Tp is the smal lest set su\\rh that:\\n\\n1. P r ⊆ T p\\n\\n2. if A, B ∈ T p, then (A/B), (A\\\\B) ∈ T p\\n\\nIf F (a) = {A1, . . . , An} we usual ly write G : a 7→ A1, . . . , An .\\n\\nˆ s ∈ P r is the distinguished atomi\\r \\rategory\\n\\nIn a CCG, \\rombinatory properties are uniquely determined by their stru\\rture. There\\n\\nare only two modes of type \\rombination: so-\\ralled (a\\r\\rording to the notation introdu\\red\\n\\nin [Lam58℄ and almost universally adopted) Ba\\rkward Appli\\ration:\\n\\nand Forward Appli\\ration:\\n\\nA non-empty sequen\\re of types A1, . . . , An is said to derive a type B , that is\\n\\nA, A\\\\B ⇒ B\\n\\nB/A, A ⇒ B.\\n\\nA1, . . . , An ⇒ B,\\n\\nif repeated appli\\rations of the rules of Ba\\rkward and Forward appli\\ration to the sequen\\re\\n\\nA1, . . . , An results in B .\\n\\nIn order to de(cid:28)ne the language generated by a CCG we have to establish a \\rriterion to\\n\\nidentify a string belonging to that language. That\\'s what is done by the following\\n\\nDe(cid:28)nition 5.2 The binary relation\\n\\nis de(cid:28)ned as fol lows. Let A, B ∈ T p, let α, β ∈ T p∗\\n\\n,\\n\\n⇒⊆ T p∗ × T p∗\\n\\nα A A\\\\B β ⇒ α B β\\nα B/A A β ⇒ α B β\\n\\nThe language generated by a CCG G is the set\\n\\n{a1 · · · an ∈ Σ∗ | for 1 ≤ i ≤ n, ∃Ai, G : ai 7→ Ai, and A1 . . . An\\n\\n∗⇒ s}\\n\\nwhere\\n\\n∗⇒ is the re(cid:29)exive, transitive \\rlosure of ⇒.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n23\\n\\nInformally, we \\ran say that a string of symbols belongs to the language generated by a CCG\\n\\nif there exists a derivation of the distinguished \\rategory s out of at least one sequen\\re of\\n\\ntypes assigned by the grammar to the symbols of the string.\\n\\nExample 5.3 The fol lowing grammar generates the language {anbn | n > 0}:\\n\\nHere is a derivation for a3b3\\n\\n:\\n\\na :\\nb\\n\\ns/B,\\n: B, s\\\\B\\n\\ns/B s/B s/B B s\\\\B s\\\\B ⇒ s/B s/B s s\\\\B s\\\\B ⇒\\ns/B s/B B s\\\\B ⇒ s/B s s\\\\B ⇒\\n\\ns/B B ⇒ s\\n\\nWeak generative \\rapa\\rity of CCGs was \\rhara\\rterized by Gaifman (see [BH64℄):\\n\\nTheorem 5.4 (Gaifman, 1964) The set of languages generated by CCGs \\roin\\rides with\\n\\nthe set of \\rontext-free languages.\\n\\nFrom the proof of Gaifman\\'s theorem, we immediately obtain the following normal form\\n\\nTheorem 5.5 (Gaifman normal form) Every \\rategorial grammar is equivalent to a \\rat-\\n\\negorial grammar whi\\rh assigns only \\rategories of the form\\n\\nExample 5.6 A CCG equivalent to that in example 5.3 in Gaifman normal form is the\\n\\ntheorem:\\n\\nfol lowing\\n\\nand here is a derivation for a3b3\\n\\n:\\n\\nA, A/B, (A/B)/C.\\n\\na :\\n\\ns/B, (s/B)/s\\n\\nb\\n\\n: B\\n\\ns/B B\\n\\n(s/B)/s\\n\\ns\\n\\ns/B\\n\\ns\\n\\ns/B\\n\\ns\\n\\nB\\n\\nB\\n\\n(s/B)/B\\n\\nIn the previous example we make use for the (cid:28)rst time of a (cid:16)natural dedu\\rtion(cid:17) notation\\n\\nfor derivations, that in the present work will substitute the \\rumbersome notation used in\\n\\nexample 5.3.\\n\\nRR n° 0123456789\\n\\n\\x0c24\\n\\nBonato\\n\\n5.2 Extensions of Classi\\ral Categorial Grammars\\n\\nAs stated in the previous se\\rtion, CCG formalism \\romes with only two redu\\rtion rules whi\\rh\\n\\nyield smaller types out of larger ones. Montague\\'s work on semanti\\rs (see [Mon97℄) led to\\n\\nthe de(cid:28)nition of two further (cid:16)type-raising(cid:17) rules, by whi\\rh it is possible to \\ronstru\\rt new\\n\\nsynta\\rti\\r \\rategories out of atomi\\r ones. We \\ran extend the de(cid:28)nition of CCGs as presented\\n\\nin the previous se\\rtion by adding to the former de(cid:28)nition two new type \\rhange rules:\\n\\nOther type-\\rhange rules that were proposed are the \\romposition:\\n\\nαBβ ⇒ α(A/B)\\\\Aβ\\nαBβ ⇒ αA/(B\\\\A)β\\n\\nA/B B/C\\nA/C\\n\\nC\\\\B B\\\\A\\nC\\\\A\\n\\nA/B\\n(A/C)/(B/C)\\n\\nB\\\\A\\n(C\\\\B)\\\\(C\\\\A)\\n\\nand the Gea\\rh Rules:\\n\\nWe \\ran extend the formalism of CCG by adding to de(cid:28)nition 5.2 any type \\rhange rule\\n\\nwe need to formalize spe\\ri(cid:28)\\r phenomena in natural language. Su\\rh a rule-based approa\\rh\\n\\nwas adopted by Steedman (see [Ste93℄) who enri\\rhes \\rlassi\\ral \\rategorial grammar formalism\\n\\nwith a (cid:28)nite number of type-\\rhanges rules. On the other hand, as it will be made \\rlear in\\n\\nthe following se\\rtion, Lambek\\'s approa\\rh is a dedu\\rtive one: he de(cid:28)nes a \\ral\\rulus in whi\\rh\\n\\ntype \\rhanges rules spring out as a \\ronsequen\\re of the operations performed on the types.\\n\\nOne \\rould ask why we should follow the dedu\\rtive rather than the rule-based approa\\rh.\\n\\nTo begin with, as proved in [Zie89℄, Lambek Cal\\rulus is not (cid:28)nitely axiomatizable, that\\n\\nis to say that adding a (cid:28)nite number of type-\\rhange rules to the formalism of CCG one\\n\\n\\rannot derive all the type \\rhange rules provable in the Lambek Cal\\rulus. Moreover, the two\\n\\napproa\\rhes are very di(cid:27)erent under a theoreti\\ral viewpoint.\\n\\nFrom a linguisti\\r perspe\\rtive, Steedman pointed out that there is no reason why we\\n\\nshould sti\\rk to a dedu\\rtive approa\\rh instead of to a rule based one: he underlines the\\n\\nimportan\\re of introdu\\ring ad ho\\r rules to formalize spe\\ri(cid:28)\\r linguisti\\r phenomena. Why\\n\\nshould we subordinate the use of spe\\ri(cid:28)\\r type \\rhange rules to their derivability in some\\n\\n\\ral\\rulus?\\n\\nOne of the most \\rompelling reasons to do so is given by Moortgat (see [Moo97℄) who\\n\\nstresses the systemati\\rity of the relation between syntax and semanti\\rs provided in a de-\\n\\ndu\\rtive framework. Also, Lambek Cal\\rulus enjoys an important property: it is sound and\\n\\n\\romplete with respe\\rt to free semigroup model, i.e. an interpretation with respe\\rt to formal\\n\\nlanguages . That is to say, rules that are not dedu\\rible in Lambek Cal\\rulus are not sound,\\n\\nand so they \\ran be \\ronsidered as linguisti\\rally implausible.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n25\\n\\n5.3\\n\\n(Asso\\riative) Lambek Cal\\rulus\\n\\nCategorial grammars \\ran be analyzed from a proof theoreti\\ral perspe\\rtive by observing the\\n\\n\\rlose \\ronne\\rtion between the (cid:16)slashes(cid:17) of a \\rategorial grammar and impli\\ration in intuition-\\n\\nisti\\r logi\\rs. The rule that allows us to infer that if w is of type A/B and v is of type B , then\\nwv is of type A, behaves like the modus ponens rule of inferen\\re in logi\\r. On the basis of this\\n\\nsimilarity Lambek proposed an ar\\rhite\\rture for \\rategorial grammars based on two levels:\\n\\nˆ a synta\\rti\\r \\ral\\rulus, i.e. a dedu\\rtive system in whi\\rh statement of the form\\n\\nA1, . . . , An ⊢ B,\\n\\nto be read (cid:16)from the types A1, . . . , An we \\ran infer type B (cid:17) \\ran be proved;\\n\\nˆ a \\rategorial grammar as presented in de(cid:28)nition 5.1, wherein the relation ⇒ is \\rhanged\\n\\nto allow any type \\rhange rule that \\rould be dedu\\red at the previous level.\\n\\nIn doing so, instead of adding a (cid:28)nite number of type \\rhange rules to our grammar, every\\n\\ntype \\rhange rule that \\ran be derived in the Lambek Cal\\rulus is added to the \\rategorial\\n\\ngrammar.\\n\\nThe following formalizations for Lambek Cal\\rulus are presented a\\r\\rording, respe\\rtively,\\n\\nto the formalism of sequent \\ral\\rulus and to the formalism of natural dedu\\rtion. Note that in\\n\\nthe present work we will use the expression Lambek Cal\\rulus to refer to produ\\rt-free Lambek\\n\\nCal\\rulus: indeed we will never make use of the produ\\rt `·\\' (whi\\rh \\rorresponds to the tensor\\n\\nof linear logi\\r).\\n\\nDe(cid:28)nition 5.7 The sequent \\ral\\rulus formalization of the Lambek \\ral\\rulus \\rontains the ax-\\n\\niom [ID℄ and the rules of inferen\\re [/R℄, [/L℄, [\\\\R℄, [\\\\L℄, and [Cut℄:\\n\\n[ID]\\n\\nA ⊢ A\\n\\nΓ, A ⊢ B\\n\\nΓ ⊢ B/A\\n\\nA, Γ ⊢ B\\n\\nΓ ⊢ A\\\\B\\n\\n[/R]\\n\\n[\\\\R]\\n\\nΓ ⊢ A ∆, B, Π ⊢ C\\n\\n∆, B/A, Γ, Π ⊢ C\\n\\nΓ ⊢ A ∆, B, Π ⊢ C\\n\\n∆, Γ, A\\\\B, Π ⊢ C\\n\\n[/L]\\n\\n[\\\\L]\\n\\n∆ ⊢ B Γ, B, Π ⊢ A\\n\\n[Cut]\\n\\nΓ, ∆, Π ⊢ A\\n\\nNote: in [/R] and [\\\\R] there is a side \\rondition stipulating that Γ 6= ∅.\\n\\nThe side \\rondition imposed for [/R] and [\\\\R] rules formalizes the fa\\rt that in Lambek\\n\\nCal\\rulus one is not allowed to \\ran\\rel all the premises from the left-hand side of a derivation.\\n\\nOtherwise stated, in Lambek Cal\\rulus there are no dedu\\rtions of the form\\n\\n⊢ A.\\n\\nRR n° 0123456789\\n\\n\\x0c26\\n\\nBonato\\n\\nCoherently with our interpretation of Lambek Cal\\rulus as a dedu\\rtive system to derive\\n\\nthe type of a sequen\\re of symbols of the alphabet out of the types of ea\\rh symbol, su\\rh a\\n\\nderivation makes no sense, sin\\re it would mean assigning a type to an empty sequen\\re of\\n\\nwords.\\n\\nfol lows:\\n\\nDe(cid:28)nition 5.8 The natural dedu\\rtion formalization of the Lambek Cal\\rulus is de(cid:28)ned as\\n\\nA [ID]\\n\\n·\\n·\\n·\\n·\\nA/B\\n\\n·\\n·\\n·\\n·\\nB\\n\\n·\\n·\\n·\\n·\\nB\\n\\n·\\n·\\n·\\n·\\nB\\\\A\\n\\n[/E]\\n\\n[\\\\E]\\n\\n[B]\\n\\n[B]\\n\\nA\\n\\n·\\n·\\n·\\n·\\nA\\n\\nA\\n\\n·\\n·\\n·\\n·\\nA\\n\\n[/I]\\n\\n[\\\\I]\\n\\nA/B\\n\\nB\\\\A\\n\\nNote: in [/I℄ and [\\\\I℄ rules the \\ran\\rel led assumption is always, respe\\rtively, the rightmost\\n\\nand the leftmost un\\ran\\rel led assumption, and there must be at least another un\\ran\\rel led\\n\\nhypothesis.\\n\\nBoth formalisms have advantages and disadvantages. However, due to the \\rlose \\ronne\\r-\\n\\ntion between natural dedu\\rtion proofs and λ-terms and be\\rause the tree-like stru\\rture of\\n\\ndedu\\rtions resembles derivations trees of grammars, the natural dedu\\rtion version will be\\n\\nthe primary ob je\\rt of study in the present work.\\n\\nFor later purposes we introdu\\re here the notion of derivation in Lambek \\ral\\rulus that\\n\\nwill be useful later for the de(cid:28)nition of the stru\\rture of a senten\\re in a Lambek grammar.\\n\\nA derivation of B from A1, . . . , An is a \\rertain kind of unary-binary bran\\rhing tree that\\nen\\rodes a proof of A1, . . . , An ⊢ B . Ea\\rh node of a derivation is labeled with a type, and\\nea\\rh internal node has an additional label whi\\rh, for Lambek grammars, is either /E, \\\\E, /I ,\\nor \\\\I and that indi\\rates whi\\rh Lambek \\ral\\rulus rule is used at ea\\rh step of a derivation. For\\n\\nea\\rh o\\r\\rurren\\re of an introdu\\rtion rule there must be a \\rorresponding previously unmarked\\n\\nleaf type A whi\\rh must be marked as [A] (that \\rorresponds to (cid:16)dis\\rharging(cid:17) an assumption\\n\\nin natural dedu\\rtion).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n27\\n\\nThe set of derivations is indu\\rtively de(cid:28)ned as follows:\\n\\nDe(cid:28)nition 5.9 Let A, B ∈ Tp and Γ, ∆ ∈ Tp+\\n\\n,\\n\\nˆ A (the tree \\ronsisting of a single node labeled by A) is a derivation of A from A.\\n\\nˆ \"Ba\\rkslash elimination\". If\\n\\nG\\n\\nD1\\n\\nA\\n\\nD\\n\\nD2\\n\\nA\\\\B\\n\\n\\\\E\\n\\nB\\n\\nis a derivation of A from Γ and\\n\\nis a derivation of A\\\\B from ∆, then\\n\\nG\\n\\nD1\\n\\nA\\n\\nD\\n\\nD2\\n\\nA\\\\B\\n\\nis a derivation of B from Γ, ∆.\\n\\nRR n° 0123456789\\n\\n\\x0c28\\n\\nBonato\\n\\nˆ \"Ba\\rkslash introdu\\rtion\". If\\n\\nis a derivation of B from {A, Γ}, then\\n\\nA, G\\n\\nD1\\n\\nB\\n\\n[A], G\\n\\nD1\\n\\nB\\n\\n\\\\I\\nA\\\\B\\n\\nis a derivation of A\\\\B from Γ. The leaf labeled by [A℄ is \\ral led a dis\\rharged leaf.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n29\\n\\nˆ \"Slash elimination\". If\\n\\nG\\n\\nD1\\n\\nB/A\\n\\nD\\n\\nD2\\n\\nA\\n\\n/E\\n\\nB\\n\\nis a derivation of B/A from Γ and\\n\\nis a derivation of A from ∆, then\\n\\nG\\n\\nD1\\n\\nB/A\\n\\nD\\n\\nD2\\n\\nA\\n\\nis a derivation of B from Γ, ∆.\\n\\nRR n° 0123456789\\n\\n\\x0cG, A\\n\\nD1\\n\\nB\\n\\nG, [A]\\n\\nD1\\n\\nB\\n\\n/I\\nB/A\\n\\n\\\\E\\ny\\n\\n/I\\ny/(x\\\\y)\\n\\n30\\n\\nBonato\\n\\nˆ \"Slash introdu\\rtion\". If\\n\\nis a derivation of B from {Γ, A} then\\n\\nis a derivation of B/A from Γ. The leaf labeled by [A℄ is \\ral led a dis\\rharged leaf.\\n\\nExample 5.10 The fol lowing example is a derivation of x from y/(x\\\\y) (whi\\rh proves one\\n\\nof the two type-raising rules in Lambek Cal\\rulus):\\n\\nx\\n\\n[x\\\\y]\\n\\n5.4 Non-asso\\riative Lambek Cal\\rulus\\n\\nLambek Cal\\rulus, as de(cid:28)ned in the previous se\\rtion, is impli\\ritly asso\\riative. In order to\\n\\nuse Lambek \\ral\\rulus to des\\rribe some linguisti\\r phenomena we have to forbid asso\\riativ-\\n\\nity and so the hierar\\rhi\\ral embedding of hypotheses is respe\\rted. Another linguisti\\rally\\n\\nattra\\rtive feature of non-asso\\riative Lambek \\ral\\rulus is that it provides useful logi\\ral to\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n31\\n\\nsupport semanti\\rs, but at the same time it prohibits transitivity, that sometimes leads to\\n\\novergeneration.\\n\\nDe(cid:28)nition 5.11 The natural dedu\\rtion formalization of the non-asso\\riative Lambek Cal\\ru-\\n\\nlus (SND) has the fol lowing axioms and rules of inferen\\re, presented in the sequent format:\\n\\n[ID]\\n\\nA ⊢ A\\n\\n[/E]\\n\\nΓ ⊢ A/B ∆ ⊢ B\\n\\nΓ ⊢ B ∆ ⊢ B\\\\A\\n\\n[\\\\E]\\n\\n(Γ, ∆) ⊢ A\\n\\n(Γ, ∆) ⊢ A\\n\\n(Γ, B) ⊢ A\\n\\n(B, Γ) ⊢ A\\n\\n[/I]\\n\\n[\\\\I]\\n\\nΓ ⊢ A/B\\nNote: in [/I] and [\\\\I] there is a side \\rondition stipulating that Γ 6= ∅.\\n\\nΓ ⊢ B\\\\A\\n\\n5.5 Normalization and Normal Forms\\n\\nAs one \\ran easily see, in Lambek Cal\\rulus there are in(cid:28)nitely many proofs for any dedu\\rtion\\n\\nA1, . . . , An ⊢ B . Sin\\re, as it will be extensively explained in se\\rtion 6, proofs in Lambek\\n\\nCal\\rulus play a de\\risive role in de(cid:28)ning the notion of stru\\rture for a senten\\re generated\\n\\nby a Lambek grammar, su\\rh an arbitrary proliferation of proofs for dedu\\rtions is quite\\n\\nundesirable.\\n\\nsame result.\\n\\nThe following de(cid:28)nition introdu\\res a useful relation between proofs in Lambek Cal\\rulus\\n\\nthat formalizes our idea of a (cid:16)minimal(cid:17) proof for any dedu\\rtion. It provides two normaliza-\\n\\ntion s\\rhemes that \\ran be applied to a derivation to produ\\re a (cid:16)simpler(cid:17) derivation of the\\n\\nDe(cid:28)nition 5.12 The relation >1 between proofs in the natural dedu\\rtion formalization of\\n\\nLambek Cal\\rulus is de(cid:28)ned in the fol lowing way:\\n\\n·\\n·\\n·\\n·\\nA\\n·\\n·\\n·\\n·\\nB\\n\\n>1\\n\\n[\\\\I]\\n\\n[\\\\E]\\n\\n·\\n·\\n·\\n·\\nA\\n\\n[B]\\n\\n[A]\\n·\\n·\\n·\\n·\\nB\\n\\nA\\\\B\\n\\nB\\n\\n·\\n·\\n·\\n·\\nB\\\\A\\n\\nA\\n\\nB\\\\A\\n\\n[A]\\n·\\n·\\n·\\n·\\nB\\n\\nB/A\\n\\n·\\n·\\n·\\n·\\n\\n>1\\n\\n·\\n·\\n·\\n·\\nA\\n\\n[/E]\\n\\n[/I]\\n\\nB\\n\\n·\\n·\\n·\\n·\\nA\\n\\n·\\n·\\n·\\n·\\nB\\n\\n·\\n·\\n·\\n·\\nA/B\\n\\n·\\n·\\n·\\n·\\nB\\\\A\\n\\n[\\\\E]\\n\\n>1\\n\\n[\\\\I]\\n\\nA/B [B]\\n\\n[/E]\\n\\n>1\\n\\nA\\n\\nA/B\\n\\n[/I]\\n\\nThe symbol ≥ stands for re(cid:29)exive and transitive \\rlosure of >1 . Relation >1 is usual ly de(cid:28)ned\\nas β -η-\\ronversion, while ≥ as β -η-redu\\rtion.\\n\\nRR n° 0123456789\\n\\n\\x0c32\\n\\nBonato\\n\\nThe relation ≥ satis(cid:28)es the following properties (see [Wan93℄, [Roo91℄):\\n\\nTheorem 5.13 (Wansing, 1993) The relation ≥ is \\ron(cid:29)uent (in the Chur\\rh-Rosser mean-\\ning), i.e. if δ1 ≥ δ2 and δ1 ≥ δ3 , then there exists a δ4 su\\rh that δ2 ≥ δ4 and δ3 ≥ δ4 .\\n\\nTheorem 5.14 (Roorda, 1991) The relation ≥ is both weakly and strongly normalizing,\\n\\nthat is, every proof \\ran be redu\\red in normal form and every redu\\rtion terminates after at\\n\\nmost a (cid:28)nite number of steps.\\n\\nDe(cid:28)nition 5.15 (β -η-normal form) A proof tree for the Lambek Cal\\rulus is said to be in\\nβ -η -normal form is none of its subtrees is of the form\\n\\n[B]\\n·\\n·\\n·\\n·\\nA\\n\\n[B]\\n·\\n·\\n·\\n·\\nA\\n\\nA\\n\\n[/I]\\n\\nA/B\\n\\nB\\n\\n[\\\\I]\\n\\nB\\n\\nB\\\\A\\n\\n[/E]\\n\\n[\\\\E]\\n\\nA/B [B]\\n\\n[B] B\\\\A\\n\\n[/E]\\n\\n[/I]\\n\\nA\\n\\nA/B\\n\\nA\\n\\nA\\n\\nB\\\\A\\n\\n[\\\\E]\\n\\n[\\\\I]\\n\\n5.6 Basi\\r Fa\\rts about Lambek Cal\\rulus\\n\\nLet\\'s summarize here some meaningful properties for Lambek \\ral\\rulus, whi\\rh is:\\n\\nˆ intuitionisti\\r: only one formula is allowed on the right-hand side of a dedu\\rtion. This\\n\\nmeans there is neither involutive negation, nor disjun\\rtion;\\n\\nˆ linear: so-\\ralled stru\\rtural rules of logi\\rs are not allowed: two equal hypotheses \\ran\\'t\\n\\nbe \\ronsidered as only one, and on the other hand we are not allowed to (cid:16)dupli\\rate(cid:17)\\n\\nhypotheses at will. Lambek \\ral\\rulus is what we \\rall a resour\\re-aware logi\\rs, wherein\\n\\nhypotheses must be \\ronsidered as \\ronsumable resour\\res;\\n\\nˆ non-\\rommutative: hypotheses don\\'t \\rommute among them, that is, the impli\\rit oper-\\n\\nator (cid:16)·(cid:17) in this \\ral\\rulus is not \\rommutative. This is what makes possible the existen\\re\\nof the two (cid:16)impli\\rations(cid:17) (/ and \\\\), the (cid:28)rst one \\ronsuming its right argument, the\\n\\nse\\rond one its left argument.\\n\\nSin\\re Lambek proved a \\rut-elimination theorem for his \\ral\\rulus (see [Lam58℄), among\\n\\nthe many \\ronsequen\\res of the normalization theorems there are the subformula property,\\n\\nthat is:\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n33\\n\\nProposition 5.16 Every formula that o\\r\\rurs in a normal form natural dedu\\rtion proof of\\n\\n\\rut-free sequent \\ral\\rulus proof is either a subformula of the (un\\ran\\rel led) assumptions or of\\n\\nthe \\ron\\rlusion;\\n\\nand de\\ridability for Lambek \\ral\\rulus:\\n\\nProposition 5.17 Derivability in the Lambek Cal\\rulus is de\\ridable.\\n\\nIn fa\\rt, given a sequent to prove in Lambek \\ral\\rulus, \\rut-elimination property authorizes us\\n\\nto look for a \\rut-free proof. But if the sequent \\romes from the appli\\ration of a rule other\\n\\nthat \\rut, this \\ran\\'t but be made in a (cid:28)nite number of di(cid:27)erent ways, and in any \\rase we\\n\\nhave to prove one or two smaller (i.e. with less symbols) sequents. This is enough to prove\\n\\nde\\ridability for Lambek \\ral\\rulus.\\n\\nTheorem 5.14 states that any proof has a normal form and theorem 5.13 that this nor-\\n\\nmal form is unique. This doesn\\'t mean that there is a unique normal form proof for any\\n\\ndedu\\rtion. The following theorem by van Benthem sheds light on this point:\\n\\nTheorem 5.18 (van Benthem) For any sequent\\n\\nA1, . . . , An ⊢ B\\n\\nthere are only (cid:28)nitely many di(cid:27)erent normal form proofs in the Lambek Cal\\rulus.\\n\\nThis is quite an unsatisfa\\rtory result: we still have a one-to-many \\rorresponden\\re be-\\n\\ntween a sequent and its normal proofs. This leads to what is generally known as the problem\\n\\nof spurious ambiguities for Lambek grammars.\\n\\n5.7 Lambek Grammars\\n\\nA Lambek grammar extends the traditional notion of \\rategorial grammars as presented in\\n\\nse\\rtion 5.1 by a whole dedu\\rtive system in the following way:\\n\\nˆ a lexi\\ron assigns to ea\\rh word wi a (cid:28)nite set of types\\n\\nF (wi) = {t1\\n\\ni , . . . , tki\\n\\ni } ⊂ ℘(T p);\\n\\nˆ the language generated by this fully lexi\\ralized grammar is the set of all the sequen\\res\\n\\nw1 · · · wn of words of the lexi\\ron su\\rh that for ea\\rh wi there exists a type ti ∈ F (wi)\\n\\nsu\\rh that\\n\\nFormally:\\n\\nis provable in Lambek \\ral\\rulus.\\n\\nt1, . . . , tn ⊢ s\\n\\nRR n° 0123456789\\n\\n\\x0c34\\n\\nBonato\\n\\nDe(cid:28)nition 5.19 (Lambek grammar) A Lambek grammar is a triple G = hΣ, s, F i, su\\rh\\n\\nthat\\n\\nˆ Σ is a (cid:28)nite set (the vo\\rabulary),\\n\\nˆ s is the distinguished \\rategory (a propositional variable),\\n\\nˆ F : Σ → ℘(T p) is a fun\\rtion whi\\rh maps ea\\rh symbol of the alphabet into the set if its\\n\\ntypes. If F (a) = {A1, . . . , An} we write G : a 7→ A1, . . . , An .\\n\\nFor w ∈ Σ∗, w = a1 · · · an , we say that G a\\r\\repts w if there is a proof in Lambek \\ral\\rulus of\\n\\nA1, . . . , An ⊢ s\\n\\nwith G : ai 7→ Ai for ea\\rh i.\\n\\nThe language generated by a Lambek grammar G is\\n\\nL(G) = {a1 · · · an ∈ Σ∗ | for 1 ≤ i ≤ n, ∃Ai, G : ai 7→ Ai and A1, . . . , An ⊢ s}.\\n\\nExample 5.20 Let Σ = {Mary, \\rooked, the, beans} be our alphabet and s our distin-\\n\\nguished \\rategory. Let\\'s take F su\\rh that\\n\\nMary : np\\n\\ncooked :\\n\\n(np\\\\s)/np\\n\\nthe : np/n\\n: n\\n\\nbeans\\n\\nnp, (np\\\\s)/np, np/n, n ⊢ s\\n\\nThen Mary \\rooked the beans belongs to the language generated by this grammar, be\\rause in\\n\\nLambek \\ral\\rulus we \\ran prove:\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n35\\n\\nWeak generative \\rapa\\rity for asso\\riative Lambek grammars was \\rhara\\rterized (see [Pen97℄)\\n\\nby the following \\relebrated theorem, one of the (cid:28)nest and most re\\rent a\\rhievements in this\\n\\n(cid:28)eld:\\n\\nTheorem 5.21 (Pentus, 1997) The languages generated by asso\\riative Lambek grammars\\n\\nare exa\\rtly the \\rontext-free languages.\\n\\nAnalogously, for non-asso\\riative Lambek grammars Buszkowski proved (see [Bus86℄):\\n\\nTheorem 5.22 (Buszkowski, 1986) The languages generated by non-asso\\riative Lambek\\n\\ngrammars are exa\\rtly the \\rontext-free languages.\\n\\n6 Proofs as Grammati\\ral Stru\\rtures\\n\\nIn this se\\rtion we will introdu\\re the notion of stru\\rture for a senten\\re generated by a Lambek\\n\\ngrammar. On the basis of a re\\rent work by Hans-Joerg Tiede (see [Tie99℄) who proved some\\n\\nimportant theorems about the tree language of proof trees in Lambek \\ral\\rulus, we will adopt\\n\\nas the underlying stru\\rture of a senten\\re in a Lambek grammar a proof of its well-formedness\\n\\nin Lambek \\ral\\rulus. We will see in se\\rtion 9 how this \\rhoi\\re a(cid:27)e\\rts the pro\\ress of learning\\n\\na rigid Lambek grammar on the basis of stru\\rtured positive data.\\n\\n6.1\\n\\n(Partial) Parse Trees for Lambek Grammars\\n\\nJust as a derivation en\\rodes a proof of A1, . . . , An ⊢ B , the notion of parse tree introdu\\red\\nby the following de(cid:28)nition en\\rodes a proof of a1 · · · an ∈ L(G) where G is a Lambek grammar\\nand a1, . . . , an are symbols of its alphabet.\\n\\nDe(cid:28)nition 6.1 Let G = hΣ, s, F i be a Lambek grammar, then\\n\\nˆ if D is a derivation of B from A1, . . . , An , and a1, . . . , an are symbols of alphabet Σ\\nsu\\rh that G : ai 7→ Ai for 1 ≤ i ≤ n, the result of atta\\rhing a1, . . . , an , from left to\\nright in this order, to the undis\\rharged leaf nodes of D is a partial parse tree of G.\\n\\na1\\nA1\\n\\nan\\nAn\\n\\n...\\n\\nD\\n\\nB\\n\\nˆ A parse tree of G is a partial parse tree of G whose root node is labeled by the distin-\\n\\nguished \\rategory s.\\n\\nRR n° 0123456789\\n\\n\\x0c36\\n\\nBonato\\n\\nIf a1 · · · an is the string of symbols atta\\rhed to the leaf nodes of a partial parse tree P ,\\na1 · · · an is said to be the yield of P . If a parse tree P of G yields a1 · · · an , then P is \\ralled\\na parse of a1 · · · an in G.\\n\\nExample 6.2 Let Σ = {he, him, likes} be our alphabet and let G a Lambek grammar su\\rh\\n\\nthat\\n\\nThen the fol lowing is a parse for he likes him:\\n\\nG : likes\\n\\n7→ (np\\\\s)/np,\\n\\nhe 7→ s/(np\\\\s),\\nhim 7→ (s/np)\\\\s.\\n\\nlikes\\n(np\\\\s)/np\\n\\n[np]\\n\\nhe\\ns/(np\\\\s)\\n\\n/E\\nnp\\\\s\\n\\n/E\\ns\\n\\n/I\\ns/np\\n\\nhim\\n(s/np)\\\\s\\n\\n\\\\E\\n\\ns\\n\\n6.2 Tree Languages and Automata\\n\\nIn order to fully appre\\riate the pe\\ruliarity of Lambek grammars with respe\\rt to their strong\\n\\ngenerative \\rapa\\rity, we re\\rall here some basi\\r de(cid:28)nitions about the notion of tree language\\n\\nas presented in [Tie99℄.\\n\\nDe(cid:28)nition 6.3 (Trees and tree languages) A tree is a term over a (cid:28)nite signature Σ\\n\\rontaining fun\\rtion and \\ronstant symbols. The set of n-ary fun\\rtion symbols in Σ wil l be\\ndenoted by Σn . The set of al l terms over Σ wil l be denoted by TΣ ; a subset of TΣ is \\ral led a\\n\\ntree language or a forest.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n37\\n\\nDe(cid:28)nition 6.4 (Yield of a tree) The yield of a tree t is de(cid:28)ned by\\n\\nyield(c) = c,\\n\\nfor c ∈ Σ0\\n\\nyield(f (t1, . . . , tn)) = yield(t1), . . . , yield(tn),\\n\\nfor f ∈ Σn, n > 0\\n\\nThus, the yield of a tree is the string of symbols o\\r\\rurring as its leaves.\\n\\nDe(cid:28)nition 6.5 (Root of a tree) The root of a tree t is de(cid:28)ned by\\n\\nroot(c) = c,\\nroot(f (t1, . . . , tn)) = f,\\n\\nfor c ∈ Σ0\\nfor f ∈ Σn, n > 0.\\n\\nIn the following subse\\rtions three in\\rreasingly more powerful \\rlasses of tree languages\\n\\nare presented: lo\\ral, regular and \\rontext-free tree languages. Note that even if the names\\n\\nfor these \\rlasses of tree languages are the same as those for \\rlasses of string languages, their\\n\\nmeaning is very di(cid:27)erent.\\n\\n6.2.1 Lo\\ral Tree Languages\\n\\nWe \\ran think of a lo\\ral tree language as a tree language whose membership problem \\ran be\\n\\nde\\rided by just looking at some very simple (lo\\ral) properties of trees. A formalization of\\n\\nsu\\rh an intuitive notion is given by the following de(cid:28)nitions:\\n\\nDe(cid:28)nition 6.6 (Fork of a tree) The fork of a tree t is de(cid:28)ned by\\n\\nf ork(c) = ∅,\\n\\nfor c ∈ Σ0\\n\\nf ork(f (t1, . . . , tn)) = {hf, root(t1), . . . , root(tn)i} ∪\\n\\nf ork(ti)\\n\\nn\\n\\n[i=1\\n\\nDe(cid:28)nition 6.7 (Fork of a tree language) For a tree language L, we de(cid:28)ne\\n\\nf ork(L) =\\n\\nf ork(t)\\n\\n[t∈L\\n\\nNote that, sin\\re Σ is (cid:28)nite, f ork(TΣ) is always (cid:28)nite.\\n\\nDe(cid:28)nition 6.8 (Lo\\ral tree language) A tree language L ⊆ TΣ is lo\\ral if there are sets\\nR ⊆ Σ and E ⊆ f ork(TΣ), su\\rh that, for al l t ∈ TΣ , t ∈ L i(cid:27) root(t) ∈ R and f ork(t) ⊆ E .\\n\\nThat\\rher (see [Tha67℄) \\rhara\\rterized the relation between lo\\ral tree languages and the\\n\\nderivation trees of \\rontext-free string grammars by the following\\n\\nTheorem 6.9 (That\\rher, 1967) S is the set of derivation trees of some \\rontext-free string\\n\\ngrammar i(cid:27) S is lo\\ral.\\n\\nRR n° 0123456789\\n\\n\\x0c38\\n\\nBonato\\n\\n6.2.2 Regular Tree Languages\\n\\nAmong many di(cid:27)erent equivalent de(cid:28)nitions for regular tree languages, we follow Tiede\\'s\\n\\napproa\\rh in \\rhoosing the following one, based on (cid:28)nite tree automata.\\n\\nDe(cid:28)nition 6.10 (Finite tree automaton) A (cid:28)nite tree automaton is a quadruple hΣ, Q, q0, ∆i,\\n\\nsu\\rh that\\n\\nˆ Σ is a (cid:28)nite signature,\\n\\nˆ Q is a (cid:28)nite set of unary states,\\n\\nˆ q0 ∈ Q is the start state,\\n\\nˆ ∆ is a (cid:28)nite set of transition rules of the fol lowing type:\\n\\nq(c) → c for c ∈ Σ0\\n\\nq(f (v1, . . . , vn)) → f (q1(v1), . . . , qn(vn)) for f ∈ Σn, q, q1, . . . , qn ∈ Q\\n\\nWe \\ran think of a (cid:28)nite tree automaton as a devi\\re whi\\rh s\\rans non-deterministi\\rally a tree\\n\\nfrom root to frontier. It a\\r\\repts a tree if it su\\r\\reeds in reading the whole tree, it reje\\rts it\\n\\notherwise.\\n\\nIn order to de(cid:28)ne the notion of tree language a\\r\\repted by a regular tree automaton we\\n\\nneed to de(cid:28)ne the transition relation for (cid:28)nite tree automata.\\n\\nDe(cid:28)nition 6.11 A \\rontext is a term over Σ ∪ {x} \\rontaining the zero-ary term x exa\\rtly\\n\\nDe(cid:28)nition 6.12 Let M = hΣ, Q, q0, ∆i be a (cid:28)nite tree automaton, the derivation relation\\n\\nis de(cid:28)ned by t ⇒M t′\\n\\nif for some \\rontext s and some t1, . . . , tn ∈ TΣ , there is a rule in ∆\\n\\n⇒M ⊆ TQ∪Σ × TQ∪Σ\\n\\nq(f (v1, . . . , vn)) → f (q1(v1), . . . , qn(vn))\\n\\nt = s[x 7→ q(f (t1, . . . , tn))]\\nt′ = s[x 7→ f (q1(t1), . . . , qn(tn))].\\n\\non\\re.\\n\\nand\\n\\nIf we use ⇒∗\\ntomaton M a\\r\\repts a term t ∈ TΣ if q0(t) ⇒∗\\n\\nM to denote the re(cid:29)exive, transitive \\rlosure of ⇒M , we say that a (cid:28)nite au-\\nM t. The tree language a\\r\\repted by a (cid:28)nite tree\\n\\nautomaton M is\\n\\n{t ∈ TΣ | q0(t) ⇒∗\\n\\nM t}.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n39\\n\\nDe(cid:28)nition 6.13 (Regular tree language) A tree language is regular if it is a\\r\\repted by\\n\\na (cid:28)nite tree automaton.\\n\\nlanguages:\\n\\nThe following theorem (see [Koz97℄) de(cid:28)nes the relation between lo\\ral and regular tree\\n\\nTheorem 6.14 Every lo\\ral tree language is regular.\\n\\nwhile the following (see [GS84℄) establishes a relation between regular tree languages and\\n\\n\\rontext-free string languages:\\n\\nTheorem 6.15 The yield of any regular tree language is a \\rontext-free string language.\\n\\n6.2.3 Context-free Tree Languages\\n\\nThe (cid:28)nal step in the de(cid:28)nition of more and more powerful tree language \\rlasses is made\\n\\npossible by introdu\\ring the notion of pushdown tree automaton. Again, we sti\\rk to Tiede\\'s\\n\\napproa\\rh in \\rhoosing Guesserian\\'s useful de(cid:28)nition (see [Gue83℄):\\n\\nDe(cid:28)nition 6.16 (Pushdown tree automaton) A pushdown tree automaton is a system\\n\\nhΣ, Γ, Q, q0, Z0, ∆i, su\\rh that\\n\\nˆ Σ is a (cid:28)nite signature (the input signature),\\n\\nˆ Γ is a (cid:28)nite signature (the pushdown signature; we assume Σ ∩ Γ = ∅),\\n\\nq(f (v1, . . . , vn), E(x1, . . . , xm)) → f (q1(v1, γ1), . . . , qn(vn, γn)),\\n\\nq(v, E(x1, . . . , xm)) → q′(v, γ′),\\n\\nq(c) → c\\n\\nˆ Q is a (cid:28)nite set of binary states,\\n\\nˆ q0 ∈ Q is the start state,\\n\\nˆ Z0 ∈ Γ is the initial sta\\rk symbol,\\n\\nˆ ∆ is a (cid:28)nite set of rules of the form\\n\\nwith\\n\\n(cid:21) q, q′, q1, . . . , qn ∈ Q,\\n(cid:21) c ∈ Σ0 ,\\n(cid:21) f ∈ Σn , n > 0,\\n(cid:21) E ∈ Γm ,\\n(cid:21) γ′, γ1, . . . , γn ∈ TΓ∪{x1,...,xm} .\\n\\nRR n° 0123456789\\n\\n\\x0c40\\n\\nBonato\\n\\nThe transition relation for pushdown tree automata ⇒ \\ran be de(cid:28)ned straightforwardly\\n\\nas a generalization of de(cid:28)nition 6.12. A term t is a\\r\\repted by a pushdown automaton if\\n\\nq0(t, Z0) ⇒∗ t, where ⇒∗\\n\\nis the re(cid:29)exive, transitive \\rlosure of ⇒.\\n\\nDe(cid:28)nition 6.17 (Context-free tree language) The language a\\r\\repted by a pushdown\\n\\ntree automaton is \\ral led a \\rontext-free tree language.\\n\\nThe relationship between regular and \\rontext-free tree languages is exempli(cid:28)ed by the fol-\\n\\nlowing proposition:\\n\\nfree.\\n\\nProposition 6.18 The interse\\rtion of a regular and a \\rontext-free tree language is \\rontext-\\n\\nWe know that the yield of a regular tree language is a \\rontext-free string language: there is\\n\\na similar \\ronne\\rtion between the \\rlass of \\rontext-free tree languages and the \\rlass of indexed\\n\\nlanguages, as stated by the following\\n\\nProposition 6.19 The yield of any \\rontext-free tree language is an indexed string language.\\n\\nIndexed languages have been proposed as an upper bound of the \\romplexity of natural lan-\\n\\nguages, after it was shown that \\rertain phenomena in natural languages \\rannot be des\\rribed\\n\\nwith \\rontext-free grammars (see [Gaz88℄).\\n\\n6.3 Proof Trees as Stru\\rtures for Lambek Grammars\\n\\nIn [Tie99℄ Hans-Joerg Tiede proposes, in \\rontrast with a previous approa\\rh by Buszkowski,\\n\\nto take as the stru\\rture underlying a senten\\re generated by a Lambek grammar, one of the\\n\\nin(cid:28)nite proof trees of the dedu\\rtion A1, . . . , An ⊢ s, where A1, . . . , An is a sequen\\re of types\\nassigned by the grammar to ea\\rh symbol, and s is the distinguished atomi\\r \\rategory.\\n\\nFollowing Tiede\\'s approa\\rh, we give the following\\n\\nDe(cid:28)nition 6.20 (Proof tree) A proof tree for a Lambek grammar is a term over the\\n\\nsignature Σ = {[/E], [\\\\E], [/I], [\\\\I], [ID]} where\\n\\nˆ [ID] is the 0-ary fun\\rtion symbol,\\n\\nˆ [/E] and [\\\\E] are the binary fun\\rtion symbols,\\n\\nˆ [/I] and [\\\\I] are the unary fun\\rtion symbols.\\n\\nThe terms over this signature represent proof trees that neither have information about the\\n\\nformulas for whi\\rh they are a proof, nor about the strings that are generated by a gram-\\n\\nmar using this proof. These terms represent proofs unambiguously, sin\\re the assumption\\n\\ndis\\rharged by an introdu\\rtion rule is univo\\rally determined by the position of the \\rorre-\\n\\nsponding [/I] or [\\\\I] fun\\rtion symbol in the proof tree.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n41\\n\\nExample 6.21 The term t = [\\\\I]([/E]([ID], [ID])) is an example of wel l-formed term over\\n\\nthis signature. There\\'s no need for additional information about the dis\\rharged assumption\\n\\nsin\\re, as we \\ran see from the tree-like representation of the term, the dis\\rharged assumption\\n\\nis unambiguously identi(cid:28)ed.\\n\\n[ID]\\n\\nID\\n\\n/E\\n\\n\\\\I\\n\\nThe following terms are examples of not well-formed proof trees for the tree language\\n\\ngenerated by any Lambek grammar:\\n\\nˆ [\\\\E](x, [/I](y)). Sin\\re the ma jor premise of the \\\\E fun\\rtion symbol is something with\\n\\na (. . .)\\\\(. . .) shape, there\\'s no way to redu\\rt that term by a \\\\E rule;\\n\\nˆ [/E[([\\\\I](x), y). Analogous to the previous situation;\\n\\nˆ [\\\\I]([\\\\E](x, [ID])) if the term x does not \\rontain at least two un\\ran\\relled assumptions;\\n\\nˆ [/I]([/E]([ID], x)), if the term x does not \\rontain at least two un\\ran\\relled assumptions.\\n\\nBy taking a proof tree as the stru\\rture of a senten\\res generated by Lambek grammars,\\n\\nTiede proved some important results about their strong generative \\rapa\\rity, that is, the\\n\\nset of the stru\\rtures assigned by a grammar to the senten\\res it generates. Sin\\re strong\\n\\ngenerative \\rapa\\rity \\ran provide a formal notion of the linguisti\\r \\ron\\rept of stru\\rture of a\\n\\nsenten\\re, this result justi(cid:28)es the \\rurrent interest toward Lambek Grammars as a promising\\n\\nmathemati\\ral tool for linguisti\\r purposes.\\n\\nTheorem 6.22 (Tiede, 1999) The set of wel l-formed proof trees of the Lambek Cal\\rulus\\n\\nTheorem 6.23 (Tiede, 1999) The set of proof trees of the Lambek Cal\\rulus is a \\rontext-\\n\\nThese two theorems show that the language of proof trees is properly a \\rontext-free tree\\n\\nIn parti\\rular, these theorems show that Lambek grammars are more powerful, with re-\\n\\nspe\\rt to strong generative \\rapa\\rity, than \\rontext-free grammars, whose stru\\rture language\\n\\nis not regular.\\n\\nfree tree language.\\n\\nlanguage.\\n\\nRR n° 0123456789\\n\\n\\x0c42\\n\\nBonato\\n\\nis a lo\\ral tree language as shown in theorem 6.9.\\n\\nWe \\ran easily introdu\\re the notion of normal form proof tree by simply extending the\\n\\nnotion of normal form proof as presented in de(cid:28)nition 5.15. We \\ran say that for normal\\n\\nform trees, in addition to the rules that prohibit terms of the form\\n\\nwe have rules that prohibit terms of the form\\n\\nand terms of the form\\n\\n[\\\\E](x, [/I](y)),\\n\\n[/E]([\\\\I](x), y),\\n\\n[\\\\E](x, [\\\\I](y))\\n\\n[/E]([/I](x), y)\\n\\n[/I]([/E](x, [ID]))\\n[\\\\I]([\\\\E]([ID], y))\\n\\nwhi\\rh \\rorrespond to β -redexes and η -redexes, respe\\rtively, as one \\ran easily see from de(cid:28)-\\n\\nnition 5.15.\\n\\nWe \\ran easily extend to the formalism of proof trees the (cid:16)redu\\rtion rules(cid:17) we\\'ve seen in\\n\\nse\\rtion 5.5 to get a normal form proof tree out of a non-normal one.\\n\\n[  ]\\n\\nt2\\n\\n\\\\I\\n\\nt1\\n\\n\\\\E\\n\\nt1\\n\\n[  ]\\n\\nt2\\n\\nt1\\n\\n/I\\n\\n[  ]\\n\\n/E\\n\\n®\\n\\n,\\n\\nt2\\n\\n®\\n\\nt2\\n\\n[  ]\\n\\nt1\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n43\\n\\nt\\n\\nt\\n\\nt\\n\\n,\\n\\n®\\n\\n[  ]\\n\\nt\\n\\n[  ]\\n\\n®\\n\\n\\\\E\\n\\n\\\\I\\n\\n/E\\n\\n/I\\n\\nAs a \\rorollary of theorem 6.22, Tiede proves that\\n\\nTheorem 6.24 (Tiede, 1999) The set of normal form proof trees of the Lambek Cal\\rulus\\n\\nis not regular,\\n\\nwhi\\rh, together with\\n\\nlanguage\\n\\nTheorem 6.25 The set of normal form proofs of the Lambek Cal\\rulus is a \\rontext-free tree\\n\\nshows that the tree language of normal form proof trees of Lambek Cal\\rulus is properly a\\n\\n\\rontext-free tree language.\\n\\n6.4 Proof-tree Stru\\rtures\\n\\nGiven a Lambek grammar G, a proof-tree stru\\rture over its alphabet Σ is a unary-binary\\nbran\\rhing tree whose leaf nodes are labeled by either [ID] (these are \\ralled \"dis\\rharged leaf\\nnodes\") or symbols of Σ and whose internal nodes are labeled by either \\\\E, /E, \\\\I , or /I .\\n\\nThe set of proof-tree stru\\rtures over Σ is denoted ΣP\\n\\nto mean proof-tree stru\\rture. A set of proof-tree stru\\rtures over Σ is \\ralled a stru\\rture\\nlanguage over Σ.\\n\\n. Often we will simply say `stru\\rture\\'\\n\\nExample 6.26 The fol lowing is an example of a proof-tree stru\\rture for the senten\\re he\\n\\nlikes him seen in example 6.2:\\n\\nRR n° 0123456789\\n\\n\\x0c44\\n\\nBonato\\n\\nlikes\\n\\n[ID]\\n\\nhe\\n\\n/E\\n\\n/E\\n\\n/I\\n\\nhim\\n\\n/E\\n\\nLet G be a Lambek grammar, and let P be a partial parse tree of G. The result of\\nstripping P of its type labels is a proof-tree stru\\rture, that is \\ralled the proof-tree stru\\rture\\nof P . If T is the stru\\rture of a parse tree P , we say that P is a parse of T .\\n\\nWe say that a Lambek grammar G generates a stru\\rture T if and only if for some parse\\ntree P of G, T is the stru\\rture of P . The set of stru\\rtures generated by G is \\ralled the\\n(proof-tree) stru\\rture language of G and is denoted PL(G). In order to distinguish L(G),\\nthe language of G, from PL(G), its stru\\rture language, we often \\rall the former the string\\nlanguage of G.\\n\\nThe yield of a proof-tree stru\\rture T is the string of symbols a1, . . . , an labeling the\\nundis\\rharged leaf nodes of T , from left to right in this order. The yield of T is denoted\\nyield(T ). Note that L(G) = {yield(T ) | T ∈ PL(G)}.\\n\\n6.5 De\\ridable and Unde\\ridable Problems about\\n\\nLambek Grammars\\n\\nSin\\re, as stated in by theorem 5.17, Lambek \\ral\\rulus is de\\ridable, the universal membership\\n\\nproblem (cid:16)s ∈ L(G)(cid:17) is de\\ridable for any senten\\re s and any Lambek grammar G.\\n\\nOn the other hand, the questions (cid:16)L(G1) = L(G2)(cid:17) and (cid:16)L(G1) ⊆ L(G2)(cid:17) for arbitrary\\nLambek grammars G1 and G2 are unde\\ridable, be\\rause the same questions are unde\\ridable\\n\\nfor \\rontext-free grammars and there exists an e(cid:27)e\\rtive pro\\redure for \\ronverting a \\rontext-\\n\\nfree grammar G′\\n\\nto a Lambek grammar G su\\rh that L(G′) = L(G).\\n\\nGiven a proof-tree stru\\rture t the question (cid:16)t ∈ PL(G)(cid:17) is de\\ridable. In fa\\rt, as shown\\n\\nby Tiede in 6.23, every proof tree language of a Lambek Grammar is a \\rontext-free tree\\n\\nlanguage; and that problem is de\\ridable for \\rontext-free tree languages (you just have to\\n\\nrun the pushdown tree automata on t).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n45\\n\\nUnfortunately, the question (cid:16)PL(G1) ⊆ PL(G2)(cid:17) has been proved de\\ridable only for\\nG1, G2 non-asso\\riative Lambek grammars. Whether it is de\\ridable or not for (asso\\riative)\\n\\nLambek grammars is still an open question and the sub je\\rt of a\\rtive resear\\rh in this (cid:28)eld.\\n\\n6.6 Substitutions\\n\\nIn this se\\rtion we introdu\\re the notion of a Lambek grammar being a substitution instan\\re\\n\\nof another. Besides, we de(cid:28)ne a notion of size of a Lambek grammar that will be de\\risive\\n\\nin our proof of learnability for Rigid Lambek Grammars presented in se\\rtion 9.4.\\n\\nFirst of all, let\\'s de(cid:28)ne what we mean when we say that a Lambek grammar is subset of\\n\\nanother one:\\n\\nDe(cid:28)nition 6.27 Let G1 , G2 be Lambek grammars; we say that G1 ⊆ G2 if and only if for\\nany a ∈ Σ su\\rh that G1 : a 7→ A we have also G2 : a 7→ A.\\n\\nExample 6.28 Let {Francesca, loves, Paolo} ⊆ Σ and let\\n\\nG1 : Francesca 7→ np\\n\\nloves\\n\\n7→ np\\\\s\\n\\nG2 : Francesca 7→ np\\n\\n7→ np\\\\s, np\\\\(s/np)\\n\\nloves\\nPaolo 7→ np\\n\\nObviously, G1 ⊆ G2\\n\\nDe(cid:28)nition 6.29 A substitution is a fun\\rtion σ : V ar → T p that maps variables to types.\\n\\nWe \\ran extend it to a fun\\rtion from types to types by setting\\n\\nσ(t) = t\\n\\nσ(A/B) = σ(A)/σ(B)\\nσ(A\\\\B) = σ(A)\\\\σ(B)\\n\\nfor al l A, B ∈ T p.\\n\\nWe use the notation {x1 7→ A1, . . . , xn 7→ An} to denote the substitution σ su\\rh that\\n\\nσ(x1) = A1, . . . , σ(xn) = An and σ(y) = y for all other variables y .\\n\\nExample 6.30 Let σ = {x 7→ x\\\\y, y 7→ s, z 7→ s/(s/x)}. Then\\n\\nσ((s/x)\\\\y) = (s/(x\\\\y))\\\\t\\n\\nand\\n\\nσ(((s/x)\\\\y)/(x/z)) = ((s/(x\\\\y))\\\\s)/((x\\\\y)/(s/(s/x))).\\n\\nRR n° 0123456789\\n\\n\\x0c46\\n\\nBonato\\n\\nThe following de(cid:28)nition introdu\\re the notion of a Lambek grammar being a substitution\\n\\ninstan\\re of another:\\n\\nDe(cid:28)nition 6.31 Let G = hΣ, s, F i be a Lambek grammar, and σ a substitution. Then σ[G]\\ndenotes the grammar obtained by applying σ in the type assignment of G, that is:\\n\\nσ[G] is \\ral led a substitution instan\\re of G.\\n\\nσ[G] = hΣ, s, σ · F i\\n\\nIt easy to prove also for Lambek grammars this straightforward but important fa\\rt that\\n\\nwas (cid:28)rst proved for CCGs in [BP90℄\\n\\nProposition 6.32 If σ[G1] ⊆ G2 , then the set of proof-tree stru\\rtures generated by G1 is a\\nsubset of the set of proof-tree stru\\rtures generated by G2 , that is PL(G1) ⊆ PL(G2).\\n\\nProof. Suppose σ[G1] ⊆ G2 . Let T ∈ PL(G1) and let P be a parse of T in G1 . Let σ[P]\\nthe result of repla\\ring ea\\rh type label A of P by σ(A). Then it is easy to see that σ[P] is a\\nparse of T in G2 . Therefore, T ∈ PL(G2).\\n\\nCorollary 6.33 If σ[G1] ⊆ G2 , then L(G1) ⊆ L(G2).\\n\\nProof. Immediate from the previous proposition and the remark at the end of se\\rtion 6.4.\\n\\nA substitution that is a one-to-one fun\\rtion from V ar to V ar is \\ralled a variable renam-\\ning. If σ is a variable renaming, then G and σ[G] are \\ralled alphabeti\\r variants. Obviously\\n\\ngrammars that are alphabeti\\r variants have exa\\rtly the same shape and are identi\\ral for all\\n\\npurposes. Therefore, grammars that are alphabeti\\r variants are treated as identi\\ral.\\n\\nProposition 6.34 Suppose σ1[G1] = G2 and σ2[G2] = G1 . Then G1 and G2 are alphabeti\\r\\n\\nvariants and thus are equal.\\n\\nProof. For ea\\rh symbol c ∈ Σ, σ1 and σ2 provide a one-to-one \\rorresponden\\re between\\n{A | G1 : c 7→ A} and {A | G2 : c 7→ A}. Indeed, if it didn\\'t and, say, {σ1(A) | G1 : c 7→\\nA} ⊂ {A | G2 : c 7→ A}, then σ2[G2] = σ2[σ1[G1]] \\rouldn\\'t be equal to G1 , and likewise\\nfor σ2 . Then, it is easy to see that σ1 ↑ V ar(G1) is a one-to-one fun\\rtion from V ar(G1)\\nonto V ar(G2), and σ2 ↑ V ar(G2) = (σ1 ↑ V ar(G1))−1\\n. One \\ran extend σ1 ↑ V ar(G1) to a\\nvariable renaming σ . Then σ[G1] = σ1[G1] = G2 .\\n\\n6.7 Grammars in Redu\\red Form\\n\\nDe(cid:28)nition 6.35 A substitution σ is said to be faithful to a grammar G if the fol lowing\\n\\n\\rondition holds:\\n\\nfor al l c ∈ dom(G), if G1 : c 7→ A, G1 : c 7→ B , and A 6= B , then σ(A) 6= σ(B).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n47\\n\\nExample 6.36 Let G be the fol lowing grammar\\n\\nG : Francesca 7→ x,\\ndances\\nwell\\n\\n7→ x\\\\s, y\\n7→ y\\\\(x\\\\s).\\n\\nσ1 = {y 7→ x},\\nσ2 = {y 7→ x\\\\s}.\\n\\nLet\\n\\nˆ σ is faithful to G1 ;\\n\\nˆ σ[G1] ⊆ G2 .\\n\\nThen σ1 is faithful to G, while σ2 is not.\\n\\nDe(cid:28)nition 6.37 Let ⊑ be a binary relation on grammars su\\rh that G1 ⊑ G2 if and only if\\nthere exists a substitution σ with the fol lowing properties:\\n\\nFrom the de(cid:28)nition above and proposition 6.34 it\\'s immediate to prove the following:\\n\\nProposition 6.38 ⊑ is re(cid:29)exive, transitive and antisymmetri\\r.\\n\\nDe(cid:28)nition 6.39 For any grammar G, de(cid:28)ne the size of G, size(G), as fol lows:\\n\\nsize(G) =\\n\\n|A|,\\n\\nXc∈Σ XG:c7→A\\n\\nwhere, for ea\\rh type A, |A| is the number of symbol o\\r\\rurren\\res in A.\\n\\nLemma 6.40 If G1 ⊑ G2 , then size(G1) ≤ size(G2),\\n\\nProof. For any type A and any substitution σ , |A| ≤ |σ(A)|. Then the lemma is immediate\\nfrom the de(cid:28)nition of ⊑.\\n\\nCorollary 6.41 For any grammar G, the set {G′ | G′ ⊑ G} is (cid:28)nite.\\n\\nProof. By lemma 6.40, {G′ | G′ ⊑ G} ⊆ {G′ | size(G′) ≤ size(G)}. The latter set must be (cid:28)-\\nnite, be\\rause for any n ∈ N, there are only (cid:28)nitely many grammars G su\\rh that size(G) = n.\\n\\nIf we write G1 ⊏ G2 to mean G1 ⊑ G2 and G1 6= G2 , we have\\n\\nCorollary 6.42 ⊏ is wel l-founded.\\n\\nDe(cid:28)nition 6.43 A grammar G is said to be in redu\\red form if there is no G′\\nG′ ⊏ G and PL(G) = PL(G′).\\n\\nsu\\rh that\\n\\nRR n° 0123456789\\n\\n\\x0c48\\n\\nBonato\\n\\n7 Lambek Grammars as a Linguisti\\r Tool\\n\\n7.1 Lambek Grammars and Syntax\\n\\nAs expli\\ritly stated in the original paper wherein Lambek laid the foundations of the Lambek\\n\\nCal\\rulus, his aim was\\n\\n[...℄ to obtain an e(cid:27)e\\rtive rule (or algorithm) for distinguishing senten\\res from\\n\\nnonsenten\\res, whi\\rh works not only for the formal languages of interest to the\\n\\nmathemati\\ral logi\\rian, but also for natural languages su\\rh as English, or at least\\n\\nfor fragments of su\\rh languages. ( [Lam58℄)\\n\\nThat\\'s why, even if Lambek grammars \\ran be simply \\ronsidered as interesting mathe-\\n\\nmati\\ral ob je\\rts, it will be useful to underline here some properties that make them also an\\n\\ninteresting tool to formalize some phenomena in natural languages.\\n\\nThe importan\\re of Lambek\\'s approa\\rh to grammati\\ral reasoning lies in the development\\n\\nof a uniform dedu\\rtive a\\r\\rount of the \\romposition of form and meaning in natural language:\\n\\nformal grammar is presented as a logi\\r, that is a system to reason about stru\\rtured linguisti\\r\\n\\nstru\\rtures.\\n\\nThe basi\\r idea underlying the notion of Categorial Grammar on whi\\rh Lambek based\\n\\nhis approa\\rh is that a grammar is a formal devi\\re to assign to ea\\rh word (a symbol of\\n\\nthe alphabet of the grammar) or expression (an ordered sequen\\re of words) one or more\\n\\nsynta\\rti\\r types that des\\rribe their fun\\rtion. Types \\ran be \\ronsidered as a formalization of\\n\\nthe linguisti\\r notion of parts of spee\\rh.\\n\\nCCGs assign to ea\\rh symbol a (cid:28)xed set of types, and provide two \\romposition rules to\\n\\nderive the type of a sequen\\re of words out of the types of its \\romponents. Su\\rh a (cid:16)(cid:28)xed\\n\\ntypes(cid:17) approa\\rh leads to some di(cid:30)\\rulties: to formalize some linguisti\\r phenomena we should\\n\\nadd further rules to the two elimination rules de(cid:28)ned for CCGs as des\\rribed in se\\rtion 5.2.\\n\\nIn the following subse\\rtions we present some examples where the dedu\\rtive approa\\rh of\\n\\nLambek grammars leads to more an elegant and \\ronsistent formalization of su\\rh linguisti\\r\\n\\nphenomena.\\n\\nIn the following subse\\rtions we take s as the primitive type of wel l-formed senten\\res in\\n\\nour language and np as the primitive type for noun phrases (su\\rh as John, Mary, he).\\n\\n7.1.1 Transitive verbs\\n\\nTransitive verbs require a name both on their left and right hand sides, as it is apparent\\n\\nfrom the well-formedness of the following senten\\res.\\n\\nnp\\nJohn (\\n\\n(np\\\\s)/np\\n\\nlikes\\n\\nnp\\nMary)\\n\\nnp\\n\\nnp\\\\(s/np)\\n\\nnp\\n\\n(\\n\\n)\\n\\nJohn\\n\\nlikes\\n\\nMary\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n49\\n\\nBoth parenthesizations lead to a derivation of s as type of the whole expression. This would\\n\\nmean that in an CCG we should assign to any transitive verb at least two distin\\rt types:\\n\\n(np\\\\s)/np and np\\\\(s/np).\\n\\nOn the \\rontrary, in a Lambek grammar, sin\\re we \\ran prove both\\n\\nwe \\ran simply assign to a transitive verb the type np\\\\s/np without any further parenthe-\\n\\nand\\n\\nsizations.\\n\\n7.1.2 Pronouns\\n\\nIf we try to assign a proper type to the personal pronoun he we noti\\re that its type is su\\rh\\n\\nthat the following senten\\res are well-formed:\\n\\nWe have two \\rhoi\\res: either we give he the same type as a name (that is, np) or we give it\\nthe type s/(np\\\\s). In the (cid:28)rst \\rase there is a problem: expressions like Jane likes he are\\n\\ronsidered as well-formed senten\\res. So, we assign to he the type s/(np\\\\s).\\n\\nAnalogously, sin\\re the personal pronoun him makes the following senten\\res well-formed:\\n\\n(np\\\\s)/np ⊢ np\\\\(s/np)\\n\\nnp\\\\(s/np) ⊢ (np\\\\s)/np\\n\\nnp\\\\s\\n\\nhe\\n\\nworks,\\n\\nnp\\\\s/np\\n\\nnp\\n\\nhe\\n\\nlikes\\n\\nJane\\n\\nnp\\n\\nnp\\\\s/np\\n\\nJane\\n\\nlikes him\\n\\nnp\\n\\nnp\\\\s\\n\\ns\\\\s/np\\n\\nJane\\n\\nworks\\n\\nfor him,\\n\\nwe assign to him the type (s/np)\\\\s (and not type np, sin\\re expressions like him likes John\\n\\nwould be well-formed).\\n\\nSin\\re a pronoun is, a\\r\\rording to its own de(cid:28)nition, something that (cid:16)stands for a noun(cid:17),\\n\\nwe wish that in our grammar ea\\rh o\\r\\rurren\\re of a pronoun \\rould be repla\\red by a name\\n\\n(while the \\ronverse is not always true): but this means that any name (say, John, of type\\n\\nnp) should also be assigned the type of he and him, that is, respe\\rtively, type s/(np\\\\s) and\\ntype (s/np)\\\\s. In other words, we need something that a\\r\\rounts for a type-raising. But\\n\\nsin\\re in Lambek Cal\\rulus we \\ran prove\\n\\nnp ⊢ s/(np\\\\s)\\nnp ⊢ (s/np)\\\\s\\n\\nfor any np and s, a Lambek grammar provides a very natural formalization of the relationship\\n\\nbetween names and pronouns: while a name \\ran always be substituted to a pronoun in a\\n\\nRR n° 0123456789\\n\\n\\x0c50\\n\\nBonato\\n\\nsenten\\re (and the type-raising derivation guarantees that a name \\ran always (cid:16)behave like(cid:17)\\n\\na pronoun if we need it to), the \\ronverse is not true (the \\ronverse of the type-raising proof\\n\\ndoesn\\'t hold in Lambek Cal\\rulus). The proof of the (cid:28)rst dedu\\rtion is reported in example\\n\\n5.10 as a derivation in a Lambek grammar.\\n\\n7.1.3 Adverbs\\n\\nIf we look for the proper type for adverbs like here we \\ran \\ronsider the well-formed senten\\re\\n\\nJohn works here. We \\ran \\rhoose between two possible parenthesizations here, that is:\\n\\nThe (cid:28)rst one suggests for here the type s\\\\s, while the se\\rond one the type (np\\\\s)\\\\(np\\\\s).\\n\\nThe good news is that, while in a CCG we should assign ea\\rh adverb at least two di(cid:27)erent\\n\\ntypes, in a Lambek grammar we \\ran prove that\\n\\nthat is to say, in Lambek grammars any adverbial expression of type s\\\\s has also type\\n(np\\\\s)\\\\(np\\\\s). More generally, we \\ran show that in Lambek Cal\\rulus\\n\\nnp\\n\\nnp\\\\s\\n\\n(\\n\\nJohn\\n\\nworks ) here\\n\\nnp\\nJohn (\\n\\nnp\\\\s\\nworks here)\\n\\ns\\\\s ⊢ (np\\\\s)\\\\(np\\\\s)\\n\\nx\\\\y ⊢ (z\\\\x)\\\\(y\\\\x)\\nx/y ⊢ (x/z)/(y/z).\\n\\n7.1.4 Hypotheti\\ral reasoning\\n\\nIn the following example, senten\\res s, noun phrases np, \\rommon nouns n, and propositions\\nphrases pp are taken to be (cid:16)\\romplete expressions(cid:17), whereas the verb dan\\res, the determiner\\n\\nthe and the preposition with are \\rategorized as in\\romplete with respe\\rt to these \\romplete\\n\\nphrases.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n51\\n\\nExample 7.1 Here is the derivation for the senten\\re Fran\\res\\ra dan\\res with the boy.\\n\\nthe\\nnp/n\\n\\nboy\\nn\\n\\nwith\\npp/np\\n\\n/E\\nnp\\n\\ndances\\n((np/s)/pp\\n\\n/E\\npp\\n\\nFrancesca\\nnp\\n\\n/E\\nnp\\\\s\\n\\n\\\\E\\ns\\n\\nThis is an example of grammati\\ral reasoning where, on the basis of the types we assigned\\n\\nto ea\\rh word, we infer the well-formedness of a sequen\\re of words. On the other hand we\\n\\n\\ran assume a di(cid:27)erent perspe\\rtive: knowing that a senten\\re is well-formed, what \\ran be\\n\\nsaid about the type of its \\romponents? In the words of Lambek: (cid:16)Given the information\\n\\nabout the \\rategorization of a \\romposite stru\\rture, what \\ron\\rlusions \\rould be draw about\\n\\nthe \\rategorization of its parts?(cid:17) ( [Lam58℄). That\\'s where the following inferen\\re patterns\\n\\n\\rome into play:\\n\\nfrom Γ, B ⊢ A,\\nfrom B, Γ ⊢ A,\\n\\ninfer Γ ⊢ A/B,\\ninfer Γ ⊢ B\\\\A\\n\\nwhi\\rh gives a linguisti\\r interpretation of the role of the (cid:16)introdu\\rtion(cid:17) rules. That\\'s what is\\n\\ndone in the following derivation whi\\rh allows us to infer that the expression the boy Fran\\res\\ra\\n\\ndan\\res with is of type np:\\n\\nRR n° 0123456789\\n\\n\\x0c52\\n\\nBonato\\n\\nwith\\npp/np\\n\\n[np]\\n\\ndances\\n((np\\\\s)/pp\\n\\n/E\\npp\\n\\nFrancesca\\nnp\\n\\n/E\\nnp\\\\s\\n\\n\\\\E\\ns\\n\\n/I\\ns/np\\n\\nwhom\\n(n\\\\n)/(s/np)\\n\\nboy\\nn\\n\\n/E\\nn\\\\n\\n\\nthe\\nnp/n\\n\\n\\\\E\\nn\\n\\n/E\\nnp\\n\\nSin\\re the relative pronoun whom (of type (n\\\\n)/(s/np)) wants to enter into \\romposition\\non its right with the relative \\rlause body, we\\'d like to assign type s/np to the latter. In\\norder to show that Fran\\res\\ra dan\\res with is indeed of type s/np, we make a hypotheti\\ral\\nassumption and suppose to have a (cid:16)ghost word(cid:17) of type np on its right. It\\'s easy to derive\\nthe \\rategory s for the senten\\re Fran\\res\\ra dan\\res with np. By withdrawing the hypotheti\\ral\\nnp assumption, we \\ron\\rlude that Fran\\res\\ra dan\\res with has type s/np.\\n\\nWe \\ran say that the \\ran\\relled hypothesis is the analogous of a (cid:16)tra\\re(cid:17) à la Chomsky\\n\\nmoving whom before Fran\\res\\ra.\\n\\n7.1.5 Transitivity\\n\\nIn the framework of CCGs a di(cid:30)\\rulty arises when we try to show the well-formedness of\\n\\nso some authors proposed to introdu\\re two new rules, whi\\rh are often referred to as `tran-\\n\\nsitivity rules\\':\\n\\ns/(np\\\\s)\\n\\nnp\\\\s/np\\n\\n(s/np)\\\\s\\n\\nhe\\n\\nlikes\\n\\nhim\\n\\n(x/y)(y/z) → x/z,\\n(x\\\\y)(y\\\\z) → x\\\\z\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n53\\n\\nIt\\'s easy to show that su\\rh rules are derivable in Lambek Cal\\rulus, as we \\ran easily see from\\n\\nthe following proof tree:\\n\\ny/z\\n\\n[z]\\n\\nx/y\\n\\n/E\\ny\\n\\n/E\\nx\\n\\nI/\\nx/z\\n\\n7.2 Lambek Grammars and Montague Semanti\\rs\\n\\nFrom a linguisti\\r point of view, one of the main reasons of interest in Lambek grammars lies\\n\\nin the natural interfa\\re that proof-tree stru\\rtures provide for Montague-like semanti\\rs. Just\\n\\nlike Curry-Howard isomorphism shows that simply typed λ-terms \\ran be seen as proofs in\\n\\nintuitionisti\\r logi\\rs, and vi\\re-versa, synta\\rti\\ral analysis of a senten\\re in a Lambek grammar\\n\\nis a proof in Lambek \\ral\\rulus, whi\\rh is naturally embedded into intuitionisti\\r logi\\rs. Indeed,\\n\\nif we read B/A and A\\\\B like the intuitionisti\\r impli\\ration A → B , every rule in Lambek\\n\\n\\ral\\rulus is a rule of intuitionisti\\r logi\\rs.\\n\\nIn order to fully appre\\riate this relation between syntax and semanti\\rs whi\\rh is par-\\n\\nti\\rularly strong for Lambek grammars, we de(cid:28)ne a morphism between synta\\rti\\r types and\\n\\nsemanti\\r types: the latter are formulas of a minimal logi\\rs (where the only allowed \\ronne\\rtor\\n\\nis →, that is, intuitionisti\\r impli\\ration) built on the two types e (entity) and t (truth values).\\n\\n(Synta\\rti\\r type)* = Semanti\\r type\\n\\ns∗\\nsn∗\\nn∗\\n\\n= t (a senten\\re is a proposition)\\n= e (a nominal sintagma denotes an entity)\\n= e → t (a noun is a subset of entities)\\n\\n(A\\\\B)∗ = (B/A)∗ = A∗ → B∗\\n\\nextends (_)∗\\n\\nto every types.\\n\\nThe lexi\\ron asso\\riates also to every word w a λ-term τk for every synta\\rti\\r type tk ∈\\n\\nL(w), su\\rh that the type of τk is pre\\risely t∗\\n\\nk , the semanti\\r type \\rorresponding to that synta\\r-\\n\\nti\\r type. We introdu\\re some \\ronstants for representing logi\\ral operations of quanti(cid:28)\\ration,\\n\\nRR n° 0123456789\\n\\n\\x0c54\\n\\nBonato\\n\\n\\ronjun\\rtion et\\r:\\n\\nConstant\\n\\nType\\n\\n∃\\n∀\\n∧\\n∨\\n⊃\\n\\n(e → t) → t\\n(e → t) → t\\nt → (t → t)\\nt → (t → t)\\nt → (t → t)\\n\\nLet the following be given:\\n\\nof t1, . . . , tn ⊢ s and\\n\\nˆ a synta\\rti\\ral analysis of w1 . . . wn in Lambek \\ral\\rulus, that is to say, a derivation D\\n\\nˆ the semanti\\rs for every word w1, . . . , wn , that is to say, λ-terms τi : t∗\\ni ,\\n\\nthen we get the semanti\\rs of the senten\\re by simply applying the following algorithm:\\n\\nˆ Substitute in D every synta\\rti\\r type with its \\rorresponding semanti\\r image; sin\\re\\n\\nintuitionisti\\r logi\\rs is an extension of Lambek \\ral\\rulus, we get a derivation D∗\\nintuitionisti\\r logi\\r of t∗\\n\\n1, . . . , t∗\\n\\nn ⊢ t = s∗\\n\\n;\\n\\ninto\\n\\nˆ this derivation in intuitionisti\\r logi\\r due to Curry-Howard isomorphism \\ran be seen as\\n\\na simply typed λ-term D∗\\n\\nλ , \\rontaining a free variable xi of type t∗\\n\\ni for every word wi ;\\n\\nˆ in D∗\\n\\nλ repla\\re ea\\rh variable xi with λ-term τi , equally typed with t∗\\ni ;\\n\\nˆ redu\\re the λ-term resulting at the end of the previous step, and we get the semanti\\r\\n\\nrepresentation of the analyzed senten\\re.\\n\\nLet\\'s \\ronsider the following example (taken from [Ret96℄):\\n\\nword Synta\\rti\\r type t\\nSemanti\\r type t∗\\nSemanti\\r representation: a λ-term of type t∗\\n(s/(sn\\\\s))/n\\n(e → t) → ((e → t) → t)\\nλP : e → t λQ : e → t(∃(λx : e(∧(P x)(Qx))))\\n\\nsome\\n\\nsenten\\res n\\n\\ntalkabout\\n\\nthemselves\\n\\ne → t\\nλx : e(senten\\re x)\\nsn\\\\(s/sn)\\ne → (e → t)\\nλx : e λy : e((talkabout x)y)\\n((sn\\\\s)/sn)\\\\(sn\\\\s)\\n(e → (e → t)) → (e → t)\\nλP : e → (e → t)λx : e((P x)x)\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n55\\n\\nFirst of all, we\\'ll prove that Some senten\\res talk about themselves is a well formed-\\n\\nsenten\\re, that is, it belongs to the language generated by the lexi\\ron at issue. This means\\n\\nbuilding a natural dedu\\rtion of:\\n\\n(s/(sn\\\\s))/n, n, sn\\\\(s/sn), ((sn\\\\s)/sn)\\\\(sn\\\\s) ⊢ s.\\n\\nIf we indi\\rate with S, N, T, M the left-hand side of synta\\rti\\r types we get\\n\\nS ⊢ (s/(sn\\\\s))/n N ⊢ n\\n\\nT ⊢ (sn\\\\s)/sn M ⊢ ((sn\\\\s)/sn)\\\\(sn\\\\s)\\n\\nS, N ⊢ s/(sn\\\\s)\\n\\n[/E]\\n\\nT, M ⊢ sn\\\\s\\n\\n[\\\\E]\\n\\n[\\\\E]\\n\\nS, N, T, M ⊢ s\\n\\nBy applying the isomorphism between synta\\rti\\r and semanti\\r types, we get the following\\n\\nare the abbreviations for semanti\\r types asso\\riated\\n\\nintuitionisti\\r proof, where S∗, N ∗, T ∗, M ∗\\nto S, N, T, M :\\n\\nS∗ ⊢ (e → t) → (e → t) → t N ∗ ⊢ e → t\\nS∗, N ∗ ⊢ (e → t) → t\\n\\n[→ E]\\n\\nT ∗ ⊢ e → e → t M ∗ ⊢ (e → e → t) → e → t\\nT ∗, M ∗ ⊢ e → t\\n\\n[→ E]\\n\\nS∗, N ∗, T ∗, M ∗ ⊢ t\\n\\n[→ E]\\n\\nThe λ-term \\roding this proof is simply ((sn)(tm)) of type t, where s, n, t, m are variables\\n\\nof types respe\\rtively S∗, N ∗, T ∗, M ∗\\n\\n.\\n\\nBy repla\\ring these variables with λ-terms of the same types asso\\riated by the lexi\\ron to\\n\\nthe words, we get the following λ-term of type t:\\n\\n((λP λQ (∃ (λx(∧(P x)(Q x)))))(λx (senten\\re x)))\\n((λP λx ((P x)x))(λx λy ((talkabout x)y)))\\n\\n(λQ (∃(λx(∧(senten\\re x)(Q x)))))(λx((talkabout x)x))\\n\\n↓ β\\n\\n↓ β\\n\\n(∃(λx(∧(senten\\re x)((talkabout x)x))))\\n\\nIf we re\\rall that the x in this last term is of type e, the latter redu\\red term represents\\n\\nthe following formula in predi\\rate \\ral\\rulus:\\n\\n∃x : e(senten\\re (x) ∧ talkabout(x, x))\\n\\nwhi\\rh is the semanti\\r representation of the previously analyzed senten\\re.\\n\\nRR n° 0123456789\\n\\n\\x0c56\\n\\nBonato\\n\\n8 Rigid Lambek Grammars\\n\\nIn the present se\\rtion we introdu\\re the notion of rigid Lambek grammar (often referred\\n\\nto as RLG), whose learnability properties will be the sub je\\rt of our inquiry in se\\rtion 9.\\n\\nBasi\\r notions and results presented here are almost trivial extensions of what has already\\n\\nbeen done for rigid CCGs (see [Kan98℄), sin\\re a spe\\ri(cid:28)\\r a spe\\ri(cid:28)\\r theory for rigid Lambek\\n\\ngrammars is still missing.\\n\\n8.1 Rigid and k-Valued Lambek Grammars\\n\\nA rigid Lambek grammar is a triple G = hΣ, s, F i, where Σ and s are de(cid:28)ned like in de(cid:28)nition\\n5.19, while F : Σ ⇀ T p is a partial fun\\rtion that assigns to ea\\rh symbol of the alphabet at\\n\\nmost one type. We \\ran easily generalize the notion of rigid Lambek grammar to the notion\\n\\nof k-valued Lambek grammar by a fun\\rtion F that assigns to ea\\rh symbol of the alphabet\\nat most k types. Formally, F : Σ ⇀\\n\\n.\\n\\nk\\ni=1 T pk\\n\\nLet an alphabet Σ be given. We \\rall Grigid the \\rlass of rigid Lambek grammars over Σ,\\n\\nand Gk−valued the \\rlass of k-valued Lambek grammars over Σ.\\n\\nLet\\'s de(cid:28)ne two \\rlasses of proof-tree stru\\rtures:\\n\\nS\\n\\nPLrigid = {PL(G) | G ∈ Grigid},\\nPLk−valued = {PL(G) | G ∈ Gk−valued}.\\n\\nMembers of PLrigid are \\ralled rigid (proof-tree) stru\\rture languages, and members of PLk−valued\\n\\nare \\ralled k-valued (proof-tree) stru\\rture languages.\\n\\nLet\\'s de(cid:28)ne two \\rlasses of strings:\\n\\nLrigid = {L(G) | G ∈ Grigid},\\nLk−valued = {L(G) | G ∈ Gk−valued}.\\n\\nMembers of Lrigid are \\ralled rigid (string) languages, and members of Lk−valued are \\ralled\\n\\nk-valued (string) languages.\\n\\nExample 8.1 Let {well, Francesca, dances} ⊆ Σ and let G1, G2 be the fol lowing Lambek\\n\\ngrammars:\\n\\nG1 : Francesca 7→ x,\\ndances\\n\\n7→ x\\\\s, y,\\n\\nwell\\n\\n7→ y\\\\(x\\\\s),\\n\\nG2 : Francesca 7→ x,\\ndances\\nwell\\n\\n7→ x\\\\s,\\n7→ (x\\\\s)\\\\(x\\\\s).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n57\\n\\nThen G2 is a rigid grammar, while G1 is not. G1 is a 2-valued grammar.\\n\\nDe(cid:28)nition 8.2 Any type A \\ran be written uniquely in the fol lowing form:\\n\\n(. . . ((p|A1)|A2)| . . .)|An\\n\\nwhere B|C stands for either B/C or C\\\\B and p ∈ P r. For 0 ≤ i ≤ n, we \\ral l the subtype\\n(. . . (p|A1)| . . .)|Ai of A a head subtype of A. p is the head of A and is denoted head(A).\\nAi \\'s are \\ral led argument subtypes of A. The number n is \\ral led the arity of A.\\n\\nThe following propositions are almost trivial extensions to rigid Lambek grammars of\\n\\nanalogous results proved by Kanazawa for CCGs in [Kan98℄. However, they deserve some\\n\\nattention sin\\re they \\ran provide a (cid:28)rst super(cid:28)\\rial insight about properties of RLGs.\\n\\nFirst of all we prove a hierar\\rhy theorem about strong generative \\rapa\\rity of k-valued\\n\\nLambek grammars.\\n\\nProposition 8.3 Let\\n\\na ∈ Σ. For ea\\rh i ≥ 1, let Ti be the fol lowing proof-tree stru\\rture:\\n\\na\\n\\ni times\\n\\na\\n\\n}.    .    .\\n\\na\\n\\n/E\\n\\n/E\\n\\nThen for ea\\rh k ≥ 1,\\n\\n{T1, . . . , Tk} ∈ PLk+1−valued − PLk−valued.\\n\\nThus, for ea\\rh k ∈ N, PLk−valued ⊂ PLk+1−valued .\\n\\nProof. (See [Kan98℄) Let Gk be the following k+1-valued grammar:\\n\\nGk : a 7→ x,\\n\\ns/x,\\n\\n(s/x)/x,\\n\\n.\\n\\n.\\n\\n.\\n\\nk times\\n{z\\nThen one \\ran easily verify that {T1, . . . , Tk} ⊂ PL(Gk).\\n\\n|\\n\\n}\\n\\n(. . . ((s/ x)/x)/ . . .)/x\\n\\n.\\n\\nRR n° 0123456789\\n\\n\\x0c58\\n\\nBonato\\n\\nLet G be a grammar su\\rh that {T1, . . . , Tk} ⊂ PL(G): we will show that G is at least\\n\\nk+1-valued.\\n\\nLet Pi be a parse of Ti in G for 1 ≤ i ≤ k . Then the leftmost leaf of Pi is the ultimate\\nfun\\rtor of Pi , and if we \\rall Ai the type labeling it, we \\ran easily verify that the its arity\\nmust be exa\\rtly i. Thus, i 6= j implies Ai 6= Aj .\\n\\nWe show that there is at least one type B su\\rh that G : a 7→ B and B 6∈ {A1, . . . , Ak}.\\nSin\\re the relation (cid:16)is an argument subtype of (cid:17) is well-founded, there is at least one i su\\rh\\nthat the argument subtypes of Ai are not in {A1, . . . , Ak}. But in order to produ\\re Pi , any\\nargument subtype of Ai must be a type assigned to a by G. Therefore G must be at least\\n\\nk+1-valued.\\n\\nThe proof of proposition 8.3 shows\\n\\nCorollary 8.4 There is no Lambek grammar G su\\rh that PL(G) = ΣP\\n\\n.\\n\\nLemma 8.5 Let G be a rigid Lambek grammar. Then for ea\\rh proof-tree stru\\rture T, there\\n\\nis at most one partial parse tree P su\\rh that T is the stru\\rture of P .\\n\\nProof. By indu\\rtion on the \\ronstru\\rtion of T .\\n\\nIndu\\rtion basis. T = c ∈ Σ. Any partial parse tree P whose stru\\rture is T is a height 0\\ntree whose only node is labeled by the symbol c and a type A su\\rh that G : c 7→ A. Sin\\re\\nG is rigid, there is at most one su\\rh type A. Then P , if it exists, is unique.\\n\\nIndu\\rtion step. There are 4 \\rases to \\ronsider:\\n\\n1. T is the following proof-tree stru\\rture:\\n\\nThen any partial parse tree of G whose stru\\rture is T has the form where P1 and P2\\n\\nT1\\n\\nT2\\n\\n\\\\E\\n\\n\\\\E\\n\\nB\\n\\nP1\\n\\nA\\n\\nP2\\n\\nA\\\\B\\n\\nare partial parse trees of G whose stru\\rtures are T1 and T2 , respe\\rtively. By indu\\rtion\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n59\\n\\nhypothesis, P1 and P2 are unique. This means that the type label B is also uniquely\\ndetermined, so P is also unique.\\n\\n2. Exa\\rtly like Case 1, with /E in pla\\re of \\\\E .\\n\\n3. T is the following proof-tree stru\\rture:\\n\\nThen any partial parse tree of G whose stru\\rture is T has the form where P1 is a\\n\\nT1\\n\\n\\\\I\\n\\nP1\\n\\nB\\n\\n\\\\I\\nA\\\\B\\n\\n[A], G\\n\\npartial parse tree of G whose stru\\rture is T1 . By indu\\rtion hypothesis, P1 is unique.\\nThis means the the type label A\\\\B is uniquely determined, so P is also unique.\\n\\n4. Exa\\rtly like Case 3, with /I in pla\\re of \\\\I .\\n\\nCorollary 8.6 If G is a rigid Lambek grammar, ea\\rh proof-tree stru\\rture T ∈ PL(G) has a\\n\\nunique parse.\\n\\nshown in se\\rtion 6.\\n\\nNote that last \\rorollary doesn\\'t state that if G is rigid, then ea\\rh string s ∈ L(G) has a\\n\\nunique parse: in general for ea\\rh senten\\re there are in(cid:28)nitely many proof trees, as extensively\\n\\nLemma 8.7 Let G be a rigid Lambek grammar. Then for ea\\rh in\\romplete proof-tree stru\\r-\\n\\nture T, there is at most one in\\romplete parse tree P of G su\\rh that T is the stru\\rture of\\nP .\\n\\nProof. See [Kan98℄ trivially extended to Lambek grammars.\\n\\nRR n° 0123456789\\n\\n\\x0c60\\n\\nBonato\\n\\n8.2 Most General Uni(cid:28)ers and ⊔ Operator\\n\\nUni(cid:28)\\ration plays a \\rru\\rial role in automated theorem proving in \\rlassi\\ral (cid:28)rst-order logi\\r and\\n\\nits extensions (see, for example, [Fit96℄ for an exposition of its use in (cid:28)rst-order logi\\r). Sin\\re\\n\\ntypes are just a spe\\rial kind of terms, the notion of uni(cid:28)\\ration applies straightforwardly to\\n\\ntypes.\\n\\nDe(cid:28)nition 8.8 Let A and B be types. A substitution σ is a uni(cid:28)er of A and B if σ(A) =\\nσ(B). A uni(cid:28)er σ is a most general uni(cid:28)er of A and B , if for any other uni(cid:28)er τ of A and\\nB , there exists a substitution η , su\\rh that τ = σ ◦ η , i.e. τ (C) = η(σ(C)), for C = A or\\nC = B .\\n\\nA substitution σ is said to unify a set A of types if for all A1, A2 ∈ A, σ(A1) = σ(A2). We\\nsay that σ uni(cid:28)es a family of sets of types, if σ uni(cid:28)es ea\\rh set in the family.\\n\\nA most general uni(cid:28)er is unique up to `renaming of variables\\'.\\n\\nExample 8.9 Let A \\ronsist of the fol lowing sets:\\n\\nA1 = {x1/x2, x3/x4},\\nA2 = {x5\\\\(x3\\\\t},\\nA3 = {x1\\\\t, x5}.\\n\\nThen the most general uni(cid:28)er of A is:\\n\\nσ = {x3 7→ x1, x4 7→ x2, x5 7→ x1\\\\t}.\\n\\nThere are many di(cid:27)erent e(cid:30)\\rient algorithms for uni(cid:28)\\ration, whi\\rh de\\ride whether a (cid:28)nite\\n\\nset of types has a uni(cid:28)er and, if it does, \\rompute a most general uni(cid:28)er for it. For illustration\\n\\npurposes, we present here a non-deterministi\\r version of an uni(cid:28)\\ration algorithm.\\n\\nOur algorithm uses the notion of disagreement pair. The easiest way to de(cid:28)ne disagree-\\n\\nment pair is to \\ronsider the types to be tree-like:\\n\\nDe(cid:28)nition 8.10 Let A and B be two types. A disagreement pair for A and B is a pair of\\nsubterms of A and B , A′, B′\\nand the path from the root of A to the root\\nof A′\\n\\nis equal to the path from the root of B to the root of B′\\n\\n, su\\rh that A′ 6= B′\\n\\n.\\n\\nThe following, non-deterministi\\r version of the uni(cid:28)\\ration algorithm is taken from [Fit96℄:\\n\\nUnifi\\ration Algorithm.\\n\\nˆ input: two types A and B ;\\n\\nand B are not uni(cid:28)able.\\n\\nˆ output: a most general uni(cid:28)er σ of A, B , if it exists, or a \\rorre\\rt statement that A\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n61\\n\\nLet σ := ǫ\\nWhile σ(A) 6= σ(B) do\\n\\nfor σ(A), σ(B);\\n\\nis a variable, then FAIL;\\n\\nbegin\\n\\n\\rhoose a disagreement pair A′, B′\\nif neither A′\\nnor B′\\nlet x be whi\\rhever of A′, B′\\nand let C be the other one of A′, B′\\nif x o\\r\\rurs in C , then FAIL;\\nlet σ := σ ◦ {x 7→ C};\\n\\nend\\n\\nis a variable (if both are, \\rhoose one)\\n\\nThe previous algorithm present one of many e(cid:30)\\rient algorithms for uni(cid:28)\\ration, so we\\n\\nthe following is a well-de(cid:28)ned notion:\\n\\nDe(cid:28)nition 8.11 We de(cid:28)ne a \\romputable partial fun\\rtion mgu that maps a (cid:28)nite family A\\nof (cid:28)nite sets of types to a most general uni(cid:28)er mgu(A), if A is uni(cid:28)able.\\n\\nThe set Grigid of all rigid Lambek grammars is partially ordered by ⊑.\\n\\nDe(cid:28)nition 8.12 Let G ⊆ Grigid , and let G ∈ G .Then G is \\ral led an upper bound of G if\\nfor every G′ ∈ G , G′ ⊑ G.\\n\\nWe introdu\\re here a new operator among rigid grammars that will be used to prove an\\n\\ninteresting property for our learning algorithm at the end of the (cid:28)fth \\rhapter.\\n\\nDe(cid:28)nition 8.13 Let G1 and G2 be rigid Lambek grammars. We \\ran assume that G1 and\\nG2 have no \\rommon variables (if they do, we \\ran always \\rhoose a suitable alphabeti\\r variant\\nof one of them su\\rh that V ar(G1) ∩ V ar(G2) = ∅). Let\\n\\nA = {{A | G1 ∪ G2 : c 7→ A} | c ∈ dom(G1 ∪ G2)}\\n\\nand let\\n\\nσ = mgu(A).\\n\\nNote that G1 ∪ G2 is a 2-valued grammar. Then we de(cid:28)ne G1 ⊔ G2 as fol lows:\\n\\nG1 ⊔ G2 = σ[G1 ∪ G2].\\n\\nIf A is not uni(cid:28)able, then G1 ⊔ G2 is unde(cid:28)ned.\\n\\nExample 8.14 Let G1 and G2 be the fol lowing rigid Lambek grammars:\\n\\nG1 : a 7→ s/x,\\n\\nb\\nG2 : b\\nc\\n\\n7→ x,\\n\\n7→ y\\\\s,\\n7→ y.\\n\\nRR n° 0123456789\\n\\n\\x0c62\\n\\nBonato\\n\\nThen\\n\\nG1 ⊔ G2 : a 7→ s/(y\\\\s),\\n\\nb\\n\\nc\\n\\n7→ y\\\\s,\\n\\n7→ y.\\n\\nObviously, from de(cid:28)nition 8.13, we have\\n\\nLemma 8.15 If G1 ⊔ G2 exists, then G1 ⊑ G1 ⊔ G2 and G2 ⊑ G1 ⊔ G2 .\\n\\nProposition 8.16 (Kanazawa, 1998) Let G1, G2 ∈ Grigid .\\nbound, then G1 ⊔ G2 exists and it\\'s the least upper bound of {G1, G2}.\\n\\nIf {G1, G2} has un upper\\n\\nProof. (See [Kan98℄).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n63\\n\\n9 Learning Rigid Lambek Grammars from Stru\\rtures\\n\\nIn the present \\rhapter we will explore a model of learning for Rigid Lambek Grammars\\n\\nbased on positive stru\\rtured data. In addition to the standard model where senten\\res are\\n\\npresented to the learner as (cid:29)at sequen\\res of words, in this somewhat enri\\rhed model, strings\\n\\n\\rome with additional information about their (cid:16)deep stru\\rture(cid:17). Following the approa\\rh\\n\\nsket\\rhed in se\\rtion 6, largely indebted with Tiede\\'s study on proof trees in Lambek \\ral\\rulus\\n\\nas grammati\\ral stru\\rtures for Lambek grammars (see [Tie99℄), in our model ea\\rh senten\\re\\n\\n\\romes to the learner with a stru\\rture in the form of a proof tree stru\\rture as extensively\\n\\ndes\\rribed in se\\rtion 6.\\n\\nFormally, given a (cid:28)nite alphabet Σ, we will present a learning algorithm for the grammar\\nsystem hGrigid, ΣP , PLi: that is to say, samples to whi\\rh the learner is exposed to are proof-\\ntree stru\\rtures over the alphabet Σ, and guesses are made about the set of rigid Lambek\\n\\ngrammars that \\ran generate su\\rh a set of stru\\rtures.\\n\\nWe follow the advi\\re of Kanazawa (see [Kan98℄) who underlines how su\\rh an approa\\rh,\\n\\nwhi\\rh turns out to be quite logi\\rally independent from an approa\\rh based on (cid:29)at strings of\\n\\nwords, seems to make the task of learning easier but doesn\\'t trivialize it. If, on one hand,\\n\\nin the pro\\ress of learning from stru\\rtures the learner is provided with more information, on\\n\\nthe other hand the \\rriterion for su\\r\\ressful learning is stri\\rter. It is not su(cid:30)\\rient that the\\n\\nstring language of G \\rontains exa\\rtly the yields of the stru\\rtures in the input sequen\\re, the\\nlearning fun\\rtion is required to \\ronverge to a grammar G that generates all the grammati\\ral\\n\\nstru\\rtures whi\\rh appear in the input sequen\\re. We \\rould say that the learning fun\\rtion\\n\\nmust \\ronverge to a grammar that is both weakly and strongly equivalent to the grammar\\n\\nthat generated the input samples.\\n\\nClearly, from a psy\\rholinguisti\\r point of view, both learning from (cid:29)at strings and from\\n\\nproof tree stru\\rtures are quite unrealisti\\r models of (cid:28)rst language a\\rquisition by human\\n\\nbeings.\\n\\nIn the (cid:28)rst \\rase, experimental eviden\\res (see [Pin94℄) show that \\rhildren \\ran\\'t\\n\\na\\rquire a language simply by passively listening to (cid:29)at strings of words. First of all, we \\ran\\n\\nthink that prosody (or pun\\rtuation, in written text) \\ran provide (cid:16)stru\\rtural(cid:17) information to\\n\\nthe \\rhildren on the synta\\rti\\r bra\\rketing of the senten\\res she is exposed to (although they\\n\\ndo not always \\roin\\ride) and it is known that prosody is needed to learn a language for a\\n\\n\\rhild. Furthermore, another interesting eviden\\re of the fa\\rt that a \\rhild needs something\\n\\nmore to learn her mother tongue is given by the fa\\rt that no \\rhildren \\ran improve their\\n\\ngrammati\\ral skills during the early stages of their language a\\rquisition pro\\ress by wat\\rhing\\n\\nTV: it seems very likely they need (cid:16)ri\\rher data(cid:17) than simple senten\\res uttered by an adult.\\n\\nSome resear\\rhers (see [Tel99℄) hypothesize this additional information \\romes to the \\rhildren\\n\\nas the semanti\\r \\rontent of the (cid:28)rst senten\\res she is exposed to, whose she \\rould have a (cid:28)rst,\\n\\nprimitive grasp through (cid:28)rst sensory-motor experien\\res.\\n\\nOn the other hand, it is also highly unlikely that a \\rhild \\ran have a\\r\\ress to something\\n\\nlike a proof tree stru\\rture of the senten\\re she is exposed to. Our belief is that a good formal\\n\\nmodel for the pro\\ress of learning should rely on something (cid:16)halfway(cid:17) between (cid:29)at strings of\\n\\nwords and highly stru\\rtured and \\romplete information \\roming from the proof tree stru\\rture\\n\\nof the senten\\re. However, sin\\re, as we\\'ve already seen in se\\rtion 7.2, proof tree stru\\rtures\\n\\nRR n° 0123456789\\n\\n\\x0c64\\n\\nBonato\\n\\nprovide a very natural support for a Montague-like semanti\\rs, we think that our model\\n\\nfor learning a rigid Lambek grammar from stru\\rtured data represents a (cid:28)rst, simple but\\n\\nmeaningful approximation of a more plausible model of learning.\\n\\nIn any \\rase, even though in most of real-world appli\\rations only unstru\\rtured data are\\n\\navailable, we are often interested not only in the senten\\res that a grammar derives, but\\n\\nalso in derivation strings that grammar assigns to senten\\res. That is, we generally want a\\n\\ngrammar that makes stru\\rtural sense.\\n\\n9.1 Grammati\\ral Inferen\\re as Uni(cid:28)\\ration\\n\\nWe set our inquiry over the learnability for rigid Lambek grammars in the more general\\n\\nlogi\\ral framework of the Theory of Uni(cid:28)\\ration. We will sti\\rk to the approa\\rh des\\rribed\\n\\nin [Ni\\r99℄ based on the attempt to redu\\re the pro\\ress of inferring a \\rategorial grammar\\n\\nto the problem of unifying a set of terms. This approa\\rh establishes a fruitful \\ronne\\rtion\\n\\nbetween Indu\\rtive Logi\\r Programming te\\rhniques and the (cid:28)eld of Grammati\\ral Inferen\\re, a\\n\\n\\ronne\\rtion that has already been proved su\\r\\ressful in devising e(cid:30)\\rient algorithms to infer\\n\\nk-valued CCGs from positive stru\\rtured data (see [Kan98℄). Our aim is to exploit as mu\\rh as\\n\\npossible what has already been done in this dire\\rtion by exploring the possibility of adapting\\n\\nexisting algorithms for CCGs to rigid Lambek grammars.\\n\\n9.2 Argument Nodes and Typing Algorithm\\n\\nOur learning algorithm is based on a pro\\ress of labeling for the nodes of a set of proof tree\\n\\nstru\\rtures. We introdu\\re here the notion of argument node for a normal form proof tree. We\\n\\nwill be a bit sloppy in de(cid:28)ning su\\rh a notion, and sometimes we will use the same notation\\n\\nto indi\\rate a node and the type it\\'s labeled by, when this doesn\\'t engender \\ronfusion, and\\n\\nmu\\rh will be left to the graphi\\ral(cid:17) interpretation of trees and their nodes. However, we \\ran\\n\\nalways think of a node as a De Bruijn-like ob je\\rt (see [dB72℄) without substantially a(cid:27)e\\rting\\n\\nthe meaning of what will be proved.\\n\\nDe(cid:28)nition 9.1 Let P be a normal form partial parse tree. Let\\'s de(cid:28)ne indu\\rtively the set\\nArg(P) of argument nodes of P . There are three \\rases to \\ronsider:\\n\\nˆ P is a single node labeled by a type x, whi\\rh is the only member of Arg(P).\\n\\nˆ P looks like one of the fol lowing\\n\\nG\\n\\nP1\\n\\nA\\n\\nD\\n\\nP2\\n\\nG\\n\\nP1\\n\\n,\\n\\nA\\\\B\\n\\nB/A\\n\\nD\\n\\nP2\\n\\nA\\n\\n\\\\E\\nB\\n\\n/E\\nB\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n65\\n\\nthen in the (cid:28)rst \\rase\\n\\nand in the se\\rond \\rase\\n\\nArg(P) = {Root(P)} ∪ Arg(P1) ∪ Arg(P2) − {Root(P2)},\\n\\nArg(P) = {Root(P)} ∪ Arg(P1) ∪ Arg(P2) − {Root(P1)}.\\n\\nˆ P looks like one of the fol lowing\\n\\n[A], G\\n\\nG, [A]\\n\\nP1\\n\\nB\\n\\n\\\\I\\nA\\\\B\\n\\n,\\n\\nP1\\n\\nB\\n\\n/I\\nB/A\\n\\nthen Arg(P) = Arg(P1).\\n\\nproof tree stru\\rture:\\n\\nThe following proposition justi(cid:28)es our interest for argument nodes for a normal form\\n\\nProposition 9.2 Let t be a wel l formed normal form proof tree stru\\rture. If ea\\rh argument\\nnode is labeled, then any other node in t \\ran be labeled with one and only one type.\\n\\nProof. We prove that, on\\re argument nodes are labeled, any other node \\ran be labeled, by\\n\\nproviding a typing algorithm; uniqueness of typing follows from the rules applied.\\n\\nBy indu\\rtion on the height h of t:\\n\\nIndu\\rtion Basis. There are two \\rases to \\ronsider:\\n\\n1. h = 0. Trivially, by de(cid:28)nition 9.1, t is a single argument node, the result of the\\n\\nappli\\ration of a single axiom rule [ID] and by de(cid:28)nition it\\'s already typed.\\n\\n2. h = 1. Then t must be the result of a single appli\\ration of a [/E] or [\\\\E] rule. By\\nhypothesis and de(cid:28)nition 9.1, its two argument nodes are labeled with, say, x1 and x2 ,\\n\\nand the remaining node must be labeled a\\r\\rording to one of the following rules:\\n\\nRR n° 0123456789\\n\\n\\x0c66\\n\\nBonato\\n\\nx2\\n\\nx2\\n\\nx \\\\x2\\n\\n1\\n\\nx2\\n\\nx /x1\\n\\n2\\n\\nx2\\n\\n®\\n\\n,\\n\\n®\\n\\n\\\\E\\n\\nx1\\n\\n\\\\E\\n\\nx1\\n\\n/E\\n\\nx1\\n\\n/E\\n\\nx1\\n\\nIndu\\rtion Step. Let t be a normal form proof tree stru\\rture of height h > 1. There are\\n\\n3 \\rases to \\ronsider:\\n\\n1. t ≡ \\\\E(t1, t2). Sin\\re, by hypothesis, ea\\rh node in Arg(t) = {Root(t)} ∪ Arg(t1) ∪\\nArg(t2) − {Root(t2)}, is labeled, then also Root(t) is labeled with, say, x2 . For the\\nsame reason, any node of Arg(t1) is labeled, too, and so, by indu\\rtion hypothesis, t1\\nis fully (and uniquely) labeled. In parti\\rular its root is labeled with, say, x1 . Sin\\re t\\nis well formed, t2 \\rannot be the result of the appli\\ration of a [/I] rule, and sin\\re t is\\nnormal, t2 \\rannot be the result of the appli\\ration of a [\\\\I] rule, so its root node is an\\nargument node of its, too. By hypothesis, ea\\rh node in Arg(t2) − {Root(t2)} has a\\n\\ntype, so we \\ran apply the following rule:\\n\\nt1\\n\\nx1\\n\\nt2\\n\\nt1\\n\\nx1\\n\\n®\\n\\nt2\\n\\nx \\\\x1\\n\\n2\\n\\n\\\\E\\n\\nx2\\n\\n\\\\E\\n\\nx2\\n\\nand t2 has all of its argument nodes (uniquely) labeled. So, by indu\\rtion hypothesis,\\nits fully and uniquely labeled, and so is t.\\n\\n2. t ≡ /E(t1, t2). Analogous to \\rase 1.\\n\\n3. t ≡ \\\\I(t1) or t ≡ /I(t1). By de(cid:28)nition, Arg(t) = Arg(t1), then by hypothesis, any ar-\\ngument node in t1 is labeled. Then, by indu\\rtion hypothesis, t1 is fully (and uniquely)\\nlabeled, and sin\\re t is well-formed, there must be at least two undis\\rharged leaves in\\nt1 . So t \\ran be fully labeled a\\r\\rording, respe\\rtively, to the following rules:\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n67\\n\\nx2\\n\\n...\\n\\n[x ]2\\n\\n...\\n\\nx2\\n\\n[x ]2\\n\\n®\\n\\n,\\n\\n®\\n\\nt1\\n\\nx1\\n\\n\\\\I\\n\\nt1\\n\\nx1\\n\\n\\\\I\\nx \\\\x2\\n\\n1\\n\\n...\\n\\nt1\\n\\nx1\\n\\n/I\\n\\n...\\n\\nt1\\n\\nx1\\n\\n/I\\nx /x1\\n\\n2\\n\\nwhere x2 labels, respe\\rtively, the leftmost and the rightmost undis\\rharged leaf.\\n\\nThe proof of the previous proposition has impli\\ritly de(cid:28)ned an algorithm for labeling in\\n\\nthe most general way the nodes of a normal form proof tree stru\\rture.\\n\\nDe(cid:28)nition 9.3 A prin\\ripal parse of a proof tree stru\\rture t is a partial parse tree T of t,\\nsu\\rh that for any other partial parse tree T ′\\nof t, there exists a substitution σ su\\rh that, if\\na node of t is labeled by type A in T , it\\'s labeled by σ(A) in T ′\\n\\n.\\n\\nFrom the proof of proposition 9.2 it\\'s easy to devise an algorithm to get a prin\\ripal parse\\n\\nfor any well formed normal form proof tree stru\\rture.\\n\\nPrin\\ripal Parse Algorithm\\n\\nˆ Input: a well formed normal form proof tree stru\\rture t;\\n\\nˆ Output: a prin\\ripal parse T of t in a Lambek grammar G.\\n\\nStep 1. Label with distin\\rt variables ea\\rh argument node in t;\\n\\nStep 2. Compute the types for the remaining nodes a\\r\\rording to the rules des\\rribed in\\n\\nthe proof of proposition 9.2.\\n\\nObviously, this algorithm always terminates. If T is the resulting parse, we \\ran easily\\nprove it\\'s prin\\ripal. If T ′\\nis another parse for t, let\\'s de(cid:28)ne a substitution σ in the following\\nway: for ea\\rh variable x ∈ V ar(G), (cid:28)nd the (unique, for \\ronstru\\rtion) node in T labeled\\nby x, and let σ(x) be the type labeling the same node in T ′\\n. By indu\\rtion on A ∈ T p(G)\\n(where T p(G) is the set of all subtypes appearing in a Lambek Grammar G), we prove that\\n\\nif A labels a node of T , σ(A) labels the \\rorresponding node of T ′\\n\\n.\\n\\nIndu\\rtion Basis. If A ∈ V ar, this holds by de(cid:28)nition.\\n\\nIndu\\rtion Step. Let A = B\\\\C labels a node of T . Then the relevant part of T must\\n\\nlook like one of the following \\rases:\\n\\nRR n° 0123456789\\n\\n\\x0c68\\n\\nBonato\\n\\nˆ First \\rase:\\n\\nBy indu\\rtion hypothesis, the \\rorresponding part of T ′\\n\\nlooks like:\\n\\nThen A′ = σ(B)\\\\σ(C) = σ(B\\\\C) = σ(A).\\n\\nˆ Se\\rond \\rase:\\n\\nBy indu\\rtion hypothesis, the \\rorresponding part of T ′\\n\\nlooks like:\\n\\nB\\n\\nB\\\\C\\n\\n\\\\E\\nC\\n\\ns(B)\\n\\nA´\\n\\n\\\\E\\ns(C)\\n\\n[B]\\n\\nC\\n\\n\\\\I\\nB\\\\C\\n\\ns\\n[ (B)]\\n\\ns(C)\\n\\n\\\\I\\nA´\\n\\nThen A′ = σ(B)\\\\σ(C) = σ(B\\\\C) = σ(A).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n69\\n\\nThe \\rase A = C/B is entirely similar, thus \\rompleting the indu\\rtion.\\nIt follows that if a node of T is labeled by A, then the \\rorresponding node of T ′\\n\\nis labeled\\n\\nby σ(A). That is to say, with a small abuse of notation, T ′ = σ(T ).\\n\\n9.3 RLG Algorithm\\n\\nOur algorithm (\\ralled RLG from Rigid Lambek Grammar) takes as its input a (cid:28)nite set D\\nof proof tree stru\\rtures over a (cid:28)nite alphabet Σ and returns a rigid Lambek grammar G over\\nthe same alphabet whose stru\\rture language \\rontains (properly) D , if it exists; a \\rorre\\rt\\n\\nstatement that there\\'s no su\\rh a rigid Lambek grammar otherwise.\\n\\nOur algorithm is based on the type algorithm des\\rribed in se\\rtion 9.2 and on the uni(cid:28)-\\n\\n\\ration algorithm des\\rribed in se\\rtion 8.2.\\n\\nRLG Algorithm.\\n\\nˆ input: a (cid:28)nite set D of proof tree stru\\rtures.\\n\\nˆ output: a rigid Lambek grammar G su\\rh that D ⊂ PL(G), if there is one.\\n\\nWe illustrate the algorithm using the following example:\\n\\na\\n\\nD={\\n\\ngirl\\n\\nloves\\n\\n[  ]\\n\\n/E\\n\\n/E\\n\\nloves\\n\\n/E\\n\\na\\n\\n/E\\n\\n,\\n\\nJohn\\n\\n\\\\E\\n\\n\\\\E\\n\\n/I\\n\\n\\\\E\\n\\npassionately\\n\\nhim\\n\\n\\\\E\\n\\ngirl\\n\\n{\\n\\nRR n° 0123456789\\n\\n\\x0c70\\n\\nBonato\\n\\nStep 1. Normalize all the proof tree stru\\rtures in D , if they are not normal, a\\r\\rording\\n\\nto the rules des\\rribed in se\\rtion 6.3.\\n\\nStep 2. Assign a type to ea\\rh node of the stru\\rture in D as follows:\\n\\n1. Assign s to ea\\rh root node.\\n\\n2. Assign distin\\rt variables to the argument nodes.\\n\\na\\n\\ngirl\\nx4\\n\\n/E\\n\\nx3\\n\\nloves\\n\\n[\\n\\n]x5\\n\\n/E\\n\\ngirl\\nx8\\n\\n/E\\n\\nx7\\n\\na\\n\\n/E\\n\\n,\\n\\nJohn\\nx6\\n\\nloves\\n\\n\\\\E\\ns\\n\\n\\\\E\\n\\nx1\\n\\npassionately\\n\\nhim\\n\\n\\\\E\\ns\\n\\n3. Compute types for the remaining nodes a\\r\\rording to the rules des\\rribed in proposition\\n\\n9.2.\\n\\na\\nx /x3\\n\\n4\\n\\ngirl\\nx4\\n\\nloves\\n(x \\\\x )/x\\n\\n2\\n\\n3\\n\\n5\\n\\n[\\n\\n]x5\\n\\n/E\\n\\nx3\\n\\n/E\\n\\nx \\\\x3\\n\\n2\\n\\na\\nx /x7\\n\\n8\\n\\ngirl\\nx8\\n\\nloves\\n(x \\\\s)/x\\n\\n6\\n\\n7\\n\\n/E\\n\\nx7\\n\\n,\\n\\nJohn\\nx6\\n\\n/E\\n\\nx \\\\s6\\n\\n\\\\E\\ns\\n\\nhim\\n(x /x )\\\\x\\n\\n2\\n\\n5\\n\\n1\\n\\n\\\\E\\n\\nx1\\n\\npassionately\\nx \\\\s1\\n\\n\\\\E\\ns\\n\\n\\\\E\\n\\nx2\\n\\n/I\\n\\n\\\\E\\n\\nx2\\n\\n/I\\n\\nx /x2\\n\\n5\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n71\\n\\nStep 3. Colle\\rt the types assigned to the leaf nodes into a grammar GF (D) \\ralled the\\ngeneral form indu\\red by D . In general, GF (D) : c 7→ A if and only if the previous step\\nassigns A to a leaf node labeled by symbol c.\\n\\nGF (D) : passionately 7→ x1\\\\s\\n\\nhim 7→ (x2/x5)\\\\x1\\n\\na 7→ x3/x4, x7/x8\\n\\n7→ x4, x8\\n7→ (x3\\\\x2)/x5, (x6\\\\s)/x7\\n\\ngirl\\nloves\\nJohn 7→ x6\\n\\nStep 4. Unify the types assigned to the same symbol. Let A = {{A | GF (D) : c 7→\\nA} | c ∈ dom(GF (D))}, and \\rompute σ = mgu(A). The algorithm fails if uni(cid:28)\\ration fails.\\n\\nσ = {x7 7→ x3, x8 7→ x4, x6 7→ x3, x2 7→ s, x5 7→ x3}\\n\\nStep 5. Let RLG(D) = σ[GF (D)].\\n\\nRLG(D) : passionately 7→ x1\\\\s\\n\\nhim 7→ (s/x3)\\\\x1\\na 7→ x3/x4\\n7→ x4\\n7→ (x3\\\\s)/x3\\n\\ngirl\\nloves\\nJohn 7→ x3\\n\\nOur algorithm is based on the (cid:16)prin\\ripal parse algorithm(cid:17) des\\rribed in the previous\\n\\nse\\rtion, whi\\rh has been proved to be \\rorre\\rt and terminate, and the uni(cid:28)\\ration algorithm\\n\\ndes\\rribed in se\\rtion 8.2. The result is, intuitively, the most general rigid Lambek Grammar\\n\\nwhi\\rh \\ran generate all the proof tree stru\\rtures appearing in the input sequen\\re.\\n\\n9.4 Properties of RLG\\n\\nto study its behaviour in the limit.\\n\\nIn the present se\\rtion we prove some properties of the RLG algorithm that will be helpful\\n\\nThe following lemma is almost trivial but it will play an important role in the \\ronvergen\\re\\n\\nproof for the RLG algorithm. It simply states that the tree language of the grammar inferred\\n\\njust after the labeling of the stru\\rtures properly \\rontains the sample stru\\rtures.\\n\\nLemma 9.4 Let D be the input set of proof tree stru\\rtures for the RLG algorithm. Then\\n\\nthe set of the proof tree stru\\rtures generated by the `general form\\' grammar \\rontains properly\\n\\nD. That is, D ⊂ PL(GF (D)).\\n\\nRR n° 0123456789\\n\\n\\x0c72\\n\\nBonato\\n\\nProof. Let D = {T1, . . . , Tn}. The labeling of the nodes of the stru\\rtures in D that pre\\redes\\nthe \\ronstru\\rtion of GF (D) in fa\\rt forms a parse tree Pi of GF (D) for ea\\rh stru\\rture Ti in\\nD . This shows D ⊆ P L(GF (D)). The proper in\\rlusion follows trivially from the fa\\rt that\\nD is by hypothesis a (cid:28)nite set, while PL(G), the set of proof tree stru\\rtures generated by a\\nLambek grammar G, is always in(cid:28)nite.\\n\\nLemma 9.5 Ea\\rh variable x ∈ V ar(GF (D)) labels a unique node in a unique parse tree\\nof D.\\n\\nProof. Obviously, by \\ronstru\\rtion, if x ∈ V ar(GF (D)), then there must be an i ∈ N su\\rh\\nthat x labels one of the nodes of a parse tree Pi . Sin\\re, by \\ronstru\\rtion, for ea\\rh i 6= j\\nthe sets of variables that label Pi are disjoint, x appears in one and only one Pi . Besides,\\n\\nsin\\re variables are assigned only during the (cid:28)rst phase of the type-assignment pro\\ress of our\\n\\nalgorithm, again by \\ronstru\\rtion ea\\rh variable labels only one node in the dedu\\rtion tree.\\n\\nThe following lemma makes expli\\rit the relation between the grammar inferred just after\\n\\nthe labeling of the stru\\rtures in the algorithm RLG, and the stru\\rture language of the rigid\\n\\ngrammar we are trying to infer.\\n\\nLemma 9.6 Let D be a (cid:28)nite set of proof tree stru\\rtures. Then, for any Lambek grammar\\nG, the fol lowing are equivalent:\\n\\n(i) D ⊆ PL(G)\\n\\n(ii) There is a substitution σ su\\rh that σ[GF (D)] ⊆ G.\\n\\nProof. (ii)⇒(i). Suppose there is a substitution σ su\\rh that σ[GF (D)] ⊆ G. Then, from\\nproposition 6.32, we have that PL(GF (D)) ⊆ PL(G). This, together with lemma 9.4 proves\\n\\n(i).\\n\\n(i) ⇒(ii). Let D = {T1, . . . , Tn} and let Pi be GF (D)\\'s parse of Ti for 1 ≤ i ≤ n.\\nAssume D ⊆ PL(G). Then G has a parse Qi of ea\\rh Ti . De(cid:28)ne a substitution σ as follows:\\nfor ea\\rh variable x ∈ V ar(GF (D)), (cid:28)nd a (unique, due to lemma 9.5) Pi that \\rontains a\\n(unique, again due to lemma 9.5) node labeled by x, and let σ(x) be the type labeling the\\n\\rorresponding node of Qi . We show that\\n\\nif A labels a node of some Pi , then σ(A) labels the \\rorresponding node of Qi .\\n\\nProof. By indu\\rtion on A ∈ T p(GF (D)) = {T | T is a subtype of some B ∈ range(GF (D))}):\\n\\nIndu\\rtion basis. If A ∈ V ar, this holds by de(cid:28)nition. If A = t, then any node labeled by\\nA in {P1, . . . , Pn} is the root node of some Pi . Sin\\re Qi is a parse tree of G, the root node\\nof Qi must be labeled by t.\\n\\nIndu\\rtion step. Let A = B\\\\C labels a node of Pi . Then the relevant part of Pi must\\n\\nlook like one of the two following \\rases:\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n73\\n\\nˆ First \\rase\\n\\nB\\n\\nB\\\\C\\n\\nBy indu\\rtion hypothesis, the \\rorresponding part of Qi looks like:\\n\\ns(B)\\n\\nA´\\n\\nThen A′ = σ(B)\\\\σ(C) = σ(B\\\\C) = σ(A).\\n\\nˆ Se\\rond \\rase\\n\\n\\\\E\\nC\\n\\nt\\n\\n\\\\E\\ns(C)\\n\\nt\\n\\n[B]\\n\\nC\\n\\n\\\\I\\nB\\\\C\\n\\nt\\n\\nRR n° 0123456789\\n\\n\\x0c74\\n\\nBonato\\n\\nBy indu\\rtion hypothesis, the \\rorresponding part of Qi looks like:\\n\\ns\\n[ (B)]\\n\\ns(C)\\n\\n\\\\I\\nA´\\n\\nt\\n\\nThen again A′ = σ(B)\\\\σ(C) = σ(B\\\\C) = σ(A).\\n\\nThe \\rase A = C/B is entirely similar, thus \\rompleting the indu\\rtion.\\nGF (D) : c 7→ A, then G : c 7→ σ(A). Therefore, σ[GF (D)] ⊆ G.\\n\\nIt follows that if\\n\\nThe following proposition establishes an (cid:16)if and only if (cid:17) relation between the in\\rlusion\\n\\nof our set of positive samples D in a tree language generated by a rigid grammar G and the\\nsu\\r\\ressful termination of the RLG algorithm when it has D as its input set. Even more,\\n\\nwe have that the rigid grammar inferred by the algorithm is not (cid:16)larger(cid:17) than the rigid\\n\\nProposition 9.7 Let D be a (cid:28)nite set of proof tree stru\\rtures. Then, for any rigid grammar\\nG, the fol lowing are equivalent:\\n\\ngrammar G.\\n\\n(i) D ⊆ PL(G);\\n\\nτ [RLG(D)] ⊆ G).\\n\\n(ii) RLG(D) exists and RLG(D) ⊑ G (equivalently, there is a substitution τ su\\rh that\\n\\nProof. (ii) ⇒ (i) follows from lemma 9.6 and the fa\\rt that RLG(D) is a substitution instan\\re\\nof GF (D).\\n\\n(i) ⇒ (ii). Assume that G is a rigid grammar su\\rh that D ⊆ P L(G). By lemma 9.6 there\\nis a substitution σ su\\rh that σ[GF (D)] ⊆ G. Sin\\re G is a rigid grammar, σ[GF (D)] is also a\\nrigid grammar. Then σ uni(cid:28)es the family A = {{A | GF (D) : c 7→ A} | c ∈ dom(GF (D))}.\\nThis means that RLG(D) exists and RLG(D) = σ0[GF (D)], where σ0 = mgu(A). Then\\nthere is a substitution τ su\\rh that σ = τ ◦ σ0 . Therefore, τ [RLG(D)] = τ [σ0[GF (D)]] =\\n(τ ◦ σ0)[GF (D)] = σ[GF (D)]. By assumption, σ[GF (D)] ⊆ G, so τ [RLG(D)] ⊆ G.\\n\\nCorollary 9.8 Let D1 and D2 be two (cid:28)nite sets of proof tree stru\\rtures su\\rh that D1 ⊆ D2 .\\nIf RLG(D2) exists, RLG(D1) also exists and RLG(D1) ⊑ RLG(D2) and PL(RLG(D1)) ⊆\\nPL(RLG(D2)).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n75\\n\\nProof. Immediate from proposition 9.7, noting that if D1 ⊆ D2 , then {G ∈ Grigid | D1 ⊆\\nPL(G)} ⊇ {G ∈ Grigid | D2 ⊆ PL(G)}.\\n\\nDe(cid:28)nition 9.9 Let ϕRLG be the learning fun\\rtion for the grammar system hGrigid, ΣP , PLi\\n\\nde(cid:28)ned as fol lows:\\n\\n1\\n\\nϕRLG(hT0, . . . , Tni) ≃ RLG({T0, . . . , Tn}).\\n\\nThanks to previous propositions and lemmas we are able to prove the \\ronvergen\\re for\\n\\nthe RLG algorithm:\\n\\nTheorem 9.10 ϕRLG learns Grigid from stru\\rtures.\\n\\nProof. We prove that ϕRLG learns the \\rlass of rigid Lambek grammars from proof tree\\n\\nstru\\rtures.\\n\\nLet G be any rigid Lambek grammar and let hTiii∈N be an in(cid:28)nite sequen\\re enumerating\\nPL(G). For ea\\rh i ∈ N, {T0, . . . , Ti} ⊆ PL(G), so by proposition 9.7 ϕRLG(hT0, . . . , Tii) =\\nRLG({T0, . . . , Ti}) is de(cid:28)ned and\\n\\nϕRLG(hT0, . . . , Tii) ⊑ ϕRLG(hT0, . . . , Ti+1i),\\n\\nby \\rorollary 9.8, and\\n\\nϕRLG(hT0, . . . , Tii) ⊑ G.\\nSin\\re, by \\rorollary 6.41, there are only (cid:28)nitely many Lambek grammars G′′ ⊑ G, ϕRLG\\n. Then PL(G) = {Ti | i ∈ N} ⊆ PL(G′). Sin\\re G′ ⊑ G,\\nmust \\ronverge on hTiii∈N to some G′\\nby proposition 6.32, PL(G′) ⊆ PL(G). Therefore, PL(G′) = PL(G).\\n\\nWhen RLG is applied su\\r\\ressively to a sequen\\re of in\\rreasing set of proof tree stru\\rtures\\n\\nD0 ⊂ D1 ⊂ D2 ⊂ · · · , it is more e(cid:30)\\rient to make use of the previous value RLG(Di−1) to\\n\\rompute the \\rurrent value RLG(Di).\\n\\nDe(cid:28)nition 9.11 If G is a rigid Lambek grammar and D is a (cid:28)nite set of proof tree stru\\r-\\n\\ntures, then let\\n\\nRLG(2)(G, D) ≃ G ⊔ RLG(D).\\n\\nLemma 9.12 If D1 and D2 are two (cid:28)nite sets of proof tree stru\\rtures,\\n\\nRLG(2)(RLG(D1), D2) ≃ RLG(D1 ∪ D2).\\n\\n1\\n\\nunde(cid:28)ned\\n\\n≃\\n\\nRe\\rall that the symbol\\n\\nmeans that either both sides are de(cid:28)ned and are equal, or else both sides are\\n\\nRR n° 0123456789\\n\\n\\x0c76\\n\\nBonato\\n\\nProof.\\n\\n(See [Kan98℄). Suppose that RLG(2)(RLG(D1), D2) is de(cid:28)ned. By lemma 8.15,\\nRLG(D1) ⊑ RLG(2)(RLG(D1), D2) and RLG(D2) = RLG(2)(RLG(D1), D2). This implies\\nthat D1 ∪ D2 ⊆ PL(RLG(2)(RLG(D1), D2)), so by proposition 9.7, RLG(D1 ∪ D2) exists\\nand RLG(D1 ∪ D2) ⊑ RLG(2)(RLG(D1), D2).\\n\\nSuppose now that RLG(D1 ∪ D2) is de(cid:28)ned. By \\rorollary 9.8, RLG(D1) and RLG(D2)\\nexist and RLG(D1) ⊑ RLG(D1 ∪D2) and RLG(D2) ⊑ RLG(D1 ∪D2). Then RLG(D1 ∪D2)\\nis an upper bound of {RLG(D1), RLG(D2)}. By proposition 8.16, RLG(D1) ⊔ RLG(D2) =\\nRLG(2)(RLG(D1), D2) exists and RLG(2)(RLG(D1), D2) ⊑ RLG(D1 ∪ D2).\\n\\nThus it has been proved that if one of RLG(2)(RLG(D1), D2) and RLG(D1 ∪ D2) is\\n\\nde(cid:28)ned the other is de(cid:28)ned and they are equal.\\n\\nProposition 9.13 ϕRLG has the fol lowing properties:\\n\\n(i) ϕRLG learns Grigid prudently.\\n\\n(ii) ϕRLG is responsive and \\ronsistent on Grigid .\\n\\n(iii) ϕRLG is set-driven.\\n\\n(iv) ϕRLG is \\ronservative.\\n\\n(v) ϕRLG is monotone in\\rreasing.\\n\\n(vi) ϕRLG is in\\rremental.\\n\\nProof.\\n\\n(i) Sin\\re range(ϕRLG) ⊆ Grigid , ϕRLG learns Grigid prudently.\\n\\n(ii) If D ⊆ L for some L ∈ PLrigid , then by proposition 9.7 RLG(D) exists and by lemma\\n9.6 D ⊆ PL(RLG(D)). This means that ϕRLG is responsive and \\ronsistent on Grigid .\\n\\n(iii) ϕRLG is set-driven by de(cid:28)nition.\\n\\n(iv) Let T ∈ PL(RLG(D)). Then D ∪ {T } ⊂ PL(RLG(D)). By proposition 9.7, RLG(D ∪\\n{T }) exists and RLG(D ∪ {T }) ⊑ RLG(D). By \\rorollary 9.8 we have also RLG(D) ⊑\\nRLG(D ∪ {T }). This shows that ϕRLG is \\ronservative.\\n\\n(v) Trivial from \\rorollary 9.8.\\n\\n(vi) De(cid:28)ne a \\romputable fun\\rtion ψ : Grigid × ΣP → Grigid as follows:\\n\\nψ(G, T ) ≃\\n\\n(cid:26)\\n\\nunde(cid:28)ned\\n\\notherwise.\\n\\nRLG(2)(G, {T })\\n\\nif G ∈ Grigid and RLG({T }) is de(cid:28)ned,\\n\\nThen by lemma 9.12, ϕRLG(hT0, . . . , Ti+1i) ≃ ψ(ϕRLG(hT0, . . . , Tii), Ti+1).\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n77\\n\\n10 Con\\rlusion and Further Resear\\rh\\n\\nThis work aims at making a further step in the dire\\rtion of bridging the gap whi\\rh still\\n\\nseparates any formal/\\romputational theory of learning from a meaningful formal linguisti\\r\\n\\ntheory.\\n\\narti\\rle of 1958.\\n\\nWe have introdu\\red the basi\\r notions of Formal Learnability Theory as (cid:28)rst formulated\\n\\nby E.M. Gold in 1967, and of Lambek Grammars, whi\\rh appeared for the (cid:28)rst time in an\\n\\nThe former, whi\\rh is one of the (cid:28)rst \\rompletely formal des\\rriptions of the pro\\ress of gram-\\n\\nmati\\ral inferen\\re, after an initial skepti\\rism about its e(cid:27)e\\rtive appli\\rability, is at present to\\n\\nob je\\rt of a renewed interest due to some meaningful and promising learnabiluty results.\\n\\nEven the latter, long negle\\rted by the linguisti\\r \\rommunity, is experien\\ring a strong\\n\\nrenewed interest as a \\ronsequen\\re of re\\rent linguisti\\rs a\\rhievements whi\\rh point at formal\\n\\ngrammars \\rompletely lexi\\ralized, as Lambek grammars are. Even if they\\'re still far from\\n\\nbeing the ultimate formal devi\\re for the formalization of human linguisti\\rs \\rompeten\\re,\\n\\nthey\\'re universally looked at as a promising tool for further developments of \\romputational\\n\\nlinguisti\\rs.\\n\\nIn the present work we\\'ve drawn the attention to a parti\\rular \\rlass of Lambek grammars\\n\\n\\ralled rigid Lambek grammars, and we\\'ve proved that they are learnable in Gold\\'s framework\\n\\nfrom a stru\\rtured input. We\\'ve used most re\\rent results by Hans-Joerg Tiede for formally\\n\\nde(cid:28)ne our notion of stru\\rture for a senten\\re: he has re\\rently proved that the proof tree\\n\\nlanguage generated by a Lambek grammar stri\\rtly \\rontains the tree language generated by\\n\\n\\rontext-free grammars. His notion of a proof as the grammati\\ral stru\\rture of a senten\\re in a\\n\\n\\rategorial grammar is also useful in providing a natural support to a Montagovian semanti\\rs\\n\\nfor that senten\\re. Therefore, our \\rhoi\\re for a stru\\rtured input for our learning algorithm in\\n\\nthe form of proof tree stru\\rtures is not gratuitous, but it\\'s \\roherent with the mainstream\\n\\nof (psy\\rho-)linguisti\\rs theories about (cid:28)rst language learning whi\\rh stress the importan\\re of\\n\\nproviding the learner with informatioannly and semanti\\rally ri\\rh input in the pro\\ress of her\\n\\nlanguage a\\rquisition.\\n\\nWe believe it to be a partial but meaningful result, whi\\rh on\\re more shows how versatile\\n\\nand powerful \\ran be this learning theory, on\\re negle\\rted be\\rause it was widely held that it\\n\\n\\rouldn\\'t but a\\r\\rount for the learnability of most trivial \\rlasses of grammars.\\n\\nMu\\rh is left to be done along many dire\\rtions. First of all, there\\'s still no real theory\\n\\nof rigid, or k-valued, Lambek grammars: we still know very few formal properties of su\\rh\\n\\ngrammars whi\\rh seem to have an undisputable linguisti\\r interest. We still la\\rk, for example,\\n\\na hierar\\rhy theorem for languages generated by k-valued Lambek grammars.\\n\\nAnother important point whi\\rh is still unanswered lies in the de\\ridibility for P L(G1) ⊆\\nP L(G2) for G1, G2 Lambek grammars, that is de\\riding whether the tree language generated\\n\\nby a grammar is \\rontained in the tree language generated by another one, for any two gram-\\n\\nmars. Su\\rh a question is de\\ridable for the non-asso\\riative variant of Lambek grammars.\\n\\nProving this question de\\ridable would allow as to very esaily devise a learning algorithm for\\n\\nRR n° 0123456789\\n\\n\\x0c78\\n\\nBonato\\n\\nk-valued Lambek grammars.\\n\\nOur learnability result is in our opinion a (cid:28)rst step toward a more \\ronvin\\ring and lin-\\n\\nguisti\\rally plausible model of learning for k-valued Lambek grammars from less and less\\n\\nstru\\rturally ri\\rh input. Needless to say, learning from su\\rh an informationally ri\\rh input\\n\\nlike proof-tree stru\\rtures are hardly has any linguisti\\r plausibility. On the other hand the\\n\\ndeep \\ronne\\rtions between proof tree stru\\rtures for a senten\\re in Lambek grammars and its\\n\\n(cid:16)Montague-like(cid:17) semanti\\rs seems to address to a more \\ronvin\\ring model for learning based\\n\\nboth on synta\\rti\\r and semanti\\r information.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n79\\n\\nReferen\\res\\n\\n[Ang80℄\\n\\nDana Angluin.\\n\\nIndu\\rtive inferen\\re of formal languages from positive data.\\n\\nInformation and Control, 45:117(cid:21)135, 1980.\\n\\n[BB75℄\\n\\nLenore Blum and Manuel Blum. Toward a mathemati\\ral theory of indu\\rtive\\n\\ninferen\\re. Information and Control, 28:125(cid:21)155, 1975.\\n\\n[BH64℄\\n\\nYehoshua Bar-Hillel. Language and Information. Addson-Wesley, Reading,\\n\\n1964.\\n\\n[BP90℄\\n\\nWo j\\rie\\rh Buszkowski and Gerald Penn. Categorial grammars determined from\\n\\nlinguisti\\r data by uni(cid:28)\\ration. Studia Logi\\ra, 49:431(cid:21)454, 1990.\\n\\n[Bus86℄\\n\\nWoi\\rie\\rh Buszkowski. Generative \\rapa\\rity of non-asso\\riative lambek \\ral\\rulus.\\n\\nBul letin of the Polish A\\rademy of S\\rien\\re and Mathemati\\rs, 1986.\\n\\n[Cho56℄\\n\\nNoam Chomsky. Three models for the des\\rription of language. IRE Transa\\r-\\n\\ntions on Information Theory IT-2, 3:113(cid:21)124, 1956.\\n\\n[Cho75℄\\n\\nNoam Chomsky. Re(cid:29)e\\rtions on Language. Pantheon, 1975.\\n\\n[dB72℄\\n\\nN. G. de Bruijn. Lambda \\ral\\rulus notation with nameless dummies. Indaga-\\n\\ntiones Mathemati\\rae, pages 381(cid:21)392, 1972.\\n\\n[Fit96℄\\n\\nMelvin Fitting. First-Order Logi\\r and Automati\\r Theorem Proving. Berlin:\\n\\nSpringer, 1996.\\n\\n[Ful88℄\\n\\nM. Fulk. Saving the phenomenon: Requirements that indu\\rtive ma\\rhines not\\n\\n\\rontradi\\rt known data. Information and Computation, 79(3):193(cid:21)209, 1988.\\n\\n[Gaz88℄\\n\\nGerald Gazdar. Appli\\rability of indexed grammars to natural languages. In\\n\\nUwe Reyle and Christian Rohrer, editors, Natural Language Parsing and Lin-\\n\\nguisti\\r Theories, pages 69(cid:21)94. Dordre\\rht:Reidel, 1988.\\n\\n[Gol67℄\\n\\nE. M. Gold. Language identi(cid:28)\\ration in the limit. Information and Control,\\n\\n[GS84℄\\n\\nFeren\\r Gé\\rseg and Magnus Steinby. Tree Automata. Akadémiai Kiadó, 1984.\\n\\n[Gue83℄\\n\\nIrène Guesserian. Pushdown tree automata. Mathemati\\ral Systems Theory,\\n\\n10:447(cid:21)474, 1967.\\n\\n16(4):237(cid:21)263, 1983.\\n\\n[JORS99℄\\n\\nSanjay Jain, Daniel N. Osherson, James S. Royer, and Arun Sharma. Systems\\n\\nthat Learn. MIT Press, Cambridge, Massa\\rhusetts, se\\rond edition, 1999.\\n\\n[Kan98℄\\n\\nMakoto Kanazawa. Learnable Classes of Categorial Grammars. Center for the\\n\\nStudy of Language and Information (CSLI), Stanford, 1998.\\n\\nRR n° 0123456789\\n\\n\\x0c80\\n\\nBonato\\n\\n[Koz97℄\\n\\nDexter Kozen. Automata and Computability. Berlin: Springer, 1997.\\n\\n[Lam58℄\\n\\nJoa\\rhim Lambek. The mathemati\\rs of senten\\re stru\\rture. Ameri\\ran Mathe-\\n\\nmati\\ral Monthly, 65:154(cid:21)170, 1958.\\n\\n[Mon97℄\\n\\nRi\\rhard Montague. The proper treatment of quanti(cid:28)\\ration in ordinary english.\\n\\nIn Jakko Hintikka, editor, Approa\\rhes to Natural Language, pages 221(cid:21)242.\\n\\nReidel, 1997.\\n\\n[Moo97℄\\n\\nMi\\rhael Moortgat. Categorial type logi\\rs. In Johan van Benthem and Ali\\re ter\\n\\nMeulen, editors, Handbook of Logi\\r and Language. North Holland, Amsterdam,\\n\\n[Ni\\r99℄\\n\\nJa\\rques Ni\\rolas. Grammati\\ral inferen\\re as uni(cid:28)\\ration. Te\\rhni\\ral Report 3632,\\n\\nIRISA, Unite\\n\\nde Re\\rher\\rhe INRIA Rennes, 1999.\\n\\n(cid:1)\\n\\n[OGL95℄\\n\\nDaniel N. Osherson, Lila R. Gleitmann, and Mark Liberman, editors. An\\n\\nInvitation to Cognitive S\\rien\\re, volume 1, \"Language\". The MIT press, Mas-\\n\\nsa\\rhusetts Institute of Te\\rhnology, Cambridge, Massa\\rhusetts, se\\rond edition,\\n\\n1997.\\n\\n1995.\\n\\n[OWdJM97℄ Daniel N. Osherson, S\\rott Weinstein, Di\\rk de Jongh, and Eri\\r Martin. Formal\\n\\nlearning theory. In Johan van Benthem and Ali\\re ter Meulen, editors, Handbook\\n\\nof Logi\\r and Language. North Holland, Amsterdam, 1997.\\n\\n[Pen97℄\\n\\nMati Pentus. Produ\\rt-free lambek \\ral\\rulus and \\rontext-free grammars. The\\n\\nJournal of Symboli\\r Logi\\r, 62(2):648(cid:21)660, 1997.\\n\\n[Pin94℄\\n\\nSteven Pinker. The Language Insti\\rt. Penguin Press, 1994.\\n\\n[Ret96℄\\n\\nChristian Retoré. Proof-nets for the lambek \\ral\\rulus - an overview. In Mi\\rhele\\n\\nAbrus\\ri and Claudia Casadio, editors, Pro\\reedings of the 1996 Roma Work-\\n\\nshop \"Proofs and Linguisti\\r Categories - Appli\\rations of Logi\\r to the Analysis\\n\\nand Implementation of Natural Language, pages 241(cid:21)262, Bologna, April 1996.\\n\\nCLUEB.\\n\\n[Roo91℄\\n\\nDirk Roorda. Resour\\re Logi\\rs: Proof-Theoreti\\ral Investigations. PhD thesis,\\n\\nUniversity of Amsterdam, 1991.\\n\\n[Shi90℄\\n\\nT. Shinohara.\\n\\nIndu\\rtive inferen\\re from positive data is powerful.\\n\\nIn The\\n\\n1990 Workshop on Computational Learning Theory, pages 97(cid:21)110, San Mateo,\\n\\nCalifornia, 1990. Morgan Kaufmann.\\n\\n[Ste93℄\\n\\nMark Steedman. Categorial grammar. Lingua, 90:221(cid:21)258, 1993.\\n\\n[Tel99℄\\n\\nIsabelle Tellier. R\\x1dle de la \\rompositionnalité dan l\\'a\\rquisition d\\'une langue. In\\n\\nA\\rtes de CAP99, pages 107(cid:21)114, Palaiseau, 1999.\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n81\\n\\n[Tha67℄\\n\\nJames W. That\\rher. Chara\\rterizing derivation trees of \\rontext-free grammars\\n\\nthrough a generalization of (cid:28)nite automata theory. Journal of Computer Sys-\\n\\ntems S\\rin\\res, pages 317(cid:21)322, 1967.\\n\\n[Tie99℄\\n\\nHans-Joerg Tiede. Dedu\\rtive Systems and Grammars: Proofs as Grammati\\ral\\n\\nStru\\rtures. PhD thesis, Indiana University, July 1999.\\n\\n[vB87℄\\n\\nJohan van Benthem. Logi\\ral syntax. Theoreti\\ral Linguisti\\rs, 14(2/3):119(cid:21)142,\\n\\n[Wan93℄\\n\\nHeinri\\rh Wansing. The Logi\\r of Information Stru\\rtures. Berlin: Springer\\n\\n1987.\\n\\nVerlag, 1993.\\n\\n[Wri89℄\\n\\nK. Wright. Identi(cid:28)\\rations of unions of languages drawn from an identi(cid:28)able\\n\\n\\rlass. In The 1989 Workshop on Computational Learning Theory, pages 328(cid:21)\\n\\n333, San Mateo, California, 1989. Morgan Kaufmann.\\n\\n[Zie89℄\\n\\nWo j\\rie\\rh Zielonka. A simple and general method for solving the (cid:28)nite axioma-\\n\\ntizability problems for Lambek\\'s synta\\rti\\r \\ral\\ruli. Studia Logi\\ra, 48(1):35(cid:21)39,\\n\\n1989.\\n\\nContents\\n\\n1 Introdu\\rtion\\n\\n3\\n\\n2 Grammati\\ral Inferen\\re\\n\\n5\\n\\n2.1 Child\\'s First Language A\\rquisition . . . . . . . . . . . . . . . . . . . . . . . .\\n\\n5\\n\\n2.2 Gold\\'s Model\\n\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n\\n5\\n\\n3 Basi\\r Notions\\n\\n6\\n\\n3.1 Grammar Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n\\n7\\n\\n3.2 Learning Fun\\rtions, Convergen\\re, Learnability . . . . . . . . . . . . . . . . .\\n\\n8\\n\\n3.3 Stru\\rtural Conditions for (Un)Learnability . . . . . . . . . . . . . . . . . . . . 10\\n\\n3.3.1 Existen\\re of a Limit Point . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n\\n3.3.2\\n\\n(In)Finite Elasti\\rity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n\\n3.3.3 Kanazawa\\'s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n\\n3.4 Constraints on Learning Fun\\rtions . . . . . . . . . . . . . . . . . . . . . . . . 15\\n\\n3.4.1 Non-restri\\rtive Constraints\\n\\n. . . . . . . . . . . . . . . . . . . . . . . . 15\\n\\n3.4.2 Restri\\rtive Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n\\nRR n° 0123456789\\n\\n\\x0c82\\n\\nBonato\\n\\n4 Is Learning Theory Powerful Enough?\\n\\n18\\n\\n4.1 First Negative Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n\\n4.2 Angluin\\'s Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n\\n4.3 Shinohara\\'s Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n\\n4.4 Kanazawa\\'s Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n\\n4.5 Our Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n\\n5 Lambek Grammars\\n\\n21\\n\\n5.1 Classi\\ral Categorial Grammars . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n\\n5.2 Extensions of Classi\\ral Categorial Grammars . . . . . . . . . . . . . . . . . . 24\\n\\n5.3 (Asso\\riative) Lambek Cal\\rulus . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n\\n5.4 Non-asso\\riative Lambek Cal\\rulus . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n\\n5.5 Normalization and Normal Forms . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n\\n5.6 Basi\\r Fa\\rts about Lambek Cal\\rulus\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 32\\n\\n5.7 Lambek Grammars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n\\n6 Proofs as Grammati\\ral Stru\\rtures\\n\\n35\\n\\n6.1 (Partial) Parse Trees for Lambek Grammars . . . . . . . . . . . . . . . . . . . 35\\n\\n6.2 Tree Languages and Automata . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n\\n6.2.1 Lo\\ral Tree Languages\\n\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n\\n6.2.2 Regular Tree Languages . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n\\n6.2.3 Context-free Tree Languages\\n\\n. . . . . . . . . . . . . . . . . . . . . . . 39\\n\\n6.3 Proof Trees as Stru\\rtures for Lambek Grammars . . . . . . . . . . . . . . . . 40\\n\\n6.4 Proof-tree Stru\\rtures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\\n\\n6.5 De\\ridable and Unde\\ridable Problems aboutLambek Grammars . . . . . . . . 44\\n\\n6.6 Substitutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n\\n6.7 Grammars in Redu\\red Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n\\n7 Lambek Grammars as a Linguisti\\r Tool\\n\\n48\\n\\n7.1 Lambek Grammars and Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n\\n7.1.1 Transitive verbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n\\n7.1.2 Pronouns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n\\n7.1.3 Adverbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\n\\n7.1.4 Hypotheti\\ral reasoning . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\n\\n7.1.5 Transitivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\n\\n7.2 Lambek Grammars and Montague Semanti\\rs\\n\\n. . . . . . . . . . . . . . . . . . 53\\n\\n8 Rigid Lambek Grammars\\n\\n56\\n\\n8.1 Rigid and k-Valued Lambek Grammars\\n\\n. . . . . . . . . . . . . . . . . . . . . 56\\n\\n8.2 Most General Uni(cid:28)ers and ⊔ Operator . . . . . . . . . . . . . . . . . . . . . . 60\\n\\nINRIA\\n\\n\\x0cLearnability for Rigid Lambek Grammars\\n\\n83\\n\\n9 Learning Rigid Lambek Grammars from Stru\\rtures\\n\\n63\\n\\n9.1 Grammati\\ral Inferen\\re as Uni(cid:28)\\ration . . . . . . . . . . . . . . . . . . . . . . . 64\\n\\n9.2 Argument Nodes and Typing Algorithm . . . . . . . . . . . . . . . . . . . . . 64\\n\\n9.3 RLG Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\\n\\n9.4 Properties of RLG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71\\n\\n10 Con\\rlusion and Further Resear\\rh\\n\\n77\\n\\nRR n° 0123456789\\n\\n\\x0cUnité de recherche INRIA Futurs\\nParc Club Orsay Université - ZAC des Vignes\\n4, rue Jacques Monod - 91893 ORSAY Cedex (France)\\n\\nUnité de recherche INRIA Lorraine : LORIA, Technopôle de Nancy-Brabois - Campus scientiﬁque\\n615, rue du Jardin Botanique - BP 101 - 54602 Villers-lès-Nancy Cedex (France)\\nUnité de recherche INRIA Rennes : IRISA, Campus universitaire de Beaulieu - 35042 Rennes Cedex (France)\\nUnité de recherche INRIA Rhône-Alpes : 655, avenue de l’Europe - 38334 Montbonnot Saint-Ismier (France)\\nUnité de recherche INRIA Rocquencourt : Domaine de Voluceau - Rocquencourt - BP 105 - 78153 Le Chesnay Cedex (France)\\nUnité de recherche INRIA Sophia Antipolis : 2004, route des Lucioles - BP 93 - 06902 Sophia Antipolis Cedex (France)\\n\\nÉditeur\\nINRIA - Domaine de Voluceau - Rocquencourt, BP 105 - 78153 Le Chesnay Cedex (France)\\n\\nhttp://www.inria.fr\\n\\nISSN 0249-6399\\n\\n\\x0c'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'bovolo f. bruzzone l. an internal crown geometric model for conifer species classification with high density lidar data. ieee transactions on geoscience and remote sensing holmgren j. persson Ã¥. identifying species of individual trees using airborne laser scanner. remote sensing of environment hyyppÃ¤ j. yu x. hyyppÃ¤ h. vastaranta m. holopainen m. kukko a. kaartinen h. jaakkola a. vaaja m. koskinen j. advances in forest inventory using airborne laser scanning. remote sensing  jing'\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teststring = \"bovolo f. bruzzone l. an internal crown geometric model for conifer species classification with high density lidar data. ieee transactions on geoscience and remote sensing holmgren j. persson \\xc3\\xa5. identifying species of individual trees using airborne laser scanner. remote sensing of environment hyypp\\xc3\\xa4 j. yu x. hyypp\\xc3\\xa4 h. vastaranta m. holopainen m. kukko a. kaartinen h. jaakkola a. vaaja m. koskinen j. advances in forest inventory using airborne laser scanning. remote sensing \\x0c jing\"\n",
    "teststring = repr(teststring)\n",
    "teststring = re.sub(r\"(\\\\x\\S\\S)\", '',teststring)\n",
    "teststring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\\\x\\S{2})\n"
     ]
    }
   ],
   "source": [
    "print (r\"(\\\\x\\S{2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'many researchers have explored methods for hierarchical reinforcement learning with temporal abstractions in which abstract actions are defined that can perform many primitive actions before terminating. however little is known about learning with state abstractions in which aspects of the state space are ignored. in previous work we developed the maxq method for hierarchical rl. in this paper we define five conditions under which state abstraction can be combined with the maxq value function decomposition. we prove that the maxq q learning algorithm converges under these conditions and show experimentally that state abstraction is important for the successful application of maxq q learning.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the Text; start from most to least specific\n",
    "cleanedText = corpusAbstract[1]\n",
    "#cleanedText = cleanedText.split(\"Abstract\",1)[1]#Removes all junk before abstract\n",
    "cleanedText = cleanedText.rsplit(\"\\nReferences\\n\", 1)[0] #Removes all references, starts from back\n",
    "cleanedText = re.sub(r'\\x0c','', cleanedText) #Remove page breaks\n",
    "cleanedText = re.sub(r'-\\n','', cleanedText)\n",
    "cleanedText = re.sub(r'\\n-','', cleanedText) #Hyphens before & after new lines are usually added for continuation of a word\n",
    "cleanedText = re.sub(r'\\n',' ',cleanedText)#Get rid of new lines replace with spaces\n",
    "#Run it 3 times to get most equations but leave most of the text\n",
    "for x in range(0,2):\n",
    "    cleanedText = re.sub(r'(\\(([^)^(]+)\\))','',cleanedText) #removes everything inside of parentheses, have to re-run for nested\n",
    "    cleanedText = re.sub(r'(\\[([^]^[]+)\\])','',cleanedText) #removes everything inside of square brackets\n",
    "    cleanedText = re.sub(r'(\\{([^}^{]+)\\})','',cleanedText) #removes everything inside of curly brackets \n",
    "cleanedText = re.sub(r'[^\\w^\\s^.]',' ', cleanedText) #Remove all characters not [a-zA-Z0-9_] excluding spaces\n",
    "cleanedText = re.sub(r'\\d','', cleanedText) #Remove all numbers\n",
    "cleanedText = re.sub(' +', ' ', cleanedText).strip() #Replace all multiple spaces with one space\n",
    "cleanedText = cleanedText.lower()\n",
    "cleanedAbs = cleanedText\n",
    "lenAbs = len(cleanedAbs)\n",
    "lastwords = cleanedAbs[-10:]\n",
    "cleanedAbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'institut national de recherche en informatique et en automatique a study on learnability for rigid lambek grammars g u a g l. s c v s c v i x r a n s s i roberto bonato n juin thème sym a p p o r t d e r e c h e r c h e a study on learnability for rigid lambek grammars roberto bonato thème sym systèmes symboliques pro jet signes rapport de re\\rher\\rhe n juin pages abstra\\rt we present basi\\r notions of gold s learnability in the limit paradigm rst pre sented in a formalization of the \\rognitive pro\\ress by whi\\rh a native speaker gets to grasp the underlying grammar of his her own native language by being exposed to well formed senten\\res generated by that grammar. then we present lambek grammars a for malism issued from \\rategorial grammars whi\\rh although not as expressive as needed for a full formalization of natural languages is parti\\rularly suited to easily implement a nat ural interfa\\re between syntax and semanti\\rs. in hte last part of this work we present a learnability result for rigid lambek grammars from stru\\rtured examples. key words formal learning theory ma\\rhine learning lambek \\ral\\rulus \\romputational linguisti\\rs formal grammars unité de recherche inria futurs parc club orsay université zac des vignes rue jacques monod orsay cedex téléphone télécopie une étude sur l apprenabilité des grammaires de lambek rigides résumé on présente les notions basiques du paradigme d apprenabilité à la limite pour une \\rlasse de grammaires formelles deni par gold en \\romme possible formalisation du pro\\ressus \\rognitif qui permet l apprentissage d une langue naturelle à partir d exemples d énon\\rés bien formés. ensuite nous presentons les grammaires de lambek un formalisme issu des grammaires \\ratégorielles que bien que en\\rore insusant à rendre \\rompte de nombre de phenomenes linguistiques a des qualités intéréssantes par rapport à l interfa\\re syntaxe sémantique. enn nous présentons un résultat d apprenabilité pour les grammaires de lambek rigides dans le modèle d apprentissage de gold à partir d exemples stru\\rturés. mots \\rlés théorie formelle de l apprentissage apprentissage automatique \\ral\\rul de lambek linguistique \\romputationnelle grammaires formelles learnability for rigid lambek grammars introdu\\rtion how \\romes it that human beings whose \\ronta\\rts with the world are brief and personal and limited are nevertheless able to know as mu\\rh as they do know sir bertrand russell. formal learning theory was rst dened in an arti\\rle by e. m. gold in as a rst eort to provide a rigurous formalization of grammati\\ral inferen\\re that is the pro\\ress by whi\\rh a learner presented with a \\rertain given subset of well formed senten\\res of a given language gets to infer the grammar that generates it. the typi\\ral example of su\\rh a pro\\ress is given by a \\rhild whi gets to master in a \\rompletely spontaneous way and on the basis of the relatively small amount of information provided by senten\\res uttered in its \\rultural environment the higly \\romplex and subtle rules of her mother tongue to the point that she \\ran utter \\rorre\\rt and original senten\\res before her third year of life. in owdjm su\\rh a formal framework is used in the broder \\rontext of the mathemati\\ral formalization of any kind of indu\\rtive reasoning. in this \\rase the learner is the s\\rientist who on the basis of nite amount of empiri\\ral eviden\\res provided by natural phenomena formulates s\\rienti\\r hypotheses would \\rould intensionally a\\r\\runt for them. after an initial skepti\\rism about the grammars that \\rould be a\\rtually learnt in gold s paradigm re\\rently there has been a renewal of interest toward this \\romputational model of learning. one of the most re\\rent results is shinohara s who proves that as soon as we bound the number of rules in a \\rontext sensitive grammar it be\\romes learnable in gold s paradigm. lambek grammars have re\\rently known a renewed interest as a mathemati\\ral tool for the des\\rription of \\rertain linguisti\\rs phenomena after having being long negle\\rted after their rst denition in lam. van benthem was among the rst who stressed the singu lar \\rorresponden\\re between montague semanti\\rs and the notion of stru\\rture asso\\riated to a senten\\re of a lambek grammar. in parti\\rular a re\\rent work by hans jorg tiede has made \\rlearer the notion of stru\\rture of a senten\\re in a lambek gram mar in \\rontrast with a previsous denition given by buszkowski. in doing so he gets to prove a meaningful result about lambek grammars that is that the \\rlass of tree languages generated by lambek grammars stri\\rtly \\rontains the \\rlass of tree languages generated by \\rontext free grammars. se\\rtion introdu\\res the basi\\r notions of learning theory by gold and provides a short review of most important known fa\\rt and results about it. se\\rtion is a short introdu\\rtion fo lambek grammars we give their denition and we present the features whi\\rh make them attra\\rtive from a \\romputational linguisti\\rs point of view. se\\rtion briey presents the \\rlass of rigid lambek grammars whi\\rh is the ob je\\rt of our lerning algorithm along with some basi\\r properties and open questions. in se\\rtion we present a learning algorithm for rigid rr n bonato lambek grammars from a stru\\rtured input the algorithm takes as its input a nite set of what has been dened in \\rhapter as proof tree stru\\rtures. it is proved \\ronvergen\\re for the algorithm and so the lernability for the \\rlass of rigid lambek grammars. inria learnability for rigid lambek grammars grammati\\ral inferen\\re. child s first language a\\rquisition one of the most \\rhallenging goals for modern \\rognitive s\\rien\\res is providing a sound theory a\\r\\rounting for the pro\\ress by whi\\rh any human being gets to master the highly \\romplex and arti\\rulated grammati\\ral stru\\rture of her mother tongue in a relatively small amount of time. between the age of and we witness in \\rhildren a linguisti\\r explosion at the end of whi\\rh we \\ran say that the \\rhild masters all the grammati\\ral rules of her mother tongue and subsequent learning is not but lexi\\ron a\\rquisition. moreover \\rognitive psy\\rhologists agree in stating that the learning pro\\ress is almost \\rompletely based on positive eviden\\re provided by the \\rultural environment wherein the \\rhild is grown up that is \\rorre\\rt statements belonging to her mother tongue. negative eviden\\re is almost \\rompletely absent and in any \\rase doesn t seem to play any signi\\rant role in the pro\\ress of learning. simply stated the \\rhild a\\rquires a language due to the exposition to \\rorre\\rt senten\\res \\roming from her linguisti\\r environment and not to the negative feedba\\rk she gets when she utters a wrong senten\\re. providing a formal framework wherein to ins\\rribe su\\rh an astounding ability to extra\\rt highly arti\\rulated knowledge from a relatively small amount of raw data was one of the ma jor for\\res that led to the the denition of a formal learning theory as the one we are going to des\\rribe in the following se\\rtions. gold s model the pro\\ress of a \\rhild s rst language a\\rquisition \\ran be seen as an instan\\re of the more general problem of grammati\\ral inferen\\re. in parti\\rular we will restri\\rt our attention to the pro\\ress of inferen\\re from positive data only. simply stated it s the pro\\ress by whi\\rh a learner \\ran a\\rquire the whole grammati\\ral stru\\rture of a formal language on the basis of well formed senten\\res belonging to the target language. in gold dened the formal model for the pro\\ress of grammati\\ral inferen\\re from positive data that will be adopted in the present work. in gold s model grammati\\ral inferen\\re is \\ron\\reived as an innite pro\\ress during whi\\rh a learner is presented with an innite stream of senten\\res s s. sn. belonging to language whi\\rh has to be learnt one senten\\re at a time. ea\\rh time the learner is presented with a new senten\\re si she formulates a new hypothesis gi on the nature of the underlying grammar that \\rould generate the language the senten\\res she has seen so far belong to sin\\re she is exposed to an innite number of senten\\res she will \\ronje\\rture an innite number of grammars g g. gn. .. rr n bonato s s. sn. g g gn. g two basi\\r assumptions are made about the stream of senten\\res she is presented with only grammati\\ral senten\\res appear in the stream \\roherently with our \\rommitment to the pro\\ress of grammar indu\\rtion from positive data only every possible senten\\re of the language must appear in the stream. the learning pro\\ress is \\ronsidered su\\r\\ressful when from a given point onward the gram mar \\ronje\\rtured by the learner doesn t \\rhange anymore and it \\roin\\rides with the grammar that a\\rtually generates the target language. it is important to stress the fa\\rt that one \\ran never know at any nite stage whether the learning has been su\\r\\ressful or not due to the innite nature of the learning pro\\ress itself at ea\\rh nite stage no one \\ran predi\\rt whether next senten\\re will \\rhange or not the \\rurrent hypothesis. the goal of the theory lies in devising a su\\r\\ressful strategy for making guesses that is one whi\\rh \\ran be proved to \\ronverge to the \\rorre\\rt grammar after a nite amount of time. gold \\ralled this \\rriterion of su\\r\\ressful learning identi\\ration in the limit. a\\r\\rording to this \\rriterion a \\rlass of grammars is said to be learnable when for any language generated by a grammar belonging to the \\rlass and for any enumeration of its senten\\res there is a learner that su\\r\\ressfully identies the \\rorre\\rt grammar that generates the language. a good deal of \\rurrent resear\\rh on formal learning theory is devoted to identifying non trivial \\rlasses of languages whi\\rh are learnable in gold s model or useful \\rriterions to dedu\\re learnability for a \\rlass of languages on the basis of some stru\\rtural property of the language. as it will be made \\rlear in the following se\\rtions a\\r\\repting this \\rriterion for su\\r\\ressful learning means that we are not interested in when the learning has taken pla\\re in fa\\rt there s no ee\\rtive way to de\\ride if it has or not at any nite stage. our aim is to devise ee\\rtive pro\\redures su\\rh that if applied to the innite input stream of senten\\res are guaranteed to \\ronverge to the grammar we are looking for if it exists. basi\\r notions we present here a short review of learning theory as des\\rribed in kan when\\re we take the prin\\ripal denitions and notation \\ronventions. inria learnability for rigid lambek grammars. grammar systems the st step in the formalization of the learning pro\\ress is the formal denition of both the \\rultural environment wherein this pro\\ress takes pla\\re and the positive eviden\\res the learner is exposed to. to do this we introdu\\re the notion of grammar system. denition. a grammar system is a triple hω s li where ˆ ω is a \\rertain re\\rursive set of nitary obje\\rts on whi\\rh me\\rhani\\ral \\romputations \\ran be \\rarried out ˆ s is a \\rertain re\\rursive subset of σ where σ is a given nite alphabet ˆ l is a fun\\rtion that maps elements of ω to subsets of s i.e. l ω. we \\ran think of ω as the hypothesis spa\\re when\\re the learner takes her grammati\\ral \\ronje\\rtures a\\r\\rording to the positive examples she has been exposed to up to a \\rertain nite stage of the learning pro\\ress. elements of ω are \\ralled grammars. positive examples presented to the learner belong to the set s its elements are \\ralled senten\\res while its subsets are \\ralled languages. as it will pro\\ress of learning intuitively we \\ran guess that the more information they bear the easier the learning pro\\ress is if it is possible at all. the fun\\rtion l maps ea\\rh grammar g belonging to ω into a subset of s whi\\rh is designated as the language generated by g. that s why we often refer to l as the naming fun\\rtion. the question of whether s l holds between any s s and g ω is addressed to as the universal membership problem. example. let σ be any nite alphabet and let df a be the set of deterministi\\r nite automata whose input alphabet is σ. for every m df a let l be the set of strings over σ a\\r\\repted by m. then hdf a σ li is a grammar system. example. let σ be any nite alphabet and let regexpr be the set of regular expressions over σ. for every r regexpr let l be the regular language represented by r. then hregexpr σ li is a grammar system. example. let σ any nite alphabet and let v ar be a \\rountably innite set of variables disjoint from σ. a pattern over σ is any element of p at be the set of patterns over σ. for every p p at let l be the set of strings that \\ran be obtained from p by uniformly repla\\ring ea\\rh variable x o\\r\\rurring in p by some string w σ. the triple hp at σ li is a grammar system. let rr n bonato ω g g φ φ φ n s l l l l n figure grammati\\ral inferen\\re. learning fun\\rtions convergen\\re learnability on\\re formally dened both the set of possible guesses the learner \\ran make and the set of the positive examples she is exposed to we need a formal notion for the me\\rhanism by whi\\rh the learner formulates hypotheses on the basis nite sets of well formed senten\\res of a given language about the grammar that generates them. denition. let hω s li be a grammar system. a learning fun\\rtion is a partial fun\\rtion that maps nite sets of senten\\res to grammars ϕ sk ω k where sk denotes the set of k ary sequen\\res of senten\\res. a learning fun\\rtion \\ran be seen as a formal model of the \\rognitive pro\\ress by whi\\rh a learner \\ronje\\rtures that a given nite set of senten\\res belongs to the language generated by a \\rertain grammar. sin\\re it s partial possibly the learner \\rannot infer any grammar from the stream of senten\\res she has seen so far. a\\r\\rording to the informal model outlined in se\\rtion. in a su\\r\\ressful learning pro\\ress we require the guesses made by the learner to remain the same from a \\rertain point onward in the innite pro\\ress of learning. that is to say there must be a nite stage after whi\\rh the grammar inferred on the basis of all the positive examples the learner has seen so far is always the same. this informal idea \\ran be made pre\\rise by introdu\\ring the notion of \\ronvergen\\re for a learning fun\\rtion denition. let hω s li be a grammar system ϕ a learning fun\\rtion an innite sequen\\re of senten\\res belonging to s and let hsiii n hs s. .i gi ϕ for any i n su\\rh that ϕ is dened on the nite sequen\\re hs. sii. ϕ is said to \\ronverge to g on hsiii n if there exists n n su\\rh that for ea\\rh i n gi is dened and gi g. as we ve already pointed out one \\ran never say exa\\rtly if and when \\ronvergen\\re of a learning fun\\rtion to a \\rertain grammar has taken pla\\re this is due to the innite nature of the pro\\ress by whi\\rh a learner gets to learn a given language in gold s model. at any nite stage of the learning pro\\ress there s no way to know whether the next senten\\re the learner will see \\rauses the \\rurrent hypothesis to \\rhange or not. we will say that a \\rlass of grammars is learnable when for ea\\rh language generated by its grammars there exists a learning fun\\rtion whi\\rh \\ronverges to the \\rorre\\rt underlying grammar on the basis of any enumeration of the senten\\res of the language. formally denition. let hω s li be a grammar system and g ω a given set of grammars. the learning fun\\rtion ϕ is said to learn g if the fol lowing \\rondition holds ˆ for every language l l ˆ and for every innite sequen\\re hsiii n that enumerates l there exists a g g su\\rh that l l su\\rh that ϕ \\ronverges to g on hsiii n. so we will say that a given learning fun\\rtion \\ronverges to a single grammar but that it learns a \\rlass of grammars. the learning for a single grammar indeed \\rould be trivially implemented by a learning fun\\rtion that for any given sequen\\re of senten\\res as input always returns that grammar. denition. a \\rlass g of grammars is \\ral led learnable if and only if there exists a learning fun\\rtion that learns g. it is \\ral led ee\\rtively learnable if and only if there is a \\romputable learning fun\\rtion that learns g. obviously ee\\rtive learnability implies learnability. rr n bonato example. let hω s li be any grammar system and let g ω and suppose there are elements w w s su\\rh that w l l and w l. then it s easy to verify that the fol lowing learning fun\\rtion learns g ϕ otherwise. if w if w and w g g g example. let s \\ronsider the grammar system hcf g σ li of \\rontext free grammars over the alphabet σ. let g be the sub\\rlass of cf g \\ronsisting of grammars whose rules are al l of the form s w where w σ let s dene the learning fun\\rtion ϕ as. we \\ran easily see that l is exa\\rtly the \\rlass of nite languages over σ. ϕ hς s p i p. where then ϕ learns g. stru\\rtural conditions for learnability one of the rst important results in learnability theory presented in gol was a su\\rient \\rondition to dedu\\re the unlearnability of a \\rlass g of grammars on the basis of some formal properties of the \\rlass of languages l l. we present here some stru\\rtural \\ronditions su\\rient to dedu\\re learnability for a \\rlass of grammars. su\\rh results are useful to get a deeper understanding to the general problem of learnability for a \\rlass of grammars. .. existen\\re of a limit point let s dene the notion of limit point for a \\rlass of languages denition. a \\rlass l of languages has a limit point if there exists an innite sequen\\re hlnin n of languages in l su\\rh that and there exists another language l l su\\rh that l l ln the language l is \\ral led limit point of l. l ln n n inria learnability for rigid lambek grammars l l l ln l figure a limit point for a \\rlass of languages. lemma. suppose that a learning fun\\rtion ϕ \\ronverges on every innite sequen\\re that enumerates a language l. then there is a nite sequen\\re hw. wli with the fol lowing properties l for every nite sequen\\re hv. vmi if l then ϕ ϕ. intuitively enough the previous lemma states that if a learning fun\\rtion \\ron verges then there must exist a nite subsequen\\re of input senten\\res that lo\\rks the guess made by the learner on the grammar the learning fun\\rtion \\ronverges to that is to say the learning fun\\rtion returns always the same grammar for any input stream of senten\\res \\rontaining that nite sequen\\re. learnability framework the lo\\rking sequen\\re lemma proves one of the rst unlearnability \\rriterions in gold s theorem. if l has a limit point then g is not learnable. an easy \\ronsequen\\re of the previous theorem is the following theorem. for any grammar system a \\rlass g of grammars is not learnable if l \\rontains al l nite languages and at least one innite language. proof sket\\rh. let l l. be a sequen\\re of nite languages and let l i li. suppose there were a learning fun\\rtion ϕ that learns the \\rlass. then ϕ must identify any nite language in a nite amount of time. but then we \\ran build an innite sequen\\re of senten\\res that for\\res ϕ to make an innite number of mistakes we rst present ϕ with enough examples from l to make it guess l then with enough examples from l to make it guess l and so on. note that all our examples belong to l. s rr n bonato .. finite elasti\\rity as we ve seen in the previous se\\rtion the existen\\re of a limit point for a \\rlass of languages implies the existen\\re of an innite as\\rending \\rhain of languages like the one des\\rribed by the following weaker \\rondition denition. a \\rlass l of languages is said to have innite elasti\\rity if there exists an innite sequen\\re hsnin n of senten\\res and an innite sequen\\re hlnin n of languages su\\rh that for every n n and sn ln ln. the following denition although trivial identies an extremely useful \\rriterion to dedu\\re learnability for a \\rlass of grammars denition. a \\rlass l of languages is said to have nite elasti\\rity if it doesn t have innite elasti\\rity. dana angluin proposed in ang a \\rhara\\rterization of the notion of learnability in a restri\\rtive setting whi\\rh is of paramount importan\\re in formal learning theory. su\\rh restri\\rtions are about the membership problem and the re\\rursive enumerability for the \\rlass of grammars whose learnability is at issue. let hω s li be a grammar system and g ω a \\rlass of grammars let s dene condition. there is an algorithm that given s s and g g determines whether s l. condition. g is a re\\rursively enumerable \\rlass of grammars. condition. is usually referred to as de\\ridability for the universal membership problem and \\rondition. as the re\\rursive enumerability \\rondition. su\\rh restri\\rtions are not unusual in \\ron\\rrete situations where learnability is at issue so they don t signi\\rantly ae\\rt the usefulness of the following \\rhara\\rterization of the notion learnability under su\\rh restri\\rtive \\ronditions. theorem. let hω s li be a grammar system for whi\\rh both \\ronditions. and. hold and let g be a re\\rursively enumerable subset of ω. then g is learnable if and only if there exists a \\romputable partial fun\\rtion ψ ω n s su\\rh that for al l n n ψ is dened if and only if g g and l for al l g g tg is a nite subset of l for al l g g g if tg l then l l. inria learnability for rigid lambek grammars note from this point onward unless otherwise stated we will restri\\rt our attention to \\rlasses of grammars that fulll both \\rondition. and \\rondition .. angluin s theorem introdu\\res the notion of tg as the tel l tale set for a given language. learnability in the restri\\rted environment is \\rhara\\rterized by the existen\\re of a me\\rhanism to enumerate all the senten\\res belonging to su\\rh a nite subset of the target language. even more a tell tale set for a given grammar g is su\\rh that if it is in\\rluded in the language generated by another grammar g then ˆ either l is in\\rluded in l ˆ or l \\rontains other senten\\res as well as those belonging to l. otherwise stated it is never the \\rase that tg l l. the point of the tell tale subset is that on\\re the strings of that subset have appeared among the sample strings we need not fear overgeneralization in guessing a grammar g. this is be\\rause the true answer even if it is not l \\rannot be a proper subset of l. this means that a learner who has seen only the senten\\res belonging to the tell tale set for a given grammar g is justied in \\ronje\\rturing g as the underlying grammar sin\\re doing so never results in overshooting or in\\ronsisten\\ry. tg lg lg lg figure a tell tale set for l. as a \\ronsequen\\re of angluin s theorem wright proved in wri the following theorem. let hω s li and g be as in theorem .. if l has nite elasti\\rity then g is learnable. in su\\rh a restri\\rted framework therefore the task of proving learnability for a \\rertain \\rlass of grammars \\ran be redu\\red to the usually simpler task of proving its nite elasti\\rity. rr n bonato due to wright s theorem we \\ran establish the following useful impli\\rations l has nite elasti\\rity g is learnable l has a limit point g is unlearnable g is unlearnable l has innite elasti\\rity the impli\\rations indi\\rated by depend on the de\\ridability of universal membership and re\\rursive enumerability of the \\rlass of grammars at issue as dened in \\ronditions. and .. .. kanazawa s theorem the following theorem whi\\rh is a generalization of a previous theorem by wright provides a su\\rient \\rondition for a \\rlass of grammars to have nite elasti\\rity and therefore to be learnable. a relation r σ υ for every s σ the set is nite. is said to be nite valued if and only if theorem. let m be a \\rlass of languages over υ that has nite elasti\\rity and let be a nite valued relation. then l also has nite r σ υ elasti\\rity. elasti\\rity. this theorem is a powerful tool to prove nite elasti\\rity for \\rlasses of grammars. on\\re we prove the nite elasti\\rity for a \\rertain \\rlass of grammars in the straight way we \\ran get a proof for nite elasti\\rity of other \\rlasses of grammars due to the relatively loose requirements of the theorem. all we have to do is to devise a smart nite valued relation between the rst \\rlass and a new \\rlass of grammars su\\rh that the anti image of the latter under this relation is the \\rlass for whi\\rh we want to prove nite r σ υ r m figure kanazawa s theorem. inria learnability for rigid lambek grammars. constraints on learning fun\\rtions in the denition of learnability nothing is said about the behaviour of learning fun\\rtions apart from \\ronvergen\\re to a \\rorre\\rt grammar. further \\ronstraints \\ran be imposed one \\ran \\rhoose a \\rertain learning strategy. intuitively a strategy refers to a poli\\ry or preferen\\re for \\rhoosing hypotheses. formally a strategy \\ran be analyzed as merely pi\\rking a subset of possible learning fun\\rtions. strategies \\ran be grouped by numerous properties. we \\rhoose to group them by restri\\rtiveness dened as follows denition. if a strategy \\ronstrains the \\rlass of learnable languages it is said to be restri\\rtive. for example strategies are grouped as \\romputational \\ronstraints \\ronstraints on potential \\ronje\\rtures \\ronstraints on the relation between \\ronje\\rtures et. sin\\re the \\rlasses we will be dis\\russing are all \\rlasses of re\\rursive languages restri\\rtive will be taken to mean restri\\rtive for \\rlasses of re\\rursive languages. .. non restri\\rtive constraints the proof of theorem. implies that in a grammar system where universal membership is de\\ridable a re\\rursively enumerable \\rlass of grammars is learnable if and only if there is a \\romputable learning fun\\rtion that learns it order independently prudently and is responsive and \\ronsistent on this \\rlass. denition. a learning fun\\rtion ϕ learns g orderindependently if for al l l l there exists g g su\\rh that l l and for al l innite sequen\\res hsiii n that enumerate l ϕ \\ronverges on hsiii n to g. intuitively this seems a reasonable strategy. there does not seem to be an a priori reason why either the order of presentation should inuen\\re the nal \\rhoi\\re of hypothesis. on the other hand it has already been proved that in any grammar system a \\rlass of grammars is learnable if and only if there is a \\romputable learning fun\\rtion that learns it order independently. denition. a learning fun\\rtion ϕ learns g exa\\rtly if for al l g su\\rh that ϕ learns g l l. in other words the learning fun\\rtion will not hypothesize grammars that are outside its \\rlass. this is not really a \\ronstraint on learning fun\\rtions but on the relation between a \\rlass of languages and a learning fun\\rtion. for every learning fun\\rtion there exists a \\rlass that it learns exa\\rtly. the reason for this \\ronstraint is the idea that \\rhildren only learn languages that have at least a \\rertain minimal expressiveness. if we want to model language learning we want learning fun\\rtions to learn a \\rhosen \\rlass exa\\rtly. there seems to be empiri\\ral support for this idea. some of it \\romes from studies of \\rhildren raised in pidgin diale\\rts some from studies of sensory deprived \\rhildren. rr n bonato denition. a learning fun\\rtion ϕ learns g prudently if ϕ learns g and range g. note that prudent learning implies exa\\rt learning. this redu\\res to the \\rondition that a learning fun\\rtion should only produ\\re a hypothesis if the learning fun\\rtion \\ran ba\\rk up its hypotheses i.e. if the hypothesis is \\ronrmed by the input the learning fun\\rtion is able to identify the language. denition. a learning fun\\rtion ϕ is responsive on g if for any l l and for any nite sequen\\re hs. sii of elements of l ϕ is dened. this \\ronstraint \\ran be regarded as the \\romplement of prudent learning if all senten\\res found in the input are in a language in the \\rlass of languages learned the learning fun\\rtion should always produ\\re a hypothesis. denition. a learning fun\\rtion ϕ is \\ronsistent on g if for any l l and for any nite sequen\\re hs. sii of elements of l either ϕ is undened or l. the idea behind this \\ronstraint is that all the data given should be explained by the \\rhosen hypothesis. it should be self evident that this is a desirable property. indeed one would almost expe\\rt it to be part of the denition of learning. however learning fun\\rtions that are not \\ronsistent are not ne\\ressarily trivial. if for example the input is noisy it would not be unreasonable for a learning fun\\rtion to ignore \\rertain data be\\rause it \\ronsiders them as unreliable. also it is a well known fa\\rt that \\rhildren do not learn languages \\ronsistently. .. restri\\rtive constraints denition. a learning fun\\rtion ϕ learns g set driven if ϕ is determined by or more pre\\risely if the fol lowing holds whenever ϕ is dened if and only if ϕ is dened and if they are dened they are equal. it is easy to see that set drivenness implies order independen\\re. set driven learning \\rould be very loosely des\\rribed as order independent learning with the addition of ignoring doubles in the input. it is obvious that this is a ni\\re property for a learning fun\\rtion to have one would not expe\\rt the \\rhoi\\re of hypothesis to be inuen\\red by repeated presentation of the same data. the assumption here is that the order of presentation and the number of repetitions are essentially arbitrary i.e. they \\rarry no information that is of any use to the learning fun\\rtion. one \\ran devise situations where this is not the \\rase. denition. a learning fun\\rtion ϕ is \\ronservative if for any nite sequen\\re hs. sii of senten\\res and for any senten\\re si whenever ϕ is dened and si l ϕ is also dened and ϕ ϕ. inria learnability for rigid lambek grammars at rst glan\\re \\ronservatism may seem a desirable property. why \\rhange your hypothesis if there is no dire\\rt need for it one \\rould imagine \\rases however where it would not be unreasonable for a learning fun\\rtion to \\rhange its mind even though the new data ts in the \\rurrent hypothesis. su\\rh a fun\\rtion \\rould for example make reasonable but wild guesses whi\\rh it \\rould later retra\\rt. the fun\\rtion \\rould note after a while that the inputs \\rover only a proper subset of its \\ronje\\rtured language. while su\\rh behaviour will sometimes result in temporarily overshooting su\\rh a fun\\rtion \\rould still be guaranteed to \\ronverge to the \\rorre\\rt hypothesis in the limit. it is a \\rommon assumption in \\rognitive s\\rien\\re that human \\rognitive pro\\resses \\ran be simulated by \\romputer. this would lead one to believe that \\rhildren s learning fun\\rtions are \\romputable. the \\rorresponding strategy is the set of all partial and total re\\rursive fun\\rtions. sin\\re this is only a subset of all possible fun\\rtions the \\romputability strategy is a non trivial hypothesis but not ne\\ressarily a restri\\rtive one. the \\romputability \\ronstraint intera\\rts with \\ronsisten\\ry proposition. there is a \\rol le\\rtion of languages that is identiable by a \\romputable learning fun\\rtion but by no \\ronsistent \\romputable learning fun\\rtion. the \\romputability \\ronstraint also intera\\rts with \\ronservative learning proposition. there is a \\rol le\\rtion of languages that is identiable by a \\romputable learning fun\\rtion but by no \\ronservative \\romputable learning fun\\rtion. denition. the learning fun\\rtion ϕ is monotone in\\rreasing if for al l nite sequen\\res hs. sni and hs. sn mi whenever ϕ and ϕ are dened l l. when a learning fun\\rtion that is monotone in\\rreasing \\rhanges its hypothesis the language asso\\riated with the previous hypothesis will be in\\rluded in the language asso\\ri ated with the new hypothesis. there seems to be little or no empiri\\ral support for su\\rh a \\ronstraint. denition. the learning fun\\rtion ϕ is in\\rremental if there exists a \\romputable fun\\rtion ψ su\\rh that ϕ ψ. an in\\rremental learning fun\\rtion does not need to store previous data. all it needs is \\rurrent input sn and its previous hypothesis. a generalized form of this \\ronstraint \\ralled memory limitation limits a\\r\\ress for a learning fun\\rtion to only n previous elements of the input sequen\\re. this seems reasonable from an empiri\\ral point of view it seems improbable that \\rhildren store all utteran\\res they en\\rounter. rr n bonato note that on an innite sequen\\re enumerating language l in l a \\ronservative learning fun\\rtion ϕ learning g never outputs any grammar that generates a proper superset of l. let ϕ be a \\ronservative and \\romputable learning fun\\rtion that is responsive and \\ronsistent on g and learns g prudently. then whenever l for some l l l must be a minimal element of the set. this implies the following \\rondition condition. there is a \\romputable partial fun\\rtion ψ that takes any nite set d of senten\\res and maps it to a grammar ψ g su\\rh that l is a minimal element of whenever the latter set is non empty. denition. let ψ a \\romputable fun\\rtion satisfying \\rondition .. dene a learning fun\\rtion ϕ as fol lows ϕ ψ ϕ ϕ if si l ψ otherwise. under \\rertain \\ronditions the fun\\rtion just dened is guaranteed to learn g one su\\rh \\rase is where l g has nite elasti\\rity. proposition. let g be a \\rlass of grammars su\\rh that l has nite elasti\\rity and a \\romputable fun\\rtion ψ satisfying \\rondition. exists. then the learning fun\\rtion ϕ dened in denition. learns g. is learning theory powerful enough. first negative results one of the main and apparently dis\\rouraging \\ronsequen\\res of the theorem. proved by gold in the original arti\\rle wherein he laid the foundations of formal learning theory was that none of the four \\rlasses of chomsky s hierar\\rhy is learnable under the \\rriterion of identi\\ration in the limit. su\\rh a rst negative result has been taken for a long time as a proof that identifying languages from positive data a\\r\\rording to his identi\\ration in the limit \\rriterion was too hard a task. gold himself looks quite pessimisti\\r about the future of the theory he has just dened along its main dire\\rtions however the results presented in the last se\\rtion show that only the most trivial \\rlass of languages \\ronsidered is learnable... gol inria learnability for rigid lambek grammars. angluin s results the rst example of non trivial \\rlass of learnable grammars was dis\\rovered by dana angluin. if p at is dened like in example. we \\ran prove that the \\rlass of all pattern languages has nite elasti\\rity and therefore it is learnable. furthermore su\\rh a learnable \\rlass of grammars was also the rst example of an interesting \\rlass of grammars that \\rross \\ruts chomsky hierar\\rhy therefore showing that chomsky s is not but one of many meaningful possible \\rlassi\\rations for formal grammars. shinohara s results initial pessimism about ee\\rtive usefulness of gold s notion of identi\\ration in the limit was denitely abandoned after an impressive result by shinohara who proves that k rigid \\rontext sensitive grammars have nite elasti\\rity for any k. sin\\re the universal membership problem for \\rontext sensitive grammars is de\\ridable that \\rlass of grammars is learnable. this is a parti\\rular \\rase of his more general result about nite elasti\\rity for what he \\ralls monotoni\\r formal system. kanazawa s results makoto kanazawa in kan makes another de\\risive step toward bridging the existing gap between formal learning theory and \\romputational linguisti\\rs. indeed he gets some important results on the learnability for some non trivial sub\\rlasses of classi\\ral categorial grammars. analogously to what is done in shi he proves that as soon as we bound the maximum number of types a \\rlassi\\ral \\rategorial grammar assigns to a word we get sub\\rlasses whi\\rh \\ran be ee\\rtively learnable in parti\\rular he proves ee\\rtive learnability for the \\rlass of k valued classi\\ral categorial grammars both from stru\\rtures and from strings. in the rst \\rase ea\\rh string of the language the learner is presented to \\romes with additional information about the underlying stru\\rture indu\\red by the grammar formalism that generates the language. the availability of su\\rh additional information for ea\\rh string is somewhat in \\rontrast with gold s model of learning and gives rise to weaker results. on the other hand psy\\rhologi\\ral plausibility of the pro\\ress is preserved by the fa\\rt that su\\rh an underlying stru\\rture \\ran be seen as some kind of semanti\\r information that \\rould be available to the \\rhild learning the language from the very early stages of her \\rognitive the present work pushes kanazawa s results a little further in the dire\\rtion of proving the ee\\rtive learnability for more and more powerful and expressive \\rlasses of formal languages. in parti\\rular we will be able to prove learnability for the \\rlass of rigid lambek grammars development. our results rr n bonato and to show an ee\\rtive algorithm to learn them on the basis of a stru\\rtured input. mu\\rh is left to be done along this dire\\rtion of resear\\rh sin\\re even a formal theory for rigid lambek grammars is still under developed. however our results \\ronrm on\\re again that initial pessimism toward this paradigm of learning was largely unjustied and that even quite a \\romplex and linguisti\\rally motivated formalism like lambek grammars \\ran be learnt a\\r\\rording to it. inria learnability for rigid lambek grammars lambek grammars in joa\\rhim lambek proposed to extend the formalism of classi\\ral cate gorial grammars by a dedu\\rtive system to derive type \\rhange rules. a bcg is basi\\rally as a nite relation between the nite set of symbols of the alphabet and a nite set of types. combinatory properties of ea\\rh word are \\rompletely determined by the shape of its types whi\\rh \\ran be \\rombined a\\r\\rording to a small set of rules xed on\\re and for all bcgs. lambek s proposal marked the irruption of logi\\rs into grammars lambek grammars \\rome with a whole dedu\\rtive system that allows the type of a symbol to be repla\\red with a weaker type. it was rst realized by van benthem that the proofs of these type \\rhanges prin\\riples \\rarry important information about their semanti\\r interpretation following the curry howard isomorphism. thus the notion of a proof theoreti\\ral grammar was proposed that repla\\res formal grammars with dedu\\rtive systems and that in\\rludes a systemati\\r semanti\\rs for natural languages based on the relationship between proof theory and type theory. thus rather than \\ronsidering grammati\\ral \\rategories as unanalyzed prim itives they are taken to be formulas \\ronstru\\rted from atoms and \\ronne\\rtives and rather than dening grammars with respe\\rt to rewrite rules grammars are dened by the rules of inferen\\re governing the \\ronne\\rtives used in the synta\\rti\\r \\rategories. due to the renewed interest in \\rategorial grammars in the eld of \\romputational lin guisti\\rs lambek grammars are \\rurrently \\ronsidered as a promising formalism. they enjoy the relative simpli\\rity of a tightly \\ronstrained formalism as that for bcgs together with the linguisti\\rally attra\\rtive feature of full lexi\\ralization. besides although pentus proved that lambek grammars generate exa\\rtly \\rontext free languages in tie it has been shown that their strong generative \\rapa\\rity is greater than that of \\rontext free grammars. these features make them an in teresting sub je\\rt for our inquiry about their properties with respe\\rt to gold s learnability theory. classi\\ral categorial grammars the main idea whi\\rh lies behind the theory of categorial grammars is to \\ron\\reive a grammar instead as a set of rules whi\\rh generate any string of the language as a system whi\\rh assigns to ea\\rh symbol of the alphabet a set of types whi\\rh \\ran be \\rombined a\\r\\rording to a small set of rules xed for the whole \\rlass of classi\\ral categorial grammars. a \\rontext free grammar á la chomsky is made of a set of rules that generate all the strings of a given language in a top down fashion starting from an initial symbol whi\\rh identies all the well formed strings. on the \\rontrary a \\rategorial grammar a\\r\\repts a sequen\\re of symbols of the alphabet as a well formed string if and only if a sequen\\re of types assigned to them redu\\res a\\r\\rording to a xed set of rules to a distinguished type whi\\rh designates well formed strings. rr n bonato denition. a classi\\ral categorial grammar is a quadruple hς p r f si su\\rh that ˆ σ is a nite set ˆ pr is a nite set ˆ f is a fun\\rtion from σ to nite subsets of tp where tp is the smal lest set su\\rh that. p r t p. if a b t p then t p if f we usual ly write g a a. an. ˆ s p r is the distinguished atomi\\r \\rategory in a ccg \\rombinatory properties are uniquely determined by their stru\\rture. there are only two modes of type \\rombination so \\ralled ba\\rkward appli\\ration and forward appli\\ration a non empty sequen\\re of types a. an is said to derive a type b that is a a b b b a a b. a. an b if repeated appli\\rations of the rules of ba\\rkward and forward appli\\ration to the sequen\\re a. an results in b. in order to dene the language generated by a ccg we have to establish a \\rriterion to identify a string belonging to that language. that s what is done by the following denition. the binary relation is dened as fol lows. let a b t p let α β t p t p t p α a a b β α b β α b a a β α b β the language generated by a ccg g is the set where is the reexive transitive \\rlosure of. inria learnability for rigid lambek grammars informally we \\ran say that a string of symbols belongs to the language generated by a ccg if there exists a derivation of the distinguished \\rategory s out of at least one sequen\\re of types assigned by the grammar to the symbols of the string. example. the fol lowing grammar generates the language here is a derivation for ab a b s b b s b s b s b s b b s b s b s b s b s s b s b s b s b b s b s b s s b s b b s weak generative \\rapa\\rity of ccgs was \\rhara\\rterized by gaifman theorem. the set of languages generated by ccgs \\roin\\rides with the set of \\rontext free languages. from the proof of gaifman s theorem we immediately obtain the following normal form theorem. every \\rategorial grammar is equivalent to a \\rat egorial grammar whi\\rh assigns only \\rategories of the form example. a ccg equivalent to that in example. in gaifman normal form is the theorem fol lowing and here is a derivation for ab a a b c. a s b s b b s b b s s s b s s b s b b b in the previous example we make use for the rst time of a natural dedu\\rtion notation for derivations that in the present work will substitute the \\rumbersome notation used in example .. rr n bonato. extensions of classi\\ral categorial grammars as stated in the previous se\\rtion ccg formalism \\romes with only two redu\\rtion rules whi\\rh yield smaller types out of larger ones. montague s work on semanti\\rs led to the denition of two further type raising rules by whi\\rh it is possible to \\ronstru\\rt new synta\\rti\\r \\rategories out of atomi\\r ones. we \\ran extend the denition of ccgs as presented in the previous se\\rtion by adding to the former denition two new type \\rhange rules other type \\rhange rules that were proposed are the \\romposition αbβ α aβ αbβ αa β a b b c a c c b b a c a a b b a and the gea\\rh rules we \\ran extend the formalism of ccg by adding to denition. any type \\rhange rule we need to formalize spe\\ri\\r phenomena in natural language. su\\rh a rule based approa\\rh was adopted by steedman who enri\\rhes \\rlassi\\ral \\rategorial grammar formalism with a nite number of type \\rhanges rules. on the other hand as it will be made \\rlear in the following se\\rtion lambek s approa\\rh is a dedu\\rtive one he denes a \\ral\\rulus in whi\\rh type \\rhanges rules spring out as a \\ronsequen\\re of the operations performed on the types. one \\rould ask why we should follow the dedu\\rtive rather than the rule based approa\\rh. to begin with as proved in zie lambek cal\\rulus is not nitely axiomatizable that is to say that adding a nite number of type \\rhange rules to the formalism of ccg one \\rannot derive all the type \\rhange rules provable in the lambek cal\\rulus. moreover the two approa\\rhes are very dierent under a theoreti\\ral viewpoint. from a linguisti\\r perspe\\rtive steedman pointed out that there is no reason why we should sti\\rk to a dedu\\rtive approa\\rh instead of to a rule based one he underlines the importan\\re of introdu\\ring ad ho\\r rules to formalize spe\\ri\\r linguisti\\r phenomena. why should we subordinate the use of spe\\ri\\r type \\rhange rules to their derivability in some \\ral\\rulus one of the most \\rompelling reasons to do so is given by moortgat who stresses the systemati\\rity of the relation between syntax and semanti\\rs provided in a de du\\rtive framework. also lambek cal\\rulus enjoys an important property it is sound and \\romplete with respe\\rt to free semigroup model i.e. an interpretation with respe\\rt to formal languages. that is to say rules that are not dedu\\rible in lambek cal\\rulus are not sound and so they \\ran be \\ronsidered as linguisti\\rally implausible. inria learnability for rigid lambek grammars. lambek cal\\rulus categorial grammars \\ran be analyzed from a proof theoreti\\ral perspe\\rtive by observing the \\rlose \\ronne\\rtion between the slashes of a \\rategorial grammar and impli\\ration in intuition isti\\r logi\\rs. the rule that allows us to infer that if w is of type a b and v is of type b then wv is of type a behaves like the modus ponens rule of inferen\\re in logi. on the basis of this similarity lambek proposed an ar\\rhite\\rture for \\rategorial grammars based on two levels ˆ a synta\\rti\\r \\ral\\rulus i.e. a dedu\\rtive system in whi\\rh statement of the form a. an b to be read from the types a. an we \\ran infer type b \\ran be proved ˆ a \\rategorial grammar as presented in denition. wherein the relation is \\rhanged to allow any type \\rhange rule that \\rould be dedu\\red at the previous level. in doing so instead of adding a nite number of type \\rhange rules to our grammar every type \\rhange rule that \\ran be derived in the lambek cal\\rulus is added to the \\rategorial grammar. the following formalizations for lambek cal\\rulus are presented a\\r\\rording respe\\rtively to the formalism of sequent \\ral\\rulus and to the formalism of natural dedu\\rtion. note that in the present work we will use the expression lambek cal\\rulus to refer to produ\\rt free lambek cal\\rulus indeed we will never make use of the produ\\rt. denition. the sequent \\ral\\rulus formalization of the lambek \\ral\\rulus \\rontains the ax iom id and the rules of inferen\\re r l r l and cut a a γ a b γ b a a γ b γ a b γ a b π c b a γ π c γ a b π c γ a b π c b γ b π a γ π a note in and there is a side \\rondition stipulating that γ. the side \\rondition imposed for and rules formalizes the fa\\rt that in lambek cal\\rulus one is not allowed to \\ran\\rel all the premises from the left hand side of a derivation. otherwise stated in lambek cal\\rulus there are no dedu\\rtions of the form a. rr n bonato coherently with our interpretation of lambek cal\\rulus as a dedu\\rtive system to derive the type of a sequen\\re of symbols of the alphabet out of the types of ea\\rh symbol su\\rh a derivation makes no sense sin\\re it would mean assigning a type to an empty sequen\\re of words. fol lows denition. the natural dedu\\rtion formalization of the lambek cal\\rulus is dened as a a b b b b a a a a a a b b a note in i and i rules the \\ran\\rel led assumption is always respe\\rtively the rightmost and the leftmost un\\ran\\rel led assumption and there must be at least another un\\ran\\rel led hypothesis. both formalisms have advantages and disadvantages. however due to the \\rlose \\ronne\\r tion between natural dedu\\rtion proofs and λ terms and be\\rause the tree like stru\\rture of dedu\\rtions resembles derivations trees of grammars the natural dedu\\rtion version will be the primary ob je\\rt of study in the present work. for later purposes we introdu\\re here the notion of derivation in lambek \\ral\\rulus that will be useful later for the denition of the stru\\rture of a senten\\re in a lambek grammar. a derivation of b from a. an is a \\rertain kind of unary binary bran\\rhing tree that en\\rodes a proof of a. an b. ea\\rh node of a derivation is labeled with a type and ea\\rh internal node has an additional label whi\\rh for lambek grammars is either e e i or i and that indi\\rates whi\\rh lambek \\ral\\rulus rule is used at ea\\rh step of a derivation. for ea\\rh o\\r\\rurren\\re of an introdu\\rtion rule there must be a \\rorresponding previously unmarked leaf type a whi\\rh must be marked as. inria learnability for rigid lambek grammars the set of derivations is indu\\rtively dened as follows denition. let a b tp and γ tp ˆ a is a derivation of a from a. ˆ ba\\rkslash elimination. if g d a d d a b e b is a derivation of a from γ and is a derivation of a b from then g d a d d a b is a derivation of b from γ. rr n bonato ˆ ba\\rkslash introdu\\rtion. if is a derivation of b from then a g d b g d b i a b is a derivation of a b from γ. the leaf labeled by a is \\ral led a dis\\rharged leaf. inria learnability for rigid lambek grammars ˆ slash elimination. if g d b a d d a e b is a derivation of b a from γ and is a derivation of a from then g d b a d d a is a derivation of b from γ. rr n g a d b g d b i b a e y i y bonato ˆ slash introdu\\rtion. if is a derivation of b from then is a derivation of b a from γ. the leaf labeled by a is \\ral led a dis\\rharged leaf. example. the fol lowing example is a derivation of x from y x. non asso\\riative lambek cal\\rulus lambek cal\\rulus as dened in the previous se\\rtion is impli\\ritly asso\\riative. in order to use lambek \\ral\\rulus to des\\rribe some linguisti\\r phenomena we have to forbid asso\\riativ ity and so the hierar\\rhi\\ral embedding of hypotheses is respe\\rted. another linguisti\\rally attra\\rtive feature of non asso\\riative lambek \\ral\\rulus is that it provides useful logi\\ral to inria learnability for rigid lambek grammars support semanti\\rs but at the same time it prohibits transitivity that sometimes leads to overgeneration. denition. the natural dedu\\rtion formalization of the non asso\\riative lambek cal\\ru lus has the fol lowing axioms and rules of inferen\\re presented in the sequent format a a γ a b b γ b b a a a a a γ a b note in and there is a side \\rondition stipulating that γ. γ b a. normalization and normal forms as one \\ran easily see in lambek cal\\rulus there are innitely many proofs for any dedu\\rtion a. an b. sin\\re as it will be extensively explained in se\\rtion proofs in lambek cal\\rulus play a de\\risive role in dening the notion of stru\\rture for a senten\\re generated by a lambek grammar su\\rh an arbitrary proliferation of proofs for dedu\\rtions is quite undesirable. same result. the following denition introdu\\res a useful relation between proofs in lambek cal\\rulus that formalizes our idea of a minimal proof for any dedu\\rtion. it provides two normaliza tion s\\rhemes that \\ran be applied to a derivation to produ\\re a simpler derivation of the denition. the relation between proofs in the natural dedu\\rtion formalization of lambek cal\\rulus is dened in the fol lowing way a b a b a b b b a a b a b b a a b a b a b b a a b a a b the symbol stands for reexive and transitive \\rlosure of. relation is usual ly dened as β η \\ronversion while as β η redu\\rtion. rr n bonato the relation satises the following properties theorem. the relation is \\ronuent i.e. if δ δ and δ δ then there exists a δ su\\rh that δ δ and δ δ. theorem. the relation is both weakly and strongly normalizing that is every proof \\ran be redu\\red in normal form and every redu\\rtion terminates after at most a nite number of steps. denition. a proof tree for the lambek cal\\rulus is said to be in β η normal form is none of its subtrees is of the form a a a a b b b b a a b b a a a b a a b a. basi\\r fa\\rts about lambek cal\\rulus let s summarize here some meaningful properties for lambek \\ral\\rulus whi\\rh is ˆ intuitionisti\\r only one formula is allowed on the right hand side of a dedu\\rtion. this means there is neither involutive negation nor disjun\\rtion ˆ linear so \\ralled stru\\rtural rules of logi\\rs are not allowed two equal hypotheses \\ran t be \\ronsidered as only one and on the other hand we are not allowed to dupli\\rate hypotheses at will. lambek \\ral\\rulus is what we \\rall a resour\\re aware logi\\rs wherein hypotheses must be \\ronsidered as \\ronsumable resour\\res ˆ non \\rommutative hypotheses don t \\rommute among them that is the impli\\rit oper ator in this \\ral\\rulus is not \\rommutative. this is what makes possible the existen\\re of the two impli\\rations the rst one \\ronsuming its right argument the se\\rond one its left argument. sin\\re lambek proved a \\rut elimination theorem for his \\ral\\rulus among the many \\ronsequen\\res of the normalization theorems there are the subformula property that is inria learnability for rigid lambek grammars proposition. every formula that o\\r\\rurs in a normal form natural dedu\\rtion proof of \\rut free sequent \\ral\\rulus proof is either a subformula of the assumptions or of the \\ron\\rlusion and de\\ridability for lambek \\ral\\rulus proposition. derivability in the lambek cal\\rulus is de\\ridable. in fa\\rt given a sequent to prove in lambek \\ral\\rulus \\rut elimination property authorizes us to look for a \\rut free proof. but if the sequent \\romes from the appli\\ration of a rule other that \\rut this \\ran t but be made in a nite number of dierent ways and in any \\rase we have to prove one or two smaller sequents. this is enough to prove de\\ridability for lambek \\ral\\rulus. theorem. states that any proof has a normal form and theorem. that this nor mal form is unique. this doesn t mean that there is a unique normal form proof for any dedu\\rtion. the following theorem by van benthem sheds light on this point theorem. for any sequent a. an b there are only nitely many dierent normal form proofs in the lambek cal\\rulus. this is quite an unsatisfa\\rtory result we still have a one to many \\rorresponden\\re be tween a sequent and its normal proofs. this leads to what is generally known as the problem of spurious ambiguities for lambek grammars. lambek grammars a lambek grammar extends the traditional notion of \\rategorial grammars as presented in se\\rtion. by a whole dedu\\rtive system in the following way ˆ a lexi\\ron assigns to ea\\rh word wi a nite set of types f ˆ the language generated by this fully lexi\\ralized grammar is the set of all the sequen\\res w wn of words of the lexi\\ron su\\rh that for ea\\rh wi there exists a type ti f su\\rh that formally is provable in lambek \\ral\\rulus. t. tn s rr n bonato denition. a lambek grammar is a triple g hς s f i su\\rh that ˆ σ is a nite set ˆ s is the distinguished \\rategory ˆ f σ is a fun\\rtion whi\\rh maps ea\\rh symbol of the alphabet into the set if its types. if f we write g a a. an. for w σ w a an we say that g a\\r\\repts w if there is a proof in lambek \\ral\\rulus of a. an s with g ai ai for ea\\rh i. the language generated by a lambek grammar g is l. example. let σ be our alphabet and s our distin guished \\rategory. let s take f su\\rh that mary np cooked np the np n n beans np np np n n s then mary \\rooked the beans belongs to the language generated by this grammar be\\rause in lambek \\ral\\rulus we \\ran prove inria learnability for rigid lambek grammars weak generative \\rapa\\rity for asso\\riative lambek grammars was \\rhara\\rterized by the following \\relebrated theorem one of the nest and most re\\rent a\\rhievements in this eld theorem. the languages generated by asso\\riative lambek grammars are exa\\rtly the \\rontext free languages. analogously for non asso\\riative lambek grammars buszkowski proved theorem. the languages generated by non asso\\riative lambek grammars are exa\\rtly the \\rontext free languages. proofs as grammati\\ral stru\\rtures in this se\\rtion we will introdu\\re the notion of stru\\rture for a senten\\re generated by a lambek grammar. on the basis of a re\\rent work by hans joerg tiede who proved some important theorems about the tree language of proof trees in lambek \\ral\\rulus we will adopt as the underlying stru\\rture of a senten\\re in a lambek grammar a proof of its well formedness in lambek \\ral\\rulus. we will see in se\\rtion how this \\rhoi\\re ae\\rts the pro\\ress of learning a rigid lambek grammar on the basis of stru\\rtured positive data. parse trees for lambek grammars just as a derivation en\\rodes a proof of a. an b the notion of parse tree introdu\\red by the following denition en\\rodes a proof of a an l where g is a lambek grammar and a. an are symbols of its alphabet. denition. let g hς s f i be a lambek grammar then ˆ if d is a derivation of b from a. an and a. an are symbols of alphabet σ su\\rh that g ai ai for i n the result of atta\\rhing a. an from left to right in this order to the undis\\rharged leaf nodes of d is a partial parse tree of g. a a an an ... d b ˆ a parse tree of g is a partial parse tree of g whose root node is labeled by the distin guished \\rategory s. rr n bonato if a an is the string of symbols atta\\rhed to the leaf nodes of a partial parse tree p a an is said to be the yield of p. if a parse tree p of g yields a an then p is \\ralled a parse of a an in g. example. let σ be our alphabet and let g a lambek grammar su\\rh that then the fol lowing is a parse for he likes him g likes np he s him s. likes np he s e np s e s i s np him s e s. tree languages and automata in order to fully appre\\riate the pe\\ruliarity of lambek grammars with respe\\rt to their strong generative \\rapa\\rity we re\\rall here some basi\\r denitions about the notion of tree language as presented in tie. denition. a tree is a term over a nite signature σ \\rontaining fun\\rtion and \\ronstant symbols. the set of n ary fun\\rtion symbols in σ wil l be denoted by σn. the set of al l terms over σ wil l be denoted by tς a subset of tς is \\ral led a tree language or a forest. inria learnability for rigid lambek grammars denition. the yield of a tree t is dened by yield c for c σ yield yield. yield for f σn n thus the yield of a tree is the string of symbols o\\r\\rurring as its leaves. denition. the root of a tree t is dened by root c root f for c σ for f σn n. in the following subse\\rtions three in\\rreasingly more powerful \\rlasses of tree languages are presented lo\\ral regular and \\rontext free tree languages. note that even if the names for these \\rlasses of tree languages are the same as those for \\rlasses of string languages their meaning is very dierent. .. lo\\ral tree languages we \\ran think of a lo\\ral tree language as a tree language whose membership problem \\ran be de\\rided by just looking at some very simple properties of trees. a formalization of su\\rh an intuitive notion is given by the following denitions denition. the fork of a tree t is dened by f ork for c σ f ork f ork n i denition. for a tree language l we dene f ork f ork t l note that sin\\re σ is nite f ork is always nite. denition. a tree language l tς is lo\\ral if there are sets r σ and e f ork su\\rh that for al l t tς t l i root r and f ork e. that\\rher \\rhara\\rterized the relation between lo\\ral tree languages and the derivation trees of \\rontext free string grammars by the following theorem. s is the set of derivation trees of some \\rontext free string grammar i s is lo\\ral. rr n bonato .. regular tree languages among many dierent equivalent denitions for regular tree languages we follow tiede s approa\\rh in \\rhoosing the following one based on nite tree automata. denition. a nite tree automaton is a quadruple hς q q i su\\rh that ˆ σ is a nite signature ˆ q is a nite set of unary states ˆ q q is the start state ˆ is a nite set of transition rules of the fol lowing type q c for c σ q f for f σn q q. qn q we \\ran think of a nite tree automaton as a devi\\re whi\\rh s\\rans non deterministi\\rally a tree from root to frontier. it a\\r\\repts a tree if it su\\r\\reeds in reading the whole tree it reje\\rts it otherwise. in order to dene the notion of tree language a\\r\\repted by a regular tree automaton we need to dene the transition relation for nite tree automata. denition. a \\rontext is a term over σ \\rontaining the zero ary term x exa\\rtly denition. let m hς q q i be a nite tree automaton the derivation relation is dened by t m t if for some \\rontext s and some t. tn tς there is a rule in m tq σ tq σ q f t s t s. on\\re. and if we use tomaton m a\\r\\repts a term t tς if q m to denote the reexive transitive \\rlosure of m we say that a nite aum t. the tree language a\\r\\repted by a nite tree automaton m is. inria learnability for rigid lambek grammars denition. a tree language is regular if it is a\\r\\repted by a nite tree automaton. languages the following theorem denes the relation between lo\\ral and regular tree theorem. every lo\\ral tree language is regular. while the following establishes a relation between regular tree languages and \\rontext free string languages theorem. the yield of any regular tree language is a \\rontext free string language. .. context free tree languages the nal step in the denition of more and more powerful tree language \\rlasses is made possible by introdu\\ring the notion of pushdown tree automaton. again we sti\\rk to tiede s approa\\rh in \\rhoosing guesserian s useful denition denition. a pushdown tree automaton is a system hς γ q q z i su\\rh that ˆ σ is a nite signature ˆ γ is a nite signature q f q q q c ˆ q is a nite set of binary states ˆ q q is the start state ˆ z γ is the initial sta\\rk symbol ˆ is a nite set of rules of the form with q q q. qn q c σ f σn n e γm γ γ. γn tγ. rr n bonato the transition relation for pushdown tree automata \\ran be dened straightforwardly as a generalization of denition .. a term t is a\\r\\repted by a pushdown automaton if q t where is the reexive transitive \\rlosure of. denition. the language a\\r\\repted by a pushdown tree automaton is \\ral led a \\rontext free tree language. the relationship between regular and \\rontext free tree languages is exemplied by the fol lowing proposition free. proposition. the interse\\rtion of a regular and a \\rontext free tree language is \\rontext we know that the yield of a regular tree language is a \\rontext free string language there is a similar \\ronne\\rtion between the \\rlass of \\rontext free tree languages and the \\rlass of indexed languages as stated by the following proposition. the yield of any \\rontext free tree language is an indexed string language. indexed languages have been proposed as an upper bound of the \\romplexity of natural lan guages after it was shown that \\rertain phenomena in natural languages \\rannot be des\\rribed with \\rontext free grammars. proof trees as stru\\rtures for lambek grammars in tie hans joerg tiede proposes in \\rontrast with a previous approa\\rh by buszkowski to take as the stru\\rture underlying a senten\\re generated by a lambek grammar one of the innite proof trees of the dedu\\rtion a. an s where a. an is a sequen\\re of types assigned by the grammar to ea\\rh symbol and s is the distinguished atomi\\r \\rategory. following tiede s approa\\rh we give the following denition. a proof tree for a lambek grammar is a term over the signature σ where ˆ is the ary fun\\rtion symbol ˆ and are the binary fun\\rtion symbols ˆ and are the unary fun\\rtion symbols. the terms over this signature represent proof trees that neither have information about the formulas for whi\\rh they are a proof nor about the strings that are generated by a gram mar using this proof. these terms represent proofs unambiguously sin\\re the assumption dis\\rharged by an introdu\\rtion rule is univo\\rally determined by the position of the \\rorre sponding or fun\\rtion symbol in the proof tree. inria learnability for rigid lambek grammars example. the term t is an example of wel l formed term over this signature. there s no need for additional information about the dis\\rharged assumption sin\\re as we \\ran see from the tree like representation of the term the dis\\rharged assumption is unambiguously identied. id e i the following terms are examples of not well formed proof trees for the tree language generated by any lambek grammar ˆ. sin\\re the ma jor premise of the e fun\\rtion symbol is something with a shape there s no way to redu\\rt that term by a e rule ˆ e. analogous to the previous situation ˆ if the term x does not \\rontain at least two un\\ran\\relled assumptions ˆ if the term x does not \\rontain at least two un\\ran\\relled assumptions. by taking a proof tree as the stru\\rture of a senten\\res generated by lambek grammars tiede proved some important results about their strong generative \\rapa\\rity that is the set of the stru\\rtures assigned by a grammar to the senten\\res it generates. sin\\re strong generative \\rapa\\rity \\ran provide a formal notion of the linguisti\\r \\ron\\rept of stru\\rture of a senten\\re this result justies the \\rurrent interest toward lambek grammars as a promising mathemati\\ral tool for linguisti\\r purposes. theorem. the set of wel l formed proof trees of the lambek cal\\rulus theorem. the set of proof trees of the lambek cal\\rulus is a \\rontext these two theorems show that the language of proof trees is properly a \\rontext free tree in parti\\rular these theorems show that lambek grammars are more powerful with re spe\\rt to strong generative \\rapa\\rity than \\rontext free grammars whose stru\\rture language is not regular. free tree language. language. rr n bonato is a lo\\ral tree language as shown in theorem .. we \\ran easily introdu\\re the notion of normal form proof tree by simply extending the notion of normal form proof as presented in denition .. we \\ran say that for normal form trees in addition to the rules that prohibit terms of the form we have rules that prohibit terms of the form and terms of the form whi\\rh \\rorrespond to β redexes and η redexes respe\\rtively as one \\ran easily see from de nition .. we \\ran easily extend to the formalism of proof trees the redu\\rtion rules we ve seen in se\\rtion. to get a normal form proof tree out of a non normal one. t i t e t t t i e t t t inria learnability for rigid lambek grammars t t t t e i e i as a \\rorollary of theorem. tiede proves that theorem. the set of normal form proof trees of the lambek cal\\rulus is not regular whi\\rh together with language theorem. the set of normal form proofs of the lambek cal\\rulus is a \\rontext free tree shows that the tree language of normal form proof trees of lambek cal\\rulus is properly a \\rontext free tree language. proof tree stru\\rtures given a lambek grammar g a proof tree stru\\rture over its alphabet σ is a unary binary bran\\rhing tree whose leaf nodes are labeled by either or symbols of σ and whose internal nodes are labeled by either e e i or i. the set of proof tree stru\\rtures over σ is denoted σp to mean proof tree stru\\rture. a set of proof tree stru\\rtures over σ is \\ralled a stru\\rture language over σ. often we will simply say stru\\rture example. the fol lowing is an example of a proof tree stru\\rture for the senten\\re he likes him seen in example. rr n bonato likes he e e i him e let g be a lambek grammar and let p be a partial parse tree of g. the result of stripping p of its type labels is a proof tree stru\\rture that is \\ralled the proof tree stru\\rture of p. if t is the stru\\rture of a parse tree p we say that p is a parse of t. we say that a lambek grammar g generates a stru\\rture t if and only if for some parse tree p of g t is the stru\\rture of p. the set of stru\\rtures generated by g is \\ralled the stru\\rture language of g and is denoted pl. in order to distinguish l the language of g from pl its stru\\rture language we often \\rall the former the string language of g. the yield of a proof tree stru\\rture t is the string of symbols a. an labeling the undis\\rharged leaf nodes of t from left to right in this order. the yield of t is denoted yield. note that l. de\\ridable and unde\\ridable problems about lambek grammars sin\\re as stated in by theorem. lambek \\ral\\rulus is de\\ridable the universal membership problem s l is de\\ridable for any senten\\re s and any lambek grammar g. on the other hand the questions l l and l l for arbitrary lambek grammars g and g are unde\\ridable be\\rause the same questions are unde\\ridable for \\rontext free grammars and there exists an ee\\rtive pro\\redure for \\ronverting a \\rontext free grammar g to a lambek grammar g su\\rh that l l. given a proof tree stru\\rture t the question t pl is de\\ridable. in fa\\rt as shown by tiede in. every proof tree language of a lambek grammar is a \\rontext free tree language and that problem is de\\ridable for \\rontext free tree languages. inria learnability for rigid lambek grammars unfortunately the question pl pl has been proved de\\ridable only for g g non asso\\riative lambek grammars. whether it is de\\ridable or not for lambek grammars is still an open question and the sub je\\rt of a\\rtive resear\\rh in this eld. substitutions in this se\\rtion we introdu\\re the notion of a lambek grammar being a substitution instan\\re of another. besides we dene a notion of size of a lambek grammar that will be de\\risive in our proof of learnability for rigid lambek grammars presented in se\\rtion .. first of all let s dene what we mean when we say that a lambek grammar is subset of another one denition. let g g be lambek grammars we say that g g if and only if for any a σ su\\rh that g a a we have also g a a. example. let σ and let g francesca np loves np s g francesca np np s np loves paolo np obviously g g denition. a substitution is a fun\\rtion σ v ar t p that maps variables to types. we \\ran extend it to a fun\\rtion from types to types by setting σ t σ σ σ σ σ σ for al l a b t p. we use the notation to denote the substitution σ su\\rh that σ a. σ an and σ y for all other variables y. example. let σ. then σ t and σ s. rr n bonato the following denition introdu\\re the notion of a lambek grammar being a substitution instan\\re of another denition. let g hς s f i be a lambek grammar and σ a substitution. then σ denotes the grammar obtained by applying σ in the type assignment of g that is σ is \\ral led a substitution instan\\re of g. σ hς s σ f i it easy to prove also for lambek grammars this straightforward but important fa\\rt that was rst proved for ccgs in bp proposition. if σ g then the set of proof tree stru\\rtures generated by g is a subset of the set of proof tree stru\\rtures generated by g that is pl pl. proof. suppose σ g. let t pl and let p be a parse of t in g. let σ the result of repla\\ring ea\\rh type label a of p by σ. then it is easy to see that σ is a parse of t in g. therefore t pl. corollary. if σ g then l l. proof. immediate from the previous proposition and the remark at the end of se\\rtion .. a substitution that is a one to one fun\\rtion from v ar to v ar is \\ralled a variable renaming. if σ is a variable renaming then g and σ are \\ralled alphabeti\\r variants. obviously grammars that are alphabeti\\r variants have exa\\rtly the same shape and are identi\\ral for all purposes. therefore grammars that are alphabeti\\r variants are treated as identi\\ral. proposition. suppose σ g and σ g. then g and g are alphabeti\\r variants and thus are equal. proof. for ea\\rh symbol c σ σ and σ provide a one to one \\rorresponden\\re between and. indeed if it didn t and say then σ σ \\rouldn t be equal to g and likewise for σ. then it is easy to see that σ v ar is a one to one fun\\rtion from v ar onto v ar and σ v ar. one \\ran extend σ v ar to a variable renaming σ. then σ σ g. grammars in redu\\red form denition. a substitution σ is said to be faithful to a grammar g if the fol lowing \\rondition holds for al l c dom if g c a g c b and a b then σ σ. inria learnability for rigid lambek grammars example. let g be the fol lowing grammar g francesca x dances well x s y y. σ σ. let ˆ σ is faithful to g ˆ σ g. then σ is faithful to g while σ is not. denition. let be a binary relation on grammars su\\rh that g g if and only if there exists a substitution σ with the fol lowing properties from the denition above and proposition. it s immediate to prove the following proposition. is reexive transitive and antisymmetri. denition. for any grammar g dene the size of g size as fol lows size a xc σ xg c a where for ea\\rh type a a is the number of symbol o\\r\\rurren\\res in a. lemma. if g g then size size proof. for any type a and any substitution σ a σ. then the lemma is immediate from the denition of. corollary. for any grammar g the set is nite. proof. by lemma. the latter set must be nite be\\rause for any n n there are only nitely many grammars g su\\rh that size n. if we write g g to mean g g and g g we have corollary. is wel l founded. denition. a grammar g is said to be in redu\\red form if there is no g g g and pl pl. su\\rh that rr n bonato lambek grammars as a linguisti\\r tool. lambek grammars and syntax as expli\\ritly stated in the original paper wherein lambek laid the foundations of the lambek cal\\rulus his aim was ... to obtain an ee\\rtive rule for distinguishing senten\\res from nonsenten\\res whi\\rh works not only for the formal languages of interest to the mathemati\\ral logi\\rian but also for natural languages su\\rh as english or at least for fragments of su\\rh languages. that s why even if lambek grammars \\ran be simply \\ronsidered as interesting mathe mati\\ral ob je\\rts it will be useful to underline here some properties that make them also an interesting tool to formalize some phenomena in natural languages. the importan\\re of lambek s approa\\rh to grammati\\ral reasoning lies in the development of a uniform dedu\\rtive a\\r\\rount of the \\romposition of form and meaning in natural language formal grammar is presented as a logi\\r that is a system to reason about stru\\rtured linguisti\\r stru\\rtures. the basi\\r idea underlying the notion of categorial grammar on whi\\rh lambek based his approa\\rh is that a grammar is a formal devi\\re to assign to ea\\rh word or expression one or more synta\\rti\\r types that des\\rribe their fun\\rtion. types \\ran be \\ronsidered as a formalization of the linguisti\\r notion of parts of spee\\rh. ccgs assign to ea\\rh symbol a xed set of types and provide two \\romposition rules to derive the type of a sequen\\re of words out of the types of its \\romponents. su\\rh a xed types approa\\rh leads to some di\\rulties to formalize some linguisti\\r phenomena we should add further rules to the two elimination rules dened for ccgs as des\\rribed in se\\rtion .. in the following subse\\rtions we present some examples where the dedu\\rtive approa\\rh of lambek grammars leads to more an elegant and \\ronsistent formalization of su\\rh linguisti\\r phenomena. in the following subse\\rtions we take s as the primitive type of wel l formed senten\\res in our language and np as the primitive type for noun phrases. .. transitive verbs transitive verbs require a name both on their left and right hand sides as it is apparent from the well formedness of the following senten\\res. np john np np np john likes mary inria learnability for rigid lambek grammars both parenthesizations lead to a derivation of s as type of the whole expression. this would mean that in an ccg we should assign to any transitive verb at least two distin\\rt types np and np. on the \\rontrary in a lambek grammar sin\\re we \\ran prove both we \\ran simply assign to a transitive verb the type np s np without any further parenthe and sizations. .. pronouns if we try to assign a proper type to the personal pronoun he we noti\\re that its type is su\\rh that the following senten\\res are well formed we have two \\rhoi\\res either we give he the same type as a name or we give it the type s. in the rst \\rase there is a problem expressions like jane likes he are \\ronsidered as well formed senten\\res. so we assign to he the type s. analogously sin\\re the personal pronoun him makes the following senten\\res well formed np np np np np s he works np s np np he likes jane np np s np jane likes him np np s s s np jane works for him we assign to him the type s. sin\\re a pronoun is a\\r\\rording to its own denition something that stands for a noun we wish that in our grammar ea\\rh o\\r\\rurren\\re of a pronoun \\rould be repla\\red by a name but this means that any name should also be assigned the type of he and him that is respe\\rtively type s and type s. in other words we need something that a\\r\\rounts for a type raising. but sin\\re in lambek cal\\rulus we \\ran prove np s np s for any np and s a lambek grammar provides a very natural formalization of the relationship between names and pronouns while a name \\ran always be substituted to a pronoun in a rr n bonato senten\\re the \\ronverse is not true. the proof of the rst dedu\\rtion is reported in example. as a derivation in a lambek grammar. .. adverbs if we look for the proper type for adverbs like here we \\ran \\ronsider the well formed senten\\re john works here. we \\ran \\rhoose between two possible parenthesizations here that is the rst one suggests for here the type s s while the se\\rond one the type. the good news is that while in a ccg we should assign ea\\rh adverb at least two dierent types in a lambek grammar we \\ran prove that that is to say in lambek grammars any adverbial expression of type s s has also type. more generally we \\ran show that in lambek cal\\rulus np np s here np john s s x y x y. .. hypotheti\\ral reasoning in the following example senten\\res s noun phrases np \\rommon nouns n and propositions phrases pp are taken to be \\romplete expressions whereas the verb dan\\res the determiner the and the preposition with are \\rategorized as in\\romplete with respe\\rt to these \\romplete phrases. inria learnability for rigid lambek grammars example. here is the derivation for the senten\\re fran\\res\\ra dan\\res with the boy. the np n boy n with pp np e np dances pp e pp francesca np e np s e s this is an example of grammati\\ral reasoning where on the basis of the types we assigned to ea\\rh word we infer the well formedness of a sequen\\re of words. on the other hand we \\ran assume a dierent perspe\\rtive knowing that a senten\\re is well formed what \\ran be said about the type of its \\romponents in the words of lambek given the information about the \\rategorization of a \\romposite stru\\rture what \\ron\\rlusions \\rould be draw about the \\rategorization of its parts. that s where the following inferen\\re patterns \\rome into play from γ b a from b γ a infer γ a b infer γ b a whi\\rh gives a linguisti\\r interpretation of the role of the introdu\\rtion rules. that s what is done in the following derivation whi\\rh allows us to infer that the expression the boy fran\\res\\ra dan\\res with is of type np rr n bonato with pp np dances pp e pp francesca np e np s e s i s np whom boy n e n n the np n e n e np sin\\re the relative pronoun whom wants to enter into \\romposition on its right with the relative \\rlause body we d like to assign type s np to the latter. in order to show that fran\\res\\ra dan\\res with is indeed of type s np we make a hypotheti\\ral assumption and suppose to have a ghost word of type np on its right. it s easy to derive the \\rategory s for the senten\\re fran\\res\\ra dan\\res with np. by withdrawing the hypotheti\\ral np assumption we \\ron\\rlude that fran\\res\\ra dan\\res with has type s np. we \\ran say that the \\ran\\relled hypothesis is the analogous of a tra\\re à la chomsky moving whom before fran\\res\\ra. .. transitivity in the framework of ccgs a di\\rulty arises when we try to show the well formedness of so some authors proposed to introdu\\re two new rules whi\\rh are often referred to as tran sitivity rules s np s np s he likes him x z x z inria learnability for rigid lambek grammars it s easy to show that su\\rh rules are derivable in lambek cal\\rulus as we \\ran easily see from the following proof tree y z x y e y e x i x z. lambek grammars and montague semanti\\rs from a linguisti\\r point of view one of the main reasons of interest in lambek grammars lies in the natural interfa\\re that proof tree stru\\rtures provide for montague like semanti\\rs. just like curry howard isomorphism shows that simply typed λ terms \\ran be seen as proofs in intuitionisti\\r logi\\rs and vi\\re versa synta\\rti\\ral analysis of a senten\\re in a lambek grammar is a proof in lambek \\ral\\rulus whi\\rh is naturally embedded into intuitionisti\\r logi\\rs. indeed if we read b a and a b like the intuitionisti\\r impli\\ration a b every rule in lambek \\ral\\rulus is a rule of intuitionisti\\r logi\\rs. in order to fully appre\\riate this relation between syntax and semanti\\rs whi\\rh is par ti\\rularly strong for lambek grammars we dene a morphism between synta\\rti\\r types and semanti\\r types the latter are formulas of a minimal logi\\rs built on the two types e and t. semanti\\r type s sn n t e e t a b extends to every types. the lexi\\ron asso\\riates also to every word w a λ term τk for every synta\\rti\\r type tk l su\\rh that the type of τk is pre\\risely t k the semanti\\r type \\rorresponding to that synta\\r ti\\r type. we introdu\\re some \\ronstants for representing logi\\ral operations of quanti\\ration rr n bonato \\ronjun\\rtion et\\r constant type t t t t t let the following be given of t. tn s and ˆ a synta\\rti\\ral analysis of w. wn in lambek \\ral\\rulus that is to say a derivation d ˆ the semanti\\rs for every word w. wn that is to say λ terms τi t i then we get the semanti\\rs of the senten\\re by simply applying the following algorithm ˆ substitute in d every synta\\rti\\r type with its \\rorresponding semanti\\r image sin\\re intuitionisti\\r logi\\rs is an extension of lambek \\ral\\rulus we get a derivation d intuitionisti\\r logi\\r of t. t n t s into ˆ this derivation in intuitionisti\\r logi\\r due to curry howard isomorphism \\ran be seen as a simply typed λ term d λ \\rontaining a free variable xi of type t i for every word wi ˆ in d λ repla\\re ea\\rh variable xi with λ term τi equally typed with t i ˆ redu\\re the λ term resulting at the end of the previous step and we get the semanti\\r representation of the analyzed senten\\re. let s \\ronsider the following example word synta\\rti\\r type t semanti\\r type t semanti\\r representation a λ term of type t n λp e t λq e t λx e some senten\\res n talkabout themselves e t λx e sn e λx e λy e λp e λx e inria learnability for rigid lambek grammars first of all we ll prove that some senten\\res talk about themselves is a well formed senten\\re that is it belongs to the language generated by the lexi\\ron at issue. this means building a natural dedu\\rtion of n n sn s. if we indi\\rate with s n t m the left hand side of synta\\rti\\r types we get s n n n t sn m s n s t m sn s s n t m s by applying the isomorphism between synta\\rti\\r and semanti\\r types we get the following are the abbreviations for semanti\\r types asso\\riated intuitionisti\\r proof where s n t m to s n t m s t n e t s n t t e e t m e t t m e t s n t m t the λ term \\roding this proof is simply of type t where s n t m are variables of types respe\\rtively s n t m. by repla\\ring these variables with λ terms of the same types asso\\riated by the lexi\\ron to the words we get the following λ term of type t λp λq λx λp λx λx λy λq λx λx β β λx if we re\\rall that the x in this last term is of type e the latter redu\\red term represents the following formula in predi\\rate \\ral\\rulus x e whi\\rh is the semanti\\r representation of the previously analyzed senten\\re. rr n bonato rigid lambek grammars in the present se\\rtion we introdu\\re the notion of rigid lambek grammar whose learnability properties will be the sub je\\rt of our inquiry in se\\rtion. basi\\r notions and results presented here are almost trivial extensions of what has already been done for rigid ccgs sin\\re a spe\\ri\\r a spe\\ri\\r theory for rigid lambek grammars is still missing. rigid and k valued lambek grammars a rigid lambek grammar is a triple g hς s f i where σ and s are dened like in denition. while f σ t p is a partial fun\\rtion that assigns to ea\\rh symbol of the alphabet at most one type. we \\ran easily generalize the notion of rigid lambek grammar to the notion of k valued lambek grammar by a fun\\rtion f that assigns to ea\\rh symbol of the alphabet at most k types. formally f σ. k i t pk let an alphabet σ be given. we \\rall grigid the \\rlass of rigid lambek grammars over σ and gk valued the \\rlass of k valued lambek grammars over σ. let s dene two \\rlasses of proof tree stru\\rtures s plrigid plk valued. members of plrigid are \\ralled rigid stru\\rture languages and members of plk valued are \\ralled k valued stru\\rture languages. let s dene two \\rlasses of strings lrigid lk valued. members of lrigid are \\ralled rigid languages and members of lk valued are \\ralled k valued languages. example. let σ and let g g be the fol lowing lambek grammars g francesca x dances x s y well y g francesca x dances well x s. inria learnability for rigid lambek grammars then g is a rigid grammar while g is not. g is a valued grammar. denition. any type a \\ran be written uniquely in the fol lowing form. an where b c stands for either b c or c b and p p r. for i n we \\ral l the subtype ai of a a head subtype of a. p is the head of a and is denoted head. ai s are \\ral led argument subtypes of a. the number n is \\ral led the arity of a. the following propositions are almost trivial extensions to rigid lambek grammars of analogous results proved by kanazawa for ccgs in kan. however they deserve some attention sin\\re they \\ran provide a rst super\\rial insight about properties of rlgs. first of all we prove a hierar\\rhy theorem about strong generative \\rapa\\rity of k valued lambek grammars. proposition. let a σ. for ea\\rh i let ti be the fol lowing proof tree stru\\rture a i times a. a e e then for ea\\rh k plk valued plk valued. thus for ea\\rh k n plk valued plk valued. proof. let gk be the following k valued grammar gk a x s x x. k times. x. rr n bonato let g be a grammar su\\rh that pl we will show that g is at least k valued. let pi be a parse of ti in g for i k. then the leftmost leaf of pi is the ultimate fun\\rtor of pi and if we \\rall ai the type labeling it we \\ran easily verify that the its arity must be exa\\rtly i. thus i j implies ai aj. we show that there is at least one type b su\\rh that g a b and b. sin\\re the relation is an argument subtype of is well founded there is at least one i su\\rh that the argument subtypes of ai are not in. but in order to produ\\re pi any argument subtype of ai must be a type assigned to a by g. therefore g must be at least k valued. the proof of proposition. shows corollary. there is no lambek grammar g su\\rh that pl σp. lemma. let g be a rigid lambek grammar. then for ea\\rh proof tree stru\\rture t there is at most one partial parse tree p su\\rh that t is the stru\\rture of p. proof. by indu\\rtion on the \\ronstru\\rtion of t. indu\\rtion basis. t c σ. any partial parse tree p whose stru\\rture is t is a height tree whose only node is labeled by the symbol c and a type a su\\rh that g c a. sin\\re g is rigid there is at most one su\\rh type a. then p if it exists is unique. indu\\rtion step. there are \\rases to \\ronsider. t is the following proof tree stru\\rture then any partial parse tree of g whose stru\\rture is t has the form where p and p t t e e b p a p a b are partial parse trees of g whose stru\\rtures are t and t respe\\rtively. by indu\\rtion inria learnability for rigid lambek grammars hypothesis p and p are unique. this means that the type label b is also uniquely determined so p is also unique. exa\\rtly like case with e in pla\\re of e. t is the following proof tree stru\\rture then any partial parse tree of g whose stru\\rture is t has the form where p is a t i p b i a b g partial parse tree of g whose stru\\rture is t. by indu\\rtion hypothesis p is unique. this means the the type label a b is uniquely determined so p is also unique. exa\\rtly like case with i in pla\\re of i. corollary. if g is a rigid lambek grammar ea\\rh proof tree stru\\rture t pl has a unique parse. shown in se\\rtion. note that last \\rorollary doesn t state that if g is rigid then ea\\rh string s l has a unique parse in general for ea\\rh senten\\re there are innitely many proof trees as extensively lemma. let g be a rigid lambek grammar. then for ea\\rh in\\romplete proof tree stru\\r ture t there is at most one in\\romplete parse tree p of g su\\rh that t is the stru\\rture of p. proof. see kan trivially extended to lambek grammars. rr n bonato. most general uniers and operator uni\\ration plays a \\rru\\rial role in automated theorem proving in \\rlassi\\ral rst order logi\\r and its extensions. sin\\re types are just a spe\\rial kind of terms the notion of uni\\ration applies straightforwardly to types. denition. let a and b be types. a substitution σ is a unier of a and b if σ σ. a unier σ is a most general unier of a and b if for any other unier τ of a and b there exists a substitution η su\\rh that τ σ η i.e. τ η for c a or c b. a substitution σ is said to unify a set a of types if for all a a a σ σ. we say that σ unies a family of sets of types if σ unies ea\\rh set in the family. a most general unier is unique up to renaming of variables. example. let a \\ronsist of the fol lowing sets a a a. then the most general unier of a is σ. there are many dierent e\\rient algorithms for uni\\ration whi\\rh de\\ride whether a nite set of types has a unier and if it does \\rompute a most general unier for it. for illustration purposes we present here a non deterministi\\r version of an uni\\ration algorithm. our algorithm uses the notion of disagreement pair. the easiest way to dene disagree ment pair is to \\ronsider the types to be tree like denition. let a and b be two types. a disagreement pair for a and b is a pair of subterms of a and b a b and the path from the root of a to the root of a is equal to the path from the root of b to the root of b su\\rh that a b. the following non deterministi\\r version of the uni\\ration algorithm is taken from fit unifi\\ration algorithm. ˆ input two types a and b and b are not uniable. ˆ output a most general unier σ of a b if it exists or a \\rorre\\rt statement that a inria learnability for rigid lambek grammars let σ ǫ while σ σ do for σ σ is a variable then fail begin \\rhoose a disagreement pair a b if neither a nor b let x be whi\\rhever of a b and let c be the other one of a b if x o\\r\\rurs in c then fail let σ σ end is a variable the previous algorithm present one of many e\\rient algorithms for uni\\ration so we the following is a well dened notion denition. we dene a \\romputable partial fun\\rtion mgu that maps a nite family a of nite sets of types to a most general unier mgu if a is uniable. the set grigid of all rigid lambek grammars is partially ordered by. denition. let g grigid and let g g .then g is \\ral led an upper bound of g if for every g g g g. we introdu\\re here a new operator among rigid grammars that will be used to prove an interesting property for our learning algorithm at the end of the fth \\rhapter. denition. let g and g be rigid lambek grammars. we \\ran assume that g and g have no \\rommon variables. let a and let σ mgu. note that g g is a valued grammar. then we dene g g as fol lows g g σ. if a is not uniable then g g is undened. example. let g and g be the fol lowing rigid lambek grammars g a s x b g b c x y s y. rr n bonato then g g a s b c y s y. obviously from denition. we have lemma. if g g exists then g g g and g g g. proposition. let g g grigid. bound then g g exists and it s the least upper bound of. if has un upper proof. inria learnability for rigid lambek grammars learning rigid lambek grammars from stru\\rtures in the present \\rhapter we will explore a model of learning for rigid lambek grammars based on positive stru\\rtured data. in addition to the standard model where senten\\res are presented to the learner as at sequen\\res of words in this somewhat enri\\rhed model strings \\rome with additional information about their deep stru\\rture. following the approa\\rh sket\\rhed in se\\rtion largely indebted with tiede s study on proof trees in lambek \\ral\\rulus as grammati\\ral stru\\rtures for lambek grammars in our model ea\\rh senten\\re \\romes to the learner with a stru\\rture in the form of a proof tree stru\\rture as extensively des\\rribed in se\\rtion. formally given a nite alphabet σ we will present a learning algorithm for the grammar system hgrigid σp pli that is to say samples to whi\\rh the learner is exposed to are prooftree stru\\rtures over the alphabet σ and guesses are made about the set of rigid lambek grammars that \\ran generate su\\rh a set of stru\\rtures. we follow the advi\\re of kanazawa who underlines how su\\rh an approa\\rh whi\\rh turns out to be quite logi\\rally independent from an approa\\rh based on at strings of words seems to make the task of learning easier but doesn t trivialize it. if on one hand in the pro\\ress of learning from stru\\rtures the learner is provided with more information on the other hand the \\rriterion for su\\r\\ressful learning is stri\\rter. it is not su\\rient that the string language of g \\rontains exa\\rtly the yields of the stru\\rtures in the input sequen\\re the learning fun\\rtion is required to \\ronverge to a grammar g that generates all the grammati\\ral stru\\rtures whi\\rh appear in the input sequen\\re. we \\rould say that the learning fun\\rtion must \\ronverge to a grammar that is both weakly and strongly equivalent to the grammar that generated the input samples. clearly from a psy\\rholinguisti\\r point of view both learning from at strings and from proof tree stru\\rtures are quite unrealisti\\r models of rst language a\\rquisition by human beings. in the rst \\rase experimental eviden\\res show that \\rhildren \\ran t a\\rquire a language simply by passively listening to at strings of words. first of all we \\ran think that prosody \\ran provide stru\\rtural information to the \\rhildren on the synta\\rti\\r bra\\rketing of the senten\\res she is exposed to and it is known that prosody is needed to learn a language for a \\rhild. furthermore another interesting eviden\\re of the fa\\rt that a \\rhild needs something more to learn her mother tongue is given by the fa\\rt that no \\rhildren \\ran improve their grammati\\ral skills during the early stages of their language a\\rquisition pro\\ress by wat\\rhing tv it seems very likely they need ri\\rher data than simple senten\\res uttered by an adult. some resear\\rhers hypothesize this additional information \\romes to the \\rhildren as the semanti\\r \\rontent of the rst senten\\res she is exposed to whose she \\rould have a rst primitive grasp through rst sensory motor experien\\res. on the other hand it is also highly unlikely that a \\rhild \\ran have a\\r\\ress to something like a proof tree stru\\rture of the senten\\re she is exposed to. our belief is that a good formal model for the pro\\ress of learning should rely on something halfway between at strings of words and highly stru\\rtured and \\romplete information \\roming from the proof tree stru\\rture of the senten\\re. however sin\\re as we ve already seen in se\\rtion. proof tree stru\\rtures rr n bonato provide a very natural support for a montague like semanti\\rs we think that our model for learning a rigid lambek grammar from stru\\rtured data represents a rst simple but meaningful approximation of a more plausible model of learning. in any \\rase even though in most of real world appli\\rations only unstru\\rtured data are available we are often interested not only in the senten\\res that a grammar derives but also in derivation strings that grammar assigns to senten\\res. that is we generally want a grammar that makes stru\\rtural sense. grammati\\ral inferen\\re as uni\\ration we set our inquiry over the learnability for rigid lambek grammars in the more general logi\\ral framework of the theory of uni\\ration. we will sti\\rk to the approa\\rh des\\rribed in ni\\r based on the attempt to redu\\re the pro\\ress of inferring a \\rategorial grammar to the problem of unifying a set of terms. this approa\\rh establishes a fruitful \\ronne\\rtion between indu\\rtive logi\\r programming te\\rhniques and the eld of grammati\\ral inferen\\re a \\ronne\\rtion that has already been proved su\\r\\ressful in devising e\\rient algorithms to infer k valued ccgs from positive stru\\rtured data. our aim is to exploit as mu\\rh as possible what has already been done in this dire\\rtion by exploring the possibility of adapting existing algorithms for ccgs to rigid lambek grammars. argument nodes and typing algorithm our learning algorithm is based on a pro\\ress of labeling for the nodes of a set of proof tree stru\\rtures. we introdu\\re here the notion of argument node for a normal form proof tree. we will be a bit sloppy in dening su\\rh a notion and sometimes we will use the same notation to indi\\rate a node and the type it s labeled by when this doesn t engender \\ronfusion and mu\\rh will be left to the graphi\\ral interpretation of trees and their nodes. however we \\ran always think of a node as a de bruijn like ob je\\rt without substantially ae\\rting the meaning of what will be proved. denition. let p be a normal form partial parse tree. let s dene indu\\rtively the set arg of argument nodes of p. there are three \\rases to \\ronsider ˆ p is a single node labeled by a type x whi\\rh is the only member of arg. ˆ p looks like one of the fol lowing g p a d p g p a b b a d p a e b e b inria learnability for rigid lambek grammars then in the rst \\rase and in the se\\rond \\rase arg arg arg arg arg arg. ˆ p looks like one of the fol lowing g g p b i a b p b i b a then arg arg. proof tree stru\\rture the following proposition justies our interest for argument nodes for a normal form proposition. let t be a wel l formed normal form proof tree stru\\rture. if ea\\rh argument node is labeled then any other node in t \\ran be labeled with one and only one type. proof. we prove that on\\re argument nodes are labeled any other node \\ran be labeled by providing a typing algorithm uniqueness of typing follows from the rules applied. by indu\\rtion on the height h of t indu\\rtion basis. there are two \\rases to \\ronsider. h. trivially by denition. t is a single argument node the result of the appli\\ration of a single axiom rule and by denition it s already typed. h. then t must be the result of a single appli\\ration of a or rule. by hypothesis and denition. its two argument nodes are labeled with say x and x and the remaining node must be labeled a\\r\\rording to one of the following rules rr n bonato x x x x x x x x e x e x e x e x indu\\rtion step. let t be a normal form proof tree stru\\rture of height h. there are \\rases to \\ronsider. t e. sin\\re by hypothesis ea\\rh node in arg arg arg is labeled then also root is labeled with say x. for the same reason any node of arg is labeled too and so by indu\\rtion hypothesis t is fully labeled. in parti\\rular its root is labeled with say x. sin\\re t is well formed t \\rannot be the result of the appli\\ration of a rule and sin\\re t is normal t \\rannot be the result of the appli\\ration of a rule so its root node is an argument node of its too. by hypothesis ea\\rh node in arg has a type so we \\ran apply the following rule t x t t x t x x e x e x and t has all of its argument nodes labeled. so by indu\\rtion hypothesis its fully and uniquely labeled and so is t. t e. analogous to \\rase. t i or t i. by denition arg arg then by hypothesis any argument node in t is labeled. then by indu\\rtion hypothesis t is fully labeled and sin\\re t is well formed there must be at least two undis\\rharged leaves in t. so t \\ran be fully labeled a\\r\\rording respe\\rtively to the following rules inria learnability for rigid lambek grammars x ... ... x t x i t x i x x ... t x i ... t x i x x where x labels respe\\rtively the leftmost and the rightmost undis\\rharged leaf. the proof of the previous proposition has impli\\ritly dened an algorithm for labeling in the most general way the nodes of a normal form proof tree stru\\rture. denition. a prin\\ripal parse of a proof tree stru\\rture t is a partial parse tree t of t su\\rh that for any other partial parse tree t of t there exists a substitution σ su\\rh that if a node of t is labeled by type a in t it s labeled by σ in t. from the proof of proposition. it s easy to devise an algorithm to get a prin\\ripal parse for any well formed normal form proof tree stru\\rture. prin\\ripal parse algorithm ˆ input a well formed normal form proof tree stru\\rture t ˆ output a prin\\ripal parse t of t in a lambek grammar g. step. label with distin\\rt variables ea\\rh argument node in t step. compute the types for the remaining nodes a\\r\\rording to the rules des\\rribed in the proof of proposition .. obviously this algorithm always terminates. if t is the resulting parse we \\ran easily prove it s prin\\ripal. if t is another parse for t let s dene a substitution σ in the following way for ea\\rh variable x v ar nd the node in t labeled by x and let σ be the type labeling the same node in t. by indu\\rtion on a t p we prove that if a labels a node of t σ labels the \\rorresponding node of t. indu\\rtion basis. if a v ar this holds by denition. indu\\rtion step. let a b c labels a node of t. then the relevant part of t must look like one of the following \\rases rr n bonato ˆ first \\rase by indu\\rtion hypothesis the \\rorresponding part of t looks like then a σ σ σ σ. ˆ se\\rond \\rase by indu\\rtion hypothesis the \\rorresponding part of t looks like b b c e c s a e s c i b c s s i a then a σ σ σ σ. inria learnability for rigid lambek grammars the \\rase a c b is entirely similar thus \\rompleting the indu\\rtion. it follows that if a node of t is labeled by a then the \\rorresponding node of t is labeled by σ. that is to say with a small abuse of notation t σ. rlg algorithm our algorithm takes as its input a nite set d of proof tree stru\\rtures over a nite alphabet σ and returns a rigid lambek grammar g over the same alphabet whose stru\\rture language \\rontains d if it exists a \\rorre\\rt statement that there s no su\\rh a rigid lambek grammar otherwise. our algorithm is based on the type algorithm des\\rribed in se\\rtion. and on the uni \\ration algorithm des\\rribed in se\\rtion .. rlg algorithm. ˆ input a nite set d of proof tree stru\\rtures. ˆ output a rigid lambek grammar g su\\rh that d pl if there is one. we illustrate the algorithm using the following example a d girl loves e e loves e a e john e e i e passionately him e girl rr n bonato step. normalize all the proof tree stru\\rtures in d if they are not normal a\\r\\rording to the rules des\\rribed in se\\rtion .. step. assign a type to ea\\rh node of the stru\\rture in d as follows. assign s to ea\\rh root node. assign distin\\rt variables to the argument nodes. a girl x e x loves x e girl x e x a e john x loves e s e x passionately him e s. compute types for the remaining nodes a\\r\\rording to the rules des\\rribed in proposition .. a x x girl x loves x x e x e x x a x x girl x loves x e x john x e x s e s him x e x passionately x s e s e x i e x i x x inria learnability for rigid lambek grammars step. colle\\rt the types assigned to the leaf nodes into a grammar gf \\ralled the general form indu\\red by d. in general gf c a if and only if the previous step assigns a to a leaf node labeled by symbol c. gf passionately x s him x a x x x x x x x x girl loves john x step. unify the types assigned to the same symbol. let a and \\rompute σ mgu. the algorithm fails if uni\\ration fails. σ step. let rlg σ. rlg passionately x s him x a x x x x girl loves john x our algorithm is based on the prin\\ripal parse algorithm des\\rribed in the previous se\\rtion whi\\rh has been proved to be \\rorre\\rt and terminate and the uni\\ration algorithm des\\rribed in se\\rtion .. the result is intuitively the most general rigid lambek grammar whi\\rh \\ran generate all the proof tree stru\\rtures appearing in the input sequen\\re. properties of rlg to study its behaviour in the limit. in the present se\\rtion we prove some properties of the rlg algorithm that will be helpful the following lemma is almost trivial but it will play an important role in the \\ronvergen\\re proof for the rlg algorithm. it simply states that the tree language of the grammar inferred just after the labeling of the stru\\rtures properly \\rontains the sample stru\\rtures. lemma. let d be the input set of proof tree stru\\rtures for the rlg algorithm. then the set of the proof tree stru\\rtures generated by the general form grammar \\rontains properly d. that is d pl. rr n bonato proof. let d. the labeling of the nodes of the stru\\rtures in d that pre\\redes the \\ronstru\\rtion of gf in fa\\rt forms a parse tree pi of gf for ea\\rh stru\\rture ti in d. this shows d p l. the proper in\\rlusion follows trivially from the fa\\rt that d is by hypothesis a nite set while pl the set of proof tree stru\\rtures generated by a lambek grammar g is always innite. lemma. ea\\rh variable x v ar labels a unique node in a unique parse tree of d. proof. obviously by \\ronstru\\rtion if x v ar then there must be an i n su\\rh that x labels one of the nodes of a parse tree pi. sin\\re by \\ronstru\\rtion for ea\\rh i j the sets of variables that label pi are disjoint x appears in one and only one pi. besides sin\\re variables are assigned only during the rst phase of the type assignment pro\\ress of our algorithm again by \\ronstru\\rtion ea\\rh variable labels only one node in the dedu\\rtion tree. the following lemma makes expli\\rit the relation between the grammar inferred just after the labeling of the stru\\rtures in the algorithm rlg and the stru\\rture language of the rigid grammar we are trying to infer. lemma. let d be a nite set of proof tree stru\\rtures. then for any lambek grammar g the fol lowing are equivalent d pl there is a substitution σ su\\rh that σ g. proof. suppose there is a substitution σ su\\rh that σ g. then from proposition. we have that pl pl. this together with lemma. proves. let d and let pi be gf s parse of ti for i n. assume d pl. then g has a parse qi of ea\\rh ti. dene a substitution σ as follows for ea\\rh variable x v ar nd a pi that \\rontains a node labeled by x and let σ be the type labeling the \\rorresponding node of qi. we show that if a labels a node of some pi then σ labels the \\rorresponding node of qi. proof. by indu\\rtion on a t p indu\\rtion basis. if a v ar this holds by denition. if a t then any node labeled by a in is the root node of some pi. sin\\re qi is a parse tree of g the root node of qi must be labeled by t. indu\\rtion step. let a b c labels a node of pi. then the relevant part of pi must look like one of the two following \\rases inria learnability for rigid lambek grammars ˆ first \\rase b b c by indu\\rtion hypothesis the \\rorresponding part of qi looks like s a then a σ σ σ σ. ˆ se\\rond \\rase e c t e s t c i b c t rr n bonato by indu\\rtion hypothesis the \\rorresponding part of qi looks like s s i a t then again a σ σ σ σ. the \\rase a c b is entirely similar thus \\rompleting the indu\\rtion. gf c a then g c σ. therefore σ g. it follows that if the following proposition establishes an if and only if relation between the in\\rlusion of our set of positive samples d in a tree language generated by a rigid grammar g and the su\\r\\ressful termination of the rlg algorithm when it has d as its input set. even more we have that the rigid grammar inferred by the algorithm is not larger than the rigid proposition. let d be a nite set of proof tree stru\\rtures. then for any rigid grammar g the fol lowing are equivalent grammar g. d pl τ g. rlg exists and rlg g equivalently there is a substitution τ su\\rh that proof. follows from lemma. and the fa\\rt that rlg is a substitution instan\\re of gf. assume that g is a rigid grammar su\\rh that d p l. by lemma. there is a substitution σ su\\rh that σ g. sin\\re g is a rigid grammar σ is also a rigid grammar. then σ unies the family a. this means that rlg exists and rlg σ where σ mgu. then there is a substitution τ su\\rh that σ τ σ. therefore τ τ σ. by assumption σ g so τ g. corollary. let d and d be two nite sets of proof tree stru\\rtures su\\rh that d d. if rlg exists rlg also exists and rlg rlg and pl pl. inria learnability for rigid lambek grammars proof. immediate from proposition. noting that if d d then. denition. let ϕrlg be the learning fun\\rtion for the grammar system hgrigid σp pli dened as fol lows ϕrlg rlg. thanks to previous propositions and lemmas we are able to prove the \\ronvergen\\re for the rlg algorithm theorem. ϕrlg learns grigid from stru\\rtures. proof. we prove that ϕrlg learns the \\rlass of rigid lambek grammars from proof tree stru\\rtures. let g be any rigid lambek grammar and let htiii n be an innite sequen\\re enumerating pl. for ea\\rh i n pl so by proposition. ϕrlg rlg is dened and ϕrlg ϕrlg by \\rorollary. and ϕrlg g. sin\\re by \\rorollary. there are only nitely many lambek grammars g g ϕrlg. then pl pl. sin\\re g g must \\ronverge on htiii n to some g by proposition. pl pl. therefore pl pl. when rlg is applied su\\r\\ressively to a sequen\\re of in\\rreasing set of proof tree stru\\rtures d d d it is more e\\rient to make use of the previous value rlg to \\rompute the \\rurrent value rlg. denition. if g is a rigid lambek grammar and d is a nite set of proof tree stru\\r tures then let rlg g rlg. lemma. if d and d are two nite sets of proof tree stru\\rtures rlg rlg. undened re\\rall that the symbol means that either both sides are dened and are equal or else both sides are rr n bonato proof. suppose that rlg is dened. by lemma. rlg rlg and rlg rlg. this implies that d d pl rlg so by proposition. rlg exists and rlg rlg. suppose now that rlg is dened. by \\rorollary. rlg and rlg exist and rlg rlg and rlg rlg. then rlg is an upper bound of. by proposition. rlg rlg rlg exists and rlg rlg. thus it has been proved that if one of rlg and rlg is dened the other is dened and they are equal. proposition. ϕrlg has the fol lowing properties ϕrlg learns grigid prudently. ϕrlg is responsive and \\ronsistent on grigid. ϕrlg is set driven. ϕrlg is \\ronservative. ϕrlg is monotone in\\rreasing. ϕrlg is in\\rremental. proof. sin\\re range grigid ϕrlg learns grigid prudently. if d l for some l plrigid then by proposition. rlg exists and by lemma. d pl. this means that ϕrlg is responsive and \\ronsistent on grigid. ϕrlg is set driven by denition. let t pl. then d pl. by proposition. rlg exists and rlg rlg. by \\rorollary. we have also rlg rlg. this shows that ϕrlg is \\ronservative. trivial from \\rorollary .. dene a \\romputable fun\\rtion ψ grigid σp grigid as follows ψ undened otherwise. rlg if g grigid and rlg is dened then by lemma. ϕrlg ψ. inria learnability for rigid lambek grammars con\\rlusion and further resear\\rh this work aims at making a further step in the dire\\rtion of bridging the gap whi\\rh still separates any formal \\romputational theory of learning from a meaningful formal linguisti\\r theory. arti\\rle of. we have introdu\\red the basi\\r notions of formal learnability theory as rst formulated by e.m. gold in and of lambek grammars whi\\rh appeared for the rst time in an the former whi\\rh is one of the rst \\rompletely formal des\\rriptions of the pro\\ress of gram mati\\ral inferen\\re after an initial skepti\\rism about its ee\\rtive appli\\rability is at present to ob je\\rt of a renewed interest due to some meaningful and promising learnabiluty results. even the latter long negle\\rted by the linguisti\\r \\rommunity is experien\\ring a strong renewed interest as a \\ronsequen\\re of re\\rent linguisti\\rs a\\rhievements whi\\rh point at formal grammars \\rompletely lexi\\ralized as lambek grammars are. even if they re still far from being the ultimate formal devi\\re for the formalization of human linguisti\\rs \\rompeten\\re they re universally looked at as a promising tool for further developments of \\romputational linguisti\\rs. in the present work we ve drawn the attention to a parti\\rular \\rlass of lambek grammars \\ralled rigid lambek grammars and we ve proved that they are learnable in gold s framework from a stru\\rtured input. we ve used most re\\rent results by hans joerg tiede for formally dene our notion of stru\\rture for a senten\\re he has re\\rently proved that the proof tree language generated by a lambek grammar stri\\rtly \\rontains the tree language generated by \\rontext free grammars. his notion of a proof as the grammati\\ral stru\\rture of a senten\\re in a \\rategorial grammar is also useful in providing a natural support to a montagovian semanti\\rs for that senten\\re. therefore our \\rhoi\\re for a stru\\rtured input for our learning algorithm in the form of proof tree stru\\rtures is not gratuitous but it s \\roherent with the mainstream of linguisti\\rs theories about rst language learning whi\\rh stress the importan\\re of providing the learner with informatioannly and semanti\\rally ri\\rh input in the pro\\ress of her language a\\rquisition. we believe it to be a partial but meaningful result whi\\rh on\\re more shows how versatile and powerful \\ran be this learning theory on\\re negle\\rted be\\rause it was widely held that it \\rouldn t but a\\r\\rount for the learnability of most trivial \\rlasses of grammars. mu\\rh is left to be done along many dire\\rtions. first of all there s still no real theory of rigid or k valued lambek grammars we still know very few formal properties of su\\rh grammars whi\\rh seem to have an undisputable linguisti\\r interest. we still la\\rk for example a hierar\\rhy theorem for languages generated by k valued lambek grammars. another important point whi\\rh is still unanswered lies in the de\\ridibility for p l p l for g g lambek grammars that is de\\riding whether the tree language generated by a grammar is \\rontained in the tree language generated by another one for any two gram mars. su\\rh a question is de\\ridable for the non asso\\riative variant of lambek grammars. proving this question de\\ridable would allow as to very esaily devise a learning algorithm for rr n bonato k valued lambek grammars. our learnability result is in our opinion a rst step toward a more \\ronvin\\ring and lin guisti\\rally plausible model of learning for k valued lambek grammars from less and less stru\\rturally ri\\rh input. needless to say learning from su\\rh an informationally ri\\rh input like proof tree stru\\rtures are hardly has any linguisti\\r plausibility. on the other hand the deep \\ronne\\rtions between proof tree stru\\rtures for a senten\\re in lambek grammars and its montague like semanti\\rs seems to address to a more \\ronvin\\ring model for learning based both on synta\\rti\\r and semanti\\r information. inria learnability for rigid lambek grammars referen\\res ang dana angluin. indu\\rtive inferen\\re of formal languages from positive data. information and control. bb lenore blum and manuel blum. toward a mathemati\\ral theory of indu\\rtive inferen\\re. information and control. bh yehoshua bar hillel. language and information. addson wesley reading. bp wo j\\rie\\rh buszkowski and gerald penn. categorial grammars determined from linguisti\\r data by uni\\ration. studia logi\\ra. bus woi\\rie\\rh buszkowski. generative \\rapa\\rity of non asso\\riative lambek \\ral\\rulus. bul letin of the polish a\\rademy of s\\rien\\re and mathemati\\rs. cho noam chomsky. three models for the des\\rription of language. ire transa\\r tions on information theory it. cho noam chomsky. ree\\rtions on language. pantheon. db n. g. de bruijn. lambda \\ral\\rulus notation with nameless dummies. indaga tiones mathemati\\rae pages. fit melvin fitting. first order logi\\r and automati\\r theorem proving. berlin springer. ful m. fulk. saving the phenomenon requirements that indu\\rtive ma\\rhines not \\rontradi\\rt known data. information and computation. gaz gerald gazdar. appli\\rability of indexed grammars to natural languages. in uwe reyle and christian rohrer editors natural language parsing and lin guisti\\r theories pages. dordre\\rht reidel. gol e. m. gold. language identi\\ration in the limit. information and control gs feren\\r gé\\rseg and magnus steinby. tree automata. akadémiai kiadó. gue irène guesserian. pushdown tree automata. mathemati\\ral systems theory. jors sanjay jain daniel n. osherson james s. royer and arun sharma. systems that learn. mit press cambridge massa\\rhusetts se\\rond edition. kan makoto kanazawa. learnable classes of categorial grammars. center for the study of language and information stanford. rr n bonato koz dexter kozen. automata and computability. berlin springer. lam joa\\rhim lambek. the mathemati\\rs of senten\\re stru\\rture. ameri\\ran mathe mati\\ral monthly. mon ri\\rhard montague. the proper treatment of quanti\\ration in ordinary english. in jakko hintikka editor approa\\rhes to natural language pages. reidel. moo mi\\rhael moortgat. categorial type logi\\rs. in johan van benthem and ali\\re ter meulen editors handbook of logi\\r and language. north holland amsterdam ni\\r ja\\rques ni\\rolas. grammati\\ral inferen\\re as uni\\ration. te\\rhni\\ral report irisa unite de re\\rher\\rhe inria rennes. ogl daniel n. osherson lila r. gleitmann and mark liberman editors. an invitation to cognitive s\\rien\\re volume language. the mit press mas sa\\rhusetts institute of te\\rhnology cambridge massa\\rhusetts se\\rond edition. owdjm daniel n. osherson s\\rott weinstein di\\rk de jongh and eri\\r martin. formal learning theory. in johan van benthem and ali\\re ter meulen editors handbook of logi\\r and language. north holland amsterdam. pen mati pentus. produ\\rt free lambek \\ral\\rulus and \\rontext free grammars. the journal of symboli\\r logi\\r. pin steven pinker. the language insti\\rt. penguin press. ret christian retoré. proof nets for the lambek \\ral\\rulus an overview. in mi\\rhele abrus\\ri and claudia casadio editors pro\\reedings of the roma work shop proofs and linguisti\\r categories appli\\rations of logi\\r to the analysis and implementation of natural language pages bologna april. clueb. roo dirk roorda. resour\\re logi\\rs proof theoreti\\ral investigations. phd thesis university of amsterdam. shi t. shinohara. indu\\rtive inferen\\re from positive data is powerful. in the workshop on computational learning theory pages san mateo california. morgan kaufmann. ste mark steedman. categorial grammar. lingua. tel isabelle tellier. r\\x1dle de la \\rompositionnalité dan l a\\rquisition d une langue. in a\\rtes de cap pages palaiseau. inria learnability for rigid lambek grammars tha james w. that\\rher. chara\\rterizing derivation trees of \\rontext free grammars through a generalization of nite automata theory. journal of computer sys tems s\\rin\\res pages. tie hans joerg tiede. dedu\\rtive systems and grammars proofs as grammati\\ral stru\\rtures. phd thesis indiana university july. vb johan van benthem. logi\\ral syntax. theoreti\\ral linguisti\\rs wan heinri\\rh wansing. the logi\\r of information stru\\rtures. berlin springer. verlag. wri k. wright. identi\\rations of unions of languages drawn from an identiable \\rlass. in the workshop on computational learning theory pages san mateo california. morgan kaufmann. zie wo j\\rie\\rh zielonka. a simple and general method for solving the nite axioma tizability problems for lambek s synta\\rti\\r \\ral\\ruli. studia logi\\ra. contents introdu\\rtion grammati\\ral inferen\\re. child s first language a\\rquisition. gold s model. basi\\r notions. grammar systems. learning fun\\rtions convergen\\re learnability. stru\\rtural conditions for learnability. .. existen\\re of a limit point. .. finite elasti\\rity. .. kanazawa s theorem. constraints on learning fun\\rtions. .. non restri\\rtive constraints. .. restri\\rtive constraints. rr n bonato is learning theory powerful enough. first negative results. angluin s results. shinohara s results. kanazawa s results. our results. lambek grammars. classi\\ral categorial grammars. extensions of classi\\ral categorial grammars. lambek cal\\rulus. non asso\\riative lambek cal\\rulus. normalization and normal forms. basi\\r fa\\rts about lambek cal\\rulus. lambek grammars. proofs as grammati\\ral stru\\rtures. parse trees for lambek grammars. tree languages and automata. .. lo\\ral tree languages. .. regular tree languages. .. context free tree languages. proof trees as stru\\rtures for lambek grammars. proof tree stru\\rtures. de\\ridable and unde\\ridable problems aboutlambek grammars. substitutions. grammars in redu\\red form. lambek grammars as a linguisti\\r tool. lambek grammars and syntax. .. transitive verbs. .. pronouns. .. adverbs. .. hypotheti\\ral reasoning. .. transitivity. lambek grammars and montague semanti\\rs. rigid lambek grammars. rigid and k valued lambek grammars. most general uniers and operator. inria learnability for rigid lambek grammars learning rigid lambek grammars from stru\\rtures. grammati\\ral inferen\\re as uni\\ration. argument nodes and typing algorithm. rlg algorithm. properties of rlg. con\\rlusion and further resear\\rh rr n unité de recherche inria futurs parc club orsay université zac des vignes rue jacques monod orsay cedex unité de recherche inria lorraine loria technopôle de nancy brabois campus scientiﬁque rue du jardin botanique bp villers lès nancy cedex unité de recherche inria rennes irisa campus universitaire de beaulieu rennes cedex unité de recherche inria rhône alpes avenue de l europe montbonnot saint ismier unité de recherche inria rocquencourt domaine de voluceau rocquencourt bp le chesnay cedex unité de recherche inria sophia antipolis route des lucioles bp sophia antipolis cedex éditeur inria domaine de voluceau rocquencourt bp le chesnay cedex http www.inria.fr issn'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    cleanedText = str(text)\n",
    "    if \"\\nReferences\\n\" in text:\n",
    "        cleanedText = cleanedText.rsplit(\"\\nReferences\\n\", 1)[0] #Removes all references, starts from back\n",
    "    cleanedText = re.sub(r\"(\\x0c)\", '', cleanedText) #Remove page breaks and other pdf injections any combination of \\x then two non whitespace characters\n",
    "    cleanedText = re.sub(r'-\\n','', cleanedText)\n",
    "    cleanedText = re.sub(r'\\n-','', cleanedText) #Hyphens before & after new lines are usually added for continuation of a word\n",
    "    cleanedText = re.sub(r'\\n',' ',cleanedText)#Get rid of new lines replace with spaces\n",
    "    #Remove everything between parentheses or brackets 3 times to get most equations but leave most of the text\n",
    "    for x in range(0,2):\n",
    "        cleanedText = re.sub(r'(\\(([^)^(]+)\\))','',cleanedText) #removes everything inside of parentheses, have to re-run for nested\n",
    "        cleanedText = re.sub(r'(\\[([^]^[]+)\\])','',cleanedText) #removes everything inside of square brackets\n",
    "        cleanedText = re.sub(r'(\\{([^}^{]+)\\})','',cleanedText) #removes everything inside of curly brackets \n",
    "    cleanedText = re.sub(r'[^\\w^\\s^.]',' ', cleanedText) #Remove all characters not [a-zA-Z0-9_] excluding spaces and periods\n",
    "    cleanedText = re.sub(r'\\d','', cleanedText) #Remove all numbers\n",
    "    cleanedText = re.sub(r' {2,}', ' ', cleanedText).strip() #Replace all multiple spaces with one space\n",
    "    cleanedText = re.sub(r'(\\. ){2,}', '. ', cleanedText).strip() #Replace all multiple period spaces with one space\n",
    "    cleanedText = re.sub(r'(\\s\\.\\s)', '. ', cleanedText).strip() #Replace all space period space with period space\n",
    "    cleanedText = str(cleanedText)\n",
    "    cleanedText = cleanedText.lower()\n",
    "    cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001004v1.txt\n",
      "0002006v1.txt\n",
      "0009001v3.txt\n",
      "0009007v1.txt\n",
      "0011032v1.txt\n",
      "0011044v1.txt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "direct = r'C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\testTokenized'\n",
    "theFiles = glob.glob((direct+\"\\*.txt\"))\n",
    "for fileName in theFiles:\n",
    "    name = fileName.rsplit('\\\\',1)[1]\n",
    "    name = re.sub(r'\\n','',name)\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelim Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rough_words = nltk.word_tokenize(cleanedText) \n",
    "sent_tokes = nltk.sent_tokenize(cleanedText) \n",
    "wordFreqs = {}\n",
    "sent_scores = {}\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "for w in rough_words:\n",
    "    if w not in stopwords and re.match(r'[\\\\A\\w]*[aeiou]+[\\w$]*',w): \n",
    "        if w not in wordFreqs.keys():   \n",
    "            wordFreqs[w] = 1\n",
    "        else:\n",
    "            wordFreqs[w] +=1\n",
    "\n",
    "mostFreqy = max(wordFreqs.values())\n",
    "\n",
    "for word in wordFreqs.keys():\n",
    "    wordFreqs[word] = (wordFreqs[word]/mostFreqy)\n",
    "\n",
    "        \n",
    "        \n",
    "for sentence in sent_tokes:\n",
    "    #print (sentence)\n",
    "    for word in sentence.split():\n",
    "        #print (word)\n",
    "        if word in wordFreqs.keys():\n",
    "            #print (word)\n",
    "            if len(sentence.split(' ')) <30:\n",
    "                if sentence not in sent_scores.keys():\n",
    "                    sent_scores[sentence] = wordFreqs[word]\n",
    "                else:\n",
    "                    sent_scores[sentence] += wordFreqs[word]\n",
    "                    \n",
    "summaryML = heapq.nlargest(10, sent_scores, key = sent_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a.': 0.00847457627118644,\n",
       " 'able': 0.00847457627118644,\n",
       " 'according': 0.00847457627118644,\n",
       " 'accuracy': 0.00847457627118644,\n",
       " 'accurate': 0.01694915254237288,\n",
       " 'achieved': 0.025423728813559324,\n",
       " 'acknowledged': 0.00847457627118644,\n",
       " 'acknowledgments': 0.00847457627118644,\n",
       " 'active': 0.211864406779661,\n",
       " 'adding': 0.00847457627118644,\n",
       " 'addition': 0.00847457627118644,\n",
       " 'additional': 0.0423728813559322,\n",
       " 'additionally': 0.00847457627118644,\n",
       " 'advantage': 0.03389830508474576,\n",
       " 'advantages': 0.00847457627118644,\n",
       " 'agglomerative': 0.00847457627118644,\n",
       " 'ai': 0.025423728813559324,\n",
       " 'al': 0.06779661016949153,\n",
       " 'alc': 0.1016949152542373,\n",
       " 'algorithm': 0.2711864406779661,\n",
       " 'algorithms': 0.01694915254237288,\n",
       " 'allr': 0.05084745762711865,\n",
       " 'almost': 0.03389830508474576,\n",
       " 'aln': 0.03389830508474576,\n",
       " 'also': 0.025423728813559324,\n",
       " 'alternative': 0.00847457627118644,\n",
       " 'alternatively': 0.00847457627118644,\n",
       " 'amsterdam': 0.00847457627118644,\n",
       " 'analysis': 0.00847457627118644,\n",
       " 'analyze': 0.00847457627118644,\n",
       " 'appeared': 0.01694915254237288,\n",
       " 'appears': 0.00847457627118644,\n",
       " 'applicable': 0.00847457627118644,\n",
       " 'application': 0.05084745762711865,\n",
       " 'applications': 0.00847457627118644,\n",
       " 'applied': 0.025423728813559324,\n",
       " 'approach': 0.00847457627118644,\n",
       " 'approaches': 0.00847457627118644,\n",
       " 'appropriate': 0.03389830508474576,\n",
       " 'approximate': 0.01694915254237288,\n",
       " 'approximated': 0.00847457627118644,\n",
       " 'approximates': 0.025423728813559324,\n",
       " 'approximation': 0.00847457627118644,\n",
       " 'arbitrarily': 0.00847457627118644,\n",
       " 'arbitrary': 0.01694915254237288,\n",
       " 'areas': 0.025423728813559324,\n",
       " 'argsortj': 0.01694915254237288,\n",
       " 'argued': 0.00847457627118644,\n",
       " 'around': 0.03389830508474576,\n",
       " 'arrives': 0.00847457627118644,\n",
       " 'assign': 0.00847457627118644,\n",
       " 'assigned': 0.00847457627118644,\n",
       " 'assigning': 0.025423728813559324,\n",
       " 'assignments': 0.00847457627118644,\n",
       " 'asymptotically': 0.00847457627118644,\n",
       " 'authors': 0.00847457627118644,\n",
       " 'automatic': 0.00847457627118644,\n",
       " 'automatically': 0.00847457627118644,\n",
       " 'available': 0.025423728813559324,\n",
       " 'average': 0.025423728813559324,\n",
       " 'averaged': 0.03389830508474576,\n",
       " 'averaging': 0.025423728813559324,\n",
       " 'avoid': 0.00847457627118644,\n",
       " 'avoiding': 0.00847457627118644,\n",
       " 'axis': 0.00847457627118644,\n",
       " 'back': 0.00847457627118644,\n",
       " 'bad': 0.01694915254237288,\n",
       " 'based': 0.2627118644067797,\n",
       " 'baseline': 0.00847457627118644,\n",
       " 'basic': 0.01694915254237288,\n",
       " 'basis': 0.01694915254237288,\n",
       " 'becomes': 0.025423728813559324,\n",
       " 'behavior': 0.00847457627118644,\n",
       " 'behind': 0.00847457627118644,\n",
       " 'belong': 0.025423728813559324,\n",
       " 'belonging': 0.00847457627118644,\n",
       " 'belongs': 0.0423728813559322,\n",
       " 'better': 0.11016949152542373,\n",
       " 'big': 0.00847457627118644,\n",
       " 'bilinear': 0.00847457627118644,\n",
       " 'block': 0.06779661016949153,\n",
       " 'border': 0.00847457627118644,\n",
       " 'bounded': 0.00847457627118644,\n",
       " 'bounding': 0.01694915254237288,\n",
       " 'bout': 0.00847457627118644,\n",
       " 'boxes': 0.01694915254237288,\n",
       " 'call': 0.025423728813559324,\n",
       " 'called': 0.025423728813559324,\n",
       " 'candidate': 0.025423728813559324,\n",
       " 'candidates': 0.025423728813559324,\n",
       " 'case': 0.059322033898305086,\n",
       " 'cases': 0.00847457627118644,\n",
       " 'cell': 0.11864406779661017,\n",
       " 'cells': 0.1440677966101695,\n",
       " 'challenge': 0.00847457627118644,\n",
       " 'change': 0.03389830508474576,\n",
       " 'changed': 0.00847457627118644,\n",
       " 'changing': 0.00847457627118644,\n",
       " 'character': 0.00847457627118644,\n",
       " 'characters': 0.1016949152542373,\n",
       " 'choice': 0.00847457627118644,\n",
       " 'chosen': 0.03389830508474576,\n",
       " 'ci': 0.059322033898305086,\n",
       " 'cij': 0.05084745762711865,\n",
       " 'clas': 0.00847457627118644,\n",
       " 'class': 0.1440677966101695,\n",
       " 'classes': 0.1016949152542373,\n",
       " 'classical': 0.00847457627118644,\n",
       " 'classifying': 0.00847457627118644,\n",
       " 'classiﬁcation': 0.19491525423728814,\n",
       " 'classiﬁcations': 0.025423728813559324,\n",
       " 'classiﬁed': 0.01694915254237288,\n",
       " 'classiﬁer': 0.0847457627118644,\n",
       " 'classiﬁers': 0.07627118644067797,\n",
       " 'clear': 0.00847457627118644,\n",
       " 'clearly': 0.00847457627118644,\n",
       " 'close': 0.025423728813559324,\n",
       " 'clusn': 0.00847457627118644,\n",
       " 'cluster': 0.3474576271186441,\n",
       " 'clustering': 0.5254237288135594,\n",
       " 'clusterings': 0.13559322033898305,\n",
       " 'clusters': 0.423728813559322,\n",
       " 'colloquium': 0.00847457627118644,\n",
       " 'combine': 0.00847457627118644,\n",
       " 'combined': 0.05084745762711865,\n",
       " 'combining': 0.03389830508474576,\n",
       " 'comparative': 0.00847457627118644,\n",
       " 'compared': 0.059322033898305086,\n",
       " 'comparing': 0.025423728813559324,\n",
       " 'comparison': 0.00847457627118644,\n",
       " 'complexities': 0.01694915254237288,\n",
       " 'complexity': 0.16101694915254236,\n",
       " 'complicated': 0.00847457627118644,\n",
       " 'computation': 0.0423728813559322,\n",
       " 'computational': 0.05084745762711865,\n",
       " 'computationally': 0.00847457627118644,\n",
       " 'computations': 0.07627118644067797,\n",
       " 'compute': 0.0423728813559322,\n",
       " 'computed': 0.1016949152542373,\n",
       " 'computing': 0.11016949152542373,\n",
       " 'concept': 0.00847457627118644,\n",
       " 'concluded': 0.00847457627118644,\n",
       " 'conclusions': 0.01694915254237288,\n",
       " 'consequently': 0.03389830508474576,\n",
       " 'considerably': 0.025423728813559324,\n",
       " 'considered': 0.0423728813559322,\n",
       " 'consistent': 0.01694915254237288,\n",
       " 'consisting': 0.00847457627118644,\n",
       " 'constituting': 0.00847457627118644,\n",
       " 'construct': 0.01694915254237288,\n",
       " 'constructed': 0.00847457627118644,\n",
       " 'constructing': 0.00847457627118644,\n",
       " 'construction': 0.00847457627118644,\n",
       " 'contain': 0.05084745762711865,\n",
       " 'contains': 0.025423728813559324,\n",
       " 'contributions': 0.00847457627118644,\n",
       " 'conﬁdence': 0.0423728813559322,\n",
       " 'conﬁdences': 0.13559322033898305,\n",
       " 'copies': 0.00847457627118644,\n",
       " 'correspond': 0.00847457627118644,\n",
       " 'corresponding': 0.00847457627118644,\n",
       " 'cost': 0.03389830508474576,\n",
       " 'could': 0.03389830508474576,\n",
       " 'creating': 0.00847457627118644,\n",
       " 'criterion': 0.00847457627118644,\n",
       " 'cursive': 0.06779661016949153,\n",
       " 'curve': 0.01694915254237288,\n",
       " 'curves': 0.11864406779661017,\n",
       " 'data': 0.0423728813559322,\n",
       " 'dataset': 0.2711864406779661,\n",
       " 'datasets': 0.2966101694915254,\n",
       " 'david': 0.00847457627118644,\n",
       " 'default': 0.00847457627118644,\n",
       " 'delft': 0.00847457627118644,\n",
       " 'demands': 0.00847457627118644,\n",
       " 'dendrogram': 0.00847457627118644,\n",
       " 'dense': 0.01694915254237288,\n",
       " 'densities': 0.07627118644067797,\n",
       " 'density': 0.1440677966101695,\n",
       " 'depend': 0.00847457627118644,\n",
       " 'dependent': 0.01694915254237288,\n",
       " 'depends': 0.00847457627118644,\n",
       " 'derivative': 0.00847457627118644,\n",
       " 'described': 0.06779661016949153,\n",
       " 'description': 0.00847457627118644,\n",
       " 'desired': 0.00847457627118644,\n",
       " 'deteriorated': 0.00847457627118644,\n",
       " 'determination': 0.00847457627118644,\n",
       " 'determine': 0.05084745762711865,\n",
       " 'determined': 0.01694915254237288,\n",
       " 'determines': 0.00847457627118644,\n",
       " 'deterministic': 0.00847457627118644,\n",
       " 'developed': 0.00847457627118644,\n",
       " 'deviate': 0.00847457627118644,\n",
       " 'deﬁned': 0.11016949152542373,\n",
       " 'digits': 0.059322033898305086,\n",
       " 'dij': 0.03389830508474576,\n",
       " 'dimensional': 0.0423728813559322,\n",
       " 'dimensionalities': 0.00847457627118644,\n",
       " 'discrete': 0.00847457627118644,\n",
       " 'discussed': 0.0423728813559322,\n",
       " 'distance': 0.1016949152542373,\n",
       " 'distances': 0.1016949152542373,\n",
       " 'distant': 0.00847457627118644,\n",
       " 'distinction': 0.00847457627118644,\n",
       " 'distributed': 0.00847457627118644,\n",
       " 'diﬀerence': 0.00847457627118644,\n",
       " 'diﬀerences': 0.00847457627118644,\n",
       " 'diﬀerent': 0.11016949152542373,\n",
       " 'domain': 0.025423728813559324,\n",
       " 'done': 0.00847457627118644,\n",
       " 'drawback': 0.00847457627118644,\n",
       " 'drops': 0.00847457627118644,\n",
       " 'due': 0.01694915254237288,\n",
       " 'e.g': 0.05084745762711865,\n",
       " 'easy': 0.00847457627118644,\n",
       " 'elements': 0.00847457627118644,\n",
       " 'enlarged': 0.025423728813559324,\n",
       " 'entire': 0.059322033898305086,\n",
       " 'entirely': 0.00847457627118644,\n",
       " 'entropy': 0.00847457627118644,\n",
       " 'equal': 0.00847457627118644,\n",
       " 'equally': 0.00847457627118644,\n",
       " 'equals': 0.00847457627118644,\n",
       " 'erroneously': 0.00847457627118644,\n",
       " 'error': 0.05084745762711865,\n",
       " 'errors': 0.00847457627118644,\n",
       " 'especially': 0.00847457627118644,\n",
       " 'essential': 0.00847457627118644,\n",
       " 'estimate': 0.01694915254237288,\n",
       " 'estimated': 0.0423728813559322,\n",
       " 'estimates': 0.05084745762711865,\n",
       " 'estimating': 0.00847457627118644,\n",
       " 'et': 0.01694915254237288,\n",
       " 'evalin': 0.00847457627118644,\n",
       " 'evaluated': 0.00847457627118644,\n",
       " 'evaluation': 0.07627118644067797,\n",
       " 'even': 0.025423728813559324,\n",
       " 'every': 0.16101694915254236,\n",
       " 'exactly': 0.01694915254237288,\n",
       " 'example': 0.00847457627118644,\n",
       " 'examples': 0.06779661016949153,\n",
       " 'expected': 0.0423728813559322,\n",
       " 'experiment': 0.025423728813559324,\n",
       " 'experimentally': 0.00847457627118644,\n",
       " 'experiments': 0.06779661016949153,\n",
       " 'expert': 0.00847457627118644,\n",
       " 'explained': 0.00847457627118644,\n",
       " 'explanation': 0.00847457627118644,\n",
       " 'expressed': 0.00847457627118644,\n",
       " 'extend': 0.00847457627118644,\n",
       " 'extended': 0.01694915254237288,\n",
       " 'extensively': 0.01694915254237288,\n",
       " 'eﬀective': 0.00847457627118644,\n",
       " 'eﬀort': 0.03389830508474576,\n",
       " 'eﬃcient': 0.00847457627118644,\n",
       " 'eﬃciently': 0.00847457627118644,\n",
       " 'factor': 0.00847457627118644,\n",
       " 'fast': 0.13559322033898305,\n",
       " 'faster': 0.025423728813559324,\n",
       " 'feasibility': 0.00847457627118644,\n",
       " 'feasible': 0.025423728813559324,\n",
       " 'feature': 0.025423728813559324,\n",
       " 'features': 0.025423728813559324,\n",
       " 'fig': 0.025423728813559324,\n",
       " 'figure': 0.211864406779661,\n",
       " 'first': 0.025423728813559324,\n",
       " 'fmsaln': 0.00847457627118644,\n",
       " 'follow': 0.00847457627118644,\n",
       " 'followed': 0.025423728813559324,\n",
       " 'following': 0.06779661016949153,\n",
       " 'follows': 0.01694915254237288,\n",
       " 'formal': 0.00847457627118644,\n",
       " 'found': 0.15254237288135594,\n",
       " 'fukunaga': 0.025423728813559324,\n",
       " 'full': 0.00847457627118644,\n",
       " 'fully': 0.00847457627118644,\n",
       " 'function': 0.059322033898305086,\n",
       " 'future': 0.01694915254237288,\n",
       " 'gbyte': 0.00847457627118644,\n",
       " 'general': 0.00847457627118644,\n",
       " 'generated': 0.01694915254237288,\n",
       " 'generating': 0.00847457627118644,\n",
       " 'given': 0.0847457627118644,\n",
       " 'goes': 0.00847457627118644,\n",
       " 'good': 0.05084745762711865,\n",
       " 'gradient': 0.0423728813559322,\n",
       " 'graph': 0.01694915254237288,\n",
       " 'graphically': 0.00847457627118644,\n",
       " 'grow': 0.00847457627118644,\n",
       " 'guaranteed': 0.00847457627118644,\n",
       " 'hand': 0.025423728813559324,\n",
       " 'handle': 0.01694915254237288,\n",
       " 'handwritten': 0.0423728813559322,\n",
       " 'happen': 0.00847457627118644,\n",
       " 'happens': 0.00847457627118644,\n",
       " 'help': 0.00847457627118644,\n",
       " 'hierarchy': 0.00847457627118644,\n",
       " 'high': 0.06779661016949153,\n",
       " 'higher': 0.05084745762711865,\n",
       " 'highest': 0.025423728813559324,\n",
       " 'highly': 0.00847457627118644,\n",
       " 'hold': 0.00847457627118644,\n",
       " 'holds': 0.00847457627118644,\n",
       " 'hospitality': 0.00847457627118644,\n",
       " 'hour': 0.01694915254237288,\n",
       " 'however': 0.07627118644067797,\n",
       " 'human': 0.025423728813559324,\n",
       " 'hundreds': 0.00847457627118644,\n",
       " 'i.': 0.01694915254237288,\n",
       " 'idea': 0.01694915254237288,\n",
       " 'illustrated': 0.00847457627118644,\n",
       " 'illustration': 0.00847457627118644,\n",
       " 'implementation': 0.03389830508474576,\n",
       " 'implies': 0.01694915254237288,\n",
       " 'important': 0.01694915254237288,\n",
       " 'improved': 0.00847457627118644,\n",
       " 'improvements': 0.00847457627118644,\n",
       " 'improving': 0.00847457627118644,\n",
       " 'included': 0.00847457627118644,\n",
       " 'including': 0.01694915254237288,\n",
       " 'indices': 0.025423728813559324,\n",
       " 'information': 0.09322033898305085,\n",
       " 'ing': 0.00847457627118644,\n",
       " 'initial': 0.00847457627118644,\n",
       " 'inspected': 0.00847457627118644,\n",
       " 'inspecting': 0.00847457627118644,\n",
       " 'inspired': 0.00847457627118644,\n",
       " 'instead': 0.0423728813559322,\n",
       " 'integer': 0.00847457627118644,\n",
       " 'intensities': 0.00847457627118644,\n",
       " 'intensive': 0.01694915254237288,\n",
       " 'interest': 0.00847457627118644,\n",
       " 'interested': 0.00847457627118644,\n",
       " 'intermediate': 0.00847457627118644,\n",
       " 'interpolation': 0.00847457627118644,\n",
       " 'interpreted': 0.00847457627118644,\n",
       " 'introduction': 0.00847457627118644,\n",
       " 'inﬂuence': 0.01694915254237288,\n",
       " 'iterating': 0.00847457627118644,\n",
       " 'iteration': 0.01694915254237288,\n",
       " 'iterations': 0.0423728813559322,\n",
       " 'iteratively': 0.01694915254237288,\n",
       " 'judgement': 0.00847457627118644,\n",
       " 'kernel': 0.03389830508474576,\n",
       " 'kernels': 0.01694915254237288,\n",
       " 'kmeans': 0.2542372881355932,\n",
       " 'known': 0.03389830508474576,\n",
       " 'koontz': 0.00847457627118644,\n",
       " 'label': 0.03389830508474576,\n",
       " 'labeled': 0.11016949152542373,\n",
       " 'labeling': 0.1271186440677966,\n",
       " 'labels': 0.06779661016949153,\n",
       " 'laboratory': 0.00847457627118644,\n",
       " 'languages': 0.00847457627118644,\n",
       " 'large': 0.15254237288135594,\n",
       " 'larger': 0.0847457627118644,\n",
       " 'largest': 0.03389830508474576,\n",
       " 'latter': 0.00847457627118644,\n",
       " 'lda': 0.06779661016949153,\n",
       " 'learning': 0.2288135593220339,\n",
       " 'least': 0.03389830508474576,\n",
       " 'leave': 0.03389830508474576,\n",
       " 'left': 0.025423728813559324,\n",
       " 'less': 0.07627118644067797,\n",
       " 'let': 0.01694915254237288,\n",
       " 'letter': 0.00847457627118644,\n",
       " 'letters': 0.09322033898305085,\n",
       " 'level': 0.13559322033898305,\n",
       " 'levels': 0.059322033898305086,\n",
       " 'like': 0.01694915254237288,\n",
       " 'likely': 0.00847457627118644,\n",
       " 'limited': 0.01694915254237288,\n",
       " 'log': 0.00847457627118644,\n",
       " 'loog': 0.00847457627118644,\n",
       " 'look': 0.00847457627118644,\n",
       " 'loop': 0.05084745762711865,\n",
       " 'loops': 0.01694915254237288,\n",
       " 'low': 0.06779661016949153,\n",
       " 'lower': 0.03389830508474576,\n",
       " 'lowresolution': 0.00847457627118644,\n",
       " 'made': 0.0423728813559322,\n",
       " 'magnitude': 0.00847457627118644,\n",
       " 'main': 0.00847457627118644,\n",
       " 'make': 0.01694915254237288,\n",
       " 'many': 0.00847457627118644,\n",
       " 'marcel': 0.00847457627118644,\n",
       " 'marco': 0.00847457627118644,\n",
       " 'matlab': 0.00847457627118644,\n",
       " 'matrices': 0.00847457627118644,\n",
       " 'matrix': 0.03389830508474576,\n",
       " 'maximum': 0.01694915254237288,\n",
       " 'may': 0.1694915254237288,\n",
       " 'mean': 0.0423728813559322,\n",
       " 'meaning': 0.00847457627118644,\n",
       " 'meaningful': 0.01694915254237288,\n",
       " 'means': 0.01694915254237288,\n",
       " 'measure': 0.00847457627118644,\n",
       " 'measured': 0.00847457627118644,\n",
       " 'measuring': 0.00847457627118644,\n",
       " 'medoid': 0.025423728813559324,\n",
       " 'medoids': 0.025423728813559324,\n",
       " 'member': 0.01694915254237288,\n",
       " 'members': 0.00847457627118644,\n",
       " 'memory': 0.00847457627118644,\n",
       " 'merged': 0.00847457627118644,\n",
       " 'might': 0.03389830508474576,\n",
       " 'million': 0.025423728813559324,\n",
       " 'millions': 0.025423728813559324,\n",
       " 'min': 0.00847457627118644,\n",
       " 'minimum': 0.025423728813559324,\n",
       " 'minutes': 0.00847457627118644,\n",
       " 'mnist': 0.09322033898305085,\n",
       " 'modal': 0.1864406779661017,\n",
       " 'modals': 0.00847457627118644,\n",
       " 'mode': 0.2627118644067797,\n",
       " 'moderate': 0.00847457627118644,\n",
       " 'modes': 0.06779661016949153,\n",
       " 'modiﬁed': 0.00847457627118644,\n",
       " 'moltmann': 0.00847457627118644,\n",
       " 'moreover': 0.05084745762711865,\n",
       " 'much': 0.01694915254237288,\n",
       " 'multi': 0.09322033898305085,\n",
       " 'multiple': 0.025423728813559324,\n",
       " 'mutual': 0.06779661016949153,\n",
       " 'name': 0.025423728813559324,\n",
       " 'named': 0.00847457627118644,\n",
       " 'narrow': 0.00847457627118644,\n",
       " 'natural': 0.00847457627118644,\n",
       " 'nearest': 0.15254237288135594,\n",
       " 'need': 0.025423728813559324,\n",
       " 'needed': 0.0847457627118644,\n",
       " 'needs': 0.01694915254237288,\n",
       " 'neglected': 0.00847457627118644,\n",
       " 'negligible': 0.01694915254237288,\n",
       " 'neighbor': 0.07627118644067797,\n",
       " 'neighborhood': 0.19491525423728814,\n",
       " 'neighborhoods': 0.00847457627118644,\n",
       " 'neighboring': 0.01694915254237288,\n",
       " 'neighbors': 0.0847457627118644,\n",
       " 'nested': 0.05084745762711865,\n",
       " 'nesting': 0.03389830508474576,\n",
       " 'nevertheless': 0.00847457627118644,\n",
       " 'new': 0.00847457627118644,\n",
       " 'next': 0.09322033898305085,\n",
       " 'ni': 0.03389830508474576,\n",
       " 'nmi': 0.025423728813559324,\n",
       " 'noise': 0.00847457627118644,\n",
       " 'noisy': 0.00847457627118644,\n",
       " 'non': 0.01694915254237288,\n",
       " 'normalized': 0.11016949152542373,\n",
       " 'note': 0.00847457627118644,\n",
       " 'number': 0.22033898305084745,\n",
       " 'numbers': 0.0847457627118644,\n",
       " 'o.': 0.0423728813559322,\n",
       " 'object': 0.23728813559322035,\n",
       " 'objects': 1.0,\n",
       " 'observation': 0.00847457627118644,\n",
       " 'observations': 0.00847457627118644,\n",
       " 'observed': 0.025423728813559324,\n",
       " 'obtain': 0.025423728813559324,\n",
       " 'obtained': 0.11016949152542373,\n",
       " 'obtaining': 0.00847457627118644,\n",
       " 'obviously': 0.00847457627118644,\n",
       " 'often': 0.01694915254237288,\n",
       " 'one': 0.1864406779661017,\n",
       " 'ones': 0.07627118644067797,\n",
       " 'onestep': 0.00847457627118644,\n",
       " 'operation': 0.00847457627118644,\n",
       " 'optimization': 0.00847457627118644,\n",
       " 'option': 0.00847457627118644,\n",
       " 'order': 0.07627118644067797,\n",
       " 'orders': 0.00847457627118644,\n",
       " 'original': 0.1016949152542373,\n",
       " 'originally': 0.00847457627118644,\n",
       " 'originals': 0.03389830508474576,\n",
       " 'otherwise': 0.00847457627118644,\n",
       " 'output': 0.00847457627118644,\n",
       " 'outside': 0.00847457627118644,\n",
       " 'overlapping': 0.025423728813559324,\n",
       " 'oﬀer': 0.00847457627118644,\n",
       " 'pairwise': 0.00847457627118644,\n",
       " 'paper': 0.05084745762711865,\n",
       " 'papers': 0.00847457627118644,\n",
       " 'parallel': 0.00847457627118644,\n",
       " 'parameter': 0.059322033898305086,\n",
       " 'parameters': 0.00847457627118644,\n",
       " 'parametric': 0.00847457627118644,\n",
       " 'participated': 0.00847457627118644,\n",
       " 'particular': 0.00847457627118644,\n",
       " 'particulary': 0.00847457627118644,\n",
       " 'parzen': 0.00847457627118644,\n",
       " 'pattern': 0.00847457627118644,\n",
       " 'per': 0.01694915254237288,\n",
       " 'perform': 0.00847457627118644,\n",
       " 'performance': 0.01694915254237288,\n",
       " 'performances': 0.01694915254237288,\n",
       " 'performed': 0.01694915254237288,\n",
       " 'performs': 0.00847457627118644,\n",
       " 'permissable': 0.00847457627118644,\n",
       " 'pi': 0.03389830508474576,\n",
       " 'pif': 0.00847457627118644,\n",
       " 'pixels': 0.06779661016949153,\n",
       " 'playing': 0.00847457627118644,\n",
       " 'point': 0.00847457627118644,\n",
       " 'pointer': 0.01694915254237288,\n",
       " 'pointers': 0.06779661016949153,\n",
       " 'points': 0.00847457627118644,\n",
       " 'popular': 0.00847457627118644,\n",
       " 'pos': 0.00847457627118644,\n",
       " 'possibilities': 0.03389830508474576,\n",
       " 'possible': 0.01694915254237288,\n",
       " 'practice': 0.00847457627118644,\n",
       " 'practise': 0.00847457627118644,\n",
       " 'predicativist': 0.00847457627118644,\n",
       " 'prediction': 0.00847457627118644,\n",
       " 'prematurely': 0.00847457627118644,\n",
       " 'presented': 0.059322033898305086,\n",
       " 'preset': 0.00847457627118644,\n",
       " 'previous': 0.00847457627118644,\n",
       " 'prime': 0.00847457627118644,\n",
       " 'probability': 0.01694915254237288,\n",
       " 'problem': 0.00847457627118644,\n",
       " 'proc': 0.00847457627118644,\n",
       " 'procedure': 0.3135593220338983,\n",
       " 'procedures': 0.0847457627118644,\n",
       " 'propagated': 0.00847457627118644,\n",
       " 'propagating': 0.00847457627118644,\n",
       " 'properties': 0.01694915254237288,\n",
       " 'property': 0.01694915254237288,\n",
       " 'proportional': 0.00847457627118644,\n",
       " 'proposal': 0.01694915254237288,\n",
       " 'proposals': 0.00847457627118644,\n",
       " 'proposed': 0.0423728813559322,\n",
       " 'prototype': 0.0423728813559322,\n",
       " 'prototypes': 0.01694915254237288,\n",
       " 'public': 0.00847457627118644,\n",
       " 'publicly': 0.00847457627118644,\n",
       " 'purpose': 0.01694915254237288,\n",
       " 'qi': 0.0847457627118644,\n",
       " 'qij': 0.01694915254237288,\n",
       " 'qualities': 0.00847457627118644,\n",
       " 'quality': 0.00847457627118644,\n",
       " 'radials': 0.00847457627118644,\n",
       " 'random': 0.07627118644067797,\n",
       " 'randomly': 0.06779661016949153,\n",
       " 'range': 0.00847457627118644,\n",
       " 'ranging': 0.025423728813559324,\n",
       " 'rank': 0.01694915254237288,\n",
       " 'ranked': 0.00847457627118644,\n",
       " 'rate': 0.01694915254237288,\n",
       " 'rates': 0.00847457627118644,\n",
       " 'rationale': 0.00847457627118644,\n",
       " 'reached': 0.01694915254237288,\n",
       " 'real': 0.01694915254237288,\n",
       " 'realized': 0.00847457627118644,\n",
       " 'really': 0.00847457627118644,\n",
       " 'reason': 0.00847457627118644,\n",
       " 'reasoning': 0.00847457627118644,\n",
       " 'recall': 0.00847457627118644,\n",
       " 'receive': 0.025423728813559324,\n",
       " 'recognition': 0.00847457627118644,\n",
       " 'recomputation': 0.00847457627118644,\n",
       " 'recomputed': 0.00847457627118644,\n",
       " 'reduce': 0.01694915254237288,\n",
       " 'reduced': 0.00847457627118644,\n",
       " 'refer': 0.01694915254237288,\n",
       " 'regions': 0.00847457627118644,\n",
       " 'reinders': 0.00847457627118644,\n",
       " 'reject': 0.059322033898305086,\n",
       " 'rejected': 0.00847457627118644,\n",
       " 'rejecting': 0.01694915254237288,\n",
       " 'rejects': 0.01694915254237288,\n",
       " 'relate': 0.00847457627118644,\n",
       " 'related': 0.03389830508474576,\n",
       " 'relative': 0.00847457627118644,\n",
       " 'remainder': 0.01694915254237288,\n",
       " 'remaining': 0.00847457627118644,\n",
       " 'remove': 0.00847457627118644,\n",
       " 'repeat': 0.06779661016949153,\n",
       " 'repeated': 0.025423728813559324,\n",
       " 'repeating': 0.00847457627118644,\n",
       " 'represent': 0.00847457627118644,\n",
       " 'representation': 0.00847457627118644,\n",
       " 'representative': 0.00847457627118644,\n",
       " 'represented': 0.0423728813559322,\n",
       " 'resolution': 0.059322033898305086,\n",
       " 'resolutions': 0.03389830508474576,\n",
       " 'restarts': 0.00847457627118644,\n",
       " 'restricted': 0.01694915254237288,\n",
       " 'result': 0.05084745762711865,\n",
       " 'resulting': 0.07627118644067797,\n",
       " 'results': 0.13559322033898305,\n",
       " 'retrieving': 0.00847457627118644,\n",
       " 'reverse': 0.00847457627118644,\n",
       " 'right': 0.025423728813559324,\n",
       " 'rotated': 0.01694915254237288,\n",
       " 'rounded': 0.00847457627118644,\n",
       " 'row': 0.00847457627118644,\n",
       " 'rule': 0.01694915254237288,\n",
       " 'run': 0.0423728813559322,\n",
       " 'running': 0.00847457627118644,\n",
       " 'runs': 0.00847457627118644,\n",
       " 'sample': 0.00847457627118644,\n",
       " 'save': 0.00847457627118644,\n",
       " 'scale': 0.01694915254237288,\n",
       " 'scaling': 0.00847457627118644,\n",
       " 'scheme': 0.025423728813559324,\n",
       " 'schemes': 0.00847457627118644,\n",
       " 'search': 0.01694915254237288,\n",
       " 'searched': 0.00847457627118644,\n",
       " 'searches': 0.00847457627118644,\n",
       " 'second': 0.01694915254237288,\n",
       " 'seconds': 0.03389830508474576,\n",
       " 'section': 0.1440677966101695,\n",
       " 'sections': 0.00847457627118644,\n",
       " 'see': 0.11016949152542373,\n",
       " 'seek': 0.00847457627118644,\n",
       " 'seeking': 0.23728813559322035,\n",
       " 'seem': 0.00847457627118644,\n",
       " 'seems': 0.00847457627118644,\n",
       " 'seen': 0.00847457627118644,\n",
       " 'select': 0.025423728813559324,\n",
       " 'selected': 0.11016949152542373,\n",
       " 'selecting': 0.00847457627118644,\n",
       " 'selection': 0.01694915254237288,\n",
       " 'semantics': 0.00847457627118644,\n",
       " 'sense': 0.00847457627118644,\n",
       " 'separable': 0.00847457627118644,\n",
       " 'separate': 0.00847457627118644,\n",
       " 'sequential': 0.00847457627118644,\n",
       " 'series': 0.00847457627118644,\n",
       " 'serve': 0.00847457627118644,\n",
       " 'set': 0.3050847457627119,\n",
       " 'sets': 0.03389830508474576,\n",
       " 'setting': 0.01694915254237288,\n",
       " 'seventies': 0.00847457627118644,\n",
       " 'several': 0.025423728813559324,\n",
       " 'shape': 0.025423728813559324,\n",
       " 'shaped': 0.00847457627118644,\n",
       " 'shapes': 0.00847457627118644,\n",
       " 'share': 0.025423728813559324,\n",
       " 'shift': 0.0423728813559322,\n",
       " 'show': 0.01694915254237288,\n",
       " 'showing': 0.00847457627118644,\n",
       " 'shown': 0.07627118644067797,\n",
       " 'shows': 0.0423728813559322,\n",
       " 'si': 0.01694915254237288,\n",
       " 'sible': 0.00847457627118644,\n",
       " 'signiﬁcant': 0.01694915254237288,\n",
       " 'signiﬁcantly': 0.03389830508474576,\n",
       " 'sik': 0.01694915254237288,\n",
       " 'similar': 0.0423728813559322,\n",
       " 'simpler': 0.00847457627118644,\n",
       " 'simultaneously': 0.025423728813559324,\n",
       " 'single': 0.0847457627118644,\n",
       " 'size': 0.1440677966101695,\n",
       " 'sized': 0.00847457627118644,\n",
       " 'sizes': 0.1864406779661017,\n",
       " 'siﬁcation': 0.00847457627118644,\n",
       " 'slightly': 0.01694915254237288,\n",
       " 'slow': 0.025423728813559324,\n",
       " 'slower': 0.00847457627118644,\n",
       " 'slowly': 0.00847457627118644,\n",
       " 'small': 0.1016949152542373,\n",
       " 'smaller': 0.0847457627118644,\n",
       " 'smallest': 0.025423728813559324,\n",
       " 'smooth': 0.00847457627118644,\n",
       " 'software': 0.00847457627118644,\n",
       " 'solution': 0.00847457627118644,\n",
       " 'solved': 0.01694915254237288,\n",
       " 'sometimes': 0.01694915254237288,\n",
       " 'soon': 0.00847457627118644,\n",
       " 'sort': 0.01694915254237288,\n",
       " 'sortj': 0.01694915254237288,\n",
       " 'space': 0.0423728813559322,\n",
       " 'spaces': 0.025423728813559324,\n",
       " 'sparse': 0.00847457627118644,\n",
       " 'special': 0.01694915254237288,\n",
       " 'speed': 0.025423728813559324,\n",
       " 'speedup': 0.01694915254237288,\n",
       " 'spheres': 0.00847457627118644,\n",
       " 'spherical': 0.00847457627118644,\n",
       " 'split': 0.01694915254237288,\n",
       " 'stability': 0.00847457627118644,\n",
       " 'stand': 0.00847457627118644,\n",
       " 'starting': 0.00847457627118644,\n",
       " 'starts': 0.00847457627118644,\n",
       " 'statistical': 0.00847457627118644,\n",
       " 'step': 0.01694915254237288,\n",
       " 'steps': 0.025423728813559324,\n",
       " 'still': 0.00847457627118644,\n",
       " 'stopped': 0.00847457627118644,\n",
       " 'stops': 0.00847457627118644,\n",
       " 'storage': 0.00847457627118644,\n",
       " 'store': 0.05084745762711865,\n",
       " 'stored': 0.059322033898305086,\n",
       " 'storing': 0.00847457627118644,\n",
       " 'structure': 0.0423728813559322,\n",
       " 'studied': 0.03389830508474576,\n",
       " 'study': 0.025423728813559324,\n",
       " 'studying': 0.00847457627118644,\n",
       " 'subsections': 0.00847457627118644,\n",
       " 'subset': 0.05084745762711865,\n",
       " 'subsets': 0.0423728813559322,\n",
       " 'suggesting': 0.00847457627118644,\n",
       " 'suited': 0.00847457627118644,\n",
       " 'sum': 0.00847457627118644,\n",
       " 'summarized': 0.025423728813559324,\n",
       " 'summary': 0.00847457627118644,\n",
       " 'supplied': 0.01694915254237288,\n",
       " 'supplying': 0.00847457627118644,\n",
       " 'support': 0.01694915254237288,\n",
       " 'surprisingly': 0.00847457627118644,\n",
       " 'suﬃcient': 0.00847457627118644,\n",
       " 'suﬃciently': 0.00847457627118644,\n",
       " 'symbols': 0.01694915254237288,\n",
       " 'symmetry': 0.00847457627118644,\n",
       " 'table': 0.059322033898305086,\n",
       " 'takes': 0.00847457627118644,\n",
       " 'target': 0.01694915254237288,\n",
       " 'tax': 0.00847457627118644,\n",
       " 'tend': 0.00847457627118644,\n",
       " 'tering': 0.00847457627118644,\n",
       " 'thank': 0.00847457627118644,\n",
       " 'thereby': 0.1271186440677966,\n",
       " 'therefore': 0.00847457627118644,\n",
       " 'thousands': 0.01694915254237288,\n",
       " 'three': 0.11864406779661017,\n",
       " 'threshold': 0.00847457627118644,\n",
       " 'ti': 0.01694915254237288,\n",
       " 'time': 0.1271186440677966,\n",
       " 'times': 0.07627118644067797,\n",
       " 'together': 0.00847457627118644,\n",
       " 'top': 0.00847457627118644,\n",
       " 'total': 0.05084745762711865,\n",
       " 'traced': 0.00847457627118644,\n",
       " 'traditional': 0.00847457627118644,\n",
       " 'trained': 0.0423728813559322,\n",
       " 'training': 0.09322033898305085,\n",
       " 'tree': 0.00847457627118644,\n",
       " 'trees': 0.00847457627118644,\n",
       " 'true': 0.01694915254237288,\n",
       " 'twice': 0.00847457627118644,\n",
       " 'two': 0.11016949152542373,\n",
       " 'type': 0.00847457627118644,\n",
       " 'uated': 0.00847457627118644,\n",
       " 'uk': 0.025423728813559324,\n",
       " 'uniformly': 0.00847457627118644,\n",
       " 'uniquely': 0.00847457627118644,\n",
       " 'unlabeled': 0.01694915254237288,\n",
       " 'update': 0.01694915254237288,\n",
       " 'updating': 0.01694915254237288,\n",
       " 'us': 0.00847457627118644,\n",
       " 'use': 0.05084745762711865,\n",
       " 'used': 0.3050847457627119,\n",
       " 'useful': 0.00847457627118644,\n",
       " 'user': 0.0423728813559322,\n",
       " 'using': 0.13559322033898305,\n",
       " 'value': 0.01694915254237288,\n",
       " 'values': 0.07627118644067797,\n",
       " 'variability': 0.00847457627118644,\n",
       " 'variable': 0.00847457627118644,\n",
       " 'variants': 0.00847457627118644,\n",
       " 'various': 0.0423728813559322,\n",
       " 'vector': 0.03389830508474576,\n",
       " 'vectors': 0.00847457627118644,\n",
       " 'verify': 0.01694915254237288,\n",
       " 'version': 0.00847457627118644,\n",
       " 'versions': 0.03389830508474576,\n",
       " 'view': 0.00847457627118644,\n",
       " 'vision': 0.00847457627118644,\n",
       " 'way': 0.06779661016949153,\n",
       " 'ways': 0.01694915254237288,\n",
       " 'well': 0.09322033898305085,\n",
       " 'whether': 0.025423728813559324,\n",
       " 'wide': 0.00847457627118644,\n",
       " 'windows': 0.00847457627118644,\n",
       " 'within': 0.00847457627118644,\n",
       " 'without': 0.025423728813559324,\n",
       " 'wonder': 0.00847457627118644,\n",
       " 'world': 0.01694915254237288,\n",
       " 'worse': 0.00847457627118644,\n",
       " 'would': 0.025423728813559324,\n",
       " 'written': 0.00847457627118644,\n",
       " 'xi': 0.06779661016949153,\n",
       " 'yet': 0.00847457627118644,\n",
       " 'yield': 0.025423728813559324,\n",
       " 'zero': 0.00847457627118644,\n",
       " 'zoomed': 0.025423728813559324,\n",
       " 'ηi': 0.00847457627118644,\n",
       " 'ﬁeld': 0.00847457627118644,\n",
       " 'ﬁgure': 0.01694915254237288,\n",
       " 'ﬁgures': 0.03389830508474576,\n",
       " 'ﬁnal': 0.025423728813559324,\n",
       " 'ﬁnding': 0.03389830508474576,\n",
       " 'ﬁve': 0.01694915254237288,\n",
       " 'ﬁxed': 0.00847457627118644}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a signiﬁcantly faster algorithm is presented for the original knn mode seeking procedure.',\n",
       " 'it has the advantages over the well known mean shift algorithm that it is feasible in high dimensional vector spaces and results in uniquely well deﬁned modes.',\n",
       " 'moreover without any additional computational eﬀort it may yield a multi scale hierarchy of clusterings.',\n",
       " 'the time complexity is just o. resulting computing times range from seconds for objects to minutes for objects and to less than an hour for objects.',\n",
       " 'the space complexity is just o. the procedure is well suited for ﬁnding large sets of small clusters and is thereby a candidate to analyze thousands of clusters in millions of objects.',\n",
       " 'the knn mode seeking procedure can be used for active learning by assigning the clusters to the class of the modal objects of the clusters.',\n",
       " 'its feasibility is shown by some examples with up to .',\n",
       " 'million handwritten digits.',\n",
       " 'the obtained classiﬁcation results based on the clusterings are compared with those obtained by the nearest neighbor rule and the support vector classiﬁer based on the same labeled objects for training.',\n",
       " 'it can be concluded that using the clustering structure for classiﬁcation can be signiﬁcantly better than using the trained classiﬁers.',\n",
       " 'a drawback of using the clustering for classiﬁcation however is that no classiﬁer is obtained that may be used for out of sample objects.',\n",
       " 'introduction mode seeking clustering is based on ﬁnding the modes of the estimated probability density function of a given set of objects.',\n",
       " 'for every mode a cluster is deﬁned consisting of all objects for which the density gradient followed from that object arrives at the particular mode.',\n",
       " 'the basic idea can be traced back to two papers by fukunaga et al.',\n",
       " 'in the seventies.',\n",
       " 'in order to be able to handle arbitrarily shaped clusters non parametric density estimates are needed.',\n",
       " 'fukunaga et al.',\n",
       " 'considered the two well known ways parzen kernel densities as well as estimates based on the k nearest neighbors .',\n",
       " 'the kernel density estimate has been studied extensively for mode seeking clustering.',\n",
       " 'it has been made most popular by the mean shift algorithm .',\n",
       " 'this is based on gradient estimates computed from the derivative of the kernel function.',\n",
       " 'for higher dimensionalities iteratively computing and following the gradient is a computationally intensive procedure.',\n",
       " 'moreover the number of restarts that is needed is a multiple of the number of modes.',\n",
       " 'a randomly selected subset of objects is used for starting the gradient searches.',\n",
       " 'the mean shift procedure is particulary useful for low dimensional datasets with a small or moderate number of clusters.',\n",
       " 'an additional problem to be solved is the selection of the kernel.',\n",
       " 'a small one will result in many clusters a large one will combine them and may yield a too smooth result.',\n",
       " 'in practise this may be solved by running the entire procedure for a set of kernels.',\n",
       " 'the knn mode seeking clustering as described in is simpler faster but less accurate than the original proposal by koontz and fukunaga .',\n",
       " 'densities are not exactly computed but are just related to the distance to the k th nearest neighbor.',\n",
       " 'the smaller k the higher the clustering resolution and the more modes are found.',\n",
       " 'gradient steps are deﬁned by setting and following pointers from every object to the one with the highest density in its neighborhood which we will call the modal object .',\n",
       " 'consequently after computing all n n distances between the n objects in a dataset all modes can be found by following the pointers from all objects.',\n",
       " 'the computational eﬀort is negligible compared to the distance computations of the previous step.',\n",
       " 'in it is discussed how to avoid the storage of all distances.',\n",
       " 'a big advantage of the proposal is that diﬀerent clustering resolutions related to a set of neighborhood sizes k can be simultaneously computed without the need of any recomputation.',\n",
       " 'this can be achieved by just the cost of storing multiple pointers which is feasible as the full distance matrix is not stored.',\n",
       " 'the total space complexity is o in which d is the number of features and m is the number of neighborhood sizes.',\n",
       " 'from the application point of view knn mode seeking has the advantage the concept of modal objects has been used in a diﬀerent way outside statistical data analysis in the ﬁeld of natural languages by f. moltmann see a predicativist semantics of modals based on modal objects proc.',\n",
       " 'of the amsterdam colloquium .',\n",
       " 'over the mean shift algorithm that an automatic scaling is included in a k nearest neighbor approach.',\n",
       " 'objects in less dense areas will be related to more distant objects than in high density regions.',\n",
       " 'in the mean shift algorithm kernels have the same shape over the entire vector space.',\n",
       " 'in this paper a fast procedure for knn mode seeking is presented evalin section the fast uated and applied to the labeling of large datasets.',\n",
       " 'algorithm is discussed and it is shown that it approximates the same clusn instead of all n n distances.',\n",
       " 'this is tering by computing just n achieved by constructing a set of overlapping cells by which for every object the number of candidates that might belong to the k nearest neighbors is signiﬁcantly reduced.',\n",
       " 'whether this approximation is appropriate depends on the structure of the data and the type of clusters to be searched and thereby on the application.',\n",
       " 'in section various possibilities of the labeling of a large dataset are considered based on mode seeking clustering.',\n",
       " 'by using the labels of just the modal objects the clustering can be used for labeling all other objects resulting in an active labeling procedure.',\n",
       " 'this classiﬁcation scheme can be improved by using the multi level clustering property of the knn mode seeking procedure that is obtained by almost no additional computational eﬀort.',\n",
       " 'the same structure can be used for including a reject option.',\n",
       " 'the proposed procedures are illustrated and evaluated is section by some of large datasets of handwritten characters ranging from objects to almost million objects.',\n",
       " 'computing times cluster qualities and classiﬁcation performances as a function of the number of labeled objects are measured and graphically shown.',\n",
       " 'conclusions are summarized in the ﬁnal section .',\n",
       " 'the software and some dataset used in this paper are publicly available .',\n",
       " 'fast knn mode seeking algorithm .',\n",
       " 'the original knn mode seeking algorithm in the version of knn mode seeking as described in object densities are deﬁned as the reverse of the distance to the k th nearest neighbor.',\n",
       " 'the below algorithm is used.',\n",
       " 'it is good for very large datasets with n objects.',\n",
       " 'all pairwise distances are needed two times.',\n",
       " 'as n distances cannot be stored they are computed twice.',\n",
       " 'this is done for a set of m neighborhood sizes k in parallel by which nm densities and nm pointers have to be stored.',\n",
       " 'these are used to compute nm cluster indices for m diﬀerent clustering resolutions of the n objects.',\n",
       " '.',\n",
       " 's is the user supplied set of objects with size n. .',\n",
       " 'k is a user deﬁned set of target neighborhood sizes k .',\n",
       " 'i sik.',\n",
       " 'sort them si sortj store density estimates k k f k .',\n",
       " 'repeat for all n objects xi in s .',\n",
       " 'compute its distances dij to all other objects xj in s. .',\n",
       " '.',\n",
       " '.',\n",
       " 'next i .',\n",
       " 'repeat for all n objects xi in s .',\n",
       " 'compute its distances dij to all other objects xj in s. .',\n",
       " 'rank them ti argsortj .',\n",
       " '.',\n",
       " 'next i .',\n",
       " 'repeat for all neighborhood sizes k k .',\n",
       " 'repeat until no change i uk .',\n",
       " '.',\n",
       " 'next k store clustering for neighborhood size k ck in the steps the densities are computed for a set of resolutions deﬁned by k and stored for all objects.',\n",
       " 'the neighborhoods themselves are not stored in this algorithm.',\n",
       " 'they are recomputed in the next loop in order to ﬁnd for every neighborhood size k the objects with the highest densities.',\n",
       " 'the pointers to objects with higher densities are for all resolutions followed in the iteration loop .',\n",
       " 'this ﬁnal loop takes almost no time in comparison with the two other ones.',\n",
       " 'in case the studied neighborhood sizes are small e.g.',\n",
       " 'up to the indices of the neighborhood objects can be stored in the ﬁrst loop.',\n",
       " 'for that case the computing time of the second loop becomes negligible too.',\n",
       " 'as we are interested in larger neighborhood sizes this does not hold for the experiments described in section .',\n",
       " 'the time complexity of this algorithm is at least o as in the ﬁrst loop the distances of all objects to all other ones have to be computed.',\n",
       " 'as they are not stored no use of symmetry can be made.',\n",
       " 'various proposals have been made to speed up the computation of the nearest neighbors e.g.',\n",
       " 'by the use of k d trees.',\n",
       " 'they are especially eﬀective in low dimensional spaces and for an determination of the ﬁrst nearest neighbor.',\n",
       " 'they do not oﬀer a solution for ﬁnding the neighbors in a large neighborhood which is needed to ﬁnd larger clusters.',\n",
       " 'in the remainder of this paper we will refer to this original knn mode seeking algorithm by ms. .',\n",
       " 'the proposed fast knn mode seeking algorithm the original algorithm presented in section .',\n",
       " 'is slow for very large datasets due to its time complexity.',\n",
       " 'every object is compared with every other object.',\n",
       " 'for measuring densities however it is suﬃcient to relate objects just with their neighboring ones.',\n",
       " 'if candidate neighborhood objects could be selected without inspecting them all a speedup would be realized.',\n",
       " 'in a procedure is presented which experimentally appeared to have a time complexity of o. this procedure however is based on a ﬁxed neighborhood size while the advantage of our procedure is that it can handle simultaneously a set of neighborhood sizes.',\n",
       " 'inspired by the result of we developed the following procedure.',\n",
       " 'first a small set p of m n objects is selected e.g.',\n",
       " 'at random.',\n",
       " 'it is not essential that p is a subset of the given dataset s but its feature representation should be in the same domain as s. next the nearest neighbor graph is computed in which every object in s points to its nearest neighbor in p. in this way s is split into m subsets and the space is split into m cells.',\n",
       " 'for this operation nm distance computations are needed.',\n",
       " 'cells contain on the average n m objects but may have diﬀerent sizes.',\n",
       " 'we name this set of non overlapping cells the p cells.',\n",
       " 'for suﬃciently small values of k it is expected that the k nearest neighbors of an object are in the same cell.',\n",
       " 'consequently just n instead of n distances need to be computed in addition to ﬁnd for every object in s its k nearest neighbors.',\n",
       " 'in total this demands thereby at least nm n distance computations .',\n",
       " 'this is n is chosen.',\n",
       " 'the total number of distances that has to minimum if m be computed is thereby at least n n. in every p cell some objects may be close to the cell border and it might thereby happen that some of their k nearest neighbors in the total dataset s are in a neighboring cell and are thereby not considered.',\n",
       " 'in order to reduce the probability that this happens we enlarged the set of candidates deﬁned by all objects that share the same object in p as their nearest neighbor in p and change it to all objects that share the same object in p as belonging to their set of c nearest neighbors.',\n",
       " 'this results in a set of overlapping cells to be called q cells that contain in the order of cn m objects.',\n",
       " 'for every p cell there is a larger q cell that entirely contains the p cell.',\n",
       " 'the neighborhood search in the fast mode seeking procedure will for every object be restricted to the objects in the q cell deﬁned by the pif all q cells would contain exactly this cell to which the object belongs.',\n",
       " 'number of objects the number of distance computations is now minimum cn distance computations.',\n",
       " 'so the for m n .',\n",
       " 'the speed up of the fast time complexity of the fast algorithm is o n algorithm is thereby in the order of n c. cn resulting in at least n a formal description of the algorithm is given below.',\n",
       " 'it follows the same three loops as the algorithm in section .. the ﬁrst two loops however are now restricted to the objects in the q cells instead of all objects.',\n",
       " 'the p set is chosen at random from the available dataset s. .',\n",
       " 's is the user supplied set of objects with size n. .',\n",
       " 'c is the user deﬁned complexity parameter.',\n",
       " '.',\n",
       " 'k is a user deﬁned set of target neighborhood sizes k .',\n",
       " '.',\n",
       " 'select at random a subset p of m .',\n",
       " 'determine for every object in s its c nearest neighbors in p. .',\n",
       " 'construct a set of m p cells of objects in s that have the same object cn objects out of s. in p as their nearest neighbor in p. .',\n",
       " 'construct a set of m q cells of objects in s that share the same object in p in their c nearest neighbors in p. i sik.',\n",
       " 'sort them si sortj store density estimates k k f k .',\n",
       " 'repeat for all n objects xi in s .',\n",
       " 'determine the p cell pi to which xi belongs.',\n",
       " '.',\n",
       " 'determine the q cell qi to which pi belongs.',\n",
       " '.',\n",
       " 'compute all distances dij of xi to all objects xj in qi.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'next i .',\n",
       " 'repeat for all n objects xi in s .',\n",
       " 'determine the p cell pi to which xi belongs.',\n",
       " '.',\n",
       " 'determine the q cell qi to which pi belongs.',\n",
       " '.',\n",
       " 'compute all distances dij of xi to all objects xj in qi.',\n",
       " '.',\n",
       " 'rank them ti argsortj qi store for all k k a pointer uk .',\n",
       " '.',\n",
       " 'next i .',\n",
       " 'repeat for all sizes k k .',\n",
       " 'repeat until no change i uk .',\n",
       " '.',\n",
       " 'next k store clustering for neighborhood size k ck our implementation is for the selection of the subset p slightly more complicated.',\n",
       " 'a fully random choice may result is some very small p cells.',\n",
       " 'this may result in a bad quality of the knn search.',\n",
       " 'for that reason we remove the few p cells that contain less than n objects.',\n",
       " 'in section some real world examples are given comparing the fast algorithm with the original one.',\n",
       " 'in the remainder of this paper we will refer to the fast knn mode seeking by fms or fms c in which c is the value of the complexity parameter.',\n",
       " 'by default c .',\n",
       " 'classifying objects based on knn mode seek ing clustering in this section some ways are described to use knn mode seeking clustering for the classiﬁcation of a large set of unlabeled objects using a small set of labeled ones.',\n",
       " 'the clustering procedure is applied to the entire dataset.',\n",
       " 'in case the objects to be labeled are determined by the clustering this results in active learning.',\n",
       " '.',\n",
       " 'knn mode seeking applied to active learning an important application of knn mode seeking is based on the property that clusters are represented by a single object the modal object.',\n",
       " 'this is the object with the highest estimated density in the corresponding cluster.',\n",
       " 'all other objects in the cluster have a pointer to this one.',\n",
       " 'consequently a fast way of labeling the entire dataset is achieved by labeling the modal objects by a human expert followed by assigning all objects to the class of the modal object of their cluster.',\n",
       " 'this may reduce the cost of labeling considerably.',\n",
       " 'moreover it is expected that the modal objects represent the dataset well.',\n",
       " 'thereby the obtained classiﬁcation may be more accurate than a classiﬁer trained by a randomly selected training set of the same size.',\n",
       " 'the following procedure is used .',\n",
       " 'perform ms or fms clustering on the entire dataset using a set of values for k e.g.',\n",
       " 'k resulting in diﬀerent clusterings ci i .',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'determine the number of clusters ni for every clustering ci.',\n",
       " '.',\n",
       " 'select an appropriate clustering ci w.r.t.',\n",
       " 'the permissable cost of labeling the ni modal objects found for clustering ci i .',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'label the ni modal objects of clustering ci .',\n",
       " '.',\n",
       " 'assign for every cluster in clustering ci all objects to the class of their modal object.',\n",
       " 'this can be considered as a way of active learning.',\n",
       " 'therefore we name the procedure ms al or fms al.',\n",
       " 'there are however some diﬀerences with the traditional active learning procedures as the above algorithm is a onestep procedure.',\n",
       " 'there is no intermediate or ﬁnal classiﬁer computed that is used to select additional objects to be labeled.',\n",
       " 'it seems thereby to be most appropriate for labeling a given dataset as all objects to be labeled are used for estimating the density of these objects.',\n",
       " 'there is no prediction of densities of future not yet seen objects.',\n",
       " 'in the above algorithm several clusterings are found but just a single one is used the one with an appropriate number of clusters.',\n",
       " 'one may wonder whether the other available clusterings cannot be used for improving the classiﬁcation.',\n",
       " 'in the next subsections some possibilities are discussed.',\n",
       " '.',\n",
       " 'knn mode seeking combined with multi level conﬁdence based classiﬁcation in the active learning classiﬁcation procedure as deﬁned above all objects within a cluster receive the same class assignments.',\n",
       " 'the rationale behind it is that a cluster is expected to contain similar objects.',\n",
       " 'in case more objects in a cluster have known labels or class conﬁdences q assigning a cluster average of class conﬁdences to all objects in the cluster follows the same idea qij cij xt cij q here qij is an estimated row vector of class conﬁdences based on cluster cij being cluster j of clustering i. let qi be the n r matrix of the class conﬁdences for the r classes of all n objects and let ai be an n n matrix with ai t t cij if xt cij xt cij otherwise we ranked the clusterings from low resolution to high resolution clusterings.',\n",
       " 'the conﬁdences qi are estimated from the conﬁdences qi of clustering level i with less clusters by averaging the conﬁdences of level i according to the clustering of level i qi ai qi by iterating over all clustering levels conﬁdence estimates can be obtained for all of them from an initial estimate.',\n",
       " 'this can be obtained from the ﬁrst level q by active learning.',\n",
       " 'on this level for every cluster the modal object is selected and labeled.',\n",
       " 'all objects in a cluster are given the same conﬁdence one for the class of the label and zero for all other classes.',\n",
       " 'the described procedure of propagating and averaging conﬁdences is consistent with the active learning procedure in which all objects receive the same class as the modal object.',\n",
       " 'as on higher clustering levels some clusters may contain objects of diﬀerent lower resolution clusters the object conﬁdences may receive contributions of various classes.',\n",
       " 'several alternative updating schemes may be possible for a given a set of clusterings.',\n",
       " 'in playing around with one of the datasets discussed in section the above procedure has been chosen for combining multi level clusterings based on fms or ms for active learning.',\n",
       " 'we name it fms alc or ms alc if based on the ms clustering.',\n",
       " 'the matrix a is large but sparse.',\n",
       " 'in our implementation computations are made cluster by cluster avoiding the need to store a. .',\n",
       " 'reject curves for knn mode seeking classiﬁcation as the active learning classiﬁers ms alc and fms alc output conﬁdences they may be used for rejecting objects with a low conﬁdence of the selected class .',\n",
       " 'in section some examples will be shown.',\n",
       " 'in a sequential active learning scheme objects with a low classiﬁcation conﬁdence might be good candidates for additional labeling.',\n",
       " '.',\n",
       " 'use of kmeans as a baseline procedure a good candidate for a comparative study of the properties of the proposed fms is the classical kmeans procedure .',\n",
       " 'it iteratively ﬁnds a preset number of clusters k by updating cluster means.',\n",
       " 'in order to obtain modal objects to label the clusters the cluster procedure should be extended e.g.',\n",
       " 'by the computation of cluster medoid objects in the clusters that are most close to the cluster means see .',\n",
       " 'in our implementation medoid objects are just used for labeling the clustering is not changed.',\n",
       " 'the total number of distance computations is n if the algorithm runs for η iterations.',\n",
       " 'for large datasets η can be large before stability is reached.',\n",
       " 'in practice the algorithm can be stopped prematurely obtaining an approximate clustering.',\n",
       " 'note that the parameter k has a diﬀerent meaning in the two algorithms kmeans and knn mode seeking.',\n",
       " 'in mode seeking k determines the size of the neighborhood used for setting pointers to objects with a higher density.',\n",
       " 'by following the pointers the total number of modes in the entire dataset may be considerably smaller than n k. the kmeans algorithm on the other hand will result in k clusters .',\n",
       " 'like ms or fms kmeans can be used for active labeling.',\n",
       " 'instead of the modes the medoids are used.',\n",
       " 'if the procedure is run for a number of times using diﬀerent values of k a similar multi level clustering is found as by ms. thereby two diﬀerent classiﬁcation procedures are obtained kmeans al for active learning based on the medoids of a single clustering and kmeans alc if the set of clustering levels is combined.',\n",
       " 'clusters found by the kmeans algorithm have a spherical shape.',\n",
       " 'moreover all spheres have the same size.',\n",
       " 'consequently the cluster medoids are with some noise uniformly distributed over the domain of the dataset.',\n",
       " 'the ms procedure on the other hand ﬁnds clusters for which the shapes follow the shape of the density function around the density modes.',\n",
       " 'in low density areas the clusters are thereby wide in high density areas they are narrow.',\n",
       " 'a signiﬁcant diﬀerence between the two approaches is the computational eﬀort needed for ﬁnding a series of clusterings with diﬀerent numbers of clusters.',\n",
       " 'in ms this is performed in a single run while kmeans needs for every cluster size a new call.',\n",
       " 'moreover the time needed for such a call is proportional with k the desired number of clusters.',\n",
       " 'this implies that kmeans is bad for large numbers of clusters and good for small numbers.',\n",
       " 'by comparing the numbers of distance computations needed for the two cn for fms and n for kmeans procedures n n kmeans has a larger computational see above it shows that for k complexity in case a single clustering with k clusters has to be performed.',\n",
       " 'in this reasoning we neglected the inﬂuence of the complexity parameter c of fms and the number of iterations η used in of kmeans.',\n",
       " 'in case classiﬁcation conﬁdences are to be found multiple clustering are needed some with a high number of clusters.',\n",
       " 'for such applications the time complexity of the kmeans procedure will be soon much larger than of fms.',\n",
       " '.',\n",
       " 'creating a nested set of multi level clusterings for an arbitrary multi level set of clusterings c with ni clusters of clustering ci it is not guaranteed that the levels are nested.',\n",
       " 'they are nested if all objects in a high resolution cluster chj belong to the same low resolution cluster ck with nh n. nested clusterings can be better interpreted.',\n",
       " 'e.g.',\n",
       " 'agglomerative clusterings are automatically nested and can be inspected by a dendrogram.',\n",
       " 'there is an easy top down procedure to make a given multi level clustering nested if the clusters are represented by prototypes like the modal objects in this paper.',\n",
       " 'the following steps are used to change a given lowresolution clustering c into a modiﬁed clustering c which is consistent with a high resolution clustering ch.',\n",
       " '.',\n",
       " 'all objects of all clusters in ch for which the cluster prototypes belong to the same cluster cj are assigned to the same cluster in c j. .',\n",
       " 'if the prototype of cj is a member of c j it becomes the prototype of c j as well.',\n",
       " '.',\n",
       " 'if the prototype of cj is not a member of c j the prototype of the largest constituting cluster in ch becomes the prototype of c j. in our active learning experiments we extended knn mode seeking and kmeans with nesting.',\n",
       " 'the resulting procedures are called ms aln fmsaln and kmeans aln.',\n",
       " 'application to hand written characters in this section experiments will be presented with three related large datasets.',\n",
       " 'they serve as an illustration of the possibilities of knn mode seeking as well as an evaluation of its performance for clustering and active learning.',\n",
       " 'they are selected on the basis of their size in order to show the speed of the algorithms for larger datasets.',\n",
       " '.',\n",
       " 'the datasets we selected three large real world character based datasets and represented them in the same way by their pixels using the same classes.',\n",
       " 'additionally we combined the sets and enlarged the resulting set by including rotated copies of the characters.',\n",
       " 'the tree basic sets are mnist.',\n",
       " 'this is the well known public domain dataset of handwritten digits in about equally sized classes.',\n",
       " 'originally they have the same size of pixels.',\n",
       " 'we normalized them all to pixels using bilinear interpolation by which they can be represented in a dimensional feature space.',\n",
       " 'feature vectors are normalized such that their elements sum to one.',\n",
       " 'see fig.',\n",
       " 'for an arbitrary subset showing the originals as well as the normalized ones.',\n",
       " 'for the purpose of this ﬁgure only all sizes and maximum intensities are made equal.',\n",
       " 'in a leave one out nn experiment a classiﬁcation error of .',\n",
       " 'was found for the original dataset and .',\n",
       " 'for the normalized one.',\n",
       " 'block letters.',\n",
       " 'these are handwritten characters labeled in classes letters digits and some special symbols.',\n",
       " 'the largest class contains characters the smallest one has just characters.',\n",
       " 'the bounding boxes around the characters have diﬀerent sizes ranging from to pixels.',\n",
       " 'we normalized this dataset in the same way as the mnist digits see fig.',\n",
       " 'for examples.',\n",
       " 'in a leave one out nn experiment a classiﬁcation error of .',\n",
       " 'was found.',\n",
       " 'cursive letters.',\n",
       " 'these are handwritten characters labeled in classes letters digits and some special symbols.',\n",
       " 'the largest class contains characters the smallest one has characters.',\n",
       " 'the bounding boxes around the characters have diﬀerent sizes ranging from to pixels.',\n",
       " 'we normalized this dataset in the same way as the mnist digits see fig.',\n",
       " 'for examples.',\n",
       " 'in a leave one out nn experiment a classiﬁcation error of .',\n",
       " 'was found.',\n",
       " 'we also combined the three datasets into a single one called all with objects having the same classes as the block letters.',\n",
       " 'in order to challenge the possibilities of the procedure even further this set is enlarged by a factor by adding rotated versions of all characters over π π and π radials.',\n",
       " 'this dataset named allr has objects still with figure mnist examples originals and normalized to pixels.',\n",
       " 'figure block letters examples originals and normalized to pixels.',\n",
       " 'figure cursive letters examples originals and normalized to pixels.',\n",
       " 'dataset classes objects features mnist block cursive all allr nn error .',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'table summary of the datasets used in the experiments.',\n",
       " 'classes and represented by features.',\n",
       " 'the estimated leave one out nn errors of these two datasets are .',\n",
       " 'and .. the properties of the ﬁve datasets as used by us are summarized in table .',\n",
       " '.',\n",
       " 'clustering the following procedures extensively discussed in the sections and are used in the experiments kmeans the kmeans algorithm as described in .',\n",
       " 'ms the original knn mode seeking algorithm as described in .',\n",
       " 'fms the fast knn mode seeking algorithm as described in .. fms fms and fms stand for the variants with complexity parameters and .',\n",
       " 'in the experiments with the ms procedures the set of neighborhood sizes was chosen such that k .',\n",
       " 'k with k and k n i. n is the number of objects in the dataset.',\n",
       " 'values in k were rounded to integer.',\n",
       " 'for n the size of k is and for n .',\n",
       " 'million it is .',\n",
       " 'first we used the largest dataset allr to verify the speedup that was expected for the fms procedure.',\n",
       " 'a complexity of c was used in the construction of the q cells see section .. computing times for various subsets of the allr dataset are shown in figure .',\n",
       " 'surprisingly it shows that the computing time is o while it was argued in section .',\n",
       " 'that the minimum would be o. our explanation is that smaller datasets have smaller p cells and q cells resulting in smaller matrices used in the distance computation.',\n",
       " 'in our matlab implementation this is less eﬃcient.',\n",
       " 'the clustering of larger datasets can thereby be computed more eﬃciently.',\n",
       " 'in order to study the inﬂuence of the complexity parameter of the fms algorithm it was run on the three smaller datasets mnist block and cursive for c and .',\n",
       " 'results are compared with ms and kmeans.',\n",
       " 'the latter was run for all numbers of clusters that were found by ms. to save computing time of kmeans at the cost of accuracy optimization figure computing time for fms as a function of the dataset size.',\n",
       " 'subsets of the allr datasets were used.',\n",
       " 'the ﬁgure shows that the time complexity is o. iterations have been limited to s for every number of clusters.',\n",
       " 'computing times in seconds on a .',\n",
       " 'ghz hp z pc under windows with gbyte memory are given in table .',\n",
       " 'dataset objects kmeans mnist block cursive all allr ms fms fms fms .',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " 'table computing times in seconds for a set of multi level clusterings see also figure .',\n",
       " 'in figure the numbers of clusters found by ms and fms are shown as a function of the neighborhood parameter k for the three smaller datasets.',\n",
       " 'two observations may be of interest.',\n",
       " 'first the ﬁgures show that the fast procedures fms fms and fms ﬁnd for small neighborhood sizes about the same numbers of clusters as found by the slow original procedure ms. for k the numbers slowly deviate more clusters are found than by ms most likely due to the limited cell sizes by which some clusters cannot be merged.',\n",
       " 'it can be clearly observed that the higher the complexity parameter c the better the fms c curves approximate the ms ones.',\n",
       " 'for k clustering by fms stops as this is about the size of the smallest cells.',\n",
       " 'figure numbers of clusters found for the three datasets by ms and fms.',\n",
       " 'the right ﬁgures are zoomed versions of the ones on the left.',\n",
       " 'a second observation is that the average cluster sizes of the three datasets seem to be diﬀerent.',\n",
       " 'in a combined graph based on the ms curves figure this can be observed better.',\n",
       " 'the block letter dataset has smaller clusters than the cursive letters as it has considerably less objects and is thereby less dense.',\n",
       " 'the even smaller mnist digits dataset has however for k about the same cluster sizes as cursive letters.',\n",
       " 'this might be explained by the lower variability of mnist see figure .',\n",
       " 'figure averaged cluster sizes of the ms procedure for the three smaller datasets.',\n",
       " '.',\n",
       " 'cluster evaluation by the mutual information with true labels the purpose of clustering is to ﬁnd meaningful subsets in the data.',\n",
       " 'whether clusters are meaningful is application dependent but very often it implies that they should make sense for human judgement.',\n",
       " 'in this paper we are thereby using labeled datasets and verify to what extend the obtained clusters correspond with the human class labeling.',\n",
       " 'the measure we use is the below deﬁned normalized mutual information between the cluster labels ηi and the class labels λj i p log i j p pp which is the mutual information.',\n",
       " 'it is normalized to obtain values between and in i min in which h x is the entropy of a discrete random variable x. the values of nmi between the true class labels and the ms and fms clusterings of three datasets is shown in figure .',\n",
       " 'for large numbers of clusters the value of nmi approximates one as small clusters tend to have objects of a single class.',\n",
       " 'kmeans performs similar and often figure clustering evaluation for three datasets based on the normalized mutual information as deﬁned by .',\n",
       " 'the right ﬁgures are zoomed versions of the ones on the left.',\n",
       " 'even better than ms on the basis of this criterion.',\n",
       " 'for larger complexities c results for the proposed fms c are almost similar to those of the much slower original ms algorithm.',\n",
       " 'in figure the evaluation curves of the ﬁve datasets are shown together.',\n",
       " 'they all grow asymptotically to nmi which is obviously the case if the number of clusters equals the size of the dataset.',\n",
       " 'if every object is in a separate cluster the mutual information between the object labels and the clustering is one.',\n",
       " 'the mnist results are better as there are just instead of classes and because these classes are better separable.',\n",
       " 'moreover in general holds that the larger the dataset the lower the curves.',\n",
       " 'see table for dataset sizes.',\n",
       " 'figure clustering evaluation by the normalized mutual information for all datasets based on fms .',\n",
       " '.',\n",
       " 'cluster evaluation by active learning an important application of clustering of large datasets is active learning representative objects to be labeled are found by the structure in the data.',\n",
       " 'in the next step these objects may be used for training a classiﬁer.',\n",
       " 'alternatively the clusters can be used to label the unlabeled objects by the labeled objects in the same cluster.',\n",
       " 'in our experiments the modal objects obtained by ms or fms or the medoid objects determined in the kmeans clusters are used for labeling the other objects in the same cluster.',\n",
       " 'in figure learning curves are presented for the three clustering procedures kmeans ms and fms .',\n",
       " 'they are compared with two lda classiﬁers and the nn rule ms lda using the modal objects of the clusters after retrieving their random lda using a randomly generated training set repeated random nn using a randomly generated training set repeated labels for training.',\n",
       " 'times and averaged.',\n",
       " 'times and averaged.',\n",
       " 'these curves are based on single experiments and look noisy.',\n",
       " 'a number of them those based on ms are deterministic as they are not dependent on a randomly selected subset of objects.',\n",
       " 'so repeating and averaging will figure active learning evaluation for three datasets.',\n",
       " 'ms lda is the lda classiﬁer trained by the modal objects of the clusters.',\n",
       " 'random lda and random nn are trained by a randomly selected training set with the size of the number of clusters on the x axis.',\n",
       " 'the right ﬁgures are zoomed versions of the ones on the left.',\n",
       " 'not help.',\n",
       " 'nevertheless it is clear that the clustering based classiﬁcations are signiﬁcantly better than those obtained by the lda and nn.',\n",
       " 'this can be expected as these classiﬁers depend on the selected objects only while the clustering based classiﬁcations use the entire data structure.',\n",
       " 'an advantage of training a classiﬁer however is that it can be used for future objects while the clustering based classiﬁcation is only applicable to the objects that participated in the clustering.',\n",
       " 'there is a distinction between the two lda classiﬁers suggesting that using a clustering scheme for selecting a training set for a classiﬁer is better than using a randomly selected training set.',\n",
       " 'as was observed for the mutual information in section .',\n",
       " 'it appears that also for active learning the fast algorithm fms c approximates the performance of the original procedure ms for larger complexities see figure .',\n",
       " 'the results of the maximum complexity c studied here are close to the results of ms but their computation is some orders of magnitude faster see section .',\n",
       " 'and table .',\n",
       " 'in figure the learning curves of fms based on the classiﬁcation error are summarized for all datasets.',\n",
       " 'the relative behavior is similar to the mutual information curves in figure .',\n",
       " 'figure active learning evaluation based on fms al compared for all datasets.',\n",
       " 'the kmeans procedure is sometimes better sometimes worse than the ms based procedures.',\n",
       " 'however the computation of learning curves as presented here is highly computational intensive for kmeans as it has to be repeated for all values of k. the mode seeking clustering ms needs just a single run and can be well approximated by the fast fms algorithm see table .',\n",
       " 'recall that the number of distance computations needed for fms is o while it is for kmeans o with η the number of iterations used per update.',\n",
       " 'as we have bounded the computing time per iteration to s it appeared that for small values of nk hundreds of iterations could be used while for large values just one update could be possible.',\n",
       " 'this may have deteriorated the results of kmeans.',\n",
       " 'next we studied the active learning classiﬁcation results of combining all clustering levels as proposed in section .. in figure the original learning curves of ms al are compared with the combined classiﬁers fms alc and and with nesting fms aln.',\n",
       " 'it shows that signiﬁcant improvements could be reached.',\n",
       " 'the fms alc procedure however is slow as for all objects the conﬁdences have to be propagated and averaged over the clustering levels.',\n",
       " 'nesting is fast as it is based on changing cluster indices only.',\n",
       " 'figure active learning evaluation comparing active learning classiﬁcation results based on a single clustering level fms al with the combining the cluster level classiﬁcations fms alc and with nesting fms aln.',\n",
       " '.',\n",
       " 'reject curves the fms alc and kmeans alc classiﬁers yield conﬁdences that may be used for studying reject curves.',\n",
       " 'as an example we considered cases of about clusters found by fms thereby generating training sets of bout objects.',\n",
       " 'all other objects were classiﬁed and results with conﬁdences lower than some threshold were rejected.',\n",
       " 'the classiﬁcation performances of the remaining objects as a function of the rejects rate are shown in figure .',\n",
       " 'the kmeans alc classiﬁer shows better results.',\n",
       " 'its reject curve for the mnist dataset is really good.',\n",
       " 'it starts with rejecting just erroneously classiﬁed objects as for low rejects rates the error curve drops as fast as the reject rate goes up.',\n",
       " 'figure reject curves for the three datasets based on slightly more than labeled objects and conﬁdences computed by fms alc.',\n",
       " 'conclusions the main results of our study are we found a feasible way to ﬁnd density information of datasets of millions of objects in high dimensional spaces.',\n",
       " 'this information is expressed in modal objects and pointers to them for every object in the dataset.',\n",
       " 'the obtained density information is multi scale as it is based on several neighborhood sizes simultaneously.',\n",
       " 'the modal objects can be used to obtain a multi level clustering pos sible thousands of clusters in millions of objects.',\n",
       " 'by labeling the modal objects a good active learning classiﬁer is constructed that is better than classiﬁers trained by randomly selected subsets of the dataset.',\n",
       " 'by combining the classiﬁcation results of various clustering levels clas siﬁcation conﬁdences resulting in better classiﬁers are obtained.',\n",
       " 'the time complexity of the procedure is o resulting in seconds for objects to less than an hour for objects.',\n",
       " 'acknowledgments the authors thank marco loog david tax marcel reinders and the members of the delft pattern recognition laboratory for support and hospitality.',\n",
       " 'prime vision is acknowledged for supplying the datasets block letters and cursive letters.']"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a big advantage of the proposal is that diﬀerent clustering resolutions related to a set of neighborhood sizes k can be simultaneously computed without the need of any recomputation.': 1.6271186440677963,\n",
       " 'a drawback of using the clustering for classiﬁcation however is that no classiﬁer is obtained that may be used for out of sample objects.': 1.61864406779661,\n",
       " 'a fully random choice may result is some very small p cells.': 0.41525423728813565,\n",
       " 'a number of them those based on ms are deterministic as they are not dependent on a randomly selected subset of objects.': 0.7372881355932204,\n",
       " 'a randomly selected subset of objects is used for starting the gradient searches.': 1.5847457627118646,\n",
       " 'a second observation is that the average cluster sizes of the three datasets seem to be diﬀerent.': 1.0084745762711864,\n",
       " 'a signiﬁcant diﬀerence between the two approaches is the computational eﬀort needed for ﬁnding a series of clusterings with diﬀerent numbers of clusters.': 0.6864406779661018,\n",
       " 'a signiﬁcantly faster algorithm is presented for the original knn mode seeking procedure.': 0.9915254237288136,\n",
       " 'a small one will result in many clusters a large one will combine them and may yield a too smooth result.': 1.3220338983050846,\n",
       " 'acknowledgments the authors thank marco loog david tax marcel reinders and the members of the delft pattern recognition laboratory for support and hospitality.': 0.13559322033898308,\n",
       " 'additionally we combined the sets and enlarged the resulting set by including rotated copies of the characters.': 0.5423728813559321,\n",
       " 'agglomerative clusterings are automatically nested and can be inspected by a dendrogram.': 0.21186440677966104,\n",
       " 'algorithm is discussed and it is shown that it approximates the same clusn instead of all n n distances.': 0.4661016949152542,\n",
       " 'all objects in a cluster are given the same conﬁdence one for the class of the label and zero for all other classes.': 1.847457627118644,\n",
       " 'all objects of all clusters in ch for which the cluster prototypes belong to the same cluster cj are assigned to the same cluster in c j. .': 2.516949152542373,\n",
       " 'all other objects in the cluster have a pointer to this one.': 1.3644067796610169,\n",
       " 'all other objects were classiﬁed and results with conﬁdences lower than some threshold were rejected.': 1.3305084745762712,\n",
       " 'all pairwise distances are needed two times.': 0.3050847457627119,\n",
       " 'alternatively the clusters can be used to label the unlabeled objects by the labeled objects in the same cluster.': 2.898305084745763,\n",
       " 'an additional problem to be solved is the selection of the kernel.': 0.0847457627118644,\n",
       " 'and .. the properties of the ﬁve datasets as used by us are summarized in table .': 0.728813559322034,\n",
       " 'and table .': 0.059322033898305086,\n",
       " 'application to hand written characters in this section experiments will be presented with three related large datasets.': 0.7627118644067797,\n",
       " 'as an example we considered cases of about clusters found by fms thereby generating training sets of bout objects.': 0.9067796610169491,\n",
       " 'as n distances cannot be stored they are computed twice.': 0.2627118644067797,\n",
       " 'as on higher clustering levels some clusters may contain objects of diﬀerent lower resolution clusters the object conﬁdences may receive contributions of various classes.': 3.525423728813559,\n",
       " 'as they are not stored no use of symmetry can be made.': 0.11864406779661019,\n",
       " 'as was observed for the mutual information in section .': 0.3305084745762712,\n",
       " 'as we are interested in larger neighborhood sizes this does not hold for the experiments described in section .': 0.7627118644067796,\n",
       " 'assign for every cluster in clustering ci all objects to the class of their modal object.': 2.432203389830508,\n",
       " 'block letters.': 0.06779661016949153,\n",
       " 'by combining the classiﬁcation results of various clustering levels clas siﬁcation conﬁdences resulting in better classiﬁers are obtained.': 1.4067796610169492,\n",
       " 'by default c .': 0.00847457627118644,\n",
       " 'by labeling the modal objects a good active learning classiﬁer is constructed that is better than classiﬁers trained by randomly selected subsets of the dataset.': 2.347457627118644,\n",
       " 'by the computation of cluster medoid objects in the clusters that are most close to the cluster means see .': 2.3389830508474576,\n",
       " 'by the use of k d trees.': 0.05084745762711865,\n",
       " 'by using the labels of just the modal objects the clustering can be used for labeling all other objects resulting in an active labeling procedure.': 3.76271186440678,\n",
       " 'c is the user deﬁned complexity parameter.': 0.31355932203389825,\n",
       " 'cells contain on the average n m objects but may have diﬀerent sizes.': 1.5,\n",
       " 'classes and represented by features.': 0.1440677966101695,\n",
       " 'cluster evaluation by active learning an important application of clustering of large datasets is active learning representative objects to be labeled are found by the structure in the data.': 3.6610169491525424,\n",
       " 'cluster evaluation by the mutual information with true labels the purpose of clustering is to ﬁnd meaningful subsets in the data.': 1.2711864406779658,\n",
       " 'clustering the following procedures extensively discussed in the sections and are used in the experiments kmeans the kmeans algorithm as described in .': 1.9661016949152543,\n",
       " 'clusters found by the kmeans algorithm have a spherical shape.': 1.1101694915254237,\n",
       " 'compute all distances dij of xi to all objects xj in qi.': 2.4915254237288136,\n",
       " 'compute its distances dij to all other objects xj in s. .': 2.3559322033898304,\n",
       " 'computing times cluster qualities and classiﬁcation performances as a function of the number of labeled objects are measured and graphically shown.': 2.1610169491525424,\n",
       " 'computing times in seconds on a .': 0.22033898305084745,\n",
       " 'conclusions are summarized in the ﬁnal section .': 0.211864406779661,\n",
       " 'conclusions the main results of our study are we found a feasible way to ﬁnd density information of datasets of millions of objects in high dimensional spaces.': 2.101694915254237,\n",
       " 'consequently after computing all n n distances between the n objects in a dataset all modes can be found by following the pointers from all objects.': 1.8728813559322035,\n",
       " 'consequently just n instead of n distances need to be computed in addition to ﬁnd for every object in s its k nearest neighbors.': 0.864406779661017,\n",
       " 'consequently the cluster medoids are with some noise uniformly distributed over the domain of the dataset.': 0.45762711864406774,\n",
       " 'considered the two well known ways parzen kernel densities as well as estimates based on the k nearest neighbors .': 1.0593220338983051,\n",
       " 'construct a set of m q cells of objects in s that share the same object in p in their c nearest neighbors in p. i sik.': 1.9661016949152543,\n",
       " 'cursive letters.': 0.06779661016949153,\n",
       " 'dataset classes objects features mnist block cursive all allr nn error .': 1.728813559322034,\n",
       " 'dataset objects kmeans mnist block cursive all allr ms fms fms fms .': 1.805084745762712,\n",
       " 'densities are not exactly computed but are just related to the distance to the k th nearest neighbor.': 0.48305084745762716,\n",
       " 'determine for every object in s its c nearest neighbors in p. .': 0.6864406779661018,\n",
       " 'determine the number of clusters ni for every clustering ci.': 1.4152542372881356,\n",
       " 'determine the p cell pi to which xi belongs.': 0.5423728813559323,\n",
       " 'determine the q cell qi to which pi belongs.': 0.576271186440678,\n",
       " 'even better than ms on the basis of this criterion.': 0.15254237288135594,\n",
       " 'every object is compared with every other object.': 0.6186440677966102,\n",
       " 'fast knn mode seeking algorithm .': 0.9067796610169492,\n",
       " 'feature vectors are normalized such that their elements sum to one.': 0.1610169491525424,\n",
       " 'figure active learning evaluation based on fms al compared for all datasets.': 1.1186440677966103,\n",
       " 'figure averaged cluster sizes of the ms procedure for the three smaller datasets.': 1.2966101694915253,\n",
       " 'figure block letters examples originals and normalized to pixels.': 0.5847457627118644,\n",
       " 'figure clustering evaluation by the normalized mutual information for all datasets based on fms .': 1.6440677966101698,\n",
       " 'figure cursive letters examples originals and normalized to pixels.': 0.5847457627118644,\n",
       " 'figure numbers of clusters found for the three datasets by ms and fms.': 1.288135593220339,\n",
       " 'figure reject curves for the three datasets based on slightly more than labeled objects and conﬁdences computed by fms alc.': 2.4322033898305087,\n",
       " 'first a small set p of m n objects is selected e.g.': 1.542372881355932,\n",
       " 'first we used the largest dataset allr to verify the speedup that was expected for the fms procedure.': 0.7627118644067796,\n",
       " 'fms the fast knn mode seeking algorithm as described in .. fms fms and fms stand for the variants with complexity parameters and .': 1.1610169491525424,\n",
       " 'for an arbitrary subset showing the originals as well as the normalized ones.': 0.3135593220338983,\n",
       " 'for every mode a cluster is deﬁned consisting of all objects for which the density gradient followed from that object arrives at the particular mode.': 2.35593220338983,\n",
       " 'for every p cell there is a larger q cell that entirely contains the p cell.': 0.5169491525423728,\n",
       " 'for higher dimensionalities iteratively computing and following the gradient is a computationally intensive procedure.': 0.3220338983050847,\n",
       " 'for k clustering by fms stops as this is about the size of the smallest cells.': 0.7033898305084746,\n",
       " 'for large datasets η can be large before stability is reached.': 0.6101694915254238,\n",
       " 'for large numbers of clusters the value of nmi approximates one as small clusters tend to have objects of a single class.': 2.5338983050847457,\n",
       " 'for larger complexities c results for the proposed fms c are almost similar to those of the much slower original ms algorithm.': 0.4830508474576271,\n",
       " 'for measuring densities however it is suﬃcient to relate objects just with their neighboring ones.': 1.194915254237288,\n",
       " 'for n the size of k is and for n .': 0.1440677966101695,\n",
       " 'for such applications the time complexity of the kmeans procedure will be soon much larger than of fms.': 0.9745762711864405,\n",
       " 'for suﬃciently small values of k it is expected that the k nearest neighbors of an object are in the same cell.': 0.7033898305084746,\n",
       " 'for that case the computing time of the second loop becomes negligible too.': 0.4067796610169492,\n",
       " 'for that reason we remove the few p cells that contain less than n objects.': 0.288135593220339,\n",
       " 'for the normalized one.': 0.11016949152542373,\n",
       " 'for the purpose of this ﬁgure only all sizes and maximum intensities are made equal.': 0.288135593220339,\n",
       " 'for this operation nm distance computations are needed.': 0.1864406779661017,\n",
       " 'fukunaga et al.': 0.0423728813559322,\n",
       " 'ghz hp z pc under windows with gbyte memory are given in table .': 0.1694915254237288,\n",
       " 'if candidate neighborhood objects could be selected without inspecting them all a speedup would be realized.': 1.4406779661016946,\n",
       " 'if every object is in a separate cluster the mutual information between the object labels and the clustering is one.': 1.745762711864407,\n",
       " 'if the prototype of cj is a member of c j it becomes the prototype of c j as well.': 0.1271186440677966,\n",
       " 'in a combined graph based on the ms curves figure this can be observed better.': 0.6864406779661018,\n",
       " 'in a leave one out nn experiment a classiﬁcation error of .': 1.4745762711864407,\n",
       " 'in a sequential active learning scheme objects with a low classiﬁcation conﬁdence might be good candidates for additional labeling.': 1.9322033898305087,\n",
       " 'in case classiﬁcation conﬁdences are to be found multiple clustering are needed some with a high number of clusters.': 1.4661016949152545,\n",
       " 'in case the objects to be labeled are determined by the clustering this results in active learning.': 2.059322033898305,\n",
       " 'in case the studied neighborhood sizes are small e.g.': 0.576271186440678,\n",
       " 'in figure learning curves are presented for the three clustering procedures kmeans ms and fms .': 1.6016949152542372,\n",
       " 'in figure the evaluation curves of the ﬁve datasets are shown together.': 0.7966101694915255,\n",
       " 'in figure the learning curves of fms based on the classiﬁcation error are summarized for all datasets.': 1.0932203389830508,\n",
       " 'in figure the numbers of clusters found by ms and fms are shown as a function of the neighborhood parameter k for the three smaller datasets.': 1.466101694915254,\n",
       " 'in it is discussed how to avoid the storage of all distances.': 0.05932203389830508,\n",
       " 'in low density areas the clusters are thereby wide in high density areas they are narrow.': 1.0338983050847457,\n",
       " 'in mode seeking k determines the size of the neighborhood used for setting pointers to objects with a higher density.': 2.288135593220339,\n",
       " 'in ms this is performed in a single run while kmeans needs for every cluster size a new call.': 1.076271186440678,\n",
       " 'in order to be able to handle arbitrarily shaped clusters non parametric density estimates are needed.': 0.7627118644067795,\n",
       " 'in order to obtain modal objects to label the clusters the cluster procedure should be extended e.g.': 2.4237288135593222,\n",
       " 'in our implementation computations are made cluster by cluster avoiding the need to store a. .': 0.9406779661016949,\n",
       " 'in our implementation medoid objects are just used for labeling the clustering is not changed.': 2.016949152542373,\n",
       " 'in our matlab implementation this is less eﬃcient.': 0.11864406779661017,\n",
       " 'in practice the algorithm can be stopped prematurely obtaining an approximate clustering.': 0.32203389830508466,\n",
       " 'in practise this may be solved by running the entire procedure for a set of kernels.': 0.8813559322033899,\n",
       " 'in section some examples will be shown.': 0.211864406779661,\n",
       " 'in section some real world examples are given comparing the fast algorithm with the original one.': 0.8644067796610169,\n",
       " 'in section various possibilities of the labeling of a large dataset are considered based on mode seeking clustering.': 1.576271186440678,\n",
       " 'in the above algorithm several clusterings are found but just a single one is used the one with an appropriate number of clusters.': 1.6016949152542372,\n",
       " 'in the experiments with the ms procedures the set of neighborhood sizes was chosen such that k .': 0.8728813559322034,\n",
       " 'in the mean shift algorithm kernels have the same shape over the entire vector space.': 0.4915254237288136,\n",
       " 'in the next step these objects may be used for training a classiﬁer.': 1.6779661016949152,\n",
       " 'in the next subsections some possibilities are discussed.': 0.13559322033898305,\n",
       " 'in the remainder of this paper we will refer to this original knn mode seeking algorithm by ms. .': 0.9576271186440679,\n",
       " 'in this paper a fast procedure for knn mode seeking is presented evalin section the fast uated and applied to the labeling of large datasets.': 1.6610169491525424,\n",
       " 'in this paper we are thereby using labeled datasets and verify to what extend the obtained clusters correspond with the human class labeling.': 1.4576271186440677,\n",
       " 'in this reasoning we neglected the inﬂuence of the complexity parameter c of fms and the number of iterations η used in of kmeans.': 0.8220338983050848,\n",
       " 'in total this demands thereby at least nm n distance computations .': 0.39830508474576276,\n",
       " 'inspired by the result of we developed the following procedure.': 0.13559322033898305,\n",
       " 'instead of the modes the medoids are used.': 0.13559322033898305,\n",
       " 'introduction mode seeking clustering is based on ﬁnding the modes of the estimated probability density function of a given set of objects.': 2.0508474576271185,\n",
       " 'is slow for very large datasets due to its time complexity.': 0.6186440677966102,\n",
       " 'it appears that also for active learning the fast algorithm fms c approximates the performance of the original procedure ms for larger complexities see figure .': 1.7627118644067794,\n",
       " 'it can be clearly observed that the higher the complexity parameter c the better the fms c curves approximate the ms ones.': 0.5508474576271185,\n",
       " 'it can be concluded that using the clustering structure for classiﬁcation can be signiﬁcantly better than using the trained classiﬁers.': 1.2288135593220342,\n",
       " 'it has been made most popular by the mean shift algorithm .': 0.4067796610169492,\n",
       " 'it has the advantages over the well known mean shift algorithm that it is feasible in high dimensional vector spaces and results in uniquely well deﬁned modes.': 1.033898305084746,\n",
       " 'it is good for very large datasets with n objects.': 0.5,\n",
       " 'it iteratively ﬁnds a preset number of clusters k by updating cluster means.': 1.0338983050847457,\n",
       " 'it seems thereby to be most appropriate for labeling a given dataset as all objects to be labeled are used for estimating the density of these objects.': 2.2203389830508473,\n",
       " 'it shows that signiﬁcant improvements could be reached.': 0.1016949152542373,\n",
       " 'it starts with rejecting just erroneously classiﬁed objects as for low rejects rates the error curve drops as fast as the reject rate goes up.': 1.440677966101695,\n",
       " 'its feasibility is shown by some examples with up to .': 0.15254237288135594,\n",
       " 'its reject curve for the mnist dataset is really good.': 0.4491525423728813,\n",
       " 'k is a user deﬁned set of target neighborhood sizes k .': 1.711864406779661,\n",
       " 'k resulting in diﬀerent clusterings ci i .': 0.38135593220338987,\n",
       " 'k with k and k n i. n is the number of objects in the dataset.': 1.2372881355932204,\n",
       " 'kmeans performs similar and often figure clustering evaluation for three datasets based on the normalized mutual information as deﬁned by .': 2.194915254237288,\n",
       " 'knn mode seeking combined with multi level conﬁdence based classiﬁcation in the active learning classiﬁcation procedure as deﬁned above all objects within a cluster receive the same class assignments.': 3.864406779661017,\n",
       " 'label the ni modal objects of clustering ci .': 1.8389830508474578,\n",
       " 'like ms or fms kmeans can be used for active labeling.': 0.788135593220339,\n",
       " 'million handwritten digits.': 0.06779661016949153,\n",
       " 'million it is .': 0.025423728813559324,\n",
       " 'moreover all spheres have the same size.': 0.059322033898305086,\n",
       " 'moreover in general holds that the larger the dataset the lower the curves.': 0.4576271186440678,\n",
       " 'moreover it is expected that the modal objects represent the dataset well.': 1.5593220338983051,\n",
       " 'moreover the number of restarts that is needed is a multiple of the number of modes.': 0.6101694915254237,\n",
       " 'moreover the time needed for such a call is proportional with k the desired number of clusters.': 0.5254237288135593,\n",
       " 'moreover without any additional computational eﬀort it may yield a multi scale hierarchy of clusterings.': 0.5169491525423728,\n",
       " 'ms lda is the lda classiﬁer trained by the modal objects of the clusters.': 1.4491525423728813,\n",
       " 'ms the original knn mode seeking algorithm as described in .': 0.9406779661016951,\n",
       " 'nesting is fast as it is based on changing cluster indices only.': 0.8135593220338984,\n",
       " 'nevertheless it is clear that the clustering based classiﬁcations are signiﬁcantly better than those obtained by the lda and nn.': 1.1525423728813562,\n",
       " 'next i .': 0.3728813559322034,\n",
       " 'next k store clustering for neighborhood size k ck in the steps the densities are computed for a set of resolutions deﬁned by k and stored for all objects.': 1.7203389830508473,\n",
       " 'next k store clustering for neighborhood size k ck our implementation is for the selection of the subset p slightly more complicated.': 1.1271186440677965,\n",
       " 'note that the parameter k has a diﬀerent meaning in the two algorithms kmeans and knn mode seeking.': 0.8305084745762712,\n",
       " 'number of objects the number of distance computations is now minimum cn distance computations.': 1.7457627118644068,\n",
       " 'objects in less dense areas will be related to more distant objects than in high density regions.': 2.3728813559322033,\n",
       " 'of the amsterdam colloquium .': 0.01694915254237288,\n",
       " 'on this level for every cluster the modal object is selected and labeled.': 1.1779661016949152,\n",
       " 'one may wonder whether the other available clusterings cannot be used for improving the classiﬁcation.': 0.8644067796610169,\n",
       " 'originally they have the same size of pixels.': 0.15254237288135594,\n",
       " 'over the mean shift algorithm that an automatic scaling is included in a k nearest neighbor approach.': 0.6101694915254237,\n",
       " 'perform ms or fms clustering on the entire dataset using a set of values for k e.g.': 1.3813559322033897,\n",
       " 'prime vision is acknowledged for supplying the datasets block letters and cursive letters.': 0.5593220338983051,\n",
       " 'random lda and random nn are trained by a randomly selected training set with the size of the number of clusters on the x axis.': 1.6271186440677967,\n",
       " 'rank them ti argsortj .': 0.05084745762711865,\n",
       " 'rank them ti argsortj qi store for all k k a pointer uk .': 0.2288135593220339,\n",
       " 'recall that the number of distance computations needed for fms is o while it is for kmeans o with η the number of iterations used per update.': 1.3305084745762712,\n",
       " 'reject curves the fms alc and kmeans alc classiﬁers yield conﬁdences that may be used for studying reject curves.': 1.4152542372881358,\n",
       " 'repeat for all n objects xi in s .': 4.542372881355932,\n",
       " 'repeat for all neighborhood sizes k k .': 0.4491525423728814,\n",
       " 'repeat for all sizes k k .': 0.2542372881355932,\n",
       " 'repeat until no change i uk .': 0.2542372881355932,\n",
       " 'results are compared with ms and kmeans.': 0.19491525423728814,\n",
       " 's is the user supplied set of objects with size n. .': 3.016949152542373,\n",
       " 'see fig.': 0.11016949152542373,\n",
       " 'see table for dataset sizes.': 0.4406779661016949,\n",
       " 'select an appropriate clustering ci w.r.t.': 0.6440677966101694,\n",
       " 'select at random a subset p of m .': 0.15254237288135594,\n",
       " 'several alternative updating schemes may be possible for a given a set of clusterings.': 0.6355932203389831,\n",
       " 'so repeating and averaging will figure active learning evaluation for three datasets.': 0.8813559322033898,\n",
       " 'sort them si sortj store density estimates k k f k .': 0.5932203389830509,\n",
       " 'subsets of the allr datasets were used.': 0.38983050847457623,\n",
       " 'surprisingly it shows that the computing time is o while it was argued in section .': 0.4406779661016949,\n",
       " 'table computing times in seconds for a set of multi level clusterings see also figure .': 1.296610169491525,\n",
       " 'table summary of the datasets used in the experiments.': 0.6694915254237288,\n",
       " 'that the minimum would be o. our explanation is that smaller datasets have smaller p cells and q cells resulting in smaller matrices used in the distance computation.': 1.4322033898305087,\n",
       " 'the basic idea can be traced back to two papers by fukunaga et al.': 0.211864406779661,\n",
       " 'the below algorithm is used.': 0.2711864406779661,\n",
       " 'the block letter dataset has smaller clusters than the cursive letters as it has considerably less objects and is thereby less dense.': 2.3220338983050843,\n",
       " 'the bounding boxes around the characters have diﬀerent sizes ranging from to pixels.': 0.9830508474576273,\n",
       " 'the classiﬁcation performances of the remaining objects as a function of the rejects rate are shown in figure .': 1.6016949152542375,\n",
       " 'the clustering of larger datasets can thereby be computed more eﬃciently.': 1.135593220338983,\n",
       " 'the clustering procedure is applied to the entire dataset.': 0.923728813559322,\n",
       " 'the computational eﬀort is negligible compared to the distance computations of the previous step.': 0.34745762711864403,\n",
       " 'the datasets we selected three large real world character based datasets and represented them in the same way by their pixels using the same classes.': 1.5932203389830506,\n",
       " 'the described procedure of propagating and averaging conﬁdences is consistent with the active learning procedure in which all objects receive the same class as the modal object.': 2.6779661016949152,\n",
       " 'the estimated leave one out nn errors of these two datasets are .': 0.6779661016949152,\n",
       " 'the even smaller mnist digits dataset has however for k about the same cluster sizes as cursive letters.': 1.2118644067796611,\n",
       " 'the fms alc procedure however is slow as for all objects the conﬁdences have to be propagated and averaged over the clustering levels.': 2.2203389830508473,\n",
       " 'the following procedure is used .': 0.6864406779661016,\n",
       " 'the following steps are used to change a given lowresolution clustering c into a modiﬁed clustering c which is consistent with a high resolution clustering ch.': 2.2542372881355934,\n",
       " 'the kernel density estimate has been studied extensively for mode seeking clustering.': 0.7457627118644068,\n",
       " 'the kmeans alc classiﬁer shows better results.': 0.5932203389830508,\n",
       " 'the kmeans procedure is sometimes better sometimes worse than the ms based procedures.': 0.9830508474576272,\n",
       " 'the knn mode seeking clustering as described in is simpler faster but less accurate than the original proposal by koontz and fukunaga .': 1.372881355932203,\n",
       " 'the knn mode seeking procedure can be used for active learning by assigning the clusters to the class of the modal objects of the clusters.': 3.3389830508474576,\n",
       " 'the largest class contains characters the smallest one has characters.': 0.5169491525423728,\n",
       " 'the largest class contains characters the smallest one has just characters.': 0.5169491525423728,\n",
       " 'the matrix a is large but sparse.': 0.1864406779661017,\n",
       " 'the mean shift procedure is particulary useful for low dimensional datasets with a small or moderate number of clusters.': 1.152542372881356,\n",
       " 'the mnist results are better as there are just instead of classes and because these classes are better separable.': 0.6949152542372882,\n",
       " 'the modal objects can be used to obtain a multi level clustering pos sible thousands of clusters in millions of objects.': 2.754237288135593,\n",
       " 'the ms procedure on the other hand ﬁnds clusters for which the shapes follow the shape of the density function around the density modes.': 1.1864406779661016,\n",
       " 'the neighborhoods themselves are not stored in this algorithm.': 0.06779661016949153,\n",
       " 'the obtained density information is multi scale as it is based on several neighborhood sizes simultaneously.': 1.1271186440677967,\n",
       " 'the p set is chosen at random from the available dataset s. .': 0.7118644067796611,\n",
       " 'the permissable cost of labeling the ni modal objects found for clustering ci i .': 2.1271186440677963,\n",
       " 'the pointers to objects with higher densities are for all resolutions followed in the iteration loop .': 1.3220338983050848,\n",
       " 'the proposed fast knn mode seeking algorithm the original algorithm presented in section .': 1.5254237288135595,\n",
       " 'the proposed procedures are illustrated and evaluated is section by some of large datasets of handwritten characters ranging from objects to almost million objects.': 1.9661016949152543,\n",
       " 'the rationale behind it is that a cluster is expected to contain similar objects.': 0.5,\n",
       " 'the relative behavior is similar to the mutual information curves in figure .': 0.5508474576271186,\n",
       " 'the resulting procedures are called ms aln fmsaln and kmeans aln.': 0.4830508474576271,\n",
       " 'the results of the maximum complexity c studied here are close to the results of ms but their computation is some orders of magnitude faster see section .': 0.847457627118644,\n",
       " 'the right ﬁgures are zoomed versions of the ones on the left.': 0.5847457627118644,\n",
       " 'the same structure can be used for including a reject option.': 0.42372881355932207,\n",
       " 'the smaller k the higher the clustering resolution and the more modes are found.': 0.788135593220339,\n",
       " 'the software and some dataset used in this paper are publicly available .': 0.6694915254237288,\n",
       " 'the time complexity is just o. resulting computing times range from seconds for objects to minutes for objects and to less than an hour for objects.': 2.73728813559322,\n",
       " 'the time complexity of the procedure is o resulting in seconds for objects to less than an hour for objects.': 1.8050847457627117,\n",
       " 'the time complexity of this algorithm is at least o as in the ﬁrst loop the distances of all objects to all other ones have to be computed.': 1.8220338983050848,\n",
       " 'the total number of distance computations is n if the algorithm runs for η iterations.': 0.728813559322034,\n",
       " 'the total space complexity is o in which d is the number of features and m is the number of neighborhood sizes.': 0.9152542372881356,\n",
       " 'the tree basic sets are mnist.': 0.059322033898305086,\n",
       " 'the ﬁgure shows that the time complexity is o. iterations have been limited to s for every number of clusters.': 0.8305084745762711,\n",
       " 'there are however some diﬀerences with the traditional active learning procedures as the above algorithm is a onestep procedure.': 0.8983050847457628,\n",
       " 'there is an easy top down procedure to make a given multi level clustering nested if the clusters are represented by prototypes like the modal objects in this paper.': 2.923728813559322,\n",
       " 'there is no intermediate or ﬁnal classiﬁer computed that is used to select additional objects to be labeled.': 1.593220338983051,\n",
       " 'there is no prediction of densities of future not yet seen objects.': 0.11864406779661019,\n",
       " 'thereby the obtained classiﬁcation may be more accurate than a classiﬁer trained by a randomly selected training set of the same size.': 1.3220338983050848,\n",
       " 'therefore we name the procedure ms al or fms al.': 0.4152542372881356,\n",
       " 'these are handwritten characters labeled in classes letters digits and some special symbols.': 1.0508474576271187,\n",
       " 'these are used to compute nm cluster indices for m diﬀerent clustering resolutions of the n objects.': 1.3898305084745763,\n",
       " 'these curves are based on single experiments and look noisy.': 0.5423728813559322,\n",
       " 'they all grow asymptotically to nmi which is obviously the case if the number of clusters equals the size of the dataset.': 0.9067796610169492,\n",
       " 'they are especially eﬀective in low dimensional spaces and for an determination of the ﬁrst nearest neighbor.': 0.3135593220338983,\n",
       " 'they are nested if all objects in a high resolution cluster chj belong to the same low resolution cluster ck with nh n. nested clusterings can be better interpreted.': 2.322033898305085,\n",
       " 'they are recomputed in the next loop in order to ﬁnd for every neighborhood size k the objects with the highest densities.': 1.7542372881355932,\n",
       " 'they are selected on the basis of their size in order to show the speed of the algorithms for larger datasets.': 0.4915254237288136,\n",
       " 'they do not oﬀer a solution for ﬁnding the neighbors in a large neighborhood which is needed to ﬁnd larger clusters.': 0.652542372881356,\n",
       " 'they serve as an illustration of the possibilities of knn mode seeking as well as an evaluation of its performance for clustering and active learning.': 1.4745762711864407,\n",
       " 'this can be achieved by just the cost of storing multiple pointers which is feasible as the full distance matrix is not stored.': 0.3305084745762712,\n",
       " 'this can be considered as a way of active learning.': 0.3220338983050847,\n",
       " 'this can be expected as these classiﬁers depend on the selected objects only while the clustering based classiﬁcations use the entire data structure.': 2.2033898305084745,\n",
       " 'this can be obtained from the ﬁrst level q by active learning.': 0.4576271186440678,\n",
       " 'this classiﬁcation scheme can be improved by using the multi level clustering property of the knn mode seeking procedure that is obtained by almost no additional computational eﬀort.': 2.1864406779661016,\n",
       " 'this dataset named allr has objects still with figure mnist examples originals and normalized to pixels.': 1.8559322033898302,\n",
       " 'this implies that kmeans is bad for large numbers of clusters and good for small numbers.': 1.1016949152542372,\n",
       " 'this information is expressed in modal objects and pointers to them for every object in the dataset.': 1.7542372881355934,\n",
       " 'this is based on gradient estimates computed from the derivative of the kernel function.': 0.5,\n",
       " 'this is done for a set of m neighborhood sizes k in parallel by which nm densities and nm pointers have to be stored.': 0.847457627118644,\n",
       " 'this is the object with the highest estimated density in the corresponding cluster.': 0.4576271186440678,\n",
       " 'this is the well known public domain dataset of handwritten digits in about equally sized classes.': 0.5508474576271186,\n",
       " 'this may have deteriorated the results of kmeans.': 0.3135593220338983,\n",
       " 'this may reduce the cost of labeling considerably.': 0.34745762711864403,\n",
       " 'this may result in a bad quality of the knn search.': 0.2457627118644068,\n",
       " 'this might be explained by the lower variability of mnist see figure .': 0.5,\n",
       " 'this results in a set of overlapping cells to be called q cells that contain in the order of cn m objects.': 0.9067796610169493,\n",
       " 'this ﬁnal loop takes almost no time in comparison with the two other ones.': 0.3644067796610169,\n",
       " 'times and averaged.': 0.15254237288135594,\n",
       " 'two observations may be of interest.': 0.288135593220339,\n",
       " 'up to the indices of the neighborhood objects can be stored in the ﬁrst loop.': 1.2796610169491527,\n",
       " 'use of kmeans as a baseline procedure a good candidate for a comparative study of the properties of the proposed fms is the classical kmeans procedure .': 1.3728813559322033,\n",
       " 'values in k were rounded to integer.': 0.08474576271186442,\n",
       " 'various proposals have been made to speed up the computation of the nearest neighbors e.g.': 0.39830508474576276,\n",
       " 'was found for the original dataset and .': 0.5254237288135593,\n",
       " 'we also combined the three datasets into a single one called all with objects having the same classes as the block letters.': 1.957627118644068,\n",
       " 'we name it fms alc or ms alc if based on the ms clustering.': 0.4915254237288136,\n",
       " 'we name this set of non overlapping cells the p cells.': 0.5169491525423728,\n",
       " 'we normalized them all to pixels using bilinear interpolation by which they can be represented in a dimensional feature space.': 0.44067796610169485,\n",
       " 'we normalized this dataset in the same way as the mnist digits see fig.': 1.423728813559322,\n",
       " 'whether clusters are meaningful is application dependent but very often it implies that they should make sense for human judgement.': 0.61864406779661,\n",
       " 'whether this approximation is appropriate depends on the structure of the data and the type of clusters to be searched and thereby on the application.': 0.7288135593220338}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['repeat for all n objects xi in s .',\n",
       " 'knn mode seeking combined with multi level conﬁdence based classiﬁcation in the active learning classiﬁcation procedure as deﬁned above all objects within a cluster receive the same class assignments.',\n",
       " 'by using the labels of just the modal objects the clustering can be used for labeling all other objects resulting in an active labeling procedure.',\n",
       " 'cluster evaluation by active learning an important application of clustering of large datasets is active learning representative objects to be labeled are found by the structure in the data.',\n",
       " 'as on higher clustering levels some clusters may contain objects of diﬀerent lower resolution clusters the object conﬁdences may receive contributions of various classes.',\n",
       " 'the knn mode seeking procedure can be used for active learning by assigning the clusters to the class of the modal objects of the clusters.',\n",
       " 's is the user supplied set of objects with size n. .',\n",
       " 'there is an easy top down procedure to make a given multi level clustering nested if the clusters are represented by prototypes like the modal objects in this paper.',\n",
       " 'alternatively the clusters can be used to label the unlabeled objects by the labeled objects in the same cluster.',\n",
       " 'the modal objects can be used to obtain a multi level clustering pos sible thousands of clusters in millions of objects.']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Images and links from PDF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = re.search(r'\\/.+\\.pdf',activePDF).group() #save activePDF's title\n",
    "title = title[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9905014v1.pdf'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputStream = open(activePDF, \"rb\")\n",
    "outputStream = open(\"noText.pdf\", \"wb\")\n",
    "\n",
    "src = PdfFileReader(inputStream)\n",
    "output = PdfFileWriter()\n",
    "\n",
    "[output.addPage(src.getPage(i)) for i in range(src.getNumPages())]\n",
    "#output.removeImages()\n",
    "#output.removeLinks()\n",
    "\n",
    "output.write(outputStream)\n",
    "outputStream.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentance Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_scores = {}\n",
    "\n",
    "for sentence in sentence_tokens:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in wordFreqs.keys():\n",
    "            if len(sentence.split(' ')) <30:\n",
    "                if sentence not in sentence_scores.keys():\n",
    "                    sentence_scores[sentence] = wordFreqs[word]\n",
    "                else:\n",
    "                    sentence_scores[sentence] += wordFreqs[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(This can be reﬁned using a local reward function to express preferences among the diﬀerent states satisfying Ti [8], but we omit this reﬁnement in this paper.)': 2.856643356643357,\n",
       " ', Mk}.': 1.6223776223776225,\n",
       " ', πn}, one for each subtask.': 2.7377622377622375,\n",
       " '.': 3.6503496503496504,\n",
       " '1) in which there are two main sub-tasks: Get the passenger (Get) and Deliver the passenger (Put).': 2.9615384615384617,\n",
       " '1) to the probability transition function of the recursively optimal policy for j.': 1.5244755244755246,\n",
       " '1185–1201, 1994.': 1.6153846153846154,\n",
       " '167–173, Morgan Kaufmann, 1993.': 2.6188811188811187,\n",
       " '2 The MAXQ Framework  Let M be a Markov decision problem with states S, actions A, reward function R(s′|s, a) and probability transition function P (s′|s, a).': 6.657342657342657,\n",
       " '271–278,  San Francisco, CA: Morgan Kaufmann, 1993.': 3.7097902097902096,\n",
       " '3 Conditions for Safe State Abstraction  To motivate state abstraction, consider the simple Taxi Task shown in Figure 1.': 2.458041958041958,\n",
       " '6, no.': 1.6223776223776225,\n",
       " '6, pp.': 1.632867132867133,\n",
       " '8, p. 323, 1992.': 2.6328671328671325,\n",
       " '9 9 9 1   y a M 1 2     ]     G L .': 0.9720279720279721,\n",
       " 'A hierarchical policy is a set of policies π = {π0, .': 1.937062937062937,\n",
       " 'A hierarchical policy is executed using standard procedure-call-and-return semantics, starting with the root task M0 and unfolding recursively until primitive actions are executed.': 2.052447552447552,\n",
       " 'A hierarchical policy is recursively optimal if each policy πi is optimal given the policies of its descendants in the DAG.': 0.9965034965034965,\n",
       " 'An ordered policy is a policy that breaks Q-value ties among actions by preferring the action that comes ﬁrst in some ﬁxed ordering.': 1.034965034965035,\n",
       " 'Analogous arguments apply for leaf irrelevance and V (a, x).': 2.472027972027972,\n",
       " 'Belmont, MA:  Athena Scientiﬁc, 1996.': 2.7027972027972025,\n",
       " 'Category: Reinforcement Learning and Control Preference: Oral  1  Introduction  Most work on hierarchical reinforcement learning has focused on temporal abstraction.': 1.2307692307692308,\n",
       " 'Closely related is the HAM framework, in which the programmer constructs a hierarchy of ﬁnitestate controllers [3].': 1.84965034965035,\n",
       " 'Col., Dept.': 1.6083916083916083,\n",
       " 'Comp.': 1.8251748251748254,\n",
       " 'Comp., vol.': 1.6153846153846154,\n",
       " 'Condition 1: Subtask Irrelevance.': 0.8881118881118881,\n",
       " 'Condition 2: Leaf Irrelevance.': 0.7657342657342658,\n",
       " 'Condition 3: Result Distribution Irrelevance (Undiscounted case.)': 1.5874125874125873,\n",
       " 'Condition 4: Termination.': 0.7552447552447553,\n",
       " 'Condition 5: Shielding.': 0.7447552447552448,\n",
       " 'Consider the Get subtask.': 0.7097902097902098,\n",
       " 'Consider, for example, the Get subroutine under an optimal policy for the taxi task.': 2.8986013986013983,\n",
       " 'Each action is deterministic.': 0.6958041958041958,\n",
       " 'Each controller can include non-deterministic states (where the programmer was not sure what action to perform).': 1.5839160839160837,\n",
       " 'Even a brief consideration of human-level intelligence shows that such methods cannot scale.': 0.6398601398601399,\n",
       " 'Figure 2 shows the performance of ﬂat Q and MAXQ-Q with and without state abstractions on these tasks.': 0.9685314685314685,\n",
       " 'For example, in the Options framework [1, 2], the programmer deﬁnes a set of macro actions (“options”) and provides a policy for each.': 5.0629370629370625,\n",
       " 'For example, in the Taxi task, in all states where the taxi is holding the passenger, the Put subroutine will succeed and result in a terminal state for Root.': 4.199300699300699,\n",
       " 'Hence this form of state abstraction is rarely useful for cumulative discounted reward.)': 1.3601398601398602,\n",
       " 'Hence, the taxi’s initial position is irrelevant to its resulting position.': 1.7867132867132867,\n",
       " 'Hence, they could not provide any formal results for the convergence or performance of their method.': 1.7062937062937062,\n",
       " 'However, little is known about learning with state abstractions, in which aspects of the state space are ignored.': 3.1993006993006996,\n",
       " 'If a navigation action would cause the taxi to hit a wall, the action is a no-op, and there is only the usual reward of −1.': 2.9125874125874125,\n",
       " 'In both of these approaches—and in other studies of hierarchical RL (e.g., [4, 5, 6])—each option or ﬁnite state controller must have access to the entire state space.': 5.1678321678321675,\n",
       " 'In each episode, the taxi starts in a randomly-chosen square.': 1.6958041958041963,\n",
       " 'In our previous work with MAXQ, we brieﬂy discussed state abstractions, and we employed them in our experiments.': 2.909090909090909,\n",
       " 'In previous work, we developed the MAXQ method for hierarchical RL.': 1.7062937062937062,\n",
       " 'In this paper, we deﬁne ﬁve conditions under which state abstraction can be combined with the MAXQ value function decomposition.': 2.1048951048951055,\n",
       " 'Inf.': 0.6083916083916084,\n",
       " 'Learning algorithms (such as semi-Markov Q learning) can then treat these temporally abstract actions as if they were primitives and learn a policy for selecting among them.': 1.8356643356643358,\n",
       " 'Learning rates and Boltzmann cooling rates were separately tuned to optimize the performance of each method.': 0.7622377622377623,\n",
       " 'Let H be a DAG deﬁned over subtasks {M0, .': 1.6818181818181817,\n",
       " 'Let Mi be a subtask of MDP M .': 0.7097902097902098,\n",
       " 'Let Mj be a child task of Mi with the property that whenever Mj terminates, it causes Mi to terminate too.': 1.716783216783217,\n",
       " 'Let {M0, .': 1.632867132867133,\n",
       " 'Let πx be an ordered GLIE exploration policy that is abstract.': 0.7902097902097902,\n",
       " 'Mass., Dept.': 1.6083916083916083,\n",
       " 'Our results apply in both the ﬁnite-horizon undiscounted case and the inﬁnite-horizon discounted case.': 0.6958041958041958,\n",
       " 'P  4 Experimental Results  We implemented MAXQ-Q for a noisy version of the Taxi domain and for Kaelbling’s HDG navigation task [5] using Boltzmann exploration.': 1.062937062937063,\n",
       " 'References  [1] D. Precup and R. S. Sutton, “Multi-time models for temporally abstract planning,”  in NIPS10, The MIT Press, 1998.': 5.048951048951048,\n",
       " 'Right: Task Graph.': 0.7552447552447553,\n",
       " 'Sci., Amherst, MA, 1998.': 3.629370629370629,\n",
       " 'Sci., Boulder, CO, 1998.': 3.629370629370629,\n",
       " 'Sci., Providence, RI, 1998.': 3.629370629370629,\n",
       " 'Similarly, let Q(i, s, j) be the Q value for subtask i of executing child action j in state s and then executing the current policy until termination.': 5.370629370629372,\n",
       " 'Some argue that this can be solved by clever value function approximation methods—and there is some merit in this view.': 0.7657342657342658,\n",
       " 'Such value functions and policies are said to be abstract.': 0.7237762237762239,\n",
       " 'The HAMQ learning algorithm can then be applied to learn a policy for making choices in the non-deterministic states.': 0.9265734265734267,\n",
       " 'The completion function of such subtasks can be represented using a number of values proportional to the number of resulting states.': 0.951048951048951,\n",
       " 'The episode ends when the passenger is deposited at the destination location.': 0.7587412587412588,\n",
       " 'The fact that in some cases the taxi is carrying the passenger and in other cases it is not is irrelevant.': 0.8111888111888113,\n",
       " 'The horizontal axis gives the number of primitive actions executed by each method.': 0.8006993006993007,\n",
       " 'The need for state abstraction is perhaps less obvious.': 0.9335664335664335,\n",
       " 'The next two conditions involve “funnel” actions—macro actions that move the environment from some large number of possible states to a small number of resulting states.': 1.0874125874125875,\n",
       " 'The one exception to this—the Feudal-Q method of Dayan and Hinton [7]— introduced state abstractions in an unsafe way, such that the resulting learning problem was only partially observable.': 2.251748251748252,\n",
       " 'The ordering condition is required to ensure that the recursively optimal policy is unique.': 0.8216783216783218,\n",
       " 'The result is that, when combined with the Termination condition above, we do not need to explicitly represent the completion function for Put at all!': 2.1888111888111887,\n",
       " 'The results show that state abstraction is very important, and in most cases essential, to the eﬀective application of MAXQ-Q learning.': 3.0594405594405596,\n",
       " 'The results show that without state abstractions, MAXQ-Q learning is slower to converge than ﬂat Q learning, but that with state abstraction, it is much faster.': 4.430069930069931,\n",
       " 'The second term is the cost of ﬁnishing subtask i after j is executed (discounted to the time when j is initiated).': 1.902097902097902,\n",
       " 'The subtasks of M must form a DAG with a single “root” node—no subtask may invoke itself directly or indirectly.': 0.8986013986013985,\n",
       " 'The taxi must go to the passenger’s location (the “source”), pick up the passenger, go to the destination location (the “destination”), and put down the passenger there.': 5.905594405594406,\n",
       " 'The temporal abstraction is obvious—for example, Get is a temporally extended action that can take diﬀerent numbers of steps to complete depending on the distance to the target.': 1.884615384615385,\n",
       " 'The termination and shielding cases are easy.': 0.6468531468531469,\n",
       " 'The top level policy (get passenger; deliver passenger) can be expressed very simply with these abstractions.': 1.7342657342657346,\n",
       " 'The vertical axis plots the average of 100 separate runs.': 0.6398601398601399,\n",
       " 'The “goal” of subtask Mi is to move the environment into a state such that Ti is satisﬁed.': 1.0524475524475525,\n",
       " 'The ﬁrst two conditions involve eliminating irrelevant variables within a subtask of the MAXQ decomposition.': 0.8951048951048952,\n",
       " 'Then the completion cost C(i, s, j) = 0 and does not need to be represented.': 3.7447552447552446,\n",
       " 'Then with probability 1, algorithm MAXQ-Q converges to the unique recursively optimal policy for M consistent with H and πx.': 1.9510489510489508,\n",
       " 'Theorem 2 (Convergence with State Abstraction) Let H be a MAXQ task graph that incorporates the ﬁve kinds of state abstractions deﬁned above.': 2.1153846153846154,\n",
       " 'There are four special locations in this world, marked as R(ed), B(lue), G(reen), and Y(ellow).': 7.884615384615383,\n",
       " 'There are two key points in the proof.': 0.6678321678321679,\n",
       " 'There is a passenger at one of the four locations (chosen randomly), and that passenger wishes to be transported to one of the four locations (also chosen randomly).': 3.486013986013986,\n",
       " 'There is a reward of −1 for each action and an additional reward of +20 for successfully delivering the passenger.': 0.8461538461538463,\n",
       " 'There is a reward of −10 if the taxi attempts to execute the Putdown or Pickup actions illegally.': 0.7937062937062938,\n",
       " 'This gives a completely online learning algorithm with wide applicability.': 0.7447552447552448,\n",
       " 'This is a particular kind of funnel action—it funnels all states into terminal states for Mi.': 0.7552447552447553,\n",
       " 'This is because the termination predicate for Put (i.e., that the passenger is at his or her destination location) implies the termination condition for Root (which is the same).': 3.43006993006993,\n",
       " 'This means that C(Root, s, Put) is uniformly zero, for all states s where Put is not terminated.': 4.5174825174825175,\n",
       " 'This means that we do not need to represent C(Root, s, Put) in these states.': 3.5314685314685317,\n",
       " 'This paper has shown that by understanding the reasons that state variables are irrelevant, we can obtain a simple proof of the convergence of MAXQ-Q learning under state abstraction.': 2.3671328671328675,\n",
       " 'This paper solves these problems and in addition compares the eﬀectiveness of MAXQ-Q learning with and without state abstractions.': 1.0104895104895104,\n",
       " 'This permits us to obtain the ﬁrst proof of the convergence of hierarchical RL to an optimal policy in the presence of state abstraction.': 1.1503496503496504,\n",
       " 'This task has a hierarchical structure (see Fig.': 1.111888111888112,\n",
       " 'This task illustrates the need to support both temporal abstraction and state abstraction.': 1.062937062937063,\n",
       " 'To learn the values of C(i, x, j) = Q-learning algorithm needs samples of x′ and N drawn according to P (x′, N |x, j).': 6.818181818181818,\n",
       " 'To prove convergence, we require that the exploration policy executed during learning be an ordered GLIE policy.': 1.9965034965034962,\n",
       " 'We call this second term the completion function, and denote it C(i, s, j).': 4.685314685314685,\n",
       " 'We introduce these state abstractions within the MAXQ framework [8], but the basic ideas are general.': 2.097902097902098,\n",
       " 'We now introduce the ﬁve conditions for state abstraction.': 0.9440559440559442,\n",
       " 'We prove that the MAXQ-Q learning algorithm converges under these conditions and show experimentally that state abstraction is important for the successful application of MAXQ-Q learning.': 1.1958041958041958,\n",
       " 'We will assume that the state s of the MDP is represented as a vector of state variables.': 1.1188811188811187,\n",
       " 'When deciding how to walk from the bedroom to the kitchen, we do not  \\x0cneed to think about the location of our car.': 1.6993006993006992,\n",
       " 'While this subtask is being solved, the destination of the passenger is completely irrelevant—it cannot aﬀect any of the nagivation or pickup decisions.': 1.8251748251748254,\n",
       " 'Without state abstractions, MAXQ requires 14,000 values!': 1.3356643356643356,\n",
       " 'Without state abstractions, any RL method that learns value functions must learn a separate value for each state of the world.': 2.3041958041958046,\n",
       " 'Without this condition, there are potentially many diﬀerent recursively optimal policies with diﬀerent values, depending on how ties are broken within subtasks, subsubtasks, and so on.': 4.867132867132867,\n",
       " '[10] D. P. Bertsekas and J. N. Tsitsiklis, Neuro-Dynamic Programming.': 1.8006993006993008,\n",
       " '[11] T. Jaakkola, M. I. Jordan, and S. P. Singh, “On the convergence of stochastic iterative dynamic programming algorithms,” Neur.': 4.965034965034964,\n",
       " '[2] R. S. Sutton, D. Precup, and S. Singh, “Between MDPs and Semi-MDPs: Learning, planning, and representing knowledge at multiple temporal scales,” tech.': 7.185314685314684,\n",
       " '[3] R. Parr and S. Russell, “Reinforcement learning with hierarchies of machines,” in  NIPS-10, The MIT Press, 1998.': 5.066433566433567,\n",
       " '[4] S. P. Singh, “Transfer of learning by composing solutions of elemental sequential  tasks,” Machine Learning, vol.': 4.132867132867133,\n",
       " '[5] L. P. Kaelbling, “Hierarchical reinforcement learning: Preliminary results,” in Pro ceedings ICML-10, pp.': 4.2027972027972025,\n",
       " '[6] M. Hauskrecht, N. Meuleau, C. Boutilier, L. Kaelbling, and T. Dean, “Hierarchical solution of Markov decision processes using macro-actions,” tech.': 7.013986013986013,\n",
       " '[7] P. Dayan and G. Hinton, “Feudal reinforcement learning,” in NIPS-5, pp.': 4.024475524475525,\n",
       " '[8] T. G. Dietterich, “The MAXQ method for hierarchical reinforcement learning,” in  ICML-15, Morgan Kaufmann, 1998.': 5.115384615384615,\n",
       " '[9] S. Singh, T. Jaakkola, M. L. Littman, and C. Szpesvari, “Convergence results for single-step on-policy reinforcement-learning algorithms,” tech.': 6.003496503496503,\n",
       " 'rep., Brown Univ., Dept.': 2.6188811188811187,\n",
       " 'rep., Univ.': 3.2377622377622375,\n",
       " 'we show how to convert the usual weighted max norm contraction for Q into a weighted max norm contraction for C. This is straightforward, and completes the proof.': 1.737762237762238}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryML = heapq.nlargest(10, sentence_scores, key = sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are four special locations in this world, marked as R(ed), B(lue), G(reen), and Y(ellow).',\n",
       " '[2] R. S. Sutton, D. Precup, and S. Singh, “Between MDPs and Semi-MDPs: Learning, planning, and representing knowledge at multiple temporal scales,” tech.',\n",
       " '[6] M. Hauskrecht, N. Meuleau, C. Boutilier, L. Kaelbling, and T. Dean, “Hierarchical solution of Markov decision processes using macro-actions,” tech.',\n",
       " 'To learn the values of C(i, x, j) = Q-learning algorithm needs samples of x′ and N drawn according to P (x′, N |x, j).',\n",
       " '2 The MAXQ Framework  Let M be a Markov decision problem with states S, actions A, reward function R(s′|s, a) and probability transition function P (s′|s, a).',\n",
       " '[9] S. Singh, T. Jaakkola, M. L. Littman, and C. Szpesvari, “Convergence results for single-step on-policy reinforcement-learning algorithms,” tech.',\n",
       " 'The taxi must go to the passenger’s location (the “source”), pick up the passenger, go to the destination location (the “destination”), and put down the passenger there.',\n",
       " 'Similarly, let Q(i, s, j) be the Q value for subtask i of executing child action j in state s and then executing the current policy until termination.',\n",
       " 'In both of these approaches—and in other studies of hierarchical RL (e.g., [4, 5, 6])—each option or ﬁnite state controller must have access to the entire state space.',\n",
       " '[8] T. G. Dietterich, “The MAXQ method for hierarchical reinforcement learning,” in  ICML-15, Morgan Kaufmann, 1998.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This paper presents the MAXQ approach to hierarchical reinforcement learning\\nbased on decomposing the target Markov decision process (MDP) into a hierarchy\\nof smaller MDPs and decomposing the value function of the target MDP into an\\nadditive combination of the value functions of the smaller MDPs. The paper\\ndefines the MAXQ hierarchy, proves formal results on its representational\\npower, and establishes five conditions for the safe use of state abstractions.\\nThe paper presents an online model-free learning algorithm, MAXQ-Q, and proves\\nthat it converges wih probability 1 to a kind of locally-optimal policy known\\nas a recursively optimal policy, even in the presence of the five kinds of\\nstate abstraction. The paper evaluates the MAXQ representation and MAXQ-Q\\nthrough a series of experiments in three domains and shows experimentally that\\nMAXQ-Q (with state abstractions) converges to a recursively optimal policy much\\nfaster than flat Q learning. The fact that MAXQ learns a representation of the\\nvalue function has an important benefit: it makes it possible to compute and\\nexecute an improved, non-hierarchical policy via a procedure similar to the\\npolicy improvement step of policy iteration. The paper demonstrates the\\neffectiveness of this non-hierarchical execution experimentally. Finally, the\\npaper concludes with a comparison to related work and a discussion of the\\ndesign tradeoffs in hierarchical reinforcement learning.',\n",
       " 'Many researchers have explored methods for hierarchical reinforcement\\nlearning (RL) with temporal abstractions, in which abstract actions are defined\\nthat can perform many primitive actions before terminating. However, little is\\nknown about learning with state abstractions, in which aspects of the state\\nspace are ignored. In previous work, we developed the MAXQ method for\\nhierarchical RL. In this paper, we define five conditions under which state\\nabstraction can be combined with the MAXQ value function decomposition. We\\nprove that the MAXQ-Q learning algorithm converges under these conditions and\\nshow experimentally that state abstraction is important for the successful\\napplication of MAXQ-Q learning.',\n",
       " 'The multiplicative Newton-like method developed by the author et al. is\\nextended to the situation where the dynamics is restricted to the orthogonal\\ngroup. A general framework is constructed without specifying the cost function.\\nThough the restriction to the orthogonal groups makes the problem somewhat\\ncomplicated, an explicit expression for the amount of individual jumps is\\nobtained. This algorithm is exactly second-order-convergent. The global\\ninstability inherent in the Newton method is remedied by a\\nLevenberg-Marquardt-type variation. The method thus constructed can readily be\\napplied to the independent component analysis. Its remarkable performance is\\nillustrated by a numerical simulation.',\n",
       " 'We construct new algorithms from scratch, which use the fourth order cumulant\\nof stochastic variables for the cost function. The multiplicative updating rule\\nhere constructed is natural from the homogeneous nature of the Lie group and\\nhas numerous merits for the rigorous treatment of the dynamics. As one\\nconsequence, the second order convergence is shown. For the cost function,\\nfunctions invariant under the componentwise scaling are choosen. By identifying\\npoints which can be transformed to each other by the scaling, we assume that\\nthe dynamics is in a coset space. In our method, a point can move toward any\\ndirection in this coset. Thus, no prewhitening is required.',\n",
       " 'Given a reference computer, Kolmogorov complexity is a well defined function\\non all binary strings. In the standard approach, however, only the asymptotic\\nproperties of such functions are considered because they do not depend on the\\nreference computer. We argue that this approach can be more useful if it is\\nrefined to include an important practical case of simple binary strings.\\nKolmogorov complexity calculus may be developed for this case if we restrict\\nthe class of available reference computers. The interesting problem is to\\ndefine a class of computers which is restricted in a {\\\\it natural} way modeling\\nthe real-life situation where only a limited class of computers is physically\\navailable to us. We give an example of what such a natural restriction might\\nlook like mathematically, and show that under such restrictions some error\\nterms, even logarithmic in complexity, can disappear from the standard\\ncomplexity calculus.\\n  Keywords: Kolmogorov complexity; Algorithmic information theory.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpusAbstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "for abstract in corpusAbstract:\n",
    "    corpusAbstract[count] = re.sub(r'\\n',' ',abstract)#Get rid of new lines replace with spaces\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing nested parens takes too much of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nested_parens(input_str):\n",
    "    \"\"\"Returns a copy of 'input_str' with any parenthesized text removed. Nested parentheses are handled.\"\"\"\n",
    "    result = ''\n",
    "    paren_level = 0\n",
    "    for ch in input_str:\n",
    "        if ch == '(':\n",
    "            paren_level += 1\n",
    "        elif (ch == ')') and paren_level:\n",
    "            paren_level -= 1\n",
    "        elif not paren_level:\n",
    "            result += ch\n",
    "    return result\n",
    "def remove_nested_brackets(input_str):\n",
    "    result = ''\n",
    "    paren_level = 0\n",
    "    for ch in input_str:\n",
    "        if ch == '[':\n",
    "            paren_level += 1\n",
    "        elif (ch == ']') and paren_level:\n",
    "            paren_level -= 1\n",
    "        elif not paren_level:\n",
    "            result += ch\n",
    "    return result\n",
    "def remove_nested_curlybrackets(input_str):\n",
    "    result = ''\n",
    "    paren_level = 0\n",
    "    for ch in input_str:\n",
    "        if ch == '{':\n",
    "            paren_level += 1\n",
    "        elif (ch == '}') and paren_level:\n",
    "            paren_level -= 1\n",
    "        elif not paren_level:\n",
    "            result += ch\n",
    "    return result\n",
    "\n",
    "cleanedText = remove_nested_parens(cleanedText)\n",
    "#cleanedText = remove_nested_brackets(cleanedText)\n",
    "#cleanedText = remove_nested_curlybrackets(cleanedText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFMiner 3 - No Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "1\n",
      "\n",
      " \n",
      "\n",
      "y\n",
      "a\n",
      "M\n",
      "1\n",
      "2\n",
      "\n",
      " \n",
      "\n",
      " \n",
      " \n",
      "]\n",
      "\n",
      "G\n",
      "L\n",
      ".\n",
      "s\n",
      "c\n",
      "[\n",
      " \n",
      " \n",
      "\n",
      "1\n",
      "v\n",
      "4\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "9\n",
      "9\n",
      "/\n",
      "s\n",
      "c\n",
      ":\n",
      "v\n",
      "i\n",
      "X\n",
      "r\n",
      "a\n",
      "\n",
      "Hierarchical Reinforcement Learning with the MAXQ Value\n",
      "\n",
      "Function Decomposition\n",
      "\n",
      "Thomas G. Dietterich\n",
      "\n",
      "Department of Computer Science\n",
      "\n",
      "Oregon State University\n",
      "\n",
      "Corvallis, OR 97331\n",
      "tgd@cs.orst.edu\n",
      "\n",
      "February 1, 2008\n",
      "\n",
      "Abstract\n",
      "\n",
      "This paper presents a new approach to hierarchical reinforcement learning based on decomposing\n",
      "the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing\n",
      "the value function of the target MDP into an additive combination of the value functions of the\n",
      "smaller MDPs. The decomposition, known as the MAXQ decomposition, has both a procedural\n",
      "semantics—as a subroutine hierarchy—and a declarative semantics—as a representation of the\n",
      "value function of a hierarchical policy. MAXQ uniﬁes and extends previous work on hierar-\n",
      "chical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. It is based on the\n",
      "assumption that the programmer can identify useful subgoals and deﬁne subtasks that achieve\n",
      "these subgoals. By deﬁning such subgoals, the programmer constrains the set of policies that\n",
      "need to be considered during reinforcement learning. The MAXQ value function decomposition\n",
      "can represent the value function of any policy that is consistent with the given hierarchy. The\n",
      "decomposition also creates opportunities to exploit state abstractions, so that individual MDPs\n",
      "within the hierarchy can ignore large parts of the state space. This is important for the practical\n",
      "application of the method. This paper deﬁnes the MAXQ hierarchy, proves formal results on its\n",
      "representational power, and establishes ﬁve conditions for the safe use of state abstractions. The\n",
      "paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges\n",
      "wih probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even\n",
      "in the presence of the ﬁve kinds of state abstraction. The paper evaluates the MAXQ represen-\n",
      "tation and MAXQ-Q through a series of experiments in three domains and shows experimentally\n",
      "that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster\n",
      "than ﬂat Q learning. The fact that MAXQ learns a representation of the value function has an\n",
      "important beneﬁt: it makes it possible to compute and execute an improved, non-hierarchical\n",
      "policy via a procedure similar to the policy improvement step of policy iteration. The paper\n",
      "demonstrates the eﬀectiveness of this non-hierarchical execution experimentally. Finally, the\n",
      "paper concludes with a comparison to related work and a discussion of the design tradeoﬀs in\n",
      "hierarchical reinforcement learning.\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "1 Introduction\n",
      "\n",
      "A central goal of artiﬁcial intelligence is to develop techniques for constructing robust, autonomous\n",
      "agents that are able to achieve good performance in complex, real-world environments. One fruitful\n",
      "line of research views agents from an “economic” perspective (Boutilier, Shoham, & Wellman, 1997):\n",
      "An agent interacts with an environment and receives real-valued rewards and penalties. The agent’s\n",
      "goal is to maximize the total reward it receives. The economic view makes it easy to formalize\n",
      "traditional goals of achievement (“land this airplane”). But it also makes it easy to formulate\n",
      "goals of prevention (“don’t crash into any other airplanes”) and goals of maintenance (“keep the\n",
      "air-traﬃc control system working as long as possible”). Goals of achievement can be represented\n",
      "by giving a positive reward for achieving the goal. Goals of prevention can be represented by\n",
      "giving a negative reward when bad events occur, and goals of maintenance can be represented by\n",
      "giving a positive reward for each time step that the desireable state is maintained. Furthermore,\n",
      "the economic formalism makes it possible to incorporate uncertainty—we can require the agent to\n",
      "maximize the expected value of the total reward in the face of random events in the world.\n",
      "\n",
      "This brief review shows that the economic approach is very expressive—a diﬃcult research chal-\n",
      "lenge, however, is to develop eﬃcient and scalable methods for reasoning, planning, and learning\n",
      "within the economic AI framework. The area of Stochastic Planning studies methods for ﬁnding\n",
      "optimal or near-optimal plans to maximize expected total reward in the case where the agent has\n",
      "complete knowledge of the probabilistic behavior of the environment and the reward function. The\n",
      "basic methods for this case were developed in the 1950s in the ﬁeld of “Dynamic Programming.”\n",
      "Unfortunately, these methods require time polynomial in the number of states in the state space,\n",
      "which makes them prohibitively expensive for most AI problems. Hence, recent research has fo-\n",
      "cused on methods that can exploit structure within the planning problem to work more eﬃciently\n",
      "(Boutilier, Dean, & Hanks, 1999).\n",
      "\n",
      "The area of Reinforcement Learning (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998) stud-\n",
      "ies methods for learning optimal or near-optimal plans by interacting directly with the external\n",
      "environment (as opposed to analyzing a user-provided model of the environment). Again, the basic\n",
      "methods in reinforcement learning are based on dynamic programming algorithms. However, rein-\n",
      "forcement learning methods oﬀer two important advantages over classical dynamic programming.\n",
      "First, the methods are online. This permits them to focus their attention on the parts of the state\n",
      "space that are important and ignore the rest of the space. Second, the methods can employ function\n",
      "approximation algorithms (e.g., neural networks) to represent their knowledge. This allows them\n",
      "to generalize across the state space so that the learning time scales much better.\n",
      "\n",
      "Despite the recent advances in both probabilistic planning and reinforcement learning, there\n",
      "are still many shortcomings. The biggest of these is the lack of a fully satisfactory method for\n",
      "incorporating hierarchies into these algorithms. Research in classical planning has shown that\n",
      "hierarchical methods such as hierarchical task networks (Currie & Tate, 1991), macro actions (Fikes,\n",
      "Hart, & Nilsson, 1972; Korf, 1985), and state abstraction methods (Sacerdoti, 1974; Knoblock,\n",
      "1990) can provide exponential reductions in the computational cost of ﬁnding good plans. However,\n",
      "all of the basic algorithms for probabilistic planning and reinforcement learning are “ﬂat” methods—\n",
      "they treat the state space as one huge ﬂat search space. This means that the paths from the start\n",
      "state to the goal state are very long, and the length of these paths determines the cost of learning\n",
      "and planning, because information about future rewards must be propagated backward along these\n",
      "paths.\n",
      "\n",
      "Many researchers (Singh, 1992a; Lin, 1993; Kaelbling, 1993; Dayan & Hinton, 1993; Hauskrecht,\n",
      "Meuleau, Boutilier, Kaelbling, & Dean, 1998; Parr & Russell, 1998; Sutton, Precup, & Singh, 1998)\n",
      "have experimented with diﬀerent methods of hierarchical reinforcement learning and hierarchical\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "probabilistic planning. This research has explored many diﬀerent points in the design space of\n",
      "hierarchical methods, but several of these systems were designed for speciﬁc situations. We lack\n",
      "crisp deﬁnitions of the main approaches and a clear understanding of the relative merits of the\n",
      "diﬀerent methods.\n",
      "\n",
      "This paper formalizes and clariﬁes one approach and attempts to understand how it compares\n",
      "with the other techniques. The approach, called the MAXQ method, provides a hierarchical decom-\n",
      "position of the given reinforcement learning problem into a set of subproblems. It simultaneously\n",
      "provides a decomposition of the value function for the given problem into a set of value functions\n",
      "for the subproblems. Hence, it has both a declarative semantics (as a value function decomposition)\n",
      "and a procedural semantics (as a subroutine hierarchy).\n",
      "\n",
      "A review of previous research shows that there are several important design decisions that must\n",
      "be made when constructing a hierarchical reinforcement learning system. As a way of providing\n",
      "an overview of the results in this paper, let us review these issues and see how the MAXQ method\n",
      "approaches each of them.\n",
      "\n",
      "The ﬁrst issue is how subtasks should be speciﬁed. Hierarchical reinforcement learning involves\n",
      "breaking the target Markov decision problem into a hierarchy of subproblems or subtasks. There\n",
      "are three general approaches to deﬁning these subtasks. One approach is to deﬁne each subtask\n",
      "in terms of a ﬁxed policy that is provided by the programmer. The “option” method of Sutton,\n",
      "Precup, and Singh (1998) takes this approach. The second approach is to deﬁne each subtask in\n",
      "terms of a non-deterministic ﬁnite-state controller. The Hierarchy of Abstract Machines (HAM)\n",
      "method of Parr and Russell (1998) takes this approach. This method permits the programmer\n",
      "to provide a “partial policy” that constrains the set of permitted actions at each point, but does\n",
      "not specify a complete policy for each subtask. The third approach is to deﬁne each subtask in\n",
      "terms of a termination predicate and a local reward function. These deﬁne what it means for the\n",
      "subtask to be completed and what the ﬁnal reward should be for completing the subtask. The\n",
      "MAXQ method described in this paper follows this approach, building upon previous work by\n",
      "Singh (1992a), Kaelbling (1993), Dayan and Hinton (1993), and Dean and Lin (1995).\n",
      "\n",
      "An advantage of the “option” and partial policy approaches is that the subtask can be deﬁned in\n",
      "terms of an amount of eﬀort or a course of action rather than in terms of achieving a particular goal\n",
      "condition. However, the “option” approach (at least in the simple form described here), requires\n",
      "the programmer to provide complete policies for the subtasks, which can be a diﬃcult programming\n",
      "task in real-world problems. On the other hand, the termination predicate method requires the\n",
      "programmer to guess the relative desirability of the diﬀerent states in which the subtask might\n",
      "terminate. This can also be diﬃcult, although Dean and Lin show how these guesses can be revised\n",
      "automatically by the learning algorithm.\n",
      "\n",
      "A potential drawback of all hierarchical methods is that the learned policy may be suboptimal.\n",
      "The programmer-provided hierarchy constrains the set of possible policies that can be considered. If\n",
      "these constraints are poorly chosen, the resulting policy will be suboptimal. Nonetheless, the learn-\n",
      "ing algorithms that have been developed for the “option” and partial policy approaches guarantee\n",
      "that the learned policy will be the best possible policy consistent with these constraints.\n",
      "\n",
      "The termination predicate method suﬀers from an additional source of suboptimality. The\n",
      "learning algorithm described in this paper converges to a form of local optimality that we call\n",
      "recursive optimality. This means that the policy of each subtask is locally optimal given the policies\n",
      "of its children. But there might exist better hierarchical policies where the policy for a subtask\n",
      "must be locally suboptimal so that the overall policy is optimal. This problem can be avoided by\n",
      "careful deﬁnition of termination predicates and local reward functions, but this is an added burden\n",
      "on the programmer. (It is interesting to note that this problem of recursive optimality has not been\n",
      "noticed previously. This is because previous work focused on subtasks with a single terminal state,\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "and in such cases, the problem does not arise.)\n",
      "\n",
      "The second design issue is whether to employ state abstractions within subtasks. A subtask\n",
      "employs state abstraction if it ignores some aspects of the state of the environment. For example,\n",
      "in many robot navigation problems, choices about what route to take to reach a goal location are\n",
      "independent of what the robot is currently carrying. With few exceptions, state abstraction has\n",
      "not been explored previously. We will see that the MAXQ method creates many opportunities\n",
      "to exploit state abstraction, and that these abstractions can have a huge impact in accelerating\n",
      "learning. We will also see that there is an important design tradeoﬀ: the successful use of state\n",
      "abstraction requires that subtasks be deﬁned in terms of termination predicates rather than using\n",
      "the option or partial policy methods. This is why the MAXQ method must employ termination\n",
      "predicates, despite the problems that this can create.\n",
      "\n",
      "The third design issue concerns the non-hierarchical “execution” of a learned hierarchical pol-\n",
      "icy. Kaelbling (1993) was the ﬁrst to point out that a value function learned from a hierarchical\n",
      "policy could be evaluated incrementally to yield a potentially much better non-hierarchical policy.\n",
      "Dietterich (1998) and Sutton, Singh, Precup, and Ravindran (1999) generalized this to show how\n",
      "arbitrary subroutines could be executed non-hierarchically to yield improved policies. However, in\n",
      "order to support this non-hierarchical execution, extra learning is required. Ordinarily, in hierar-\n",
      "chical reinforcement learning, the only states where learning is required at the higher levels of the\n",
      "hierarchy are states where one or more of the subroutines could terminate (plus all possible initial\n",
      "states). But to support non-hierarchical execution, learning is required in all states (and at all levels\n",
      "of the hierarchy). In general, this requires additional exploration as well as additional computation\n",
      "and memory. As a consequence of the hierarchical decomposition of the value function, the MAXQ\n",
      "method is able to support either form of execution, and we will see that there are many problems\n",
      "where the improvement from non-hierarchical execution is worth the added cost.\n",
      "\n",
      "The fourth and ﬁnal issue is what form of learning algorithm to employ. An important advantage\n",
      "of reinforcement learning algorithms is that they typically operate online. However, ﬁnding online\n",
      "algorithms that work for general hierarchical reinforcement learning has been diﬃcult, particularly\n",
      "within the termination predicate family of methods. Singh’s method relied on each subtask having\n",
      "a unique terminal state; Kaelbling employed a mix of online and batch algorithms to train her\n",
      "hierarchy; and work within the “options” framework usually assumes that the policies for the\n",
      "subproblems are given and do not need to be learned at all. The best previous online algorithms\n",
      "are the HAMQ Q learning algorithm of Parr and Russell (for the partial policy method) and the\n",
      "Feudal Q algorithm of Dayan and Hinton. Unfortunately, the HAMQ method requires “ﬂattening”\n",
      "the hierarchy, and this has several undesirable consequences. The Feudal Q algorithm is tailored\n",
      "to a speciﬁc kind of problem, and it does not converge to any well-deﬁned optimal policy.\n",
      "\n",
      "In this paper, we present a general algorithm, called MAXQ-Q, for fully-online learning of a\n",
      "hierarchical value function. We show experimentally and theoretically that the algorithm converges\n",
      "to a recursively optimal policy. We also show that it is substantially faster than “ﬂat” (i.e., non-\n",
      "hierarchical) Q learning when state abstractions are employed. Without state abstractions, it gives\n",
      "performance similar to (or even worse than) the HAMQ algorithm.\n",
      "\n",
      "The remainder of this paper is organized as follows. After introducing our notation in Section\n",
      "2, we deﬁne the MAXQ value function decomposition in Section 3 and illustrate it with a sim-\n",
      "ple example Markov decision problem. Section 4 presents an analytically tractable version of the\n",
      "MAXQ-Q learning algorithm called the MAXQ-0 algorithm and proves its convergence to a recur-\n",
      "sively optimal policy. It then shows how to extend MAXQ-0 to produce the MAXQ-Q algorithm,\n",
      "and shows how to extend the theorem similarly. Section 5 takes up the issue of state abstraction\n",
      "and formalizes a series of ﬁve conditions under which state abstractions can be safely incorporated\n",
      "into the MAXQ representation. State abstraction can give rise to a hierarchical credit assignment\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "problem, and the paper brieﬂy discusses one solution to this problem. Finally, Section 7 presents\n",
      "experiments with three example domains. These experiments give some idea of the generality of\n",
      "the MAXQ representation. They also provide results on the relative importance of temporal and\n",
      "state abstractions and on the importance of non-hierarchical execution. The paper concludes with\n",
      "further discussion of the design issues that were brieﬂy described above, and in particular, it tackles\n",
      "the question of the tradeoﬀ between the method of deﬁning subtasks (via termination predicates)\n",
      "and the ability to exploit state abstractions.\n",
      "\n",
      "Some readers may be disappointed that MAXQ provides no way of learning the structure of\n",
      "the hierarchy. Our philosophy in developing MAXQ (which we share with other reinforcement\n",
      "learning researchers, notably Parr and Russell) has been to draw inspiration from the development\n",
      "of Belief Networks (Pearl, 1988). Belief networks were ﬁrst introduced as a formalism in which\n",
      "the knowledge engineer would describe the structure of the networks and domain experts would\n",
      "provide the necessary probability estimates. Subsequently, methods were developed for learning\n",
      "the probability values directly from observational data. Most recently, several methods have been\n",
      "developed for learning the structure of the belief networks from data, so that the dependence on\n",
      "the knowledge engineer is reduced.\n",
      "\n",
      "In this paper, we will likewise require that the programmer provide the structure of the hierarchy.\n",
      "The programmer will also need to make several important design decisions. We will see below that\n",
      "a MAXQ representation is very much like a computer program, and we will rely on the programmer\n",
      "to design each of the modules and indicate the permissible ways in which the modules can invoke\n",
      "each other. Our learning algorithms will ﬁll in “implementations” of each module in such a way\n",
      "that the overall program will work well. We believe that this approach will provide a practical tool\n",
      "for solving large real-world MDPs. We also believe that it will help us understand the structure of\n",
      "hierarchical learning algorithms. It is our hope that subsequent research will be able to automate\n",
      "most of the work that we are currently requiring the programmer to do.\n",
      "\n",
      "2 Formal Deﬁnitions\n",
      "\n",
      "2.1 Markov Decision Problems and Semi-Markov Decision Problems\n",
      "\n",
      "We employ the standard deﬁnitions for Markov Decision Problems and Semi-Markov Decision\n",
      "Problems.\n",
      "\n",
      "In this paper, we restrict our attention to situations in which an agent is interacting with a fully-\n",
      "observable stochastic environment. This situation can be modeled as a Markov Decision Problem\n",
      "(MDP) hS, A, P, R, P0i deﬁned as follows:\n",
      "\n",
      "• S: this is the set of states of the environment. At each point in time, the agent can observe\n",
      "\n",
      "the complete state of the environment.\n",
      "\n",
      "• A: this is a ﬁnite set of actions. Technically, the set of available actions depends on the\n",
      "\n",
      "current state s, but we will suppress this dependence in our notation.\n",
      "\n",
      "• P : When an action a ∈ A is performed, the environment makes a probabilistic transition from\n",
      "its current state s to a resulting state s′ according to the probability distribution P (s′|s, a).\n",
      "\n",
      "• R: Similarly, when action a is performed and the environment makes its transition from s\n",
      "to s′, the agent receives a real-valued (possibly stochastic) reward R(s′|s, a). To simplify the\n",
      "notation, it is customary to treat this reward as being given at the time that action a is\n",
      "initiated, even though it may in general depend on s′ as well as on s and a.\n",
      "\n",
      "5\n",
      "\n",
      "\f",
      "• P0: This is the starting state distribution. When the MDP is initialized, it is in state s with\n",
      "\n",
      "probability P0(s).\n",
      "\n",
      "A policy, π, is a mapping from states to actions that tells what action a = π(s) to perform when\n",
      "the environment is in state s.\n",
      "\n",
      "We will consider two settings: Episodic and Inﬁnite-Horizon.\n",
      "In the episodic setting, all rewards are ﬁnite and there is at least one zero-cost absorbing\n",
      "terminal state. An absorbing terminal state is a state in which all actions lead back to the same\n",
      "state with probability 1 and zero reward. We will only consider problems where all deterministic\n",
      "policies are “proper”—that is, all deterministic policies have a non-zero probability of reaching a\n",
      "terminal state when started in an arbitrary state. In this setting, the goal of the agent is to ﬁnd\n",
      "a policy that maximizes the expected cumulative reward. In the special case where all rewards\n",
      "are non-positive, these problems are referred to as stochastic shortest path problems, because the\n",
      "rewards can be viewed as costs (i.e., lengths), and the policy attempts to move the agent along the\n",
      "path of minimum expected cost.\n",
      "\n",
      "In the inﬁnite horizon setting, all rewards are also ﬁnite. In addition, there is a discount factor\n",
      "γ, and the agent’s goal is to ﬁnd a policy that minimizes the inﬁnite discounted sum of future\n",
      "rewards.\n",
      "\n",
      "The value function V π for policy π is a function that tells, for each state s, what the expected\n",
      "cumulative reward will be of executing that policy. Let rt be a random variable that tells the reward\n",
      "that the agent receives at time step t while following policy π. We can deﬁne the value function in\n",
      "the episodic setting as\n",
      "\n",
      "V π(s) = E {rt + rt+1 + rt+2 + · · · |st = t, π} .\n",
      "\n",
      "In the discounted setting, the value function is\n",
      "\n",
      "V π(s) = En rt + γrt+1 + γ2rt+2 + · · ·(cid:12)(cid:12)(cid:12)\n",
      "\n",
      "st = t, πo .\n",
      "\n",
      "We can see that this equation reduces to the previous one when γ = 1. However, in the inﬁnite\n",
      "horizon case, this inﬁnite sum will not converge unless γ < 1.\n",
      "\n",
      "The value function satisﬁes the Bellman equation for a ﬁxed policy:\n",
      "\n",
      "V π(s) = Xs′\n",
      "\n",
      "P (s′|s, π(s))(cid:2)R(s′|s, π(s)) + γV π(s′)(cid:3) .\n",
      "\n",
      "The quantity on the right-hand side is called the backed-up value of performing action a in state s.\n",
      "For each possible successor state s′, it computes the reward that would be received and the value\n",
      "of the resulting state and then weights those according to the probability of ending up in s′.\n",
      "\n",
      "The optimal value function V ∗ is the value function that simultaneously maximizes the expected\n",
      "cumulative reward in all states s ∈ S. Bellman (1957) proved that it is the unique solution to what\n",
      "is now known as the Bellman equation:\n",
      "\n",
      "V ∗(s) = max\n",
      "\n",
      "a Xs′\n",
      "\n",
      "P (s′|s, a)(cid:2)R(s′|s, a) + γV ∗(s′)(cid:3) .\n",
      "\n",
      "(1)\n",
      "\n",
      "There may be many optimal policies that achieve this value. Any policy that chooses a in s to\n",
      "achieve the maximum on the right-hand side of this equation is an optimal policy. We will denote\n",
      "an optimal policy by π∗. Note that all optimal policies are “greedy” with respect to the backed-up\n",
      "value of the available actions.\n",
      "\n",
      "Closely related to the value function is the so-called action-value function, or Q function\n",
      "(Watkins, 1989). This function, Qπ(s, a), gives the expected cumulative reward of performing\n",
      "\n",
      "6\n",
      "\n",
      "\f",
      "action a in state s and then following policy π thereafter. The Q function also satisﬁes a Bellman\n",
      "equation:\n",
      "\n",
      "Qπ(s, a) = Xs′\n",
      "\n",
      "P (s′|s, a)(cid:2)R(s′|s, a) + γQπ(s′, π(s′))(cid:3) .\n",
      "\n",
      "The optimal action-value function is written Q∗(s, a), and it satisﬁes the equation\n",
      "\n",
      "Q∗(s, a) = Xs′\n",
      "\n",
      "P (s′|s, a)(cid:20)R(s′|s, a) + γ max\n",
      "\n",
      "a′\n",
      "\n",
      "Q∗(s′, a′)(cid:21) .\n",
      "\n",
      "(2)\n",
      "\n",
      "Note that any policy that is greedy with respect to Q∗ is an optimal policy. There may be many\n",
      "such optimal policies—they diﬀer only in how they break ties between actions with identical Q∗\n",
      "values.\n",
      "\n",
      "An action order, denoted ω, is a total order over the actions within an MDP. That is, ω is an\n",
      "anti-symmetric, transitive relation such that ω(a1, a2) is true iﬀ a1 is preferred to a2. An ordered\n",
      "greedy policy, πω is a greedy policy that breaks ties using ω. For example, suppose that the two best\n",
      "actions at state s are a1 and a2, that Q(s, a1) = Q(s, a2), and that ω(a1, a2). Then the ordered\n",
      "greedy policy πω will choose a1: πω(s) = a1. Note that although there may be many optimal\n",
      "policies for a given MDP, the ordered greedy policy, π∗\n",
      "\n",
      "ω, is unique.\n",
      "\n",
      "A discrete-time semi-Markov Decision Process (SMDP) is a generalization of the Markov Deci-\n",
      "sion Process in which the actions can take a variable amount of time to complete. In particular, let\n",
      "the random variable N denote the number of time steps that action a takes when it is executed in\n",
      "state s. We can extend the state transition probability function to be the joint distribution of the\n",
      "result states s′ and the number of time steps N when action a is performed in state s: P (s′, N |s, a).\n",
      "Similarly, the reward function can be changed to be R(s′, N |s, a).1\n",
      "\n",
      "It is straightforward to modify the Bellman equation to deﬁne the value function for a ﬁxed\n",
      "\n",
      "policy π as\n",
      "\n",
      "V π(s) = Xs′,N\n",
      "\n",
      "P (s′, N |s, π(s))hR(s′, N |s, π(s)) + γN V π(s′)i .\n",
      "\n",
      "The only change is that the expected value on the right-hand side is taken with respect to both s′\n",
      "and N , and γ is raised to the power N to reﬂect the variable amount of time that may elapse while\n",
      "executing action a.\n",
      "\n",
      "Note that because expectation is a linear operator, we can write each of these Bellman equations\n",
      "as the sum of the expected reward for performing action a and the expected value of the resulting\n",
      "state s. For example, we can rewrite the equation above as\n",
      "\n",
      "V π(s) = R(s, π(s)) + Xs′,N\n",
      "\n",
      "P (s′, N |s, π(s))γN V π(s′).\n",
      "\n",
      "(3)\n",
      "\n",
      "where R(s, π(s)) is the expected reward of performing action π(s) in state s, where the expectation\n",
      "is taken with respect to s′ and N .\n",
      "\n",
      "Note that for the episodic case, there is no diﬀerence between a MDP and a Semi-Markov\n",
      "\n",
      "Decision Process.\n",
      "\n",
      "1This formalization is slightly diﬀerent than the standard formulation of SMDPs, which separates P (s′|s, a) and\n",
      "F (t|s, a), where F is the cumulative distribution function for the probability that a will terminate in t time units,\n",
      "where t is real-valued rather than integer-valued. In our case, it is important to consider the joint distribution of s′\n",
      "and N , but we do not need to consider actions with arbitrary real-valued durations.\n",
      "\n",
      "7\n",
      "\n",
      "\f",
      "2.2 Reinforcement Learning Algorithms\n",
      "\n",
      "A reinforcement learning algorithm is an algorithm that is given access to an unknown MDP via\n",
      "the following reinforcement learning protocol. At each time step t, the algorithm is told the current\n",
      "state s of the MDP and the set of actions A(s) ⊆ A that are executable in that state. The algorithm\n",
      "chooses an action a ∈ A(s), and the MDP executes this action (which causes it to move to state\n",
      "s’) and returns a real-valued reward r. If s is an absorbing terminal state, the set of actions A(s)\n",
      "contains only the special action reset, which causes the MDP to move to one of its initial states,\n",
      "drawn according to P0.\n",
      "\n",
      "The learning algorithm is evaluated based on its observed cumulative reward. The cumulative\n",
      "reward of a good learning algorithm should converge to the cumulative reward of the optimal policy\n",
      "for the MDP.\n",
      "\n",
      "In this paper, we will make use of two well-known learning algorithms: Q learning (Watkins,\n",
      "1989; Watkins & Dayan, 1992) and SARSA(0) (Rummery & Niranjan, 1994). Both of these\n",
      "algorithms maintain a tabular representation of the action-value function Q(s, a). Every entry of\n",
      "the table is initialized arbitrarily.\n",
      "\n",
      "In Q learning, after the algorithm has observed s, chosen a, received r, and observed s′, it\n",
      "\n",
      "performs the following update:\n",
      "\n",
      "Qt(s, a) := (1 − αt)Qt−1(s, a) + αt[r + γ max\n",
      "\n",
      "a′\n",
      "\n",
      "Qt−1(s′, a′)],\n",
      "\n",
      "where αt is a learning rate parameter.\n",
      "\n",
      "Jaakkola, Jordan and Singh (1994) and Bertsekas and Tsitsiklis (1996) prove that if the agent\n",
      "\n",
      "follows an “exploration policy” that tries every action in every state inﬁnitely often and if\n",
      "\n",
      "lim\n",
      "T →∞\n",
      "\n",
      "T\n",
      "\n",
      "Xt=1\n",
      "\n",
      "αt = ∞ and\n",
      "\n",
      "lim\n",
      "T→∞\n",
      "\n",
      "T\n",
      "\n",
      "Xt=1\n",
      "\n",
      "α2\n",
      "\n",
      "t < ∞\n",
      "\n",
      "(4)\n",
      "\n",
      "then Qt converges to the optimal action-value function Q∗ with probability 1. Their proof holds in\n",
      "both settings discussed in this paper (episodic and inﬁnite-horizon).\n",
      "\n",
      "The SARSA(0) algorithm is very similar. After observing s, choosing a, observing r, observing\n",
      "\n",
      "s′, and choosing a′, the algorithm performs the following update:\n",
      "\n",
      "Qt(s, a) := (1 − αt)Qt−1(s, a) + αt(s, a)[r + γQt−1(s′, a′)],\n",
      "\n",
      "where αt is a learning rate parameter. The key diﬀerence is that the Q value of the chosen action\n",
      "a′, Q(s′, a′), appears on the right-hand side in the place where Q learning uses the Q value of the\n",
      "best action. Singh, Jaakkola, Littman, and Szepesv´ari (1998) provide two important convergence\n",
      "results: First, if a ﬁxed policy π is employed to choose actions, SARSA(0) will converge to the value\n",
      "function of that policy provided αt decreases according to Equation (4). Second, if a so-called GLIE\n",
      "policy is employed to choose actions, SARSA(0) will converge to the value function of the optimal\n",
      "policy, provided again that αt decreases according to Equation (4). A GLIE policy is deﬁned as\n",
      "follows:\n",
      "\n",
      "Deﬁnition 1 A GLIE (greedy in the limit with inﬁnite exploration) policy is any policy satisfying\n",
      "\n",
      "1. Each action is executed inﬁnitely often in every state that is visited inﬁnitely often.\n",
      "\n",
      "2. In the limit, the policy is greedy with respect to the Q-value function with probability 1.\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "\n",
      "R\n",
      "\n",
      "Y\n",
      "0\n",
      "\n",
      "G\n",
      "\n",
      "B\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "Figure 1: The Taxi Domain\n",
      "\n",
      "3 The MAXQ Value Function Decomposition\n",
      "\n",
      "At the center of the MAXQ method for hierarchical reinforcement learning is the MAXQ value\n",
      "function decomposition. MAXQ describes how to decompose the overall value function for a policy\n",
      "into a collection of value functions for individual subtasks (and subsubtasks, recursively).\n",
      "\n",
      "3.1 A Motivating Example\n",
      "\n",
      "To make the discussion concrete, let us consider the following simple example. Figure 1 shows\n",
      "a 5-by-5 grid world inhabited by a taxi agent. There are four specially-designated locations in\n",
      "this world, marked as R(ed), B(lue), G(reen), and Y(ellow). The taxi problem is episodic.\n",
      "In\n",
      "each episode, the taxi starts in a randomly-chosen square. There is a passenger at one of the\n",
      "four locations (chosen randomly), and that passenger wishes to be transported to one of the four\n",
      "locations (also chosen randomly). The taxi must go to the passenger’s location (the “source”), pick\n",
      "up the passenger, go to the destination location (the “destination”), and put down the passenger\n",
      "there. (To keep things uniform, the taxi must pick up and drop oﬀ the passenger even if he/she\n",
      "is already located at the destination!) The episode ends when the passenger is deposited at the\n",
      "destination location.\n",
      "\n",
      "There are six primitive actions in this domain: (a) four navigation actions that move the taxi\n",
      "one square North, South, East, or West, (b) a Pickup action, and (c) a Putdown action. Each action\n",
      "is deterministic. There is a reward of −1 for each action and an additional reward of +20 for\n",
      "successfully delivering the passenger. There is a reward of −10 if the taxi attempts to execute the\n",
      "Putdown or Pickup actions illegally. If a navigation action would cause the taxi to hit a wall, the\n",
      "action is a no-op, and there is only the usual reward of −1.\n",
      "\n",
      "We seek a policy that maximizes the total reward per episode. There are 500 possible states:\n",
      "25 squares, 5 locations for the passenger (counting the four starting locations and the taxi), and 4\n",
      "destinations.\n",
      "\n",
      "This task has a simple hierarchical structure in which there are two main sub-tasks: Get\n",
      "the passenger and Deliver the passenger. Each of these subtasks in turn involves the subtask\n",
      "of navigating to one of the four locations and then performing a Pickup or Putdown action.\n",
      "\n",
      "This task illustrates the need to support temporal abstraction, state abstraction, and subtask\n",
      "sharing. The temporal abstraction is obvious—for example, the process of navigating to the passen-\n",
      "ger’s location and picking up the passenger is a temporally extended action that can take diﬀerent\n",
      "numbers of steps to complete depending on the distance to the target. The top level policy (get\n",
      "passenger; deliver passenger) can be expressed very simply if these temporal abstractions can be\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "employed.\n",
      "\n",
      "The need for state abstraction is perhaps less obvious. Consider the subtask of getting the\n",
      "passenger. While this subtask is being solved, the destination of the passenger is completely\n",
      "irrelevant—it cannot aﬀect any of the nagivation or pickup decisions. Perhaps more importantly,\n",
      "when navigating to a target location (either the source or destination location of the passenger),\n",
      "only the identity of the target location is important. The fact that in some cases the taxi is carrying\n",
      "the passenger and in other cases it is not is irrelevant.\n",
      "\n",
      "Finally, support for subtask sharing is critical.\n",
      "\n",
      "If the system could learn how to solve the\n",
      "navigation subtask once, then the solution could be shared by both of the “Get the passenger”\n",
      "and “Deliver the passenger” subtasks. We will show below that the MAXQ method provides a\n",
      "value function representation and learning algorithm that supports temporal abstraction, state\n",
      "abstraction, and subtask sharing.\n",
      "\n",
      "To construct a MAXQ decomposition for the taxi problem, we must identify a set of individual\n",
      "subtasks that we believe will be important for solving the overall task. In this case, let us deﬁne\n",
      "the following four tasks:\n",
      "\n",
      "• Navigate(t). In this subtask, the goal is to move the taxi from its current location to one of\n",
      "\n",
      "the four target locations, which will be indicated by the formal parameter t.\n",
      "\n",
      "• Get. In this subtask, the goal is to move the taxi from its current location to the passenger’s\n",
      "\n",
      "current location and pick up the passenger.\n",
      "\n",
      "• Put. The goal of this subtask is to move the taxi from the current location to the passenger’s\n",
      "\n",
      "destination location and drop oﬀ the passenger.\n",
      "\n",
      "• Root. This is the whole taxi task.\n",
      "\n",
      "Each of these subtasks is deﬁned by a subgoal, and each subtask terminates when the subgoal\n",
      "\n",
      "is achieved.\n",
      "\n",
      "After deﬁning these subtasks, we must indicate for each subtask which other subtasks or prim-\n",
      "itive actions it should employ to reach its goal. For example, the Navigate(t) subtask should use\n",
      "the four primitive actions North, South, East, and West. The Get subtask should use the Navigate\n",
      "subtask and the Pickup primitive action, and so on.\n",
      "\n",
      "All of this information can be summarized by a directed acyclic graph called the task graph,\n",
      "which is shown in Figure 2. In this graph, each node corresponds to a subtask or a primitive action,\n",
      "and each edge corresponds to a potential way in which one subtask can “call” one of its child tasks.\n",
      "The notation f ormal/actual (e.g., t/source) tells how a formal parameter is to be bound to an\n",
      "actual parameter.\n",
      "\n",
      "Now suppose that for each of these subtasks, we write a policy (e.g., as a computer program)\n",
      "to achieve the subtask. We will refer to the policy for a subtask as a “subroutine”, and we can\n",
      "view the parent subroutine as invoking the child subroutine via ordinary subroutine-call-and-return\n",
      "semantics. If we have a policy for each subtask, then this gives us an overall policy for the Taxi\n",
      "MDP. The Root subtask executes its policy by calling subroutines that are policies for the Get and\n",
      "Put subtasks. The Get policy calls subroutines for the Pickup primitive action and the Navigate(t)\n",
      "subtask. And so on. We will call this collection of policies a hierarchical policy. In a hierarchical\n",
      "policy, each subroutine executes until it enters a terminal state for its subtask.\n",
      "\n",
      "3.2 Deﬁnitions\n",
      "\n",
      "Let us formalize the discussion so far.\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "Root\n",
      "\n",
      "Get\n",
      "\n",
      "Put\n",
      "\n",
      "t/source\n",
      "\n",
      "t/destination\n",
      "\n",
      "Pickup\n",
      "\n",
      "Navigate(t)\n",
      "\n",
      "Putdown\n",
      "\n",
      "North\n",
      "\n",
      "South\n",
      "\n",
      "East\n",
      "\n",
      "West\n",
      "\n",
      "Figure 2: A task graph for the Taxi problem.\n",
      "\n",
      "The MAXQ decomposition takes a given MDP M and decomposes it into a set of subtasks\n",
      "{M0, M1, . . . , Mn} with the convention that M0 is the root subtask (i.e., solving M0 solves the\n",
      "entire original MDP M ).\n",
      "\n",
      "Deﬁnition 2 An unparameterized subtask is a three-tuple, hTi, Ai, ˜Rii, deﬁned as follows:\n",
      "\n",
      "1. Ti(si) is a termination predicate that partitions S into a set of active states, Si and a set of\n",
      "terminal states, Ti. The policy for subtask Mi can only be executed if the current state s is\n",
      "in Si.\n",
      "\n",
      "2. Ai is a set of actions that can be performed to achieve subtask Mi. These actions can either\n",
      "be primitive actions from A, the set of primitive actions for the MDP, or they can be other\n",
      "subtasks, which we will denote by their indexes i. We will refer to these actions as the\n",
      "“children” of subtask i.\n",
      "If a child subtask Mj has formal parameters, then it can occur\n",
      "multiple times in Ai, and each such occurrence must specify the actual values that will be\n",
      "bound to the formal parameters. The set of actions Ai may diﬀer from one state to another, so\n",
      "technically, Ai is a function of s. However, we will suppress this dependence in our notation.\n",
      "3. ˜Ri(s′|s, a) is the pseudo-reward function, which speciﬁes a pseudo-reward for each transition\n",
      "from a state s ∈ Si to a terminal state s′ ∈ Ti. This pseudo-reward tells how desirable each\n",
      "of the terminal states is for this subtask. It is typically employed to give goal terminal states\n",
      "a pseudo-reward of 0 and any non-goal terminal states a negative reward.\n",
      "\n",
      "Each primitive action a from M is a primitive subtask in the MAXQ decomposition such that\n",
      "a is always executable, it always terminates immediately after execution, and its pseudo-reward\n",
      "function is uniformly zero.\n",
      "\n",
      "If a subtask has formal parameters, then each possible binding of actual values to the formal\n",
      "parameters speciﬁes a distinct subtask. We can think of the values of the formal parameters as being\n",
      "part of the “name” of the subtask. In practice, of course, we implement a parameterized subtask\n",
      "by parameterizing the various components of the task. If b speciﬁes the actual parameter values\n",
      "for task Mi, then we can deﬁne a parameterized termination predicate Ti(s, b) and a parameterized\n",
      "pseudo-reward function ˜Ri(s′|s, a, b). To simplify notation in the rest of the paper, we will usually\n",
      "omit these parameter bindings from our notation.\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "Table 1: Pseudo-Code for Execution of a Hierarchical Policy\n",
      "\n",
      "st is the state of the world at time t\n",
      "\n",
      "1\n",
      "2 Kt is the state of the execution stack at time t\n",
      "\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "while top(Kt) is not a primitive action\n",
      "\n",
      "Let (i, fi) := top(Kt), where\n",
      "\n",
      "i is the name of the “current” subroutine, and\n",
      "fi gives the parameter bindings for i\n",
      "\n",
      "Let (a, fa) := πi(s, fi), where\n",
      "\n",
      "a is the action and fa gives the parameter bindings chosen by policy πi\n",
      "\n",
      "push (a, fa) onto the stack Kt\n",
      "\n",
      "10 Let (a, nil) := pop(Kt) be the primitive action on the top of the stack.\n",
      "11 Execute primitive action a, and update st+1 to be\n",
      "12\n",
      "\n",
      "the resulting state of the environment.\n",
      "\n",
      "13 while top(Kt) speciﬁes a terminated subtask do\n",
      "14\n",
      "\n",
      "pop(Kt)\n",
      "\n",
      "15 Kt+1 := Kt is the resulting execution stack.\n",
      "\n",
      "Deﬁnition 3 A hierarchical policy, π, is a set containing a policy for each of the subtasks in the\n",
      "problem: π = {π0, . . . , πn}.\n",
      "\n",
      "Each subtask policy πi takes a state and returns the name of a primitive action to execute or\n",
      "the name of a subroutine (and bindings for its formal parameters) to invoke. In the terminology of\n",
      "Sutton, Precup, and Singh (1998), a subtask policy is a deterministic “option”, and its probability\n",
      "of terminating in state s (which they denote by β(s)) is 0 if s ∈ Si, and 1 if s ∈ Ti.\n",
      "\n",
      "In a parameterized task, the policy must be parameterized as well so that π takes a state and\n",
      "the bindings of formal parameters and returns a chosen action and the bindings (if any) of its\n",
      "formal parameters.\n",
      "\n",
      "Table 1 gives a pseudo-code description of the procedure for executing a hierarchical policy.\n",
      "The hierarchical policy is executed using a stack discipline, as in ordinary programming languages.\n",
      "Let Kt denote the contents of the pushdown stack at time t. When a subroutine is invoked, its\n",
      "name and actual parameters are pushed onto the stack. When a subroutine terminates, its name\n",
      "and actual parameters are popped oﬀ the stack. It is sometimes useful to think of the contents\n",
      "of the stack as being an additional part of the state space for the problem. Hence, a hierarchical\n",
      "policy implicitly deﬁnes a mapping from the current state st and current stack contents Kt to a\n",
      "primitive action a. This action is executed, and this yields a resulting state st+1 and a resulting\n",
      "stack contents Kt+1. Because of the added state information in the stack, the hierarchical policy\n",
      "is non-Markovian with respect to the original MDP.\n",
      "\n",
      "Because a hierarchical policy maps from states s and stack contents K to actions, the value\n",
      "function for a hierarchical policy must in general also assign values to all combinations of states s\n",
      "and stack contents K.\n",
      "\n",
      "Deﬁnition 4 A hierarchical value function, denoted V π(hs, Ki), gives the expected cumulative\n",
      "reward of following the hierarchical policy π starting in state s with stack contents K.\n",
      "\n",
      "In this paper, we will primarily be interested only in the “top level” value of the hierarchical\n",
      "policy—that is, the value when the stack K is empty: V π(hs, nili). This is the value of executing\n",
      "the hierarchical policy beginning in state s and starting at the top level of the hierarchy.\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "Deﬁnition 5 The projected value function, denoted V π(s), is the value of executing hierarchical\n",
      "policy π starting in state s and starting at the root of the task hierarchy.\n",
      "\n",
      "3.3 Decomposition of the Projected Value Function\n",
      "\n",
      "Now that we have deﬁned a hierarchical policy and its projected value function, we can show how\n",
      "that value function can be decomposed hierarchically. The decomposition is based on the following\n",
      "theorem:\n",
      "\n",
      "Theorem 1 Given a task graph over tasks M0, . . . , Mn and a hierarchical policy π, each subtask Mi\n",
      "deﬁnes a semi-Markov decision process with states Si, actions Ai, probability transition function\n",
      "i (s′, N |s, a), and expected reward function R(s, a) = V π(a, s), where V π(a, s) is the projected\n",
      "P π\n",
      "value function for child task Ma in state s. If a is a primitive action, V π(a, s) is deﬁned as the\n",
      "\n",
      "expected immediate reward of executing a in s: V π(a, s) = Ps′ P (s′|s, a)R(s′|s, a).\n",
      "\n",
      "Proof: Consider all of the subroutines that are descendants of task Mi in the task graph. Be-\n",
      "cause all of these subroutines are executing ﬁxed policies (speciﬁed by hierarchical policy π), the\n",
      "probability transition function P π\n",
      "i (s′, N |s, a) is a well deﬁned, stationary distribution for each child\n",
      "subroutine a. The set of states Si and the set of actions Ai are obvious. The interesting part of\n",
      "this theorem is the fact that the expected reward function R(s, a) of the SMDP is the projected\n",
      "value function of the child task Ma.\n",
      "\n",
      "To see this, let us write out the value of V π(i, s):\n",
      "\n",
      "V π(i, s) = E{rt + γrt+1 + γ2rt+2 + · · · |st = s, π}\n",
      "\n",
      "(5)\n",
      "\n",
      "This sum continues until the subroutine for task Mi enters a state in Ti.\n",
      "\n",
      "Now let us suppose that the ﬁrst action chosen by πi is a subroutine a. This subroutine is in-\n",
      "i (s′, N |s, a).\n",
      "\n",
      "voked, and it executes for a number of steps N and terminates in state s′ according to P π\n",
      "We can rewrite Equation (5) as\n",
      "\n",
      "V π(i, s) = E( N −1\n",
      "Xu=0\n",
      "\n",
      "γurt+u +\n",
      "\n",
      "∞\n",
      "\n",
      "Xu=N\n",
      "\n",
      "γurt+u(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n",
      "\n",
      "st = s, π)\n",
      "\n",
      "(6)\n",
      "\n",
      "The ﬁrst summation on the right-hand side of Equation (6) is the discounted sum of rewards for\n",
      "executing subroutine a starting in state s until it terminates, in other words, it is V π(a, s), the\n",
      "projected value function for the child task Ma. The second term on the right-hand side of the\n",
      "equation is the value of s′ for the current task i, V π(i, s′), discounted by γN , where s′ is the current\n",
      "state when subroutine a terminates. We can write this in the form of a Bellman equation:\n",
      "\n",
      "V π(i, s) = V π(πi(s), s) + Xs′,N\n",
      "\n",
      "P π\n",
      "i (s′, N |s, πi(s))γN V π(i, s′)\n",
      "\n",
      "(7)\n",
      "\n",
      "This has the same form as Equation (3), which is the Bellman equation for an SMDP, where the\n",
      "ﬁrst term is the expected reward R(s, π(s)). Q.E.D.\n",
      "\n",
      "To obtain a hierarchical decomposition of the projected value function, let us switch to the\n",
      "action-value (or Q) representation. First, we need to extend the Q notation to handle the task\n",
      "hierarchy. Let Qπ(i, s, a) be the expected cumulative reward for subtask Mi of performing action a\n",
      "in state s and then following hierarchical policy π until subtask Mi terminates. With this notation,\n",
      "we can re-state Equation (7) as follows:\n",
      "\n",
      "Qπ(i, s, a) = V π(a, s) + Xs′,N\n",
      "\n",
      "P π\n",
      "i (s′, N |s, a)γN Qπ(i, s′, π(s′)),\n",
      "\n",
      "(8)\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "(9)\n",
      "\n",
      "(10)\n",
      "\n",
      "(11)\n",
      "\n",
      "The right-most term in this equation is the expected discounted reward of completing task Mi after\n",
      "executing action a in state s. This term only depends on i, s, and a, because the summation\n",
      "marginalizes away the dependence on s′ and N . Let us deﬁne C π(i, s, a) to be equal to this term:\n",
      "\n",
      "Deﬁnition 6 The completion function, C π(i, s, a), is the expected discounted cumulative reward\n",
      "of completing subtask Mi after invoking the subroutine for subtask Ma in state s. The reward is\n",
      "discounted back to the point in time where a begins execution.\n",
      "\n",
      "C π(i, s, a) = Xs′,N\n",
      "\n",
      "P π\n",
      "i (s′, N |s, a)γN Qπ(i, s′, π(s′))\n",
      "\n",
      "With this deﬁnition, we can express the Q function recursively as\n",
      "\n",
      "Qπ(i, s, a) = V π(a, s) + C π(i, s, a).\n",
      "\n",
      "Finally, we can re-express the deﬁnition for V π(i, s) as\n",
      "\n",
      "V π(i, s) =( Qπ(i, s, πi(s))\n",
      "\n",
      "Ps′ P (s′|s, i)R(s′|s, i)\n",
      "\n",
      "if i is composite\n",
      "if i is primitive\n",
      "\n",
      "We will refer to equations (9), (10), and (11) as the decomposition equations for the MAXQ\n",
      "hierarchy under a ﬁxed hierarchical policy π. These equations recursively decompose the projected\n",
      "value function for the root, V π(0, s) into the projected value functions for the individual subtasks,\n",
      "M1, . . . , Mn and the individual completion functions C π(j, s, a) for j = 1, . . . , n. The fundamental\n",
      "quantities that must be stored to represent the value function decomposition are just the C values\n",
      "for all non-primitive subtasks and the V values for all primitive actions.\n",
      "\n",
      "To make it easier for programmers to design and debug MAXQ decompositions, we have de-\n",
      "veloped a graphical representation that we call the MAXQ graph. A MAXQ graph for the Taxi\n",
      "domain is shown in Figure 3. The graph contains two kinds of nodes, Max nodes and Q nodes. The\n",
      "Max nodes correspond to the subtasks in the task decomposition—there is one Max node for each\n",
      "primitive action and one Max node for each subtask (including the Root) task. Each primitive Max\n",
      "node i stores the value of V π(i, s). The Q nodes correspond to the actions that are available for\n",
      "each subtask. Each Q node for parent task i, state s and subtask a stores the value of C π(i, s, a).\n",
      "In addition to storing information, the Max nodes and Q nodes can be viewed as performing\n",
      "parts of the computation described by the decomposition equations. Speciﬁcally, each Max node\n",
      "i can be viewed as computing the projected value function V π(i, s) for its subtask. For primitive\n",
      "Max nodes, this information is stored in the node. For composite Max nodes, this information is\n",
      "obtained by “asking” the Q node corresponding to πi(s). Each Q node with parent task i and child\n",
      "task a can be viewed as computing the value of Qπ(i, s, a). It does this by “asking” its child task\n",
      "a for its projected value function V π(a, s) and then adding its completion function C π(i, s, a).\n",
      "\n",
      "As an example, consider the situation shown in Figure 1, which we will denote by s1. Suppose\n",
      "that the passenger is at R and wishes to go to B. Let the hierarchical policy we are evaluating be an\n",
      "optimal policy denoted by π (we will omit the superscript * to reduce the clutter of the notation).\n",
      "The value of this state under π is 10, because it will cost 1 unit to move the taxi to R, 1 unit to\n",
      "pickup the passenger, 7 units to move the taxi to B, and 1 unit to putdown the passenger, for a\n",
      "total of 10 units (a reward of −10). When the passenger is delivered, the agent gets a reward of\n",
      "+20, so the net value is +10.\n",
      "\n",
      "Figure 4 shows how the MAXQ hierarchy computes this value. To compute the value V π(Root, s1),\n",
      "\n",
      "MaxRoot consults its policy and ﬁnds that πRoot(s1) is Get. Hence, it “asks” the Q node, QGet\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "MaxRoot\n",
      "\n",
      "QGet\n",
      "\n",
      "QPut\n",
      "\n",
      "MaxGet\n",
      "\n",
      "MaxPut\n",
      "\n",
      "QPickup\n",
      "\n",
      "QNavigateForGet\n",
      "\n",
      "QNavigateForPut\n",
      "\n",
      "QPutdown\n",
      "\n",
      "t/source\n",
      "\n",
      "t/destination\n",
      "\n",
      "Pickup\n",
      "\n",
      "Putdown\n",
      "\n",
      "MaxNavigate(t)\n",
      "\n",
      "QNorth(t)\n",
      "\n",
      "QEast(t)\n",
      "\n",
      "QSouth(t)\n",
      "\n",
      "QWest(t)\n",
      "\n",
      "North\n",
      "\n",
      "East\n",
      "\n",
      "South\n",
      "\n",
      "West\n",
      "\n",
      "Figure 3: A MAXQ graph for the Taxi Domain\n",
      "\n",
      "to compute Qπ(Root, s1, Get). The completion cost for the Root task after performing a Get,\n",
      "C π(Root, s1, Get), is 12, because it will cost 8 units to deliver the customer (for a net reward of\n",
      "20 − 8 = 12) after completing the Get subtask. However, this is just the reward after completing\n",
      "the Get, so it must ask MaxGet to estimate the expected reward of performing the Get itself.\n",
      "\n",
      "The policy for MaxGet dictates that in s1, the Navigate subroutine should be invoked with\n",
      "t bound to R, so MaxGet consults the Q node, QNavigateForGet to compute the expected re-\n",
      "ward. QNavigateForGet knows that after completing the Navigate(R) task, one more action (the\n",
      "Pickup) will be required to complete the Get, so C π(MaxGet, s1, Navigate(R)) = −1. It then asks\n",
      "MaxNavigate(R) to compute the expected reward of performing a Navigate to location R.\n",
      "\n",
      "The policy for MaxNavigate chooses the North action, so MaxNavigate asks QNorth to compute\n",
      "the value. QNorth looks up its completion cost, and ﬁnds that C π(Navigate, s1, North) is 0 (i.e.,\n",
      "the Navigate task will be completed after performing the North action). It consults MaxNorth to\n",
      "determine the expected cost of performing the North action itself. Because MaxNorth is a primitive\n",
      "action, it looks up its expected reward, which is −1.\n",
      "\n",
      "Now this series of recursive computations can conclude as follows:\n",
      "\n",
      "• Qπ(Navigate(R), s1, North) = −1 + 0\n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "10\n",
      "\n",
      "MaxRoot\n",
      "\n",
      "10\n",
      "\n",
      "12\n",
      "\n",
      "QGet\n",
      "\n",
      "-2\n",
      "\n",
      "MaxGet\n",
      "\n",
      "-2\n",
      "\n",
      "QPut\n",
      "\n",
      "MaxPut\n",
      "\n",
      "QPickup\n",
      "\n",
      "QNavigateForGet\n",
      "\n",
      "QNavigateForPut\n",
      "\n",
      "QPutdown\n",
      "\n",
      "Pickup\n",
      "\n",
      "-1\n",
      "\n",
      "-1\n",
      "\n",
      "-1\n",
      "\n",
      "MaxNavigate(t)\n",
      "\n",
      "Putdown\n",
      "\n",
      "0\n",
      "\n",
      "QNorth(t)\n",
      "\n",
      "QEast(t)\n",
      "\n",
      "QSouth(t)\n",
      "\n",
      "QWest(t)\n",
      "\n",
      "-1\n",
      "\n",
      "North\n",
      "\n",
      "East\n",
      "\n",
      "South\n",
      "\n",
      "West\n",
      "\n",
      "Figure 4: Computing the value of a state using the MAXQ hierarchy. The C value of each Q node\n",
      "is shown to the left of the node. All other numbers show the values being returned up the graph.\n",
      "\n",
      "• V π(Navigate(R), s1) = −1\n",
      "\n",
      "• Qπ(Get, s1, Navigate(R)) = −1 + −1\n",
      "\n",
      "(−1 to perform the Navigate plus −1 to complete the Get.\n",
      "\n",
      "• V π(Get, s1) = −2\n",
      "\n",
      "• Qπ(Root, s1, Get) = −2 + 12\n",
      "\n",
      "(−2 to perform the Get plus 12 to complete the Root task and collect the ﬁnal reward).\n",
      "\n",
      "The end result of all of this is that the value of V π(Root, s1) is decomposed into a sum of C\n",
      "\n",
      "terms plus the expected reward of the chosen primitive action:\n",
      "\n",
      "V π(Root, s1) = V π(North, s1) + C π(Navigate(R), s1, North) +\n",
      "C π(Get, s1, Navigate(R)) + C π(Root, s1, Get)\n",
      "\n",
      "= −1 + 0 + −1 + 12\n",
      "\n",
      "= 10\n",
      "\n",
      "16\n",
      "\n",
      "\f",
      "V π(0, s)\n",
      "\n",
      "\u0018\u0018\u0018\u0018\u0018\u0018\u0018\n",
      "\n",
      "XXXXXXX\n",
      "\n",
      "V π(a1, s)\n",
      "\n",
      "\u0010\u0010\u0010\u0010\u0010\n",
      "\n",
      "PPPPP\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "V π(am−1, s)\n",
      "\n",
      "\u001a\n",
      "\n",
      "Z\n",
      "\n",
      "\u001a\n",
      "\n",
      "Z\n",
      "\n",
      "\u001a\u001a\n",
      "\n",
      "ZZ\n",
      "\n",
      "V π(am, s) C π(am−1, s, am)\n",
      "\n",
      "C π(a1, s, a2)\n",
      "\n",
      "C π(0, s, a1)\n",
      "\n",
      "r1\n",
      "\n",
      "r2\n",
      "\n",
      "r3\n",
      "\n",
      "r4\n",
      "\n",
      "r5\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "r8\n",
      "\n",
      "r9\n",
      "\n",
      "r10\n",
      "\n",
      "r11\n",
      "\n",
      "r12\n",
      "\n",
      "r13\n",
      "\n",
      "r14\n",
      "\n",
      "Figure 5: The MAXQ decomposition; r1, . . . , r14 denote the sequence of rewards received from\n",
      "primitive actions at times 1, . . . , 14.\n",
      "\n",
      "In general, the MAXQ value function decomposition has the form\n",
      "\n",
      "V π(0, s) = V π(am, s) + C π(am−1, s, am) + . . . + C π(a1, s, a2) + C π(0, s, a1),\n",
      "\n",
      "(12)\n",
      "\n",
      "where a0, a1, . . . , am is the “path” of Max nodes chosen by the hierarchical policy going from the\n",
      "Root down to a primitive leaf node.\n",
      "\n",
      "We can summarize the presentation of this section by the following theorem:\n",
      "\n",
      "Theorem 2 Let π = {πi; i = 0, . . . , n} be a hierarchical policy deﬁned for a given MAXQ graph\n",
      "with subtasks M0, . . . , Mn, and let i = 0 be the root node of the graph. Then there exist values\n",
      "for C π(i, s, a) (for internal Max nodes) and V π(i, s) (for primitive, leaf Max nodes) such that\n",
      "V π(0, s) (as computed by the decomposition equations (9), (10), and (11)) is the expected discounted\n",
      "cumulative reward of following policy π starting in state s.\n",
      "\n",
      "Proof: The proof is by induction on the number of levels in the task graph. At each level i,\n",
      "we compute values for C π(i, s, π(s)) (or V π(i, s), if i is primitive) according to the decomposition\n",
      "equations. We can apply the decomposition equations again to compute Qπ(i, s, π(s)) and apply\n",
      "Equation (8) and Theorem 1 to conclude that Qπ(i, s, π(s)) gives the value function for level i.\n",
      "When i = 0, we obtain the value function for the entire hierarchical policy. Q. E. D.\n",
      "\n",
      "It is important to note that this representation theorem does not mention the pseudo-reward\n",
      "function, because the pseudo-reward is used only during learning. This theorem captures the\n",
      "representational power of the MAXQ decomposition, but it does not address the question of whether\n",
      "there is a learning algorithm that can ﬁnd a given policy. That is the subject of the next section.\n",
      "\n",
      "4 A Learning Algorithm for the MAXQ Decomposition\n",
      "\n",
      "In order to develop a learning algorithm for the MAXQ decomposition, we must consider exactly\n",
      "what we are hoping to achieve. Of course, for any MDP M , we would like to ﬁnd an optimal policy\n",
      "π∗. However, in the MAXQ method (and in hierarchical reinforcement learning in general), the\n",
      "programmer imposes a hierarchy on the problem. This hierarchy constrains the space of possible\n",
      "policies so that it may not be possible to represent the optimal policy or its value function.\n",
      "\n",
      "17\n",
      "\n",
      "\f",
      "In the MAXQ method, the constraints take two forms. First, within a subtask, only some of the\n",
      "possible primitive actions may be permitted. For example, in the taxi task, during a Navigate(t),\n",
      "only the North, South, East, and West actions are available—the Pickup and Putdown actions are\n",
      "not allowed. Second, consider a Max node Mj with child nodes {Mj1, . . . , Mjk}. The policy learned\n",
      "for Mj must involve executing the learned policies of these child nodes. When the policy for child\n",
      "node Mji is executed, it will run until it enters a state in Tji. Hence, any policy learned for Mj\n",
      "must pass through some subset of these terminal state sets {Tj1, . . . , Tjk}.\n",
      "\n",
      "The HAM method shares these same two constraints and in addition, it imposes a partial policy\n",
      "on each node, so that the policy for any subtask Mi must be a deterministic reﬁnement of the given\n",
      "non-deterministic initial policy for node i.\n",
      "\n",
      "In the “option” approach, the policy is even further constrained. In this approach, there are\n",
      "only two non-primitive levels in the hierarchy, and the subtasks at the lower level are given complete\n",
      "policies by the programmer. Hence, any learned policy must be constructed by “concatenating”\n",
      "the given lower level policies in some order.\n",
      "\n",
      "The purpose of imposing these constraints on the policy is to incorporate prior knowledge and\n",
      "thereby reduce the size of the space that must be searched to ﬁnd a good policy. However, these\n",
      "constraints may make it impossible to learn the optimal policy.\n",
      "\n",
      "If we can’t learn the optimal policy, the next best target would be to learn the best policy that\n",
      "\n",
      "is consistent with (i.e., can be represented by) the given hierarchy.\n",
      "\n",
      "Deﬁnition 7 A hierarchically optimal policy for MDP M is a policy that achieves the highest\n",
      "cumulative reward among all policies consistent with the given hierarchy.\n",
      "\n",
      "Parr (1998b) proves that his HAMQ learning algorithm converges with probability 1 to a hier-\n",
      "archically optimal policy. Similarly, given a ﬁxed set of options, Sutton, Precup, and Singh (1998)\n",
      "prove that their SMDP learning algorithm converges to a hierarchically optimal value function.\n",
      "(Incidentally, they also show that if the primitive actions are also made available as “trivial” op-\n",
      "tions, then their SMDP method converges to the optimal policy. However, in this case, it is hard\n",
      "to say anything formal about how the options speed the learning process. They may in fact hinder\n",
      "it (Hauskrecht et al., 1998).)\n",
      "\n",
      "With the MAXQ method, we will seek an even weaker form of optimality: recursive optimality.\n",
      "\n",
      "Deﬁnition 8 A recursively optimal policy for MDP M with MAXQ decomposition {M0, . . . , Mk}\n",
      "is a hierarchical policy π = {π0, . . . , πk} such that for each subtask Mi, the corresponding policy πi\n",
      "is optimal for the SMDP deﬁned by the set of states Si, the set of actions Ai, the state transition\n",
      "probability function P π(s′, N |s, a), and the reward function given by the sum of the original reward\n",
      "function R(s′|s, a) and the pseudo-reward function ˜Ri(s′).\n",
      "\n",
      "Note that in this deﬁnition, the state transition probability distribution is deﬁned by the locally\n",
      "optimal policies {πj} of all subtasks that are descendants of Mi in the MAXQ graph. Hence,\n",
      "recursive optimality is a kind of local optimality in which the policy at each node is optimal given\n",
      "the policies of its children.\n",
      "\n",
      "The reason to seek recursive optimality rather than hierarchical optimality is that recursive\n",
      "optimality makes it possible to solve each subtask without reference to the context in which it is\n",
      "executed. This context-free property makes it easier to share and re-use subtasks. It will also turn\n",
      "out to be essential for the successful use of state abstraction.\n",
      "\n",
      "Before we proceed to describe our learning algorithm for recursive optimality, let us see how\n",
      "\n",
      "recursive optimality diﬀers from hierarchical optimality.\n",
      "\n",
      "18\n",
      "\n",
      "\f",
      "MaxRoot\n",
      "\n",
      "QExit\n",
      "\n",
      "MaxExit\n",
      "\n",
      "QGotoGoal\n",
      "\n",
      "MaxGotoGoal\n",
      "\n",
      "QExitNorth\n",
      "\n",
      "QExitSouth\n",
      "\n",
      "QExitEast\n",
      "\n",
      "QNorthG\n",
      "\n",
      "QSouthG\n",
      "\n",
      "QEastG\n",
      "\n",
      "G\n",
      "\n",
      "*\n",
      "\n",
      "*\n",
      "\n",
      "Figure 6: A simple MDP (left) and its associated MAXQ graph (right). The policy shown in the\n",
      "left diagram is recursively optimal but not hierarchically optimal. The shaded cells indicate points\n",
      "where the locally-optimal policy is not globally optimal.\n",
      "\n",
      "North\n",
      "\n",
      "South\n",
      "\n",
      "East\n",
      "\n",
      "It is easy to construct examples of policies that are recursively optimal but not hierarchically\n",
      "optimal. Consider the simple maze problem and its associated MAXQ graph shown in Figures 6.\n",
      "Suppose a robot starts somewhere in the left room, and it must reach the goal G in the right room.\n",
      "The robot has three actions, North, South, and East, and these actions are deterministic. The robot\n",
      "receives a reward of −1 for each move. Let us deﬁne two subtasks:\n",
      "\n",
      "• Exit. This task terminates when the robot exits the left room. We can set the pseudo-reward\n",
      "\n",
      "function ˜R to be 0 for the two terminal states (i.e., the two states indicated by *’s).\n",
      "\n",
      "• GotoGoal. This task terminates when the robot reaches the goal G.\n",
      "\n",
      "The arrows in Figure 6 show the locally optimal policy within each room. The arrows on the\n",
      "left seek to exit the left room by the shortest path, because this is what we speciﬁed when we set\n",
      "the pseudo-reward function to 0. The arrows on the right follow the shortest path to the goal,\n",
      "which is ﬁne. However, the resulting policy is neither hierarchically optimal nor optimal.\n",
      "\n",
      "There exists a hierarchical policy that would always exit the left room by the upper door. The\n",
      "MAXQ value function decomposition can represent the value function of this policy, but such a\n",
      "policy would not be locally optimal (because, for example, the states in the “shaded” region would\n",
      "not follow the shortest path to a doorway).\n",
      "If we consider for a moment, we can see a way to\n",
      "ﬁx this problem. The value of the upper starred state under the optimal hierarchical policy is\n",
      "−2 and the value of the lower starred state is −6. Hence, if we set ˜R to have these values, then\n",
      "the recursively-optimal policy would be hierarchically optimal (and globally optimal).\n",
      "In other\n",
      "words, if the programmer can guess the right values for the terminal states of a subtask, then the\n",
      "recursively optimal policy will be hierarchically optimal (provided that all primitive actions are\n",
      "available within the subtask).\n",
      "\n",
      "This basic idea was ﬁrst pointed out by Dean and Lin (1995). They describe an algorithm that\n",
      "makes initial guesses for the values of these starred states and then updates those guesses based\n",
      "on the computed values of the starred states under the resulting recursively-optimal policy. They\n",
      "proved that this will converge to a hierarchically optimal policy. The drawback of their method is\n",
      "\n",
      "19\n",
      "\n",
      "\f",
      "that it requires repeated solution of the resulting hierarchical learning problem, and this does not\n",
      "always yield a speedup over just solving the original, ﬂat problem.\n",
      "\n",
      "Parr (1998a) proposed an interesting approach that constructs a set of diﬀerent ˜R functions and\n",
      "computes the recursively optimal policy under each of them for each subtask. His method chooses\n",
      "the ˜R functions in such a way that the hierarchically optimal policy can be approximated to any\n",
      "desired degree. Unfortunately, the method is quite ineﬃcient, because it relies on solving a series\n",
      "of linear programming problems each of which requires time polynomial in several parameters,\n",
      "including the number of states |Si| within the subtask.\n",
      "\n",
      "This discussion suggests that while, in principle, it is possible to learn good values for the pseudo-\n",
      "reward function, in practice, we must rely on the programmer to specify a single pseudo-reward\n",
      "function, ˜R. If the programmer wishes to consider a small number of alternative pseudo-reward\n",
      "functions, they can be handled by deﬁning a small number of subtasks that are identical except\n",
      "for their ˜R functions, and permitting the learning algorithm to choose the one that gives the best\n",
      "recursively-optimal policy.\n",
      "\n",
      "In practice, we have employed the following simpliﬁed approach to deﬁning ˜R. For each subtask\n",
      "Mi, we deﬁne two predicates: the termination predicate, Ti, and a goal predicate Gi. The goal\n",
      "predicate deﬁnes a subset of the terminated states that are “goal states”, and these have a pseudo-\n",
      "reward of 0. All other terminal states have a ﬁxed constant pseudo-reward (e.g., −100) that is set\n",
      "so that it is always better to terminate in a goal state than in a non-goal state. For the problems\n",
      "on which we have tested the MAXQ method, this worked very well.\n",
      "\n",
      "In our experiments with MAXQ, we have found that it is easy to make mistakes in deﬁning\n",
      "Ti and Gi. If the goal is not deﬁned carefully, it is easy to create a set of subtasks that lead to\n",
      "inﬁnite looping. For example, consider again the problem in Figure 6. Suppose we permit a fourth\n",
      "action, West in the MDP and let us deﬁne the termination and goal predicates for the right hand\n",
      "room to be satisﬁed iﬀ either the robot reaches the goal or it exits the room. This is a very natural\n",
      "deﬁnition, since it is quite similar to the deﬁnition for the left-hand room. However, the resulting\n",
      "locally-optimal policy for this room will attempt to move to the nearest of these three locations:\n",
      "the goal, the upper door, or the lower door. We can easily see that for all but a few states near the\n",
      "goal, the only policies that can be constructed by MaxRoot will loop forever, ﬁrst trying to leave\n",
      "the left room by entering the right room, and then trying to leave the right room by entering the\n",
      "left room. This problem is easily ﬁxed by deﬁning the goal predicate Gi for the right room to be\n",
      "true if and only if the robot reaches the goal G. But avoiding such “undesired termination” bugs\n",
      "can be hard in more complex domains.\n",
      "\n",
      "Now that we have an understanding of recursively optimal policies, we present two learning\n",
      "algorithms. The ﬁrst one, called MAXQ-0, applies only in the case when the pseudo-reward function\n",
      "˜R is always zero. We will ﬁrst prove its convergence properties and then show how it can be extended\n",
      "to give the second algorithm, MAXQ-Q, which works with general pseudo-reward functions.\n",
      "\n",
      "Table 2 gives pseudo-code for MAXQ-0. MAXQ-0 is a recursive function that executes the\n",
      "current exploration policy starting at Max node i in state s. It performs actions until it reaches\n",
      "a terminal state, at which point it returns a count of the total number of primitive actions that\n",
      "have been executed. To execute an action, MAXQ-0 calls itself recursively. When the recursive call\n",
      "returns, it updates the value of the completion function for node i. It uses the count of the number\n",
      "of primitive actions to appropriately discount the value of the resulting state s′. At leaf nodes,\n",
      "MAXQ-0 updates the estimated one-step expected reward, V (i, s). The value αt(i) is a “learning\n",
      "rate” parameter that should be gradually decreased to zero in the limit.\n",
      "\n",
      "There are two things that must be speciﬁed in order to make this algorithm description complete.\n",
      "First, we must specify how to compute Vt(i, s′) in line 12, since it is not stored in the Max node.\n",
      "It is computed by the following modiﬁed versions of the decomposition equations:\n",
      "\n",
      "20\n",
      "\n",
      "\f",
      "Table 2: The MAXQ-0 learning algorithm.\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "\n",
      "function MAXQ-0(MaxNode i, State s)\n",
      "\n",
      "if i is a primitive MaxNode\n",
      "\n",
      "execute i, receive r, and observe result state s′\n",
      "Vt+1(i, s) := (1 − αt(i)) · Vt(i, s) + αt(i) · rt\n",
      "return 1\n",
      "\n",
      "else\n",
      "\n",
      "let count = 0\n",
      "while Ti(s) is false do\n",
      "\n",
      "choose an action a according to the current exploration policy πx(i, s)\n",
      "let N = MAXQ-0(a, s)\n",
      "observe result state s′\n",
      "Ct+1(i, s, a) := (1 − αt(i)) · Ct(i, s, a) + αt(i) · γN Vt(i, s′)\n",
      "count := count + N\n",
      "s := s′\n",
      "end\n",
      "\n",
      "return count\n",
      "\n",
      "end MAXQ-0\n",
      "\n",
      "Table 3: Pseudo-code for Greedy Execution of the MAXQ Graph\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "\n",
      "function EvaluateMaxNode(i, s)\n",
      "\n",
      "if i is a primitive Max node\n",
      "\n",
      "return hVt(i, s), ii\n",
      "\n",
      "else\n",
      "\n",
      "for each j ∈ Ai,\n",
      "\n",
      "let hV(j, s), aji = EvaluateMaxNode(j, s)\n",
      "\n",
      "let jhg = argmaxj Vt(j, s) + Ct(i, s, j)\n",
      "return hVt(jhg, s), ajhg i\n",
      "\n",
      "end // EvaluateMaxNode\n",
      "\n",
      "Vt(i, s) = ( maxa Qt(i, s, a)\n",
      "\n",
      "Vt(i, s)\n",
      "\n",
      "if i is composite\n",
      "if i is primitive\n",
      "\n",
      "Qt(i, s, a) = Vt(a, s) + Ct(i, s, a).\n",
      "\n",
      "(13)\n",
      "\n",
      "(14)\n",
      "\n",
      "These equations reﬂect two important changes compared with Equations (10) and (11). First,\n",
      "in the ﬁrst equation, Vt(i, s) is deﬁned in terms of the Q value of the best action a, rather than of\n",
      "the action chosen by a ﬁxed hierarchical policy. Second, there are no π superscripts, because the\n",
      "current value function, Vt(i, s) is not based on a ﬁxed hierarchical policy π.\n",
      "\n",
      "To compute Vt(i, s) using these equations, we must perform a complete search of all paths\n",
      "through the MAXQ graph starting at node i and ending at the leaf nodes. Table 3 gives pseudo-\n",
      "code for a recursive function, EvaluateMaxNode, that implements a depth-ﬁrst search. In addition\n",
      "to returning Vt(i, s), EvaluateMaxNode also returns the action at the leaf node that achieves this\n",
      "value. This information is not needed for MAXQ-0, but it will be useful later when we consider\n",
      "non-hierarchical execution of the learned recursively-optimal policy.\n",
      "\n",
      "The second thing that must be speciﬁed to complete our deﬁnition of MAXQ-0 is the exploration\n",
      "\n",
      "policy, πx. We require that πx be an ordered GLIE policy.\n",
      "\n",
      "21\n",
      "\n",
      "\f",
      "Deﬁnition 9 An ordered GLIE policy is a GLIE policy (Greedy in the Limit of Inﬁnite Explo-\n",
      "ration) that converges in the limit to an ordered greedy policy, which is a greedy policy that imposes\n",
      "an arbitrary ﬁxed order ω on the available actions and breaks ties in favor of the action a that ap-\n",
      "pears earliest in that order.\n",
      "\n",
      "We need this property in order to ensure that MAXQ-0 converges to a uniquely-deﬁned recur-\n",
      "sively optimal policy. A fundamental problem with recursive optimality is that in general, each Max\n",
      "node i will have a choice of many diﬀerent locally optimal policies given the policies adopted by its\n",
      "descendant nodes. These diﬀerent locally optimal policies will all achieve the same locally optimal\n",
      "value function, but they can give rise to diﬀerent probability transition functions P (s′, N |s, i). The\n",
      "result will be that the Semi-Markov Decision Problem deﬁned at the next level above node i in\n",
      "the MAXQ graph will diﬀer depending on which of these various locally optimal policies is chosen\n",
      "by node i. However, if we establish a ﬁxed ordering over the Max nodes in the MAXQ graph\n",
      "(e.g., a left-to-right depth-ﬁrst numbering), and break ties in favor of the lowest-numbered action,\n",
      "then this deﬁnes a unique policy at each Max node. And consequently, by induction, it deﬁnes a\n",
      "unique policy for the entire MAXQ graph. Let us call this policy π∗\n",
      "r . We will use the r subscript\n",
      "to denote recursively optimal quantities under an ordered greedy policy. Hence, the corresponding\n",
      "value function is V ∗\n",
      "r denote the corresponding completion function and action-value\n",
      "function. We now prove that the MAXQ-0 algorithm converges to π∗\n",
      "r .\n",
      "\n",
      "r , and C ∗\n",
      "\n",
      "r and Q∗\n",
      "\n",
      "Theorem 3 Let M = hS, A, P, R, P0i be either an episodic MDP for which all deterministic policies\n",
      "are proper or a discounted inﬁnite horizon MDP with discount factor γ. Let H be a MAXQ graph\n",
      "deﬁned over subtasks {M0, . . . , Mk} such that the pseudo-reward function ˜Ri(s′|s, a) is zero for all\n",
      "i, s, a, and s′. Let αt(i) > 0 be a sequence of constants for each Max node i such that\n",
      "\n",
      "lim\n",
      "T →∞\n",
      "\n",
      "T\n",
      "\n",
      "Xt=1\n",
      "\n",
      "αt(i) = ∞ and\n",
      "\n",
      "lim\n",
      "T →∞\n",
      "\n",
      "T\n",
      "\n",
      "Xt=1\n",
      "\n",
      "α2\n",
      "\n",
      "t (i) < ∞\n",
      "\n",
      "(15)\n",
      "\n",
      "Let πx(i, s) be an ordered GLIE policy at each node i and state s and assume that |Vt(i, s)| and\n",
      "|Ct(i, s, a)| are bounded for all t, i, s, and a. Then with probability 1, algorithm MAXQ-0 converges\n",
      "to π∗\n",
      "\n",
      "r , the unique recursively optimal policy for M consistent with H and πx.\n",
      "\n",
      "Proof: The proof follows an argument similar to those introduced to prove the convergence of Q\n",
      "learning and SARSA(0) (Bertsekas & Tsitsiklis, 1996; Jaakkola et al., 1994). We will employ the\n",
      "following result from stochastic approximation theory:\n",
      "\n",
      "Lemma 1 (Proposition 4.5 from Bertsekas and Tsitsiklis, 1996) Consider the iteration\n",
      "\n",
      "rt+1(x) := (1 − αt(x))rt(x) + αt(x)((U rt)(x) + wt(x) + ut(x)).\n",
      "\n",
      "Let Ft = {r0(x), . . . , rt(x), w0(x), . . . , wt−1(x), α0(x), . . . , αt(x), ∀x} be the entire history of the it-\n",
      "eration.\n",
      "\n",
      "If\n",
      "\n",
      "(a) The αt(i) ≥ 0 satisfy conditions (15)\n",
      "\n",
      "(b) For every i and t the noise terms wt(i) satisfy E[wt(i)|Ft] = 0\n",
      "\n",
      "(c) Given any norm ||·|| on Rn, there exist constants A and B such that E[w2\n",
      "\n",
      "t (i)|Ft] ≤ A+B||rt||2.\n",
      "\n",
      "22\n",
      "\n",
      "\f",
      "(d) There exists a vector r∗, a positive vector ξ, and a scalar β ∈ [0, 1), such that for all t,\n",
      "\n",
      "||U rt − r∗||ξ ≤ β||rt − r∗||ξ\n",
      "\n",
      "(e) There exists a nonnegative random sequence θt that converges to zero with probability 1 and\n",
      "\n",
      "is such that for all t\n",
      "\n",
      "|ut(x)| ≤ θt(||rt||ξ + 1)\n",
      "\n",
      "then rt converges to r∗ with probability 1. The notation || · ||ξ denotes a weighted maximum norm\n",
      "\n",
      "||A||ξ = max\n",
      "\n",
      "x\n",
      "\n",
      "|A(x)|\n",
      "ξ(x)\n",
      "\n",
      ".\n",
      "\n",
      "The structure of the proof of Theorem 3 will be inductive, starting at the leaves of the MAXQ\n",
      "graph and working toward the root. We will employ a diﬀerent time clock at each node i to count\n",
      "the number of update steps performed by MAXQ-0 at that node. The variable t will always refer\n",
      "to the time clock of the current node i.\n",
      "\n",
      "To prove the base case for any primitive Max node, we note that line 4 of MAXQ-0 is just the\n",
      "standard stochastic approximation algorithm for computing the expected reward for performing\n",
      "action a in state s, and therefore it converges under the conditions given above.\n",
      "\n",
      "To prove the recursive case, consider any composite Max node i with child node j. Let\n",
      "Pt(s′, N |s, j) be the transition probability distribution for performing child action j in state s\n",
      "at time t (i.e., while following the exploration policy in all descendent nodes of node j). By the\n",
      "inductive assumption, MAXQ-0 applied to j will converge to the (unique) recursively optimal value\n",
      "function V ∗\n",
      "r (j, s) with probability 1. Furthermore, because MAXQ-0 is following an ordered GLIE\n",
      "policy for j and its descendants, Pt(s′, N |s, j) will converge to P ∗\n",
      "r (s′, N |s, j), the unique transition\n",
      "probability function for executing child j under the locally optimal policy π∗\n",
      "r . What remains to be\n",
      "shown is that the update assignment for C (line 12 of the MAXQ-0 algorithm) will converge to the\n",
      "optimal C ∗\n",
      "\n",
      "r function with probability 1.\n",
      "\n",
      "To prove this, we will apply Lemma 1. We will identify the x in the lemma with a state-action\n",
      "pair (s, a). The vector rt will be the completion-cost table Ct(i, s, a) for all s, a and ﬁxed i after\n",
      "t update steps. The vector r∗ will be the optimal completion-cost C ∗\n",
      "r (i, s, a) (again, for ﬁxed i).\n",
      "Deﬁne the mapping U to be\n",
      "\n",
      "(U C)(i, s, a) = Xs′\n",
      "\n",
      "r (s′, N |s, a)γN (max\n",
      "P ∗\n",
      "a′\n",
      "\n",
      "[C(i, s′, a′) + V ∗\n",
      "\n",
      "r (a′, s′)])\n",
      "\n",
      "This is a C update under the MDP Mi assuming that all descendant value functions, V ∗\n",
      "transition probabilities, P ∗\n",
      "\n",
      "r (s′, N |s, a), have converged.\n",
      "\n",
      "r (a, s), and\n",
      "\n",
      "To apply the lemma, we must ﬁrst express the C update formula in the form of the update rule\n",
      "in the lemma. Let s be the state that results from performing a in state s. Line 12 can be written\n",
      "\n",
      "Ct+1(i, s, a)\n",
      "\n",
      ":= (1 − αt(i)) · Ct(i, s, a) + αt(i) · γN (max\n",
      "\n",
      "a′\n",
      "\n",
      "[Ct(i, s, a′) + Vt(a′, s)])\n",
      "\n",
      ":= (1 − αt(i)) · Ct(i, s, a) + αt(i) · [(U Ct)(i, s, a) + wt(i, s, a) + ut(i, s, a)]\n",
      "\n",
      "where\n",
      "\n",
      "wt(i, s, a) = γN (cid:18)max\n",
      "\n",
      "a′\n",
      "\n",
      "[Ct(i, s, a′) + Vt(a′, s)](cid:19) −\n",
      "\n",
      "23\n",
      "\n",
      "\f",
      "Xs′,N\n",
      "ut(i, s, a) = Xs′,N\n",
      "Xs′,N\n",
      "\n",
      "a′\n",
      "\n",
      "Pt(s′, N |s, a)γN (cid:18)max\n",
      "Pt(s′, N |s, a)γN (cid:18)max\n",
      "r (s′, N |s, a)γN (cid:18)max\n",
      "\n",
      "[Ct(i, s′, a′) + Vt(a′, s′)](cid:19)\n",
      "[Ct(i, s′, a′) + Vt(a′, s′)](cid:19) −\n",
      "r (a′, s′)](cid:19)\n",
      "\n",
      "[Ct(i, s′, a′) + V ∗\n",
      "\n",
      "P ∗\n",
      "\n",
      "a′\n",
      "\n",
      "a′\n",
      "\n",
      "Here wt(i, s, a) is the diﬀerence between doing an update at node i using the single sample point s\n",
      "drawn according to Pt(s′, N |s, a) and doing an update using the full distribution Pt(s′, N |s, a). The\n",
      "value of ut(i, s, a) captures the diﬀerence between doing an update using the current probability\n",
      "transitions Pt(s′, N |s, a) and current value functions of the children Vt(a′, s′) and doing an up-\n",
      "date using the optimal probability transitions P ∗\n",
      "r (s′, N |s, a) and the optimal values of the children\n",
      "V ∗\n",
      "r (a′, s′).\n",
      "\n",
      "We now verify the conditions of Lemma 1.\n",
      "Condition (a) is assumed in the conditions of the theorem with αt(s, a) = αt(i).\n",
      "Condition (b) is satisﬁed because s is sampled from Pt(s′, N |s, a), so the expected value of the\n",
      "\n",
      "diﬀerence is zero.\n",
      "\n",
      "Condition (c) follows directly from the assumption that the |Ct(i, s, a)| and |Vt(i, s)| are bounded.\n",
      "Condition (d) is the condition that U is a weighted max norm pseudo-contraction. We can\n",
      "derive this by starting with the weighted max norm for Q learning. It is well known that Q is\n",
      "a weighted max norm pseudo-contraction (Bertsekas & Tsitsiklis, 1996) in both the episodic case\n",
      "where all deterministic policies are proper (and the discount factor γ = 1) and in the inﬁnite horizon\n",
      "discounted case (with γ < 1). That is, there exists a positive vector ξ and a scalar β ∈ [0, 1), such\n",
      "that for all t,\n",
      "\n",
      "||T Qt − Q∗||ξ ≤ β||Qt − Q∗||ξ,\n",
      "\n",
      "(16)\n",
      "\n",
      "where T is the operator\n",
      "\n",
      "(T Q)(s, a) = Xs′,N\n",
      "\n",
      "P (s′, N |s, a)γN [R(s′|s, a) + max\n",
      "\n",
      "a′\n",
      "\n",
      "Q(s′, a′)].\n",
      "\n",
      "Now we will show how to derive the contraction for the C update operator U . Our plan is to show\n",
      "ﬁrst how to express the U operator for learning C in terms of the T operator for updating Q values.\n",
      "Then we will replace T Q in the contraction equation for Q learning with U C, and show that U is\n",
      "a weighted max-norm contraction under the same weights ξ and the same β.\n",
      "\n",
      "Recall from Eqn. (10) that Q(i, s, a) = C(i, s, a)+V (a, s). Furthermore, the U operator performs\n",
      "its updates using the optimal value functions of the child nodes, so we can write this as Qt(i, s, a) =\n",
      "Ct(i, s, a) + V ∗(a, s). Now once the children of node i have converged, the Q-function version of\n",
      "the Bellman equation for MDP Mi can be written as\n",
      "\n",
      "Q(i, s, a) = Xs′,N\n",
      "\n",
      "r (s′, N |s, a)γN [V ∗\n",
      "P ∗\n",
      "\n",
      "r (a, s) + max\n",
      "\n",
      "a′\n",
      "\n",
      "Q(i, s′, a′)].\n",
      "\n",
      "As we have noted before, V ∗\n",
      "for node i, the T operator can be rewritten as\n",
      "\n",
      "r (a, s) plays the role of the immediate reward function for Mi. Therefore,\n",
      "\n",
      "(T Q)(i, s, a) = Xs′,N\n",
      "\n",
      "r (s′|s, a)γN [V ∗\n",
      "P ∗\n",
      "\n",
      "r (a, s) + max\n",
      "\n",
      "a′\n",
      "\n",
      "Q(i, s′, a′)].\n",
      "\n",
      "24\n",
      "\n",
      "\f",
      "Now we replace Q(i, s, a) by C(i, s, a) + V ∗\n",
      "\n",
      "r (a, s), and obtain\n",
      "\n",
      "(T Q)(i, s, a) = Xs′,N\n",
      "\n",
      "r (s′, N |s, a)γN (V ∗\n",
      "P ∗\n",
      "\n",
      "r (a, s) + max\n",
      "\n",
      "a′\n",
      "\n",
      "[C(i, s′, a′) + V ∗\n",
      "\n",
      "r (a′, s′)]).\n",
      "\n",
      "Note that V ∗\n",
      "obtain\n",
      "\n",
      "r (a, s) does not depend on s′ or N , so we can move it outside the expectation and\n",
      "\n",
      "(T Q)(i, s, a) = V ∗\n",
      "\n",
      "r (a, s) + Xs′,N\n",
      "\n",
      "= V ∗\n",
      "\n",
      "r (a, s) + (U C)(i, s, a)\n",
      "\n",
      "r (s′|s, a)γN (max\n",
      "P ∗\n",
      "a′\n",
      "\n",
      "[C(i, s′, a′) + V ∗\n",
      "\n",
      "r (a′, s′)])\n",
      "\n",
      "Abusing notation slightly, we will express this in vector form as T Q(i) = V ∗\n",
      "we can write Qt(i, s, a) = Ct(i, s, a) + V ∗\n",
      "\n",
      "r (a, s) in vector form as Qt(i) = Ct(i) + V ∗\n",
      "r .\n",
      "\n",
      "r + U C(i). Similarly,\n",
      "\n",
      "Now we can substitute these two formulas into the max norm pseudo-contraction formula for\n",
      "\n",
      "T , Eqn. (16) to obtain\n",
      "\n",
      "||V ∗\n",
      "\n",
      "r + U Ct(i) − (C ∗\n",
      "\n",
      "r (i) + V ∗\n",
      "\n",
      "r )||ξ ≤ β||V ∗\n",
      "\n",
      "r + Ct(i) − (V ∗\n",
      "\n",
      "r + C ∗\n",
      "\n",
      "r (i))||ξ.\n",
      "\n",
      "The V ∗ terms cancel on both sides of the equation, and we get\n",
      "\n",
      "||U Ct(i) − C ∗\n",
      "\n",
      "r (i)||ξ ≤ β||Ct(i) − C ∗\n",
      "\n",
      "r (i)||ξ.\n",
      "\n",
      "Finally, it is easy verify (e), the most important condition. By assumption, the ordered GLIE\n",
      "policies in the child nodes converge with probability 1 to locally optimal policies for the children.\n",
      "Therefore Pt(s′, N |s, a) converges to P ∗\n",
      "r (s′, N |s, a) for all s′, N, s, and a with probability 1 and\n",
      "Vt(a, s) converges with probability 1 to V ∗\n",
      "r (a, s) for all child actions a. Therefore, |ut| converges\n",
      "to zero with probability 1. We can trivially construct a sequence θt = |ut| that bounds this\n",
      "convergence, so\n",
      "\n",
      "|ut(s, a)| ≤ θt ≤ θt(||Ct(s, a)||ξ + 1).\n",
      "\n",
      "We have veriﬁed all of the conditions of Lemma 1, so we can conclude that Ct(i) converges to\n",
      "C ∗\n",
      "r (i) with probability 1. By induction, we can conclude that this holds for all nodes in the MAXQ\n",
      "including the root node, so the value function represented by the MAXQ graph converges to the\n",
      "unique value function of the recursively optimal policy π∗\n",
      "\n",
      "r . Q.E.D.\n",
      "\n",
      "Algorithm MAXQ-0 can be extended to accelerate learning in the higher nodes of the graph by\n",
      "a technique that we call “all states updating”. When an action a is chosen for Max node i in state s,\n",
      "the execution of a will move the environment through a sequence of states s = s1, . . . , sN , sN +1 = s′.\n",
      "If a was indeed the best abstract action to choose in s1, then it should also be the best action to\n",
      "choose (at node i) in states s2 through sN . Hence, we can execute a version of line 12 in MAXQ-0\n",
      "for each of these intermediate states as shown in this replacement pseudo-code:\n",
      "\n",
      "12a\n",
      "12b\n",
      "12c\n",
      "\n",
      "for j from 1 to N do\n",
      "\n",
      "Ct+1(i, sj, a) := (1 − αt(i)) · Ct(i, sj, a) + αt(i) · γ(N +1−j)maxa′ Qt(i, s′, a′)\n",
      "end // for\n",
      "\n",
      "In our implementation, as each composite action is executed by MAXQ-0, it constructs a linked\n",
      "list of the sequence of primitive states that were visited. This list is returned when the composite\n",
      "action terminates. The parent Max node can then process each state in this list as shown above.\n",
      "The parent Max node appends the state lists that it receives from its children and passes them to\n",
      "its parent when it terminates. All experiments in this paper employ all states updating.\n",
      "\n",
      "25\n",
      "\n",
      "\f",
      "Kaelbling (1993) introduced a related, but more powerful, method for accelerating hierarchical\n",
      "reinforcement learning that she calls “all goals updating.” This method is suitable for a MAXQ\n",
      "hierarchy containing only a root task and one level of composite tasks. To understand all goals\n",
      "updating, suppose that for each primitive action, there are several composite tasks that could have\n",
      "invoked that primitive action. In all goals updating, whenever a primitive action is executed, the\n",
      "equivalent of line 12 of MAXQ-0 is applied in every composite task that could have invoked that\n",
      "primitive action. Sutton, Precup, and Singh (1998) prove that each of the composite tasks will\n",
      "converge to the optimal Q values under all goals updating.\n",
      "\n",
      "All goals updating would work in the MAXQ hierarchy for composite tasks all of whose children\n",
      "are primitive actions. However, as we have seen, at higher levels in the hierarchy, node i needs to\n",
      "obtain samples of result states drawn according to P ∗(s′, N |s, a) for composite tasks a. All goals\n",
      "updating cannot provide these samples, so it cannot be applied at these higher levels.\n",
      "\n",
      "Now that we have shown the convergence of MAXQ-0, let us design a learning algorithm for\n",
      "arbitrary pseudo-reward functions, ˜Ri(s). We could just add the pseudo-reward into MAXQ-0,\n",
      "but this has the eﬀect of changing the MDP M to have a diﬀerent reward function. The pseudo-\n",
      "rewards “contaminate” the values of all of the completion functions computed in the hierarchy.\n",
      "The resulting learned policy will not be recursively optimal for the original MDP.\n",
      "\n",
      "This problem can be solved by learning two completion functions. The ﬁrst one, C(i, s, a) is the\n",
      "completion function that we have been discussing so far in this paper. It computes the expected\n",
      "reward for completing task Mi after performing action a in state s and then following the learned\n",
      "policy for Mi. It is computed without any reference to ˜Ri. This completion function will be used\n",
      "by parent tasks to compute V (i, s), the expected reward for performing action i starting in state s.\n",
      "The second completion function ˜C(i, s, a) is a completion function that we will use only “inside”\n",
      "node i in order to discover the locally optimal policy for task Mi. This function will incorporate\n",
      "rewards both from the “real” reward function, R(s′|s, a) and from the pseudo-reward function\n",
      "˜Ri(s).\n",
      "\n",
      "We will employ two diﬀerent update rules to learn these two completion functions. The ˜C\n",
      "function will be learned using an update rule similar to the Q learning rule in line 12 of MAXQ-0.\n",
      "But the C function will be learned using an update rule similar to SARSA(0)—its purpose is to\n",
      "learn the value function for the policy that is discovered by optimizing ˜C. Pseudo-code for the\n",
      "resulting algorithm, MAXQ-Q is shown in Table 4.\n",
      "\n",
      "The key step is at lines 16 and 17. In line 16, MAXQ-Q ﬁrst updates ˜C using the value of the\n",
      "greedy action, a∗, in the resulting state. This update includes the pseudo-reward ˜Ri. Then in line\n",
      "17, MAXQ-Q updates C using this same greedy action a∗, even if this would not be the greedy\n",
      "action according to the “uncontaminated” value function. This update, of course, does not include\n",
      "the pseudo-reward function.\n",
      "\n",
      "It is important to note that whereever Vt(a, s) appears in this pseudo-code, it refers to the\n",
      "“uncontaminated” value function of state s when executing the Max node a. This is computed\n",
      "recursively in exactly the same way as in MAXQ-0.\n",
      "\n",
      "Finally, note that the pseudo-code also incorporates all-states updating, so each call to MAXQ-\n",
      "Q returns a list of all of the states that were visited during its execution, and the updates of lines\n",
      "16 and 17 are performed for each of those states. The list of states is ordered most-recent-ﬁrst, so\n",
      "the states are updated starting with the last state visited and working backward to the starting\n",
      "state, which helps speed up the algorithm.\n",
      "\n",
      "When MAXQ-Q has converged, the resulting recursively optimal policy is computed at each\n",
      "node by choosing the action a that maximizes ˜Q(i, s, a) = ˜C(i, s, a)+V (a, s) (breaking ties according\n",
      "to the ﬁxed ordering established by the ordered GLIE policy). It is for this reason that we gave the\n",
      "name “Max nodes” to the nodes that represent subtasks (and learned policies) within the MAXQ\n",
      "\n",
      "26\n",
      "\n",
      "\f",
      "Table 4: The MAXQ-Q learning algorithm.\n",
      "\n",
      "function MAXQ-Q(MaxNode i, State s)\n",
      "\n",
      "let seq = () be the sequence of states visited while executing i\n",
      "if i is a primitive MaxNode\n",
      "\n",
      "execute i, receive r, and observe result state s′\n",
      "Vt+1(i, s) := (1 − αt(i)) · Vt(i, s) + αt(i) · rt\n",
      "push s into the beginning of seq\n",
      "\n",
      "else\n",
      "\n",
      "let count = 0\n",
      "while Ti(s) is false do\n",
      "\n",
      "choose an action a according to the current exploration policy πx(i, s)\n",
      "let childSeq = MAXQ-Q(a, s), where childSeq is the sequence of states visited\n",
      "\n",
      "while executing action a.\n",
      "\n",
      "observe result state s′\n",
      "let a∗ = argmaxa′ [ ˜Ct(i, s′, a′) + Vt(a′, s′)]\n",
      "let N = length(childSeq)\n",
      "for each s in childSeq do\n",
      "\n",
      "˜Ct+1(i, s, a) := (1 − αt(i)) · ˜Ct(i, s, a) + αt(i) · γN [ ˜Ri(s′) + ˜Ct(i, s′, a∗) + Vt(a∗, s)]\n",
      "Ct+1(i, s, a) := (1 − αt(i)) · Ct(i, s, a) + αt(i) · γN [Ct(i, s′, a∗) + Vt(a∗, s′)]\n",
      "N := N − 1\n",
      "end // for\n",
      "\n",
      "append childSeq onto the front of seq\n",
      "s := s′\n",
      "end // while\n",
      "\n",
      "end // else\n",
      "\n",
      "return seq\n",
      "end MAXQ-0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "\n",
      "graph. Each Q node j with parent node i stores both ˜C(i, s, j) and C(i, s, j), and it computes both\n",
      "˜Q(i, s, j) and Q(i, s, j) by invoking its child Max node j. Each Max node i takes the maximum of\n",
      "these Q values and computes either V (i, s) or computes the best action, a∗ using ˜Q.\n",
      "\n",
      "Corollary 1 Under the same conditions as Theorem 3, MAXQ-Q converges the unique recursively\n",
      "optimal policy for MDP M deﬁned by MAXQ graph H, pseudo-reward functions ˜R, and ordered\n",
      "GLIE exploration policy πx.\n",
      "\n",
      "Proof: The argument is identical to, but more tedious than, the proof of Theorem 3. The proof\n",
      "of convergence of the ˜C values is identical to the original proof for the C values, but it relies on\n",
      "proving convergence of the “new” C values as well, which follows from the same weighted max\n",
      "norm pseudo-contraction argument. Q.E.D.\n",
      "\n",
      "5 State Abstraction\n",
      "\n",
      "There are many reasons to introduce hierarchical reinforcement learning, but perhaps the most\n",
      "important reason is to create opportunities for state abstraction. When we introduced the simple\n",
      "taxi problem in Figure 1, we pointed out that within each subtask, we can ignore certain aspects of\n",
      "the state space. For example, while performing a MaxNavigate(t), the taxi should make the same\n",
      "navigation decisions regardless of whether the passenger is in the taxi. The purpose of this section\n",
      "is to formalize the conditions under which it is safe to introduce such state abstractions and to show\n",
      "\n",
      "27\n",
      "\n",
      "\f",
      "how the convergence proofs for MAXQ-Q can be extended to prove convergence in the presence of\n",
      "state abstraction. Speciﬁcally, we will identify ﬁve conditions that permit the “safe” introduction\n",
      "of state abstractions.\n",
      "\n",
      "Throughout this section, we will use the taxi problem as a running example, and we will see\n",
      "how each of the ﬁve conditions will permit us to reduce the number of distinct values that must\n",
      "be stored in order to represent the MAXQ value function decomposition. To establish a starting\n",
      "point, let us compute the number of values that must be stored for the taxi problem without any\n",
      "state abstraction.\n",
      "\n",
      "The MAXQ representation must have tables for each of the C functions at the internal nodes\n",
      "and the V functions at the leaves. First, at the six leaf nodes, to store V (i, s), we must store\n",
      "500 values at each node (because there are 500 states; 25 locations, 4 possible destinations for the\n",
      "passenger, and 5 possible current locations for the passenger (the four special locations and inside\n",
      "the taxi itself)). Second, at the root node, there are two children, which requires 2 × 500 = 1000\n",
      "values. Third, at the MaxGet and MaxPut nodes, we have 2 actions each, so each one requires\n",
      "1000 values, for a total of 2000. Finally, at MaxNavigate(t), we have four actions, but now we\n",
      "must also consider the target parameter t, which can take four possible values. Hence, there are\n",
      "eﬀectively 2000 combinations of states and t values for each action, or 8000 total values that must\n",
      "be represented. In total, therefore, the MAXQ representation requires 14,000 separate quantities\n",
      "to represent the value function.\n",
      "\n",
      "To place this number in perspective, consider that a ﬂat Q learning representation must store a\n",
      "separate value for each of the six primitive actions in each of the 500 possible states, for a total of\n",
      "3,000 values. Hence, we can see that without state abstraction, the MAXQ representation requires\n",
      "more than four times the memory of a ﬂat Q table!\n",
      "\n",
      "5.1 Five Conditions that Permit State Abstraction\n",
      "\n",
      "We now introduce ﬁve conditions that permit the introduction of state abstractions. For each\n",
      "condition, we give a deﬁnition and then prove a lemma which states that if the condition is satisﬁed,\n",
      "then the value function for some corresponding class of policies can be represented abstractly (i.e.,\n",
      "by abstract versions of the V and C functions). For each condition, we then provide some rules for\n",
      "identifying when that condition can be satisﬁed and give examples from the taxi domain.\n",
      "\n",
      "We begin by introducing some deﬁnitions and notation.\n",
      "\n",
      "Deﬁnition 10 Let M be a MDP and H be a MAXQ graph deﬁned over M . Suppose that each state\n",
      "s can be written as a vector of values of a set of state variables. At each Max node i, suppose the\n",
      "state variables are partitioned into two sets Xi and Yi, and let χi be a function that projects a state\n",
      "s onto only the values of the variables in Xi. Then H combined with χi is called a state-abstracted\n",
      "MAXQ graph.\n",
      "\n",
      "In cases where the state variables can be partitioned, we will often write s = (x, y) to mean\n",
      "that a state s is represented by a vector of values for the state variables in X and a vector of values\n",
      "for the state variables in Y . Similarly, we will sometimes write P (x′, y′, N |x, y, a), V (a, x, y), and\n",
      "˜Ra(x′, y′) in place of P (s′, N |s, a), V (a, s), and ˜Ra(s′), respectively.\n",
      "\n",
      "Deﬁnition 11 An abstract hierarchical policy for MDP M with state-abstracted MAXQ graph H\n",
      "and associated abstraction functions χi, is a hierarchical policy in which each policy πi (correspond-\n",
      "ing to subtask Mi) satisﬁes the condition that for any two states s1 and s2 such that χi(s1) = χi(s2),\n",
      "πi(s1) = πi(s2). (When πi is a stationary stochastic policy, this is interpreted to mean that the prob-\n",
      "ability distributions for choosing actions are the same in both states.)\n",
      "\n",
      "28\n",
      "\n",
      "\f",
      "In order for MAXQ-Q to converge in the presence of state abstractions, we will require that\n",
      "at all times t its (instantaneous) exploration policy is an abstract hierarchical policy. One way to\n",
      "achieve this is to construct the exploration policy so that it only uses information from the relevant\n",
      "state variables in deciding what action to perform. Boltzmann exploration based on the (state-\n",
      "abstracted) Q values, ǫ-greedy exploration, and counter-based exploration based on abstracted\n",
      "states are all abstract exploration policies. Counter-based exploration based on the full state space\n",
      "is not an abstract exploration policy.\n",
      "\n",
      "Now that we have introduced our notation, let us describe and analyze the ﬁve abstraction\n",
      "conditions. We have identiﬁed three diﬀerent kinds of conditions under which abstractions can be\n",
      "introduced. The ﬁrst kind involves eliminating irrelevant variables within a subtask of the MAXQ\n",
      "graph. Under this form of abstraction, nodes toward the leaves of the MAXQ graph tend to have\n",
      "very few relevant variables, and nodes higher in the graph have more relevant variables. Hence,\n",
      "this kind of abstraction is most useful at the lower levels of the MAXQ graph.\n",
      "\n",
      "The second kind of abstraction arises from “funnel” actions. These are macro actions that move\n",
      "the environment from some large number of initial states to a small number of resulting states.\n",
      "The completion cost of such subtasks can be represented using a number of values proportional to\n",
      "the number of resulting states. Funnel actions tend to appear higher in the MAXQ graph, so this\n",
      "form of abstraction is most useful near the root of the graph.\n",
      "\n",
      "The third kind of abstraction arises from the structure of the MAXQ graph itself. It exploits\n",
      "the fact that large parts of the state space for a subtask may not be reachable because of the\n",
      "termination conditions of its ancestors in the MAXQ graph.\n",
      "\n",
      "We begin by describing two abstraction conditions of the ﬁrst type. Then we will present two\n",
      "\n",
      "conditions of the second type. And ﬁnally, we describe one condition of the third type.\n",
      "\n",
      "5.1.1 Condition 1: Max Node Irrelevance\n",
      "\n",
      "The ﬁrst condition arises when a set of state variables is irrelevant to a Max node.\n",
      "\n",
      "Deﬁnition 12 Let Mi be a Max node in a MAXQ graph H for MDP M . A set of state variables\n",
      "Y is irrelevant to node i if the state variables of M can be partitioned into two sets X and Y such\n",
      "that for any stationary abstract hierarchical policy π executed by the descendants of i, the following\n",
      "two properties hold:\n",
      "\n",
      "• the state transition probability distribution P π(s′, N |s, a) at node i can be factored into the\n",
      "\n",
      "product of two distributions:\n",
      "\n",
      "P π(x′, y′, N |x, y, a) = P π(y′|y, a) · P π(x′, N |x, a),\n",
      "\n",
      "(17)\n",
      "\n",
      "where y and y′ give values for the variables in Y , and x and x′ give values for the variables\n",
      "in X.\n",
      "\n",
      "• for any pair of states s1 = (x, y1) and s2 = (x, y2) such that χ(s1) = χ(s2) = x, and any child\n",
      "\n",
      "action a, V π(a, s1) = V π(a, s2) and ˜Ri(s1) = ˜Ri(s2).\n",
      "\n",
      "Lemma 2 Let M be an MDP with full-state MAXQ graph H, and suppose that state variables Yi\n",
      "are irrelevant for Max node i. Let χi(s) = x be the associated abstraction function that maps s onto\n",
      "the remaining relevant variables Xi. Let π be any abstract hierarchical policy. Then the action-\n",
      "value function Qπ at node i can be represented compactly, with only one value of the completion\n",
      "\n",
      "29\n",
      "\n",
      "\f",
      "function C π(i, s, j) for each equivalence class of states s that share the same values on the relevant\n",
      "variables.\n",
      "\n",
      "Speciﬁcally Qπ(i, s, j) can be computed as follows:\n",
      "\n",
      "Qπ(i, s, j) = V π(j, χi(s)) + C π(i, χi(s), j)\n",
      "\n",
      "where\n",
      "\n",
      "C π(i, x, j) = Xx′,N\n",
      "\n",
      "P π(x′, N |x, j) · γN [V π(π(x′), x′) + ˜Ri(x′) + C π(i, x′, π(x′))],\n",
      "\n",
      "where V π(j ′, x′) = V π(j ′, x′, y0), ˜Ri(x′) = ˜Ri(x′, y0), and π(x) = π(x, y0) for some arbitrary value\n",
      "y0 for the irrelevant state variables Yi.\n",
      "\n",
      "Proof: Deﬁne a new MDP χi(Mi) at node i as follows:\n",
      "\n",
      "• States: X = {x | χi(s) = x, for some s ∈ S}.\n",
      "\n",
      "• Actions: A.\n",
      "\n",
      "• Transition probabilities: P π(x′, N |x, a)\n",
      "\n",
      "• Reward function: V π(a, x) + ˜Ri(x′)\n",
      "\n",
      "Because π is an abstract policy, its decisions are the same for all states s such that χi(s) = x for\n",
      "some x. Therefore, it is also a well-deﬁned policy over χi(Mi). The action-value function for π over\n",
      "χi(Mi) is the unique solution to the following Bellman equation:\n",
      "\n",
      "Qπ(i, x, j) = V π(j, x) + Xx′,N\n",
      "\n",
      "P π(x′, N |x, j) · γN [ ˜Ri(x′) + Qπ(i, x′, π(x′))]\n",
      "\n",
      "(18)\n",
      "\n",
      "Compare this to the Bellman equation over Mi:\n",
      "\n",
      "Qπ(i, s, j) = V π(j, s) + Xs′,N\n",
      "\n",
      "P π(s′, N |s, j) · γN [ ˜Ri(s′) + Qπ(i, s′, π(s′))]\n",
      "\n",
      "(19)\n",
      "\n",
      "and note that V π(j, s) = V π(j, χ(s)) = V π(j, x) and ˜Ri(s′) = ˜Ri(χ(s′)) = ˜Ri(x′). Furthermore, we\n",
      "know that the distribution P π can be factored into separate distributions for Yi and Xi. Hence, we\n",
      "can rewrite (19) as\n",
      "\n",
      "Qπ(i, s, j) = V π(j, x) +Xy′\n",
      "\n",
      "P (y′|y, j) Xx′,N\n",
      "\n",
      "P π(x′, N |x, j) · γN [ ˜Ri(x′) + Qπ(i, s′, π(s′))]\n",
      "\n",
      "The right-most sum does not depend on y or y′, so the sum over y′ evaluates to 1, and can be\n",
      "eliminated to give\n",
      "\n",
      "Qπ(i, s, j) = V π(j, x) + Xx′,N\n",
      "\n",
      "P π(x′, N |x, j) · γN [ ˜Ri(x′) + Qπ(i, s′, π(s′))].\n",
      "\n",
      "(20)\n",
      "\n",
      "Finally, note that equations (18) and (20) are identical except for the expressions for the Q\n",
      "\n",
      "values. Since the solution to the Bellman equation is unique, we must conclude that\n",
      "\n",
      "Qπ(i, s, j) = Qπ(i, χ(s), j).\n",
      "\n",
      "30\n",
      "\n",
      "\f",
      "We can rewrite the right-hand side to obtain\n",
      "\n",
      "Qπ(i, s, j) = V π(j, χ(s)) + C π(i, χ(s), j),\n",
      "\n",
      "where\n",
      "\n",
      "Q.E.D.\n",
      "\n",
      "C π(i, x, j) = Xx′,N\n",
      "\n",
      "P (x′, N |x, j) · γN [V π(π(x′), x′) + ˜Ri(x′) + C π(i, x′, π(x′))].\n",
      "\n",
      "Of course we are primarily interested in being able to discover and represent the optimal policy\n",
      "at each node i. The following corollary shows that the optimal policy is an abstract policy, and\n",
      "hence, that it can be represented abstractly.\n",
      "\n",
      "Corollary 2 Consider the same conditions as Lemma 2, but with the change that the abstract\n",
      "hierarchical policy π is executed only by the descendants of node i, but not by node i. Let ρ be an\n",
      "ordering over actions. Then the optimal ordered policy π∗\n",
      "ρ at node i is an abstract policy, and its\n",
      "action-value function can be represented abstracted.\n",
      "\n",
      "Proof: Deﬁne the policy ω∗\n",
      "ρ to be the optimal ordered policy over the abstract MDP χ(M ), and\n",
      "let Q∗(i, x, j) be the corresponding optimal action-value function. Then by the same argument given\n",
      "above, Q∗ is also a solution to the optimal Bellman equation for the original MDP. This means\n",
      "that the policy π∗\n",
      "ρ deﬁned by π∗\n",
      "ρ(s) = ω∗(χ(s)) is an optimal ordered policy, and by construction,\n",
      "it is an abstract policy. Q.E.D.\n",
      "\n",
      "As stated, this condition appears quite diﬃcult to satisfy, since it requires that the state transi-\n",
      "tion probability distribution factor into X and Y components for all possible abstract hierarchical\n",
      "policies. However, in practice, this condition is often satisﬁed.\n",
      "\n",
      "For example, let us consider the Navigate(t) subtask. The source and destination of the passenger\n",
      "are irrelevant to the achievement of this subtask. Any policy that successfully completes this subtask\n",
      "will have the same value function regardless of the source and destination locations of the passenger.\n",
      "(Any policy that does not complete the subtask will have the same value function also, but all states\n",
      "will have a value of −∞.) By abstracting away the passenger source and destination, we obtain a\n",
      "huge savings in space. Instead of requiring 8000 values to represent the C functions for this task,\n",
      "we require only 400 values (4 actions, 25 locations, 4 possible values for t).\n",
      "\n",
      "One rule for noticing cases where this abstraction condition holds is to examine the subgraph\n",
      "rooted at the given Max node i. If a set of state variables is irrelevant to the leaf state transi-\n",
      "tion probabilities and reward functions and also to all pseudo-reward functions and termination\n",
      "conditions in the subgraph, then those variables satisfy the Max Node Irrelevance condition:\n",
      "\n",
      "Lemma 3 Let M be an MDP with associated MAXQ graph H, and let i be a Max node in H. Let\n",
      "Xi and Yi be a partition of the state variables for M . A set of state variables Yi is irrelevant to\n",
      "node i if\n",
      "\n",
      "• For each primitive leaf node a that is a descendant of i, P (x′, y′|x, y, a) = P (y′|y, a)P (x′|x, a)\n",
      "\n",
      "and R(x′, y′|x, y, a) = R(x′|x, a),\n",
      "\n",
      "• For each internal node j that is equal to node i or is a descendent of i , ˜Rj(x′, y′) = ˜Rj(x′)\n",
      "\n",
      "and the termination predicate Tj(x′, y′) is true iﬀ Tj(x′).\n",
      "\n",
      "31\n",
      "\n",
      "\f",
      "Proof: We must show that any abstract hierarchical policy will give rise to an SMDP at node i\n",
      "whose transition probability distribution factors and whose reward function depends only on Xi.\n",
      "By deﬁnition, any abstract hierarchical policy will choose actions based only upon information in\n",
      "Xi. Because the primitive probability transition functions factor into an independent component\n",
      "for Xi and since the termination conditions at all nodes below i are based only on the variables\n",
      "in Xi, the probability transition function Pi(x′, y′, N |x, y, a) must also factor into Pi(y′|y, a) and\n",
      "Pi(x′, N |x, a). Similarly, all of the reward functions V (j, x, y) must be equal to V (j, x), because all\n",
      "rewards received within the subtree (either at the leaves or through pseudo-rewards) depend only\n",
      "on the variables in Xi. Therefore, the variables in Yi are irrelevant for Max node i. Q.E.D.\n",
      "\n",
      "In the Taxi task, the primitive navigation actions, North, South, East, and West only depend on\n",
      "the location of the taxi and not on the location of the passenger. The pseudo-reward function and\n",
      "termination condition for the MaxNavigate(t) node only depend on the location of the taxi (and the\n",
      "parameter t). Hence, this lemma applies, and the passenger source and destination are irrelevant\n",
      "for the MaxNavigate node.\n",
      "\n",
      "5.1.2 Condition 2: Leaf Irrelevance\n",
      "\n",
      "The second abstraction condition describes situations under which we can apply state abstractions\n",
      "to leaf nodes of the MAXQ graph. For leaf nodes, we can obtain a stronger result than Lemma 2\n",
      "by using a slightly weaker deﬁnition of irrelevance.\n",
      "\n",
      "Deﬁnition 13 (Leaf Irrelevance) A set of state variables Y is irrelevant for a primitive action\n",
      "a of a MAXQ graph if for all states s the expected value of the reward function,\n",
      "\n",
      "V (a, s) = Xs′\n",
      "\n",
      "P (s′|s, a)R(s′|s, a)\n",
      "\n",
      "does not depend on any of the values of the state variables in Y . In other words, for any pair of\n",
      "states s1 and s2 that diﬀer only in their values for the variables in Y ,\n",
      "\n",
      "Xs′\n",
      "\n",
      "1\n",
      "\n",
      "P (s′\n",
      "\n",
      "1|s1, a)R(s′\n",
      "\n",
      "1|s1, a) = Xs′\n",
      "\n",
      "2\n",
      "\n",
      "P (s′\n",
      "\n",
      "2|s2, a)R(s′\n",
      "\n",
      "2|s2, a).\n",
      "\n",
      "If this condition is satisﬁed at leaf a, then the following lemma shows that we can represent its\n",
      "\n",
      "value function V (a, s) compactly.\n",
      "\n",
      "Lemma 4 Let M be an MDP with full-state MAXQ graph H, and suppose that state variables Y\n",
      "are irrelevant for leaf node a. Let χ(s) = x be the associated abstraction function that maps s onto\n",
      "the remaining relevant variables X. Then we can represent V (a, s) for any state s by an abstracted\n",
      "value function V (a, χ(s)) = V (a, x).\n",
      "\n",
      "Proof: According to the deﬁnition of Leaf Irrelevance, any two states that diﬀer only on the\n",
      "irrelevant state variables have the same value for V (a, s). Hence, we can represent this unique\n",
      "value by V (a, x). Q.E.D.\n",
      "\n",
      "Here are two rules for ﬁnding cases where Leaf Irrelevance applies. The ﬁrst rule shows that if\n",
      "\n",
      "the probability distribution factors, then we have Leaf Irrelevance.\n",
      "\n",
      "Lemma 5 Suppose the probability transition function for primitive action a, P (s′|s, a), factors\n",
      "as P (x′, y′|x, y, a) = P (y′|y, a)P (x′|x, a) and the reward function satisﬁes R(s′|s, a) = R(x′|x, a).\n",
      "Then the variables in Y are irrelevant to the leaf node a.\n",
      "\n",
      "32\n",
      "\n",
      "\f",
      "Proof: Plug in to the deﬁnition of V (a, s) and simplify.\n",
      "\n",
      "V (a, s) = Xs′\n",
      "= Xx′,y′\n",
      "= Xy′\n",
      "= Xx′\n",
      "\n",
      "P (s′|s, a)R(s′|s, a)\n",
      "\n",
      "P (y′|y, a)P (x′|x, a)R(x′|x, a)\n",
      "\n",
      "P (x′|x, a)R(x′|x, a)\n",
      "\n",
      "P (y′|y, a)Xx′\n",
      "\n",
      "P (x′|x, a)R(x′|x, a)\n",
      "\n",
      "Hence, the expected reward for the action a depends only on the variables in X and not on the\n",
      "variables in Y . Q.E.D.\n",
      "\n",
      "Lemma 6 Let R(s′|s, a) = ra be the reward function for action a in MDP M , which is always\n",
      "equal to a constant ra. Then the entire state s is irrelevant to the primitive action a.\n",
      "\n",
      "Proof:\n",
      "\n",
      "V (a, s) = Xs′\n",
      "= Xs′\n",
      "\n",
      "= ra.\n",
      "\n",
      "P (s′|s, a)R(s′|s, a)\n",
      "\n",
      "P (s′|s, a)ra\n",
      "\n",
      "This does not depend on s, so the entire state is irrelevant to the primitive action a. Q.E.D.\n",
      "\n",
      "This lemma is satisﬁed by the four leaf nodes North, South, East, and West in the taxi task,\n",
      "because their one-step reward is a constant (−1). Hence, instead of requiring 2000 values to store\n",
      "the V functions, we only need 4 values—one for each action. Similarly, the expected rewards of the\n",
      "Pickup and Putdown actions each require only 2 values, depending on whether the corresponding\n",
      "actions are legal or illegal. Hence, together, they require 4 values, instead of 1000 values.\n",
      "\n",
      "5.1.3 Condition 3: Result Distribution Irrelevance\n",
      "\n",
      "Now we consider a condition that results from “funnel” actions.\n",
      "\n",
      "Deﬁnition 14 (Result Distribution Irrelevance). A set of state variables Yj is irrelevant for\n",
      "the result distribution of action j if, for all abstract policies π executed by node j and its descendants\n",
      "in the MAXQ hierarchy, the following holds:\n",
      "for all pairs of states s1 and s2 that diﬀer only in\n",
      "their values for the state variables in Yj,\n",
      "\n",
      "for all s′ and N .\n",
      "\n",
      "P π(s′, N |s1, j) = P π(s′, N |s2, j)\n",
      "\n",
      "Lemma 7 Let M be an MDP with full-state MAXQ graph H, and suppose that the set of state\n",
      "variables Yj is irrelevant to the result distribution of action j, which is a child of Max node i. Let\n",
      "χij be the associated abstraction function: χij(s) = x. Then we can deﬁne an abstract completion\n",
      "cost function C π(i, χij(s), j) such that for all states s,\n",
      "\n",
      "C π(i, s, j) = C π(i, χij (s), j).\n",
      "\n",
      "33\n",
      "\n",
      "\f",
      "Proof: The completion function for ﬁxed policy π is deﬁned as follows:\n",
      "\n",
      "C π(i, s, j) = Xs′,N\n",
      "\n",
      "P (s′, N |s, j) · γN [ ˜Ri(s′) + Qπ(i, s′)].\n",
      "\n",
      "(21)\n",
      "\n",
      "Consider any two states s1 and s2, such that χij(s1) = χij(s2) = x. Under Result Distribution\n",
      "Irrelevance, their transition probability distributions are the same. Hence, the right-hand sides of\n",
      "(21) have the same value, and we can conclude that\n",
      "\n",
      "C π(i, s1, j) = C π(i, s2, j).\n",
      "\n",
      "Therefore, we can deﬁne an abstract completion function, C π(i, x, j) to represent this quantity.\n",
      "Q.E.D.\n",
      "\n",
      "It might appear that this condition would rarely be satisﬁed, and indeed, for inﬁnite horizon\n",
      "discounted problems, this is true. Consider, for example, the Get subroutine under an optimal\n",
      "policy for the taxi task. No matter what location that taxi has in state s, the taxi will be at the\n",
      "passenger’s starting location when the Get ﬁnishes executing (i.e., because the taxi will have just\n",
      "completed picking up the passenger). Hence, the starting location is irrelevant to the resulting\n",
      "location of the taxi. In the discounted cumulative reward setting, however, the number of steps\n",
      "N required to complete the Get action will depend very much on the starting location of the taxi.\n",
      "Consequently, P (s′, N |s, a) is not necessarily the same for any two states s with diﬀerent starting\n",
      "locations even though s′ is always the same.\n",
      "\n",
      "The important lesson to draw from this is that discounting interferes with introducing state\n",
      "abstractions based on “funnel” operators—the MAXQ framework is therefore less eﬀective when\n",
      "applied in the discounted setting.\n",
      "\n",
      "However, if we restrict attention to the episodic, undiscounted setting, then the result dis-\n",
      "tribution, P (s′|s, a), no longer depends on N , and the Result Distribution Irrelevance condition\n",
      "is satisﬁed. Fortunately, the Taxi task is an undiscounted, ﬁnite-horizon task, so we can repre-\n",
      "sent C(Root, s, Get) using 16 distinct values, because there are 16 equivalence classes of states (4\n",
      "source locations times 4 destination locations). This is much less than the 500 quantities in the\n",
      "unabstracted representation.\n",
      "\n",
      "“Funnel” actions arise in many hierarchical reinforcement learning problems. For example,\n",
      "abstract actions that move a robot to a doorway or that move a car onto the entrance ramp of a\n",
      "freeway have this property. The Result Distribution Irrelevance condition is applicable in all such\n",
      "situations as long as we are in the undiscounted setting.\n",
      "\n",
      "5.1.4 Condition 4: Termination\n",
      "\n",
      "The fourth condition is closely related to the “funnel’ property.\n",
      "It applies when a subtask is\n",
      "guaranteed to cause its parent task to terminate in a goal state. In a sense, the subtask is funneling\n",
      "the environment into the set of states described by the goal predicate of the parent task.\n",
      "\n",
      "Lemma 8 (Termination). Let Mi be a task in a MAXQ graph such that for all states s where\n",
      "the goal predicate Gi(s) is true, the pseudo-reward function ˜Ri(s) = 0. Suppose there is a child task\n",
      "a and state s such that for all hierarchical policies π,\n",
      "\n",
      "∀ s′ P π\n",
      "\n",
      "i (s′, N |s, a) > 0 ⇒ Gi(s′).\n",
      "\n",
      "(i.e., if s′ is a possible result state of applying a in s, then s′ is a goal terminal state for task i.)\n",
      "\n",
      "Then for any policy executed at node i, the completion cost C(i, s, a) is zero and does not need\n",
      "\n",
      "to be explicitly represented.\n",
      "\n",
      "34\n",
      "\n",
      "\f",
      "Proof: By the assumptions in the lemma, with probability 1 the completion cost is zero for any\n",
      "action that results in a goal terminal state. Q.E.D.\n",
      "\n",
      "For example, in the Taxi task, in all states where the taxi is holding the passenger, the Put\n",
      "subroutine will succeed and result in a goal terminal state for Root. This is because the termination\n",
      "predicate for Put (i.e., that the passenger is at his or her destination location) implies the goal\n",
      "condition for Root (which is the same). This means that C(Root, s, Put) is uniformly zero, for all\n",
      "states s where Put is not terminated.\n",
      "\n",
      "It is easy to detect cases where the Termination condition is satisﬁed. We only need to compare\n",
      "the termination predicate of a subtask with the goal predicate of the parent task. If the ﬁrst implies\n",
      "the second, then the termination condition is satisﬁed.\n",
      "\n",
      "5.1.5 Condition 5: Shielding\n",
      "\n",
      "The shielding condition arises from the structure of the MAXQ graph.\n",
      "\n",
      "Lemma 9 (Shielding). Let Mi be a task in a MAXQ graph and s be a state such that for all\n",
      "paths from the root of the graph down to node Mi there exists a subtask j (possibly equal to i) whose\n",
      "termination predicate Tj(s) is true, then the Q nodes of Mi do not need to represent C values for\n",
      "state s.\n",
      "\n",
      "Proof: Task i cannot be executed in state s, so no C values need to be estimated. Q.E.D.\n",
      "\n",
      "As with the Termination condition, the Shielding condition can be veriﬁed by analyzing the\n",
      "\n",
      "structure of the MAXQ graph and identifying nodes whose ancestor tasks are terminated.\n",
      "\n",
      "In the Taxi task, a simple example of this arises in the Put task, which is terminated in all states\n",
      "where the passenger is not in the taxi. This means that we do not need to represent C(Root, s, Put)\n",
      "in these states. The result is that, when combined with the Termination condition above, we do\n",
      "not need to explcitly represent the completion function for Put at all!\n",
      "\n",
      "5.1.6 Dicussion\n",
      "\n",
      "By applying these ﬁve abstraction conditions, we obtain the following “safe” state abstractions for\n",
      "the Taxi task:\n",
      "\n",
      "• North, South, East, and West. These terminal nodes require one quantity each, for a total of\n",
      "\n",
      "four values. (Leaf Irrelevance).\n",
      "\n",
      "• Pickup and Putdown each require 2 values (legal and illegal states), for a total of four. (Leaf\n",
      "\n",
      "Irrelevance.)\n",
      "\n",
      "• QNorth(t), QSouth(t), QEast(t), and QWest(t) each require 100 values (four values for t and\n",
      "\n",
      "25 locations). (Max Node Irrelevance.)\n",
      "\n",
      "• QNavigateForGet requires 4 values (for the four possible source locations). (The passenger\n",
      "destination is Max Node Irrelevant for MaxGet, and the taxi starting location is Result Dis-\n",
      "tribution Irrelevant for the Navigate action.)\n",
      "\n",
      "• QPickup requires 100 possible values, 4 possible source locations and 25 possible taxi locations.\n",
      "\n",
      "(Passenger destination is Max Node Irrelevant to MaxGet.)\n",
      "\n",
      "35\n",
      "\n",
      "\f",
      "• QGet requires 16 possible values (4 source locations, 4 destination locations). (Result Distri-\n",
      "\n",
      "bution Irrelevance.)\n",
      "\n",
      "• QNavigateForPut requires only 4 values (for the four possible destination locations). (The\n",
      "passenger source and destination are Max Node Irrelevant to MaxPut; the taxi location is\n",
      "Result Distribution Irrelevant for the Navigate action.)\n",
      "\n",
      "• QPutdown requires 100 possible values (25 taxi locations, 4 possible destination locations).\n",
      "\n",
      "(Passenger source is Max Node Irrelevant for MaxPut.)\n",
      "\n",
      "• QPut requires 0 values. (Termination and Shielding.)\n",
      "\n",
      "This gives a total of 632 distinct values, which is much less than the 3000 values required by\n",
      "ﬂat Q learning. Hence, we can see that by applying state abstractions, the MAXQ representation\n",
      "can give a much more compact representation of the value function. A key thing to note is that\n",
      "these state abstractions cannot be exploited with the ﬂat representation of the value function.\n",
      "\n",
      "What prior knowledge is required on the part of a programmer in order to introduce these state\n",
      "abstractions? It suﬃces to know some general constraints on the one-step reward functions, the\n",
      "one-step transition probabilities, and termination predicates, goal predicates, and pseudo-reward\n",
      "functions within the MAXQ graph. Speciﬁcally, the Max Node Irrelevance and Leaf Irrelevance\n",
      "conditions require simple analysis of the one-step transition function and the reward and pseudo-\n",
      "reward functions. Opportunities to apply the Result Distribution Irrelevance condition can be\n",
      "found by identifying “funnel” eﬀects that result from the deﬁnitions of the termination conditions\n",
      "for operators. Similarly, the Shielding and Termination conditions only require analysis of the\n",
      "termination predicates of the various subtasks. Hence, applying these ﬁve conditions to introduce\n",
      "state abstractions is a straightforward process, and once a model of the one-step transition and\n",
      "reward functions has been learned, the abstraction conditions can be checked to see if they were\n",
      "satisﬁed.\n",
      "\n",
      "5.2 Convergence of MAXQ-Q with State Abstraction\n",
      "\n",
      "We have shown that state abstractions can be safely introduced into the MAXQ value function\n",
      "decomposition under the ﬁve conditions described above. However, these conditions only guarantee\n",
      "that the value function of any ﬁxed abstract hierarchical policy can be represented—they do not\n",
      "show that the optimal policy can be represented, nor do they show that the MAXQ-Q learning\n",
      "algorithm will ﬁnd the optimal policy. The goal of this section is to prove these two results: (a) that\n",
      "the ordered recursively-optimal policy is an abstract policy and (b) that MAXQ-Q will converge\n",
      "to this policy when applied to a MAXQ graph with safe state abstractions.\n",
      "\n",
      "Lemma 10 Let M be an MDP with full-state MAXQ graph H and abstract-state MAXQ graph\n",
      "χ(H) where the abstractions satisfy the ﬁve conditions given above. Let ρ be an ordering over all\n",
      "actions in the MAXQ graph. Then the following statements are true:\n",
      "\n",
      "• The unique ordered recursively-optimal policy π∗\n",
      "\n",
      "r deﬁned by M , H, and ρ is an abstract policy\n",
      "\n",
      "(i.e., it depends only on the relevant state variables at each node),\n",
      "\n",
      "• The C and V functions in χ(H) can represent the projected value function of π∗\n",
      "r .\n",
      "\n",
      "36\n",
      "\n",
      "\f",
      "Proof: The ﬁve abstraction lemmas tell us that if the ordered recursively-optimal policy is ab-\n",
      "stract, then the C and V functions of χ(H) can represent its value function. Hence, the heart of\n",
      "this lemma is the ﬁrst claim. The last two forms of abstraction (Shielding and Termination) do not\n",
      "place any restrictions on abstract policies, so we ignore them in this proof.\n",
      "\n",
      "The proof is by induction on the levels of the MAXQ graph, starting at the leaves. As a base\n",
      "case, let us consider a Max node i all of whose children are primitive actions. In this case, there are\n",
      "no policies executed within the children of the Max node. Hence if variables Yi are irrelevant for\n",
      "node i, then we can apply our abstraction lemmas to represent the value function of any policy at\n",
      "node i—not just abstract policies. Consequently, the value function of any optimal policy for node\n",
      "i can be represented, and it will have the property that Q∗(i, s1, a) = Q∗(i, s2, a) for any states s1\n",
      "and s2 such that χi(s1) = χi(s2).\n",
      "\n",
      "Now let us impose the action ordering ρ to compute the optimal ordered policy. Consider two\n",
      "actions a1 and a2 such that ρ(a1, a2) (i.e., ρ prefers a1), and suppose that there is a “tie” in the Q∗\n",
      "function at state s1 such that the values\n",
      "\n",
      "Q∗(i, s1, a1) = Q∗(i, s1, a2)\n",
      "\n",
      "and they are the only two actions that maximize Q∗ in this state. Then the optimal ordered policy\n",
      "must choose a1. Now in all other states s2 such that χi(s1) = χi(s2), we know that the Q∗ values\n",
      "will be the same. Hence, the same tie will exist between a1 and a2, and hence, the optimal ordered\n",
      "policy must make the same choice in all such states. Hence, the optimal ordered policy for node i\n",
      "is an abstract policy.\n",
      "\n",
      "Now let us turn to the recursive case at Max node i. Make the inductive assumption that the\n",
      "ordered recursively-optimal policy is abstract within all descendant nodes and consider the locally\n",
      "optimal policy at node i. If Y is a set of state variables that are irrelevant to node i, Corollary 2\n",
      "tells us that Q∗(i, s1, j) = Q∗(i, s2, j) for all states s1 and s2 such that χi(s1) = χi(s2). Similarly,\n",
      "if Y is a set of variables irrelevant to the result distribution of a particular action j, then Lemma\n",
      "7 tells us the same thing. Hence, by the same ordering argument given above, the ordered optimal\n",
      "policy at node i must be abstract. By induction, this proves the lemma. Q.E.D.\n",
      "\n",
      "With this lemma, we have established that the combination of an MDP M , an abstract MAXQ\n",
      "graph H, and an action ordering deﬁnes a unique recursively-optimal ordered abstract policy. We\n",
      "are now ready to prove that MAXQ-Q will converge to this policy.\n",
      "\n",
      "Theorem 4 Let M = hS, A, P, R, P0i be either an episodic MDP for which all deterministic policies\n",
      "are proper or a discounted inﬁnite horizon MDP with discount factor γ < 1. Let H be an unab-\n",
      "stracted MAXQ graph deﬁned over subtasks {M0, . . . , Mk} with pseudo-reward functions ˜Ri(s′|s, a).\n",
      "Let χ(H) be a state-abstracted MAXQ graph deﬁned by applying state abstractions χi to each node i\n",
      "of H under the ﬁve conditions given above. Let πx(i, χi(s)) be an abstract ordered GLIE exploration\n",
      "policy at each node i and state s whose decisions depend only on the “relevant” state variables at\n",
      "each node i. Let π∗\n",
      "r be the unique recursively-optimal hierarchical policy deﬁned by πx, M , and\n",
      "˜R. Then with probability 1, algorithm MAXQ-Q applied to χ(H) converges to π∗\n",
      "r provided that the\n",
      "learning rates αt(i) satisfy Equation (15) and |Vt(i, χi(s))| and |Ct(i, χi(s), a)| are bounded for all\n",
      "t, i, χi(s), and a.\n",
      "\n",
      "Proof: Rather than repeating the entire proof for MAXQ-Q, we will only describe what must\n",
      "change under state abstraction. The last two forms of state abstraction refer to states whose values\n",
      "can be inferred from the structure of the MAXQ graph, and therefore do not need to be represented\n",
      "\n",
      "37\n",
      "\n",
      "\f",
      "at all. Since these values are not updated by MAXQ-Q, we can ignore them. We will now consider\n",
      "the ﬁrst three forms of state abstraction in turn.\n",
      "\n",
      "We begin by considering primitive leaf nodes. Let a be a leaf node and let Y be a set of\n",
      "state variables that are Leaf Irrelevant for a. Let s1 = (x, y1) and s2 = (x, y2) be two states that\n",
      "diﬀer only in their values for Y . Under Leaf Irrelevance, the probability transitions P (s′\n",
      "1|s1, a) and\n",
      "P (s′\n",
      "2|s2, a) need not be the same, but the expected reward of performing a in both states must be\n",
      "the same. When MAXQ-Q visits an abstract state x, it does not “know” the value of y, the part of\n",
      "the state that has been abstracted away. Nonetheless, it draws a sample according to P (s′|x, y, a),\n",
      "receives a reward R(s′|x, y, a), and updates its estimate of V (a, x) (line 5 of MAXQ-Q). Let Pt(y)\n",
      "be the probability that MAXQ-Q is visiting (x, y) given that the unabstracted part of the state is\n",
      "x. Then Line 5 of MAXQ-Q is computing a stochastic approximation to\n",
      "\n",
      "We can write this as\n",
      "\n",
      "Pt(y)Pt(s′, N |x, y, a)R(s′|x, y, a).\n",
      "\n",
      "Xs′,N,y\n",
      "\n",
      "Xy\n",
      "\n",
      "Pt(y)Xs′,N\n",
      "\n",
      "Pt(s′, N |x, y, a)R(s′|x, y, a).\n",
      "\n",
      "According to Leaf Irrelevance, the inner sum has the same value for all states s such that χ(s) = x.\n",
      "Call this value r0(x). This gives\n",
      "\n",
      "Pt(y)r0(x),\n",
      "\n",
      "Xy\n",
      "\n",
      "which is equal to r0(x) for any distribution Pt(y). Hence, MAXQ-Q converges under Leaf Irrelevance\n",
      "abstractions.\n",
      "\n",
      "Now let us turn to the two forms of abstraction that apply to internal nodes: Node Irrelevance\n",
      "and Result Distribution Irrelevance. Consider the SMDP deﬁned at each node i of the abstracted\n",
      "MAXQ graph at time t during MAXQ-Q. This would be an ordinary SMDP with transition prob-\n",
      "ability function Pt(x′, N |x, a) and reward function Vt(a, x) + ˜Ri(x′) except that when MAXQ-Q\n",
      "draws samples of state transitions, they are drawn according to the distribution Pt(s′, N |s, a) over\n",
      "the original state space. To prove the theorem, we must show that drawing (s′, N ) according to\n",
      "this second distribution is equivalent to drawing (x′, N ) according to the ﬁrst distribution.\n",
      "\n",
      "For Max Node Irrelevance, we know that for all abstract policies applied to node i and its\n",
      "\n",
      "descendants, the transition probability distribution factors as\n",
      "\n",
      "P (s′, N |s, a) = P (y′|y, a)P (x′, N |x, a).\n",
      "\n",
      "Because the exploration policy is an abstract policy, Pt(s′, N |s, a) factors in this way. This means\n",
      "that the Xi and Yi components of the state are independent of each other, and hence, sampling\n",
      "from Pt(s′, N |s, a) gives samples for Pt(x′, N |x, a). Therefore, MAXQ-Q will converge under Max\n",
      "Node Irrelevance abstractions.\n",
      "\n",
      "Finally, consider Result Distribution Irrelevance. Let j be a child of node i, and suppose Yj\n",
      "is a set of state variables that are irrelevant to the result distribution of j. When the SMDP at\n",
      "node i wishes to draw a sample from Pt(x′, N |x, j), it does not “know” the current value of y, the\n",
      "irrelevant part of the current state. However, this does not matter, because Result Distribution\n",
      "Irrelevance means that for all possible values of y, Pt(x′, y′, N |x, y, j) is the same. Hence, MAXQ-Q\n",
      "will converge under Result Distribution Irrelevance abstractions.\n",
      "\n",
      "In each of these three cases, MAXQ-Q will converge to a locally-optimal ordered policy at node\n",
      "i in the MAXQ graph. By Lemma 10, this can be extended to produce a locally-optimal ordered\n",
      "policy for the unabstracted SMDP at node i. Hence, by induction, MAXQ-Q will converge to\n",
      "\n",
      "38\n",
      "\n",
      "\f",
      "the unique ordered recursively optimal policy π∗\n",
      "exploration policy πx. Q.E.D.\n",
      "\n",
      "r deﬁned by MAXQ-Q H, MDP M , and ordered\n",
      "\n",
      "5.3 The Hierarchical Credit Assignment Problem\n",
      "\n",
      "There are still some situations where we would like to introduce state abstractions but where the\n",
      "ﬁve properties described above do not permit them. Consider the following modiﬁcation of the\n",
      "taxi problem. Suppose that the taxi has a fuel tank and that each time the taxi moves one square,\n",
      "it costs one unit of fuel. If the taxi runs out of fuel before delivering the passenger to his or her\n",
      "destination, it receives a reward of −20, and the trial ends. Fortunately, there is a ﬁlling station\n",
      "where the taxi can execute a Fillup action to ﬁll the fuel tank.\n",
      "\n",
      "To solve this modiﬁed problem using the MAXQ hierarchy, we can introduce another subtask,\n",
      "Refuel, which has the goal of moving the taxi to the ﬁlling station and ﬁlling the tank. MaxRefuel\n",
      "is a child of MaxRoot, and it invokes Navigate(t) (with t bound to the location of the ﬁlling station)\n",
      "to move the taxi to the ﬁlling station.\n",
      "\n",
      "The introduction of fuel and the possibility that we might run out of fuel means that we must\n",
      "include the current amount of fuel as a feature in representing every C value (for internal nodes)\n",
      "and V value (for leaf nodes). This is unfortunate, because our intuition tells us that the amount of\n",
      "fuel should have no inﬂuence on our decisions inside the Navigate(t) subtask. The amount of fuel\n",
      "should be taken into account by the top-level Q nodes, which must decide whether to go refuel, go\n",
      "pick up the passenger, or go deliver the passenger.\n",
      "\n",
      "Given this intuition, it is natural to try abstracting away the “amount of remaining fuel” within\n",
      "the Navigate(t) subtask. However, this doesn’t work, because when the taxi runs out of fuel and\n",
      "a −20 reward is given, the QNorth, QSouth, QEast, and QWest nodes cannot “explain” why this\n",
      "reward was received—that is, they have no consistent way of setting their C tables to predict\n",
      "when this negative reward will occur. Stated more formally, the diﬃculty is that the Max Node\n",
      "Irrelevance condition is not satisﬁed because the one-step reward function R(s′|s, a) for these actions\n",
      "depends on the amount of fuel.\n",
      "\n",
      "We call this the hierarchical credit assignment problem. The fundamental issue here is that in\n",
      "the MAXQ decomposition all information about rewards is stored in the leaf nodes of the hierarchy.\n",
      "We would like to separate out the basic rewards received for navigation (i.e., −1 for each action)\n",
      "from the reward received for exhausting fuel (−20).\n",
      "If we make the reward at the leaves only\n",
      "depend on the location of the taxi, then the Max Node Irrelevance condition will be satisﬁed.\n",
      "\n",
      "One way to do this is to have the programmer manually decompose the reward function and\n",
      "\n",
      "indicate which nodes in the hierarchy will “receive” each reward. Let R(s′|s, a) = Pi R(i, s′|s, a) be\n",
      "\n",
      "a decomposition of the reward function, such that R(i, s′|s, a) speciﬁes that part of the reward that\n",
      "must be handled by Max node i. In the modiﬁed taxi problem, for example, we can decompose the\n",
      "reward so that the leaf nodes receive all of the original penalties, but the out-of-fuel rewards must\n",
      "be handled by MaxRoot. Lines 16 and 17 of the MAXQ-Q algorithm are easily modiﬁed to include\n",
      "R(i, s′|s, a).\n",
      "\n",
      "In most domains, we believe it will be easy for the designer of the hierarchy to decompose the\n",
      "reward function. It has been straightforward in all of the problems we have studied. However, an\n",
      "interesting problem for future research is to develop an algorithm that can solve the hierarchical\n",
      "credit assignment problem autonomously.\n",
      "\n",
      "39\n",
      "\n",
      "\f",
      "6 Non-Hierarchical Execution of the MAXQ Hierarchy\n",
      "\n",
      "Up to this point in the paper, we have focused exclusively on representing and learning hierarchical\n",
      "policies. However, often the optimal policy for a MDP is not a strictly hierarchical policy. Kaelbling\n",
      "(1993) ﬁrst introduced the idea of deriving a non-hierarchical policy from the value function of a\n",
      "hierarchical policy. In this section, we exploit the MAXQ decomposition to generalize her ideas\n",
      "and apply them recursively at all levels of the hierarchy.\n",
      "\n",
      "The ﬁrst method is based on the dynamic programming algorithm known as policy iteration.\n",
      "The policy iteration algorithm starts with an initial policy π0. It then repeats the following two\n",
      "steps until the policy converges. In the policy evaluation step, it computes the value function V πk\n",
      "of the current policy πk. Then, in the policy improvement step, it computes a new policy, πk+1\n",
      "according to the rule\n",
      "\n",
      "πk+1(s) := argmax\n",
      "\n",
      "a Xs′\n",
      "\n",
      "P (s′|s, a)[R(s′|s, a) + γV πk(s′)].\n",
      "\n",
      "(22)\n",
      "\n",
      "Howard (1960) proved that if πk is not an optimal policy, then πk+1 is guaranteed to be an im-\n",
      "provement. Note that in order to apply this method, we need to know the transition probability\n",
      "distribution P (s′|s, a) and the reward function R(s′|s, a).\n",
      "\n",
      "If we know P (s′|s, a) and R(s′|s, a), we can use the MAXQ representation of the value function\n",
      "to perform one step of policy iteration. We start with a hierarchical policy π and represent its value\n",
      "function using the MAXQ hierarchy (e.g., π could have been learned via MAXQ-Q). Then, we can\n",
      "perform one step of policy improvement by applying Equation (22) using V π(0, s′) (computed by\n",
      "the MAXQ hierarchy) to compute V π(s′).\n",
      "\n",
      "Corollary 3 Let πg(s) = argmaxaPs′ P (s′|s, a)[R(s′|s, a) + γV π(0, s)], where V π(0, s) is the value\n",
      "\n",
      "function computed by the MAXQ hierarchy. Then, if π was not an optimal policy, πg is strictly\n",
      "better for at least one state in S.\n",
      "\n",
      "Proof: This is a direct consequence of Howard’s policy improvement theorem. Q.E.D.\n",
      "\n",
      "Unfortunately, we can’t iterate this policy improvement process, because the new policy, πg is\n",
      "very unlikely to be a hierarchical policy (i.e., it is unlikely to be representable in terms of local\n",
      "policies for each node of the MAXQ graph). Nonetheless, one step of policy improvement can give\n",
      "very signiﬁcant improvements.\n",
      "\n",
      "This approach to non-hierarchical execution ignores the internal structure of the MAXQ graph.\n",
      "In eﬀect, the MAXQ hierarchy is just viewed as a kind of function approximator for representing\n",
      "V π—any other representation would give the same one-step improved policy πg.\n",
      "\n",
      "The second approach to non-hierarchical execution borrows an idea from Q learning. One of\n",
      "the great beauties of the Q representation for value functions is that we can compute one step of\n",
      "policy improvement without knowing P (s′|s, a), simply by taking the new policy to be πg(s) :=\n",
      "argmaxa Q(s, a). This gives us the same one-step greedy policy as we computed above using one-\n",
      "step lookahead. With the MAXQ decomposition, we can perform these policy improvement steps\n",
      "at all levels of the hierarchy.\n",
      "\n",
      "We have already deﬁned the function that we need.\n",
      "\n",
      "In Table 3 we presented the function\n",
      "EvaluateMaxNode, which, given the current state s, conducts a search along all paths from a\n",
      "given Max node i to the leaves of the MAXQ graph and ﬁnds the path with the best value (i.e.,\n",
      "with the maximum sum of C values along the path, plus the V value at the leaf). In addition,\n",
      "EvaluateMaxNode returns the primitive action a at the end of this best path. This action a would\n",
      "\n",
      "40\n",
      "\n",
      "\f",
      "Table 5: The procedure for executing the one-step greedy policy.\n",
      "\n",
      "procedure ExecuteHGPolicy(s)\n",
      "\n",
      "repeat\n",
      "\n",
      "Let hV (0, s), ai := EvaluateMaxNode(0, s)\n",
      "execute primitive action a\n",
      "Let s be the resulting state\n",
      "\n",
      "end // ExecuteHGPolicy\n",
      "\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "\n",
      "be the ﬁrst primitive action to be executed if the learned hierarchical policy were executed starting\n",
      "in the current state s. Our second method for non-hierarchical execution of the MAXQ graph is\n",
      "to call EvaluateMaxNode in each state, and execute the primitive action a that is returned. The\n",
      "pseudo-code is shown in Table 5.\n",
      "\n",
      "We will call the policy computed by ExecuteHGPolicy the hierarchical greedy policy, and denote\n",
      "it πhg∗, where the superscript * indicates that we are computing the greedy action at each time\n",
      "step. The following theorem shows that this can give a better policy than the original, hierarchical\n",
      "policy.\n",
      "\n",
      "Theorem 5 Let G be a MAXQ graph representing the value function of hierarchical policy π (i.e.,\n",
      "in terms of C π(i, s, j), computed for all i, s, and j). Let V hg(0, s) be the value computed by\n",
      "ExecuteHGPolicy, and let πhg∗ be the resulting policy. Deﬁne V hg∗ to be the value function of πhg∗.\n",
      "Then for all states s, it is the case that\n",
      "\n",
      "V π(s) ≤ V hg(0, s) ≤ V hg∗(s).\n",
      "\n",
      "(23)\n",
      "\n",
      "Proof:\n",
      "(sketch) The left inequality in Equation (23) is satisﬁed by construction by line 7 of\n",
      "EvaluateMaxNode. To see this, consider that the original hierarchical policy, π, can be viewed as\n",
      "choosing a “path” through the MAXQ graph running from the root to one of the leaf nodes, and\n",
      "V π(0, s) is the sum of the C π values along this chosen path (plus the V π value at the leaf node). In\n",
      "contrast, EvaluateMaxNode performs a traversal of all paths through the MAXQ graph and ﬁnds\n",
      "the best path, that is, the path with the largest sum of C π (and leaf V π) values. Hence, V hg(0, s)\n",
      "must be at least as large as V π(0, s).\n",
      "\n",
      "To establish the right inequality, note that by construction V hg(0, s) is the value function of a\n",
      "policy, call it πhg, that chooses one action greedily at each level of the MAXQ graph (recursively),\n",
      "and then follows π thereafter. This is a consequence of the fact that line 7 of EvaluateMaxNode has\n",
      "C π on its right-hand side, and C π represents the cost of “completing” each subroutine by following\n",
      "π, not by following some other, greedier, policy. (In Table 3, C π is written as Ct.) However, when\n",
      "we execute ExecuteHGPolicy (and hence, execute πhg∗), we have an opportunity to improve upon\n",
      "π and πhg at each time step. Hence, V hg(0, s) is an underestimate of the actual value of πhg∗.\n",
      "Q.E.D.\n",
      "\n",
      "Note that this theorem only works in one direction. It says that if we can ﬁnd a state where\n",
      "V hg(0, s) > V π(s), then the greedy policy, πhg∗, will be strictly better than π. However, it could\n",
      "be that π is not an optimal policy and yet the structure of the MAXQ graph prevents us from\n",
      "considering an action (either primitive or composite) that would improve π. Hence, unlike the\n",
      "policy improvement theorem of Howard, we do not have a guarantee that if π is suboptimal, then\n",
      "the hierarchically greedy policy is a strict improvement.\n",
      "\n",
      "41\n",
      "\n",
      "\f",
      "In contrast, if we perform one-step policy improvement as discussed at the start of this section,\n",
      "Corollary 3 guarantees that we will improve the policy. So we can see that in general, neither\n",
      "of these two methods for non-hierarchical execution dominates the other. Nonetheless, the ﬁrst\n",
      "method only operates at the level of individual primitive actions, so it is not able to produce very\n",
      "large improvements in the policy. In contrast, the hierarchical greedy method can obtain very large\n",
      "improvements in the policy by changing which actions (i.e., subroutines) are chosen near the root\n",
      "of the hierarchy. Hence, in general, hierarchical greedy execution is probably the better method.\n",
      "(Of course, the value functions of both methods could be computed, and the one with the better\n",
      "estimated value could be executed.)\n",
      "\n",
      "Sutton, Singh, Precup and Ravindran (1999) have simultaneously developed a closely-related\n",
      "method for non-hierarchical execution of macros. Their method is equivalent to ExecuteHGPolicy\n",
      "for the special case where the MAXQ hierarchy has only one level of subtasks. The interesting\n",
      "aspect of ExecuteHGPolicy is that it permits greedy improvements at all levels of the tree to\n",
      "inﬂuence which action is chosen.\n",
      "\n",
      "Some care must be taken in applying Theorem 5 to a MAXQ hierarchy whose C values have\n",
      "been learned via MAXQ-Q. Being an online algorithm, MAXQ-Q will not have correctly learned the\n",
      "values of all states at all nodes of the MAXQ graph. For example, in the taxi problem, the value of\n",
      "C(Put, s, QPutdown) will not have been learned very well except at the four special locations. This\n",
      "is because the Put subtask cannot be executed until the passenger is in the taxi, and this usually\n",
      "means that a Get has just been completed, so the taxi is at the passenger’s source location. During\n",
      "exploration, both children of Put will be tried in such states. The PutDown will usually fail, whereas\n",
      "the Navigate will eventually succeed (perhaps after lengthy exploration) and take the taxi to the\n",
      "destination location. Now because of all states updating, the values for C(Put, s, Navigate(t)) will\n",
      "have been learned at all of the states, but the C values for the Putdown action will not. Hence, if\n",
      "we train the MAXQ representation using hierarchical execution (as in MAXQ-Q), and then switch\n",
      "to hierarchically-greedy execution, the results will be quite bad. In particular, we need to introduce\n",
      "hierarchically-greedy execution early enough so that the exploration policy is still actively exploring.\n",
      "(In theory, a GLIE exploration policy never ceases to explore, but in practice, we want to ﬁnd a\n",
      "good policy quickly, not just asymptotically).\n",
      "\n",
      "Of course an alternative would be to use hierarchically-greedy execution from the very beginning\n",
      "of learning. However, remember that the higher nodes in the MAXQ hierarchy need to obtain\n",
      "samples of P (s′, N |s, a) for each child action a.\n",
      "If the hierarchical greedy execution interrupts\n",
      "child a before it has reached a terminal state, then these samples cannot be obtained. Hence, it\n",
      "is important to begin with purely hierarchical execution during training, and make a transition to\n",
      "greedy execution at some point.\n",
      "\n",
      "The approach we have taken is to implement MAXQ-Q in such a way that we can specify a\n",
      "number of primitive actions L that can be taken hierarchically before the hierarchical execution\n",
      "is “interrupted” and control returns to the top level (where a new action can be chosen greedily).\n",
      "We start with L set very large, so that execution is completely hierarchical—when a child action\n",
      "is invoked, we are committed to execute that action until it terminates. However, gradually, we\n",
      "reduce L until it becomes 1, at which point we have hierarchical greedy execution. We time this\n",
      "so that it reaches 1 at about the same time our Boltzmann exploration cools to a temperature of\n",
      "0.1 (which is where exploration eﬀectively has halted). As the experimental results will show, this\n",
      "generally gives excellent results with very little added exploration cost.\n",
      "\n",
      "42\n",
      "\n",
      "\f",
      "7 Experimental Evaluation of the MAXQ Method\n",
      "\n",
      "We have performed a series of experiments with the MAXQ method with three goals in mind: (a)\n",
      "to understand the expressive power of the value function decomposition, (b) to characterize the\n",
      "behavior of the MAXQ-Q learning algorithm, and (c) to assess the relative importance of temporal\n",
      "abstraction, state abstraction, and non-hierarchical execution. In this section, we describe these\n",
      "experiments and present the results.\n",
      "\n",
      "7.1 The Fickle Taxi Task\n",
      "\n",
      "Our ﬁrst experiments were performed on a modiﬁed version of the taxi task. This version incor-\n",
      "porates two changes to the task described in Section 3.1. First, each of the four navigation actions\n",
      "is noisy, so that with probability 0.8 it moves in the intended direction, but with probability 0.1\n",
      "it instead moves to the right (of the intended direction) and with probability 0.1 it moves to the\n",
      "left. The second change is that after the taxi has picked up the passenger and moved one square\n",
      "away from the passenger’s source location, the passenger changes his or her destination location\n",
      "with probability 0.3. The purpose of this change is to create a situation where the optimal policy\n",
      "is not a hierarchical policy so that the eﬀectiveness of non-hierarchical execution can be measured.\n",
      "We compared four diﬀerent conﬁgurations of the learning algorithm: (a) ﬂat Q learning, (b)\n",
      "MAXQ-Q learning without any form of state abstraction, (c) MAXQ-Q learning with state abstrac-\n",
      "tion, and (d) MAXQ-Q learning with state abstraction and greedy execution. These conﬁgurations\n",
      "are controlled by many parameters. These include the following: (a) the initial values of the Q\n",
      "and C functions, (b) the learning rate (we employed a ﬁxed learning rate), (c) the cooling schedule\n",
      "for Boltzmann exploration (the GLIE policy that we employed), and (d) for non-hierarchical ex-\n",
      "ecution, the schedule for decreasing L, the number of steps of consecutive hierarchical execution.\n",
      "We optimized these settings separately for each conﬁguration with the goal of matching or exceed-\n",
      "ing (with as few primitive actions as possible) the best policy that we could code by hand. For\n",
      "Boltzmann exploration, we established an initial temperature and then a cooling rate. A separate\n",
      "temperature is maintained for each Max node in the MAXQ graph, and its temperature is reduced\n",
      "by multiplying by the cooling rate each time that subtask terminates in a goal state.\n",
      "\n",
      "The following parameters were chosen. For ﬂat Q learning: initial Q values of 0.123, learning\n",
      "rate 0.25, and Boltzmann exploration with an initial temperature of 50 and a cooling rate of 0.9879.\n",
      "(We use initial values that end in .123 as a “signature” to aid debugging.)\n",
      "\n",
      "For MAXQ-Q learning without state abstraction, we used initial values of 0.123, a learning rate\n",
      "of 0.50, and Boltzmann exploration with an initial temperature of 50 and cooling rates of .9996 at\n",
      "MaxRoot and MaxPut, 0.9939 at MaxGet, and 0.9879 at MaxNavigate.\n",
      "\n",
      "For MAXQ-Q learning with state abstraction, we used initial values of 0.123, a learning rate of\n",
      "0.25, and Boltzmann exploration with an initial temperature of 50 and cooling rates of 0.9074 at\n",
      "MaxRoot, 0.9526 at MaxPut, 0.9526 at MaxGet, and 0.9879 at MaxNavigate.\n",
      "\n",
      "For MAXQ-Q learning with non-hierarchical execution, we used the same settings as with state\n",
      "In addition, we initialized L to 500 and decreased it by 10 with each trial until it\n",
      "\n",
      "abstraction.\n",
      "reached 1. So after 50 trials, execution was completely greedy.\n",
      "\n",
      "Figure 7 shows the averaged results of 100 training trials. The ﬁrst thing to note is that all\n",
      "forms of MAXQ learning have better initial performance than ﬂat Q learning. This is because of\n",
      "the constraints introduced by the MAXQ hierarchy. For example, while the agent is executing a\n",
      "Navigate subtask, it will never attempt to pickup or putdown the passenger. Similarly, it will never\n",
      "attempt to putdown the passenger until it has ﬁrst picked up the passenger (and vice versa).\n",
      "\n",
      "The second thing to notice is that without state abstractions, MAXQ-Q learning actually takes\n",
      "\n",
      "43\n",
      "\n",
      "\f",
      "200\n",
      "\n",
      "0\n",
      "\n",
      "-200\n",
      "\n",
      "-400\n",
      "\n",
      "-600\n",
      "\n",
      "-800\n",
      "\n",
      "d\n",
      "r\n",
      "a\n",
      "w\n",
      "e\n",
      "R\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "t\n",
      "a\n",
      "l\n",
      "u\n",
      "m\n",
      "u\n",
      "C\n",
      "n\n",
      "a\n",
      "e\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "\n",
      "Hierarchical Q Learning with State Abstraction and Greedy Execution\n",
      "Hierarchical Q Learning with State Abstraction\n",
      "Hierarchical Q Learning without State Abstraction\n",
      "Flat Q Learning\n",
      "\n",
      "-1000\n",
      "\n",
      "0\n",
      "\n",
      "50000\n",
      "\n",
      "100000\n",
      "\n",
      "150000\n",
      "\n",
      "200000\n",
      "\n",
      "250000\n",
      "\n",
      "Primitive Actions\n",
      "\n",
      "Figure 7: Comparison of performance of hierarchical Q learning with ﬂat Q learning, with and\n",
      "without state abstractions, and with and without greedy evaluation.\n",
      "\n",
      "longer to converge, so that the Flat Q curve crosses the MAXQ/no abstraction curve. This shows\n",
      "that without state abstraction, the cost of learning the huge number of parameters in the MAXQ\n",
      "representation is not really worth the beneﬁts.\n",
      "\n",
      "The third thing to notice is that with state abstractions, MAXQ-Q converges very quickly to a\n",
      "hierarchically optimal policy. This can be seen more clearly in Figure 8, which focuses on the range\n",
      "of reward values in the neighborhood of the optimal policy. Here we can see that MAXQ with\n",
      "abstractions attains the hierarchically optimal policy after approximately 40,000 steps, whereas\n",
      "ﬂat Q learning requires roughly twice as long to reach the same level. However, ﬂat Q learning, of\n",
      "course, can continue onward and reach optimal performance, whereas with the MAXQ hierarchy,\n",
      "the best hierarchical policy is slow to respond to the “ﬁckle” behavior of the passenger when he/she\n",
      "changes the destination.\n",
      "\n",
      "The last thing to notice is that with greedy execution, the MAXQ policy is also able to attain\n",
      "optimal performance. But as the execution becomes “more greedy”, there is a drop in performance,\n",
      "because MAXQ-Q must learn C values in new regions of the state space that were not visited by\n",
      "the recursively optimal policy. Despite this drop in performance, greedy MAXQ-Q recovers rapidly\n",
      "and reaches hierarchically optimal performance faster than purely-hierarchical MAXQ-Q learning.\n",
      "Hence, there is no added cost—in terms of exploration—for introducing greedy execution.\n",
      "\n",
      "This experiment presents evidence in favor of three claims: ﬁrst, that hierarchical reinforcement\n",
      "learning can be much faster than ﬂat Q learning; second, that state abstraction is required by\n",
      "MAXQ for good performance; and third, that non-hierarchical execution can produce signiﬁcant\n",
      "improvements in performance with little or no added exploration cost.\n",
      "\n",
      "44\n",
      "\n",
      "\f",
      "d\n",
      "r\n",
      "a\n",
      "w\n",
      "e\n",
      "R\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "t\n",
      "a\n",
      "l\n",
      "u\n",
      "m\n",
      "u\n",
      "C\n",
      "n\n",
      "a\n",
      "e\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "\n",
      "10\n",
      "\n",
      "5\n",
      "\n",
      "0\n",
      "\n",
      "-5\n",
      "\n",
      "-10\n",
      "\n",
      "-15\n",
      "\n",
      "0\n",
      "\n",
      "MAXQ Abstract+Greedy\n",
      "\n",
      "Flat Q\n",
      "\n",
      "Optimal Policy\n",
      "\n",
      "Hier-Optimal Policy\n",
      "\n",
      "MAXQ Abstract\n",
      "\n",
      "MAXQ No Abstract\n",
      "\n",
      "50000\n",
      "\n",
      "100000\n",
      "\n",
      "150000\n",
      "\n",
      "200000\n",
      "\n",
      "250000\n",
      "\n",
      "300000\n",
      "\n",
      "Primitive Actions\n",
      "\n",
      "Figure 8: Close-up view of the previous ﬁgure. This ﬁgure also shows two horizontal lines indicating\n",
      "optimal performance and hierarchically optimal performance in this domain. To make this ﬁgure\n",
      "more readable, we have applied a 100-step moving average to the data points.\n",
      "\n",
      "7.2 Kaelbling’s HDG Method\n",
      "\n",
      "The second task that we will consider is a simple maze task introduced by Leslie Kaelbling\n",
      "(1993) and shown in Figure 10. In each trial of this task, the agent starts in a randomly-chosen\n",
      "state and must move to a randomly-chosen goal state using the usual North, South, East, and West\n",
      "operators (we employed deterministic operators). There is a small cost for each move, and the\n",
      "agent must maximize the undiscounted sum of these costs.\n",
      "\n",
      "Because the goal state can be in any of 100 diﬀerent locations, there are actually 100 diﬀerent\n",
      "MDPs. Kaelbling’s HDG method starts by choosing an arbitrary set of landmark states and deﬁning\n",
      "a Voronoi partition of the state space based on the Manhattan distances to these landmarks (i.e.,\n",
      "two states belong to the same Voronoi cell iﬀ they have the same nearest landmark). The method\n",
      "then deﬁnes one subtask for each landmark l. The subtask is to move from any state in the current\n",
      "Voronoi cell or in any neighboring Voronoi cell to the landmark l. Optimal policies for these\n",
      "subtasks are then computed.\n",
      "\n",
      "Once HDG has the policies for these subtasks, it can solve the abstract Markov Decision Problem\n",
      "of moving from each landmark state to any other landmark state using the subtask solutions as\n",
      "macro actions (subroutines). So it computes a value function for this MDP.\n",
      "\n",
      "Finally, for each possible destination location g within a Voronoi cell for landmark l, the HDG\n",
      "\n",
      "method computes the optimal policy of getting from l to g.\n",
      "\n",
      "By combining these subtasks, the HDG method can construct a good approximation to the\n",
      "optimal policy as follows. In addition to the value functions discussed above, the agent maintains\n",
      "two other functions: N L(s), the name of the landmark nearest to state s, and N (l), a list of the\n",
      "\n",
      "45\n",
      "\n",
      "\f",
      "10\n",
      "\n",
      "9\n",
      "\n",
      "8\n",
      "\n",
      "7\n",
      "\n",
      "6\n",
      "\n",
      "5\n",
      "\n",
      "4\n",
      "\n",
      "3\n",
      "\n",
      "2\n",
      "\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "Figure 9: Kaelbling’s 10-by-10 navigation task. Each circled state is a landmark state, and the\n",
      "heavy lines show the boundaries of the Voronoi cells. In each episode, a start state and a goal state\n",
      "are chosen at random. In this ﬁgure, the start state is shown by the shaded hexagon, and the goal\n",
      "state is shown by the shaded square.\n",
      "\n",
      "landmarks that are in the cells that are immediate neighbors of cell l. By combining these, the\n",
      "agent can build a list for each state s of the current landmark and the landmarks of the neighboring\n",
      "cells. For each such landmark, the agent computes the sum of three terms:\n",
      "\n",
      "(t1) the expected cost of reaching that landmark,\n",
      "\n",
      "(t2) the expected cost of moving from that landmark to the landmark in the goal cell, and\n",
      "\n",
      "(t3) the expected cost of moving from the goal-cell landmark to the goal state.\n",
      "\n",
      "Note that while terms (t1) and (t3) can be exact estimates, term (t2) is computed using the\n",
      "landmark subtasks as subroutines. This means that the corresponding path must pass through the\n",
      "intermediate landmark states rather than going directly to the goal landmark. Hence, term (t2) is\n",
      "typically an overestimate of the required distance. (Also note that (t3) is the same for all choices\n",
      "of the intermediate landmarks, so it does not need to be explicitly included in the computation.)\n",
      "\n",
      "Given this information, the agent then chooses to move toward the best of the landmarks (unless\n",
      "the agent is already in the goal Voronoi cell, in which case the agent moves toward the goal state).\n",
      "For example, in Figure 9, term (t1) is the cost of reaching the landmark in row 7, column 4, which\n",
      "is 4. Term (t2) is the cost of getting from row 7, column 4 to the landmark at row 1 column 4 (by\n",
      "going from one landmark to another). In this case, the best landmark-to-landmark path is from\n",
      "row 7, column 1 to row 5 column 6, and then to row 1 column 4. Hence, term (t2) is 12. Term (t3)\n",
      "is the cost of getting from row 1 column 4 to the goal, which is 2. The sum of these is 4 + 12 + 2\n",
      "= 18. For comparison, the optimal path has length 10.\n",
      "\n",
      "In Kaelbling’s experiments, she employed a variation of Q learning to learn terms (t1) and\n",
      "(t3), and she computed (t2) at regular intervals via the Floyd-Warshall all-sources shortest paths\n",
      "algorithm.\n",
      "\n",
      "46\n",
      "\n",
      "\f",
      "MaxRoot(g)\n",
      "\n",
      "gl/NL(g)\n",
      "\n",
      "QGotoGoalLmk(gl)\n",
      "\n",
      "QGotoGoal(g)\n",
      "\n",
      "MaxGotoGoalLmk(gl)\n",
      "\n",
      "QGotoLmk(l,gl)\n",
      "\n",
      "MaxGotoLmk(l)\n",
      "\n",
      "MaxGotoGoal(g)\n",
      "\n",
      "QNorthLmk(l)\n",
      "\n",
      "QSouthLmk(l)\n",
      "\n",
      "QEastLmk(l)\n",
      "\n",
      "QWestLmk(l)\n",
      "\n",
      "QNorthG(g)\n",
      "\n",
      "QSouthG(g)\n",
      "\n",
      "QEastG(g)\n",
      "\n",
      "QWestG(g)\n",
      "\n",
      "North\n",
      "\n",
      "South\n",
      "\n",
      "East\n",
      "\n",
      "West\n",
      "\n",
      "Figure 10: A MAXQ graph for the HDG navigation task.\n",
      "\n",
      "Figure 10 shows a MAXQ approach to solving this problem. The overall task Root, takes one\n",
      "\n",
      "argument g, which speciﬁes the goal cell. There are three subtasks:\n",
      "\n",
      "• GotoGoalLmk, go to the landmark nearest to the goal location. The termination for the\n",
      "predicate is true if the agent reaches the landmark nearest to the goal. The goal predicate is\n",
      "the same as the termination predicate.\n",
      "\n",
      "• GotoLmk(l), go to landmark l. The termination predicate for this is true if either (a) the\n",
      "agent reaches landmark l or (b) the agent is outside of the region deﬁned by the Voronoi cell\n",
      "for l and the neighboring Voronoi cells, N (l). The goal predicate for this subtask is true only\n",
      "for condition (a).\n",
      "\n",
      "• GotoGoal(g), go to the goal location g. The termination predicate for this subtask is true if\n",
      "either the agent is in the goal location or the agent is outside of the Voronoi cell N L(g) that\n",
      "contains g. The goal predicate for this subtask is true if the agent is in the goal location.\n",
      "\n",
      "The MAXQ decomposition is essentially the same as Kaelbling’s method, but somewhat redun-\n",
      "dant. Consider a state where the agent is not inside the same Voronoi cell as the goal g. In such\n",
      "\n",
      "47\n",
      "\n",
      "\f",
      "states, HDG decomposes the value function into three terms (t1), (t2), and (t3). Similarly, MAXQ\n",
      "also decomposes it into these same three terms:\n",
      "\n",
      "• V (GotoLmk(l), s, a) the cost of getting to landmark l.\n",
      "\n",
      "(Actually the sum of V (a, s) and\n",
      "\n",
      "C(GotoLmk(l), s, a).)\n",
      "\n",
      "• C(GotoGoalLmk(gl), s, M axGotoLmk(l)) the cost of getting from landmark l to the land-\n",
      "\n",
      "mark gl nearest the goal.\n",
      "\n",
      "• C(Root, s, GotoGoalLmk(gl)) the cost of getting to the goal location after reaching gl.\n",
      "\n",
      "When the agent is inside the goal Voronoi cell, then again HDG and MAXQ store essentially\n",
      "the same information. HDG stores Q(GotoGoal(g), s, a), while MAXQ breaks this into two terms:\n",
      "C(GotoGoal(g), s, a) and V (a, s) and then sums these two quantities to compute the Q value.\n",
      "\n",
      "Note that this MAXQ decomposition stores some information twice—speciﬁcally, the cost of\n",
      "getting from the goal landmark gl to the goal is stored both as C(Root, s, GotoGoalLmk(gl)) and\n",
      "as C(GotoGoal(g), s, a) + V (a, s).\n",
      "\n",
      "Let us compare the amount of memory required by ﬂat Q learning, HDG, and MAXQ. There\n",
      "are 100 locations, 4 possible actions, and 100 possible goal states, so ﬂat Q learning must store\n",
      "40,000 values.\n",
      "\n",
      "To compute quantity (t1), HDG must store 4 Q values (for the four actions) for each state s\n",
      "with respect to its own landmark and the landmarks in N (N L(s)). This gives a total of 2,028\n",
      "values that must be stored.\n",
      "\n",
      "To compute quantity (t2), HDG must store, for each landmark, information on the shortest\n",
      "path to every other landmark. There are 12 landmarks. Consider the landmark at row 6, column\n",
      "1.\n",
      "It has 5 neighboring landmarks which constitute the ﬁve macro actions that the agent can\n",
      "perform to move to another landmark. The nearest landmark to the goal cell could be any of the\n",
      "other 11 landmarks, so this gives a total of 55 Q values that must be stored. Similar computations\n",
      "for all 12 landmarks give a total of 506 values that must be stored.\n",
      "\n",
      "Finally, to compute quantity (t3), HDG must store information, for each square inside each\n",
      "Voronoi cell, about how to get to each of the other squares inside the same Voronoi cell. This\n",
      "requires 3,536 values.\n",
      "\n",
      "Hence, the grand total for HDG is 6,070, which is a huge savings over ﬂat Q learning.\n",
      "Now let’s consider the MAXQ hierarchy with and without state abstractions.\n",
      "\n",
      "• V (a, s): This is the expected reward of each primitive action in each state. There are 100\n",
      "states and 4 primitive actions, so this requires 400 values. However, because the reward is\n",
      "constant (−1), we can apply Leaf Irrelevance to store only a single value.\n",
      "\n",
      "• C(GotoLmk(l), s, a), where a is one of the four primitive actions. This requires the same\n",
      "amount of space as (t1) in Kaelbling’s representation—indeed, combined with V (a, a), this\n",
      "represents exactly the same information as (t1). It requires 2,028 values. No state abstractions\n",
      "can be applied.\n",
      "\n",
      "• C(GotoGoalLmk(gl), s, GotoLmk(l)): This is the cost of completing the GotoGoalLmk task after\n",
      "going to landmark l. If the primitive actions are deterministic, then GotoLmk(l) will always\n",
      "terminate at location l, and hence, we only need to store this for each pair of l and gl. This\n",
      "is exactly the same as Kaelbling’s quantity (t2), which requires 506 values. However, if the\n",
      "primitive actions are stochastic—as they were in Kaelbling’s original paper—then we must\n",
      "store this value for each possible terminal state of each GotoLmk action. Each of these actions\n",
      "\n",
      "48\n",
      "\n",
      "\f",
      "Table 6: Comparison of the number of values that must be stored to represent the value function\n",
      "using the HDG and MAXQ methods.\n",
      "\n",
      "HDG MAXQ\n",
      "item item\n",
      "\n",
      "(t1)\n",
      "(t2)\n",
      "(t3)\n",
      "\n",
      "V (a, s)\n",
      "C(GotoLmk(l), s, a)\n",
      "C(GotoGoalLmk, s, GotoLmk(l))\n",
      "C(GotoGoal(g), s, a)\n",
      "C(Root, s, GotoGoalLmk)\n",
      "C(Root, s, GotoGoal)\n",
      "\n",
      "Total Number of Values Required\n",
      "\n",
      "MAXQ\n",
      "\n",
      "HDG MAXQ MAXQ\n",
      "values\n",
      "0\n",
      "2,028\n",
      "506\n",
      "3,536\n",
      "0\n",
      "0\n",
      "6,070\n",
      "\n",
      "no abs\n",
      "400\n",
      "2,028\n",
      "6,600\n",
      "3,536\n",
      "100\n",
      "96\n",
      "12,760\n",
      "\n",
      "safe abs unsafe abs\n",
      "1\n",
      "2,028\n",
      "506\n",
      "3,536\n",
      "100\n",
      "0\n",
      "6,171\n",
      "\n",
      "1\n",
      "2,028\n",
      "6,600\n",
      "3,536\n",
      "100\n",
      "96\n",
      "12,361\n",
      "\n",
      "could terminate at its target landmark l or in one of the states bordering the set of Voronoi\n",
      "cells that are the neighbors of the cell for l. This requires 6,600 values. When Kaelbling\n",
      "stores values only for (t2), she is eﬀectively making the assumption that GotoLmk(l) will\n",
      "never fail to reach landmark l. This is an approximation which we can introduce into the\n",
      "MAXQ representation by our choice of state abstraction at this node.\n",
      "\n",
      "• C(GotoGoal, s, a): This is the cost of completing the GotoGoal task after making one of the\n",
      "primitive actions a. This is the same as quantity (t3) in the HDG representation, and it\n",
      "requires the same amoount of space: 3,536 values.\n",
      "\n",
      "• C(Root, s, GotoGoalLmk): This is the cost of reaching the goal once we have reached the\n",
      "landmark nearest the goal. MAXQ must represent this for all combinations of goal landmarks\n",
      "and goals. This requires 100 values. Note that these values are the same as the values of\n",
      "C(GotoGoal(g), s, a) + V (a, s) for each of the primitive actions. This means that the MAXQ\n",
      "representation stores this information twice, whereas the HDG representation only stores it\n",
      "once (as term (t3)).\n",
      "\n",
      "• C(Root, s, GotoGoal). This is the cost of completing the Root task after we have executed\n",
      "the GotoGoal task.\n",
      "If the primitive action are deterministic, this is always zero, because\n",
      "GotoGoal will have reached the goal. Hence, we can apply the Termination condition and not\n",
      "store any values at all. However, if the primitive actions are stochastic, then we must store\n",
      "this value for each possible state that borders the Voronoi cell that contains the goal. This\n",
      "requires 96 diﬀerent values. Again, in Kaelbling’s HDG representation of the value function,\n",
      "she is ignoring the probability that GotoGoal will terminate in a non-goal state. Because\n",
      "MAXQ is an exact representation of the value function, it does not ignore this possibility.\n",
      "If we (incorrectly) apply the Termination condition in this case, the MAXQ representation\n",
      "becomes a function approximation.\n",
      "\n",
      "In the stochastic case, without state abstractions, the MAXQ representation requires 12,760\n",
      "values. With safe state abstractions, it requires 12,361 values. With the approximations employed\n",
      "by Kaelbling (or equivalently, if the primitive actions are deterministic), the MAXQ representation\n",
      "with state abstractions requires 6,171 values. These numbers are summarized in Table 6. We can\n",
      "see that, with the unsafe state abstractions, the MAXQ representation requires only slightly more\n",
      "space than the HDG representation (because of the redundancy in storing C(Root, s, GotoGoalLmk).\n",
      "\n",
      "49\n",
      "\n",
      "\f",
      "This example shows that for the HDG task, we can start with the fully-general formulation\n",
      "provided by MAXQ and impose assumptions to obtain a method that is similar to HDG. The\n",
      "MAXQ formulation guarantees that the value function of the hierarchical policy will be represented\n",
      "exactly. The assumptions will introduce approximations into the value function representation.\n",
      "This might be useful as a general design methodology for building application-speciﬁc hierarchical\n",
      "representations. Our long-term goal is to develop such methods so that each new application does\n",
      "not require inventing a new set of techniques. Instead, oﬀ-the-shelf tools (e.g., based on MAXQ)\n",
      "could be specialized by imposing assumptions and state abstractions to produce more eﬃcient\n",
      "special-purpose systems.\n",
      "\n",
      "One of the most important contributions of the HDG method was that it introduced a form of\n",
      "non-hierarchical execution. As soon as the agent crosses from one Voronoi cell into another, the\n",
      "current subtask is “interrupted”, and the agent recomputes the “current target landmark”. The\n",
      "eﬀect of this is that (until it reaches the goal Voronoi cell), the agent is always aiming for a landmark\n",
      "outside of its current Voronoi cell. Hence, although the agent “aims for” a sequence of landmark\n",
      "states, it typically does not visit many of these states on its way to the goal. The states just provide\n",
      "a convenient set of intermediate targets. By taking these “shortcuts”, HDG compensates for the\n",
      "fact that, in general, it has overestimated the cost of getting to the goal, because its computed\n",
      "value function is based on a policy where the agent goes from one landmark to another.\n",
      "\n",
      "The same eﬀect is obtained by hierarchical greedy execution of the MAXQ graph (which was\n",
      "directly inspired by the HDG method). Note that by storing the N L (nearest landmark) function,\n",
      "Kaelbing’s HDG method can detect very eﬃciently when the current subtask should be interrupted.\n",
      "This technique only works for navigation problems in a space with a distance metric. In contrast,\n",
      "ExecuteHGPolicy performs a kind of “polling”, where it checks after each primitive action whether\n",
      "it should interrupt the current subroutine and invoke a new one. An important goal for future\n",
      "research on MAXQ is to ﬁnd a general purpose mechanism for avoiding unnecessary “polling”—\n",
      "that is, a mechanism that can discover eﬃciently-evaluable interrupt conditions.\n",
      "\n",
      "Figure 11 shows the results of our experiments with HDG using the MAXQ-Q learning al-\n",
      "gorithm. We employed the following parameters:\n",
      "for Flat Q learning, initial values of 0.123, a\n",
      "learning rate of 1.0, initial temperature of 50, and cooling rate of .9074; for MAXQ-Q without\n",
      "state abstractions:\n",
      "initial values of −25.123, learning rate of 1.0, initial temperature of 50, and\n",
      "cooling rates of .9074 for MaxRoot, .9999 for MaxGotoGoalLmk, .9074 for MaxGotoGoal, and .9526\n",
      "for MaxGotoLmk; for MAXQ-Q with state abstractions: initial values of −20.123, learning rate of\n",
      "1.0, initial temperature of 50, and cooling rates of .9760 for MaxRoot, .9969 for MaxGotoGoal, .9984\n",
      "for MaxGotoGoalLmk, and .9969 for MaxGotoLmk. Hierarchical greedy execution was introduced\n",
      "by starting with 3000 primitive actions per trial, and reducing this every trial by 2 actions, so that\n",
      "after 1500 trials, execution is completely greedy.\n",
      "\n",
      "The ﬁgure conﬁrms the observations made in our experiments with the Fickle Taxi task. With-\n",
      "out state abstractions, MAXQ-Q converges much more slowly than ﬂat Q learning. With state\n",
      "abstractions, it converges roughly three times as fast. Figure 12 shows a close-up view of Figure 11\n",
      "that allows us to compare the diﬀerences in the ﬁnal levels of performance of the methods. Here,\n",
      "we can see that MAXQ-Q with no state abstractions was not able to reach the quality of our hand-\n",
      "coded hierarchical policy—presumably even more exploration would be required to achieve this,\n",
      "whereas with state abstractions, MAXQ-Q is able to do slightly better than our hand-coded policy.\n",
      "With hierarchical greedy execution, MAXQ-Q is able to reach the goal using one fewer action,\n",
      "on the average—so that it approaches the performance of the best hierarchical greedy policy (as\n",
      "computed by value iteration). Notice however, that the best performance that can be obtained by\n",
      "hierarchical greedy execution of the best recursively-optimal policy cannot match optimal perfor-\n",
      "mance. Hence, Flat Q learning achieves a policy that reaches the goal state, on the average, with\n",
      "\n",
      "50\n",
      "\n",
      "\f",
      "MAXQ\n",
      "\n",
      "Flat Q\n",
      "\n",
      "MAXQ No Abstractions\n",
      "\n",
      "0\n",
      "\n",
      "-20\n",
      "\n",
      "-40\n",
      "\n",
      "-60\n",
      "\n",
      "-80\n",
      "\n",
      "-100\n",
      "\n",
      "-120\n",
      "\n",
      "-140\n",
      "\n",
      "d\n",
      "r\n",
      "a\n",
      "w\n",
      "e\n",
      "R\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "t\n",
      "a\n",
      "l\n",
      "u\n",
      "m\n",
      "u\n",
      "C\n",
      "n\n",
      "a\n",
      "e\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "\n",
      "0\n",
      "\n",
      "200000\n",
      "\n",
      "400000\n",
      "\n",
      "600000\n",
      "800000\n",
      "Primitive Actions\n",
      "\n",
      "1e+06\n",
      "\n",
      "1.2e+06\n",
      "\n",
      "1.4e+06\n",
      "\n",
      "Figure 11: Comparison of Flat Q learning with MAXQ-Q learning with and without state abstrac-\n",
      "tion. (Average of 100 runs.)\n",
      "\n",
      "about one fewer primitive action. Finally notice that as in the taxi domain, there was no added\n",
      "exploration cost for shifting to greedy execution.\n",
      "\n",
      "7.3 Parr and Russell: Hierarchies of Abstract Machines\n",
      "\n",
      "In his (1998b) dissertation work, Ron Parr considered an approach to hierarchical reinforcement\n",
      "learning in which the programmer encodes prior knowledge in the form of a hierarchy of ﬁnite-state\n",
      "controllers called a HAM (Hierarchy of Abstract Machines). The hierarchy is executed using a\n",
      "procedure-call-and-return discipline, and it provides a partial policy for the task. The policy is\n",
      "partial because each machine can include non-deterministic, “choice” machine states, in which the\n",
      "machine lists several options for action but does not specify which one should be chosen. The\n",
      "programmer puts “choice” states at any point where he/she does not know what action should\n",
      "be performed. Given this partial policy, Parr’s goal is to ﬁnd the best policy for making choices\n",
      "in the choice states. In other words, his goal is to learn a hierarchical value function V (hs, mi),\n",
      "where s is a state (of the external environment) and m contains all of the internal state of the\n",
      "hierarchy (i.e., the contents of the procedure call stack and the values of the current machine states\n",
      "for all machines appearing in the stack). A key observation is that it is only necessary to learn this\n",
      "value function at choice states hs, mi. Parr’s algorithm does not learn a decomposition of the value\n",
      "function. Instead, it “ﬂattens” the hierarchy to create a new Markov decision problem over the\n",
      "choice states hs, mi. Hence, it is hierarchical primarily in the sense that the programmer structures\n",
      "the prior knowledge hierarchically. An advantage of this is that Parr’s method can ﬁnd the optimal\n",
      "hierarchical policy subject to constraints provided by the programmer. A disadvantage is that the\n",
      "method cannot be executed “non-hierarchically” to produce a better policy.\n",
      "\n",
      "51\n",
      "\n",
      "\f",
      "MAXQ Greedy\n",
      "\n",
      "MAXQ\n",
      "\n",
      "Optimal Policy\n",
      "\n",
      "Hierarchical Greedy Optimal Policy\n",
      "\n",
      "Hierarchical Hand-coded Policy\n",
      "\n",
      "Flat Q\n",
      "\n",
      "MAXQ No Abstractions\n",
      "\n",
      "d\n",
      "r\n",
      "a\n",
      "w\n",
      "e\n",
      "R\n",
      " \n",
      "e\n",
      "v\n",
      "i\n",
      "t\n",
      "a\n",
      "l\n",
      "u\n",
      "m\n",
      "u\n",
      "C\n",
      "n\n",
      "a\n",
      "e\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "\n",
      "-6\n",
      "\n",
      "-8\n",
      "\n",
      "-10\n",
      "\n",
      "-12\n",
      "\n",
      "-14\n",
      "\n",
      "0\n",
      "\n",
      "200000\n",
      "\n",
      "400000\n",
      "\n",
      "600000\n",
      "800000\n",
      "Primitive Actions\n",
      "\n",
      "1e+06\n",
      "\n",
      "1.2e+06\n",
      "\n",
      "1.4e+06\n",
      "\n",
      "Figure 12: Expanded view comparing Flat Q learning with MAXQ-Q learning with and without\n",
      "state abstraction and with and without hierarchical greedy execution. (Average of 100 runs.)\n",
      "\n",
      "Parr illustrated his work using the maze shown in Figure 13. This maze has a high-level structure\n",
      "(i.e., as a series of hallways and intersections), and a low-level structure (a series of obstacles that\n",
      "must be avoided in order to move through the hallways and intersections). In each trial, the agent\n",
      "starts in the top left corner, and it must move to any state in the bottom right corner room. The\n",
      "agent has the usual four primitive actions, North, South, East, and West. The actions are stochastic:\n",
      "with probability 0.8, they succeed, but with probability 0.1 the action will move to the “left” and\n",
      "with probability 0.1 the action will move to the “right” instead (e.g., a North action will move east\n",
      "with probability 0.1 and west with probability 0.1). If an action would collide with a wall or an\n",
      "obstacle, it has no eﬀect.\n",
      "\n",
      "The maze is structured as a series of “rooms”, each containing a 12-by-12 block of states (and\n",
      "various obstacles). Some rooms are parts of “hallways”, because they contain walls on two opposite\n",
      "sides, and they are open on the other two sides. Other rooms are “intersections”, where two or\n",
      "more hallways meet.\n",
      "\n",
      "To test the representational power of the MAXQ hierarchy, we want to see how well it can\n",
      "represent the prior knowledge that Parr is able to represent using the HAM. We begin by describing\n",
      "Parr’s HAM for his maze task, and then we will present a MAXQ hierarchy that captures much of\n",
      "the same prior knowledge.2\n",
      "\n",
      "Parr’s top level machine, MRoot, consists of a loop with a single choice state that chooses among\n",
      "four possible child machines: MGo(East), MGo(South), MGo(W est), and MGo(N orth). The loop\n",
      "terminates when the agent reaches a goal state. MRoot will only invoke a particular machine if there\n",
      "is a hallway in the speciﬁed direction. Hence, in the start state, it will only consider MGo(South)\n",
      "\n",
      "2The author thanks Ron Parr for providing the details of the HAM for this task.\n",
      "\n",
      "52\n",
      "\n",
      "\f",
      "and MGo(East).\n",
      "\n",
      "The MGo(d) machine begins executing when the agent is in an intersection. So the ﬁrst thing it\n",
      "tries to do is to exit the intersection into a hallway in speciﬁed direction d. Then it attempts\n",
      "to traverse the hallway until it reaches another intersection.\n",
      "It does this by ﬁrst invoking a\n",
      "ExitIntersection(d) machine. When that machine returns, it then invokes a MExitHallway(d) ma-\n",
      "chine. When that machine returns, MGo also returns.\n",
      "\n",
      "The MExitIntersection and MExitHallway machines are identical except for their termination con-\n",
      "ditions. Both machines consist of a loop with one choice state that chooses among four possible sub-\n",
      "routines. To simplify their description, suppose that MGo(East) has chosen MExitIntersection(East).\n",
      "Then the four possible subroutines are MSniﬀ(East, N orth), MSniﬀ(East, South), MBack(East, N orth),\n",
      "and MBack(East, South).\n",
      "\n",
      "The MSniﬀ(d, p) machine always moves in direction d until it encounters a wall (either part of\n",
      "an obstacle or part of the walls of the maze). Then it moves in perpendicular direction p until it\n",
      "reaches the end of the wall. A wall can “end” in two ways: either the agent is now trapped in a\n",
      "corner with walls in both directions d and p or else there is no longer a wall in direction d. In the\n",
      "ﬁrst case, the MSniﬀ machine terminates; in the second case, it resumes moving in direction d.\n",
      "\n",
      "The MBack(d, p) machine moves one step backwards (in the direction opposite from d) and\n",
      "then moves ﬁve steps in direction p. These moves may or may not succeed, because the actions are\n",
      "stochastic and there may be walls blocking the way. But the actions are carried out in any case,\n",
      "and then the MBack machine returns.\n",
      "\n",
      "The MSniﬀ and MBack machines also terminate if they reach the end of a hall or the end of an\n",
      "\n",
      "intersection.\n",
      "\n",
      "These ﬁnite-state controllers deﬁne a highly constrained partial policy. The MBack, MSniﬀ,\n",
      "and MGo machines contain no choice states at all. The only choice points are in MRoot, which\n",
      "must choose the direction in which to move, and in MExitIntersection and MExitHall, which must\n",
      "decide when to call MSniﬀ, when to call MBack, and which “perpendicular” direction to tell these\n",
      "machines to try when they cannot move forward.\n",
      "\n",
      "Figure 14 shows a MAXQ graph that encodes a similar set of constraints on the policy. The\n",
      "\n",
      "subtasks are deﬁned as follows:\n",
      "\n",
      "• Root. This is exactly the same as the MRoot machine. It must choose a direction d and invoke\n",
      "Go. It terminates when the agent enters a terminal state. This is also its goal condition (of\n",
      "course).\n",
      "\n",
      "• Go(d, r). The parameter r is bound to the current 12-by-12 “room” in which the agent is\n",
      "located. Go terminates when the agent enters the room at the end of the hallway in direction\n",
      "d or when it leaves the desired hallway (e.g., in the wrong direction). The goal condition for\n",
      "Go is satisﬁed only if the agent reaches the desired intersection.\n",
      "\n",
      "• ExitInter(d, r). This terminates when the agent has exited room r. The goal condition is that\n",
      "\n",
      "the agent exit room r in direction d.\n",
      "\n",
      "• ExitHall(d, r). This terminates when the agent has exited the current hall (into some intersec-\n",
      "tion). The goal condition is that the agent has entered the desired intersection in direction\n",
      "d.\n",
      "\n",
      "• Sniﬀ(d, r). This encodes a subtask that is equivalent to the MSniﬀ machine. However, Sniﬀ\n",
      "must have two child subtasks, ToWall and FollowWall that were simply internal states of\n",
      "MSniﬀ. This is necessary, because a subtask in the MAXQ framework cannot contain any\n",
      "\n",
      "53\n",
      "\n",
      "\f",
      "internal state, whereas a ﬁnite-state controller in the HAM representation can contain as\n",
      "many internal states as necessary. In particular, it can have one state for when it is moving\n",
      "forward and another state for when it is following a wall sideways.\n",
      "\n",
      "• ToWall(d). This is equivalent to part of MSniﬀ, and it terminates when there is a wall\n",
      "in “front” of the agent in direction d. The goal condition is the same as the termination\n",
      "condition.\n",
      "\n",
      "• FollowWall(d, p). This is equivalent to the other part of MSniﬀ. It moves in direction p until\n",
      "the wall in direction d ends (or until it is stuck in a corner with walls in both directions d\n",
      "and p). The goal condition is the same as the termination condition.\n",
      "\n",
      "• Back(d, p, x, y). This attempts to encode the same information as the MBack machine, but\n",
      "this is a case where the MAXQ hierarchy cannot capture the same information. MBack simply\n",
      "executes a sequence of 6 primitive actions (one step back, ﬁve stes in direction p). But to\n",
      "do this, MBack must have 6 internal states, which MAXQ does not allow. Instead, the Back\n",
      "subtask is has the subgoal of moving the agent at least one square backwards and at least 3\n",
      "squares in the direction p. In order to determine whether it has achieved this subgoal, it must\n",
      "remember the x and y position where it started to execute, so these are bound as parameters\n",
      "to Back. Back terminates if it achieves this subgoal or if it runs into walls that prevent it\n",
      "from achieving the subgoal. The goal condition is the same as the termination condition.\n",
      "\n",
      "• BackOne(d, x, y). This moves the agent one step backwards (in the direction opposite to d.\n",
      "It needs the starting x and y position in order to tell when it has succeeded. It terminates\n",
      "if it has moved at least one unit in direction d or if there is a wall in this direction. Its goal\n",
      "condition is the same as its termination condition.\n",
      "\n",
      "• PerpThree(p, x, y). This moves the agent three steps in the direction p. It needs the starting\n",
      "x and y positions in order to tell when it has succeeded. It terminates when it has moved at\n",
      "least three units in the direction p or if there is a wall in that direction. The goal condition\n",
      "is the same as the termination condition.\n",
      "\n",
      "• Move(d). This is a “parameterized primitive” action.\n",
      "\n",
      "It executes one primitive move in\n",
      "\n",
      "direction d and terminates immediately.\n",
      "\n",
      "From this, we can see that there are three major diﬀerences between the MAXQ representation\n",
      "and the HAM representation. First, a HAM ﬁnite-state controller can contain internal states. To\n",
      "convert them into a MAXQ subtask graph, we must make a separate subtask for each internal state\n",
      "in the HAM. Second, a HAM can terminate based on an “amount of eﬀort” (e.g., performing 5\n",
      "actions), whereas a MAXQ subtask must terminate based on some change in the state of the world.\n",
      "It is impossible to deﬁne a MAXQ subtask that performs k steps and then terminate regardless of\n",
      "the eﬀects of those steps (i.e., without adding some kind of “counter” to the state of the MDP).\n",
      "Third, it is more diﬃcult to formulate the termination conditions for MAXQ subtasks than for\n",
      "HAM machines. For example, in the HAM, it was not necessary to specify that the MExitHallway\n",
      "machine terminates when it has entered a diﬀerent intersection than the one where the MGo was\n",
      "executed. However, this is important for the MAXQ method, because in MAXQ, each subtask\n",
      "learns its own value function and policy—independent of its parent tasks. For example, without\n",
      "the requirement to enter a diﬀerent intersection, the learning algorithms for MAXQ will always\n",
      "prefer to have MaxExitHall take one step backward and return to the room in which the Go action\n",
      "was started (because that is a much easier terminated state to reach). This problem does not arise\n",
      "\n",
      "54\n",
      "\n",
      "\f",
      "in the HAM approach, because the policy learned for a subtask depends on the whole “ﬂattened”\n",
      "hierarchy of machines, and returning to the state where the Go action was started does not help\n",
      "solve the overall problem of reaching the goal state in the lower right corner.\n",
      "\n",
      "To construct the MAXQ graph for this problem, we have introduced three programming tricks:\n",
      "(a) binding parameters to aspects of the current state (in order to serve as a kind of “local memory”\n",
      "for where the subtask began executing), (b) having a parameterized primitive action (in order to be\n",
      "able to pass a parameter value that speciﬁes which primitive action to perform), and (c) employing\n",
      "“inheritance of termination conditions”—that is, each subtask in this MAXQ graph (but not the\n",
      "others in this paper) inherits the termination conditions of all of its ancestor tasks. Hence, if the\n",
      "agent is in the middle of executing a ToWall action when it leaves an intersection, the ToWall\n",
      "subroutine terminates because the ExitInter subroutine has terminated.\n",
      "If this satisﬁes the goal\n",
      "condition of ExitInter, then it is also considered to satisfy the goal condition of ToWall. This\n",
      "inheritance made it easier to write the MAXQ graph, because the parents did not need to pass\n",
      "down to their children all of the information necessary to deﬁne the complete termination and goal\n",
      "predicates.\n",
      "\n",
      "There are essentially no opportunities for state abstraction in this task, because there are no ir-\n",
      "relevant features of the state. There are some opportunities to apply the Shielding and Termination\n",
      "properties, however. In particular, ExitHall(d) is guaranteed to cause its parent task, MaxGo(d) to\n",
      "terminate, so it does not require any stored C values. There are many states where some subtasks\n",
      "are terminated (e.g., Go(East) in any state where there is a wall on the east side of the room), and\n",
      "so no C values need to be stored.\n",
      "\n",
      "Nonetheless, even after applying the state elimination conditions, the MAXQ representation for\n",
      "this task requires much more space than a ﬂat representation. An exact computation is diﬃcult,\n",
      "but after applying MAXQ-Q learning, the MAXQ representation required 52,043 values, whereas\n",
      "ﬂat Q learning requires fewer than 16,704 values. Parr states that his method requires only 4,300\n",
      "values.\n",
      "\n",
      "To test the relative eﬀectiveness of the MAXQ representation, we compare MAXQ-Q learning\n",
      "with ﬂat Q learning. Because of the very large negative values that some states acquire (particularly\n",
      "during the early phases of learning), we were unable to get Boltzmann exploration to work well—\n",
      "one very bad trial would cause an action to receive such a low Q value, that it would never be tried\n",
      "again. Hence, we experimented with both ǫ-greedy exploration and counter-based exploration. The\n",
      "ǫ-greedy exploration policy is an ordered, abstract GLIE policy in which a random action is chosen\n",
      "with probability ǫ, and ǫ is gradually decreased over time. The counter-based exploration policy\n",
      "keeps track of how many times each action a has been executed in each state s. To choose an\n",
      "action in state s, it selects the action that has been executed the fewest times until all actions\n",
      "have been executed T times. Then it switches to greedy execution. Hence, it is not a genuine\n",
      "GLIE policy. Parr employed counter-based exploration policies in his experiments with this task.\n",
      "For Flat Q learning, we chose the following parameters:\n",
      "learning rate 0.50, initial value for ǫ of\n",
      "1.0, ǫ decreased by 0.001 after each successful execution of a Max node, and initial Q values of\n",
      "−200.123. For MAXQ-Q learning, we chose the following parameters: counter-based exploration\n",
      "with T = 10, learning rate equal to the reciprocal of the number of times an action had been\n",
      "performed, and initial values for the C values selected carefully to provide underestimates of the\n",
      "true C values. For example, the initial values for QExitInter were −40.123, because in the worst\n",
      "case, after completing an ExitInter task, it takes about 40 steps to complete the subsequent ExitHall\n",
      "task and hence, complete the Go parent task.\n",
      "\n",
      "Figure 15 plots the results. We can see that MAXQ-Q learning converges about 10 times faster\n",
      "than Flat Q learning. We do not know whether MAXQ-Q has converged to a recursively optimal\n",
      "policy. For comparison, we also show the performance of a hierarchical policy that we coded\n",
      "\n",
      "55\n",
      "\n",
      "\f",
      "by hand, but in our hand-coded policy, we used knowledge of contextual information to choose\n",
      "operators, so this policy is surely better than the best recursively optimal policy. HAMQ learning\n",
      "should converge to a policy equal to or slightly better than our hand-coded policy.\n",
      "\n",
      "This experiment demonstrates that the MAXQ representation can capture most—but not all—\n",
      "of the prior knowledge that can be represented by the HAMQ hierarchy. It also shows that the\n",
      "MAXQ representation requires much more care in the design of the goal conditions for the subtasks.\n",
      "\n",
      "7.4 Other Domains\n",
      "\n",
      "In addition to the three domains discussed above, we have developed MAXQ graphs for Singh’s\n",
      "(1992b) “ﬂag task”, the treasure hunter task described by Tadepalli and Dietterich (Tadepalli &\n",
      "Dietterich, 1997), and Dayan and Hinton’s (1993) Fuedal-Q learning task. All of these tasks can\n",
      "be easily and naturally placed into the MAXQ framework—indeed, all of them ﬁt more easily than\n",
      "the Parr and Russell maze task.\n",
      "\n",
      "MAXQ is able to exactly duplicate Singh’s work and his decomposition of the value function—\n",
      "while using exactly the same amount of space to represent the value function. MAXQ can also\n",
      "duplicate the results from Tadepalli and Dietterich—however, because MAXQ is not an explanation-\n",
      "based method, it is considerably slower and requires substantially more space to represent the value\n",
      "function.\n",
      "\n",
      "In the Feudal-Q task, MAXQ is able to give better performance than Feudal-Q learning. The\n",
      "reason is that in Feudal-Q learning, each subroutine makes decisions using only a Q function\n",
      "learned at that level—that is, without information about the estimated costs of the actions of its\n",
      "descendants.\n",
      "In contrast, the MAXQ value function decomposition permits each Max node to\n",
      "make decisions based on the sum of its completion function, C(i, s, j), and the costs estimated by\n",
      "its descendants, V (j, s). Of course, MAXQ also supports non-hierarchical execution, which is not\n",
      "possible for Feudal-Q, because it does not learn a value function decomposition.\n",
      "\n",
      "8 Discussion: Design Tradeoﬀs in Hierarchical Reinforcement\n",
      "\n",
      "Learning\n",
      "\n",
      "At the start of this paper, we discussed four issues concerning the design of hierarchical reinforce-\n",
      "ment learning architectures. In this section, we want to highlight a tradeoﬀ between two of those\n",
      "issues: the method for deﬁning subtasks and the use of state abstraction.\n",
      "\n",
      "MAXQ deﬁnes subtasks using a termination predicate Ti and a pseudo-reward function ˜R. There\n",
      "are at least two drawbacks of this method. First, it can be hard for the programmer to deﬁne Ti\n",
      "and ˜R correctly, since this essentially requires guessing the value function of the optimal policy\n",
      "for the MDP at all states where the subtask terminates. Second, it leads us to seek a recursively\n",
      "optimal policy rather than a hierarchically optimal policy. Recursively optimal policies may be\n",
      "much worse than hierarchically optimal ones, so we may be giving up substantial performance.\n",
      "\n",
      "However, in return for these two drawbacks, MAXQ obtains a very important beneﬁt: the\n",
      "policies and value functions for subtasks become context-free. In other words, they do not depend\n",
      "on their parent tasks or the larger context in which they are invoked. To understand this point,\n",
      "consider again the MDP shown in Figure 6.\n",
      "It is clear that the optimal policy for exiting the\n",
      "left-hand room (the Exit subtask) depends on the location of the goal. If it is at the top of the\n",
      "right-hand room, then the agent should prefer to exit via the upper door, whereas if it is at the\n",
      "bottom of the right-hand room, the agent should prefer to exit by the lower door. However, if\n",
      "we deﬁne the subtask of exiting the left-hand room using a pseudo-reward of zero for both doors,\n",
      "\n",
      "56\n",
      "\n",
      "\f",
      "then we obtain a policy that is not optimal in either case, but a policy that we can re-use in both\n",
      "cases. Furthermore, this policy does not depend on the location of the goal. Hence, we can apply\n",
      "Max node irrelevance to solve the Exit subtask using only the location of the robot and ignore the\n",
      "location of the goal.\n",
      "\n",
      "This example shows that we obtain the beneﬁts of subtask reuse and state abstraction because\n",
      "we deﬁne the subtask using a termination predicate and a pseudo-reward function. The termination\n",
      "predicate and pseudo-reward function provide a barrier that prevents “communication” of value\n",
      "information between the Exit subtask and its context.\n",
      "\n",
      "Compare this to Parr’s HAM method. The HAMQ algorithm ﬁnds the best policy consistent\n",
      "with the hierarchy. To achieve this, it must permit information to propagate “into” the Exit subtask\n",
      "(i.e., the Exit ﬁnite-state controller) from its environment. But this means that if any state that is\n",
      "reached after leaving the Exit subtask has diﬀerent values depending on the location of the goal,\n",
      "then these diﬀerent values will propagate back into the Exit subtask. To represent these diﬀerent\n",
      "values, the Exit subtask must know the location of the goal. In short, to achieve a hierarchically\n",
      "optimal policy within the Exit subtask, we must (in general) represent its value function using the\n",
      "entire state space.\n",
      "\n",
      "We can see, therefore, that there is a direct tradeoﬀ between achieving hierarchical optimality\n",
      "and achieving recursive optimality. Methods for hierarchical optimality have more freedom in\n",
      "deﬁning subtasks (e.g., using complete policies, as in the option approach, or using partial policies,\n",
      "as in the HAM approach). But they cannot employ state abstractions within subtasks, and in\n",
      "general, they cannot reuse the solution of one subtask in multiple contexts. Methods for recursive\n",
      "optimality, on the other hand, must deﬁne subtasks using some method (such as pseudo-reward\n",
      "functions) that isolates the subtask from its context. But in return, they can apply state abstraction\n",
      "and the learned policy can be reused in many contexts (where it will be more or less optimal).\n",
      "\n",
      "It is interesting that the iterative method described by Dean and Lin (1995) can be viewed as\n",
      "a method for moving along this tradeoﬀ. In the Dean and Lin method, the programmer makes an\n",
      "initial guess for the values of the terminal states of each subtask (i.e., the doorways in Figure 6).\n",
      "Based on this initial guess, the locally optimal policies for the subtasks are computed. Then\n",
      "the locally optimal policy for the parent task is computed—while holding the subtask policies\n",
      "ﬁxed (i.e., treating them as options). At this point, their algorithm has computed the recursively\n",
      "optimal solution to the original problem, given the initial guesses. Instead of solving the various\n",
      "subproblems sequentially via an oﬄine algorithm, we could use the MAXQ-Q learning algorithm.\n",
      "But the method of Dean and Lin does not stop here. Instead, it computes new values of the\n",
      "terminal states of each subtask based on the learned value function for the entire problem. This\n",
      "allows it to update its “guesses” for the values of the terminal states. The entire solution process\n",
      "can now be repeated. To obtain a new recursively optimal solution, based on the new guesses.\n",
      "They prove that if this process is iterated indeﬁnitely, it will converge to the recursively optimal\n",
      "policy (provided, of course, that no state abstractions are used within the subtasks).\n",
      "\n",
      "This suggests an extension to MAXQ-Q learning that adapts the ˜R values online. Each time a\n",
      "subtask terminates, we could update the ˜R function based on the computed value of the terminated\n",
      "state. To be precise, if j is a subtask of i, then when j terminates in state s′, we should update\n",
      "˜R(j, s′) to be equal to ˜V (i, s′) = maxa′ ˜Q(i, s′, a′). However, this will only work if ˜R(j, s′) is\n",
      "represented using the full state s′. If subtask j is employing state abstractions, x = χ(s), then\n",
      "˜R(j, x′) will need to be the average value of ˜V (i, s′), where the average is taken over all states s′ such\n",
      "that x′ = χ(s′) (weighted by the probability of visiting those states). This is easily accomplished\n",
      "by performing a stochastic approximation update of the form\n",
      "\n",
      "˜R(j, x′) = (1 − αt) ˜R(j, x′) + αt ˜V (i, s′)\n",
      "\n",
      "57\n",
      "\n",
      "\f",
      "each time subtask j terminates. Such an algorithm could be expected to converge to the best\n",
      "hierarchical policy consistent with the given state abstractions.\n",
      "\n",
      "This also suggests that in some problems, it may be worthwhile to ﬁrst learn a recursively\n",
      "optimal policy using very aggressive state abstractions and then use the learned value function\n",
      "to initialize a MAXQ representation with a more detailed representation of the states. These\n",
      "progressive reﬁnements of the state space could be guided by monitoring the degree to which the\n",
      "values of ˜V (i, s′) vary for a single abstract state x′. If they have a large variance, this means that\n",
      "the state abstractions are failing to make important distinctions in the values of the states, and\n",
      "they should be reﬁned.\n",
      "\n",
      "Both of these kinds of adaptive algorithms will take longer to converge than the basic MAXQ\n",
      "method described in this paper. But for tasks that an agent must solve many times in its lifetime,\n",
      "it is worthwhile to have learning algorithms that provide an initial useful solution but gradually\n",
      "improve that solution until it is optimal. An important goal for future research is to ﬁnd methods\n",
      "for diagnosing and repairing errors (or sub-optimalities) in the initial hierarchy so that ultimately\n",
      "the optimal policy is discovered.\n",
      "\n",
      "9 Concluding Remarks\n",
      "\n",
      "This paper has introduced a new representation for the value function in hierarchical reinforcement\n",
      "learning—the MAXQ value function decomposition. We have proved that the MAXQ decompo-\n",
      "sition can represent the value function of any hierarchical policy under both the ﬁnite-horizon\n",
      "undiscounted, cumulative reward criterion and the inﬁnite-horizon discounted reward criterion.\n",
      "This representation supports subtask sharing and re-use, because the overall value function is de-\n",
      "composed into value functions for individual subtasks.\n",
      "\n",
      "The paper introduced a learning algorithm, MAXQ-Q learning, and proved that it converges\n",
      "with probability 1 to a recursively optimal policy. The paper argued that although recursive\n",
      "optimality is weaker than either hierarchical optimality or global optimality, it is an important\n",
      "form of optimality because it permits each subtask to learn a locally optimal policy while ignoring\n",
      "the behavior of its ancestors in the MAXQ graph. This increases the opportunities for subtask\n",
      "sharing and state abstraction.\n",
      "\n",
      "We have shown that the MAXQ decomposition creates opportunities for state abstraction, and\n",
      "we identiﬁed a set of ﬁve properties (Max Node Irrelevance, Leaf Irrelevance, Result Distribution\n",
      "Irrelevance, Shielding, and Termination) that allow us to ignore large parts of the state space\n",
      "within subtasks. We proved that MAXQ-Q still converges in the presence of these forms of state\n",
      "abstraction, and we showed experimentally that state abstraction is important in practice for the\n",
      "successful application of MAXQ-Q learning—at least in the Taxi and Kaelbling HDG tasks.\n",
      "\n",
      "The paper presented two diﬀerent methods for deriving improved non-hierarchical policies from\n",
      "the MAXQ value function representation, and it has formalized the conditions under which these\n",
      "methods can improve over the hierarchical policy. The paper veriﬁed experimentally that non-\n",
      "hierarchical execution gives improved performance in the Fickle Taxi Task (where it achieves opti-\n",
      "mal performance) and in the HDG task (where it gives a substantial improvement).\n",
      "\n",
      "Finally, the paper has argued that there is a tradeoﬀ governing the design of hierarchical rein-\n",
      "forcement learning methods. At one end of the design spectrum are “context free” methods such\n",
      "as MAXQ. They provide good support for state abstraction and subtask sharing but they can only\n",
      "learn recursively optimal policies. At the other end of the spectrum are “context-sensitive” meth-\n",
      "ods such as HAMQ, the options framework, and the early work of Dean and Lin. These methods\n",
      "can discover hierarchically optimal policies (or, in some cases, globally optimal policies), but their\n",
      "\n",
      "58\n",
      "\n",
      "\f",
      "drawback is that they cannot easily exploit state abstractions or share subtasks. Because of the\n",
      "great speedups that are enabled by state abstraction, this paper has argued that the context-free\n",
      "approach is to be preferred—and that it can be relaxed as needed to obtain improved policies.\n",
      "\n",
      "Acknowledgements\n",
      "\n",
      "The author gratefully acknowledges the support of the National Science Foundation under grant\n",
      "number IRI-9626584, the Oﬃce of Naval Research under grant number N00014-95-1-0557, the Air\n",
      "Force Oﬃce of Scientiﬁc Research under grant number F49620-98-1-0375, and the Spanish Council\n",
      "for Scientiﬁc Research. In addition, the author is indebted to many colleagues for helping develop\n",
      "and clarify the ideas in this paper including Valentina Bayer, Leslie Kaelbling, Bill Langford,\n",
      "Wes Pinchot, Rich Sutton, Prasad Tadepalli, and Sebastian Thrun. I particularly want to thank\n",
      "Eric Chown for encouraging me to study Feudal reinforcement learning, Ron Parr for providing the\n",
      "details of his HAM machines, and Sebastian Thrun encouraging me to write a single comprehensive\n",
      "paper. I also thank the anonymous reviewers of previous drafts of this paper for their suggestions\n",
      "and careful reading, which have improved the paper immeasurably.\n",
      "\n",
      "References\n",
      "\n",
      "Bellman, R. E. (1957). Dynamic Programming. Princeton University Press.\n",
      "\n",
      "Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientiﬁc,\n",
      "\n",
      "Belmont, MA.\n",
      "\n",
      "Boutilier, C., Shoham, Y., & Wellman, M. (1997). Economic principles of multi-agent systems\n",
      "\n",
      "(Editorial). Artiﬁcial Intelligence, 94 (1–2), 1–6.\n",
      "\n",
      "Boutilier, C., Dean, T., & Hanks, S. (1999). Decision theoretic planning: Structural assumptions\n",
      "\n",
      "and computational leverage. Journal of Artiﬁcial Intelligence Research, To appear.\n",
      "\n",
      "Currie, K., & Tate, A. (1991). O-plan: The open planning architecture. Artiﬁcial Intelligence,\n",
      "\n",
      "52 (1), 49–86.\n",
      "\n",
      "Dayan, P., & Hinton, G. (1993). Feudal reinforcement learning. In Advances in Neural Information\n",
      "\n",
      "Processing Systems, 5, pp. 271–278. Morgan Kaufmann, San Francisco, CA.\n",
      "\n",
      "Dean, T., & Lin, S.-H. (1995). Decomposition techniques for planning in stochastic domains.\n",
      "Tech. rep. CS-95-10, Department of Computer Science, Brown University, Providence, Rhode\n",
      "Island.\n",
      "\n",
      "Dietterich, T. G. (1998). The MAXQ method for hierarchical reinforcement learning. In Fifteenth\n",
      "\n",
      "International Conference on Machine Learning.\n",
      "\n",
      "Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning and executing generalized robot plans.\n",
      "\n",
      "Artiﬁcial Intelligence, 3, 251–288.\n",
      "\n",
      "Hauskrecht, M., Meuleau, N., Boutilier, C., Kaelbling, L., & Dean, T. (1998). Hierarchical solution\n",
      "of Markov decision processes using macro-actions. Tech. rep., Brown University, Department\n",
      "of Computer Science, Providence, RI.\n",
      "\n",
      "Howard, R. A. (1960). Dynamic Programming and Markov Processes. MIT Press, Cambridge, MA.\n",
      "\n",
      "59\n",
      "\n",
      "\f",
      "Jaakkola, T., Jordan, M. I., & Singh, S. P. (1994). On the convergence of stochastic iterative\n",
      "\n",
      "dynamic programming algorithms. Neural Computation, 6 (6), 1185–1201.\n",
      "\n",
      "Kaelbling, L. P. (1993). Hierarchical reinforcement learning: Preliminary results. In Proceedings\n",
      "of the Tenth International Conference on Machine Learning, pp. 167–173 San Francisco, CA.\n",
      "Morgan Kaufmann.\n",
      "\n",
      "Knoblock, C. A. (1990). Learning abstraction hierarchies for problem solving. In Proceedings of the\n",
      "Eighth National Conference on Artiﬁcial Intelligence, pp. 923–928 Boston, MA. AAAI Press.\n",
      "\n",
      "Korf, R. E. (1985). Macro-operators: A weak method for learning. Artiﬁcial Intelligence, 26 (1),\n",
      "\n",
      "35–77.\n",
      "\n",
      "Lin, L.-J. (1993). Reinforcement learning for robots using neural networks. Ph.D. thesis, Carnegie\n",
      "\n",
      "Mellon University, Department of Computer Science, Pittsburgh, PA.\n",
      "\n",
      "Parr, R. (1998a). Flexible decomposition algorithms for weakly coupled markov decision problems.\n",
      "In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artiﬁcial Intelligence\n",
      "(UAI–98), pp. 422–430 San Francisco, CA. Morgan Kaufmann Publishers.\n",
      "\n",
      "Parr, R. (1998b). Hierarchical control and learning for Markov decision processes. Ph.D. thesis,\n",
      "\n",
      "University of California, Berkeley, California.\n",
      "\n",
      "Parr, R., & Russell, S. (1998). Reinforcement learning with hierarchies of machines. In Advances\n",
      "\n",
      "in Neural Information Processing Systems, Vol. 10 Cambridge, MA. MIT Press.\n",
      "\n",
      "Pearl, J. (1988). Probabilistic Inference in Intelligent Systems. Networks of Plausible Inference.\n",
      "\n",
      "Morgan Kaufmann, San Mateo, CA.\n",
      "\n",
      "Rummery, G. A., & Niranjan, M. (1994). Online Qlearning using connectionist systems. Tech.\n",
      "rep. CUED/FINFENG/TR 166, Cambridge University Engineering Department, Cambridge,\n",
      "England.\n",
      "\n",
      "Sacerdoti, E. D. (1974). Planning in a hierarchy of abstraction spaces. Artiﬁcial Intelligence, 5 (2),\n",
      "\n",
      "115–135.\n",
      "\n",
      "Singh, S., Jaakkola, T., Littman, M. L., & Szepesv´ari, C. (1998). Convergence results for single-step\n",
      "on-policy reinforcement-learning algorithms. Tech. rep., University of Colorado, Department\n",
      "of Computer Science, Boulder, CO.\n",
      "\n",
      "Singh, S. P. (1992a). Transfer of learning by composing solutions of elemental sequential tasks.\n",
      "\n",
      "Machine Learning, 8, 323–339.\n",
      "\n",
      "Singh, S. P. (1992b). Transfer of learning by composing solutions of elemental sequential tasks.\n",
      "\n",
      "Machine Learning, 8, 323.\n",
      "\n",
      "Sutton, R. S., Singh, S., Precup, D., & Ravindran, B. (1999). Improved switching among temporally\n",
      "abstract actions. In Advances in Neural Information Processing Systems, Vol. 11. MIT Press.\n",
      "\n",
      "Sutton, R., & Barto, A. G. (1998). Introduction to Reinforcement Learning. MIT Press, Cambridge,\n",
      "\n",
      "MA.\n",
      "\n",
      "60\n",
      "\n",
      "\f",
      "Sutton, R. S., Precup, D., & Singh, S. (1998). Between MDPs and Semi-MDPs: Learning, plan-\n",
      "ning, and representing knowledge at multiple temporal scales. Tech. rep., University of Mas-\n",
      "sachusetts, Department of Computer and Information Sciences, Amherst, MA.\n",
      "\n",
      "Tadepalli, P., & Dietterich, T. G. (1997). Hierarchical explanation-based reinforcement learning.\n",
      "In Proceedings of the Fourteenth International Conference on Machine Learning, pp. 358–366\n",
      "San Francisco, CA. Morgan Kaufmann.\n",
      "\n",
      "Watkins, C. J. C. H. (1989). Learning from Delayed Rewards. Ph.D. thesis, King’s College, Oxford.\n",
      "\n",
      "(To be reprinted by MIT Press.).\n",
      "\n",
      "Watkins, C. J., & Dayan, P. (1992). Technical note q-learning. Machine Learning, 8, 279.\n",
      "\n",
      "61\n",
      "\n",
      "\f",
      "Goal\n",
      "\n",
      "Figure 13: Parr’s maze problem. The start state is in the upper left corner, and all states in the\n",
      "lower right-hand room are terminal states.\n",
      "\n",
      "62\n",
      "\n",
      "\f",
      "MaxRoot\n",
      "\n",
      "Go(d)\n",
      "\n",
      "r/ROOM\n",
      "\n",
      "MaxGo(d,r)\n",
      "\n",
      "QExitInter(d,r)\n",
      "\n",
      "QExitHall(d,r)\n",
      "\n",
      "MaxExitInter(d,r)\n",
      "\n",
      "MaxExitHall(d,r)\n",
      "\n",
      "QSniffEI(d,p)\n",
      "\n",
      "QBackEI(d,p)\n",
      "\n",
      "QSniffEH(d,p)\n",
      "\n",
      "QBackEH(d,p)\n",
      "\n",
      "MaxSniff(d,p)\n",
      "\n",
      "MaxBack(d,p,x,y)\n",
      "\n",
      "x/X\n",
      "y/Y\n",
      "\n",
      "x/X\n",
      "\n",
      "y/Y\n",
      "\n",
      "QFollowWall(d,p)\n",
      "\n",
      "QToWall(d)\n",
      "\n",
      "QBackOne(d)\n",
      "\n",
      "QPerpThree(p)\n",
      "\n",
      "MaxFollowWall(d,p)\n",
      "\n",
      "MaxToWall(d)\n",
      "\n",
      "MaxBackOne(d)\n",
      "\n",
      "MaxPerpThree(p)\n",
      "\n",
      "d/p\n",
      "\n",
      "d/d\n",
      "\n",
      "d/Inv(d)\n",
      "\n",
      "d/p\n",
      "\n",
      "QMoveFW(d)\n",
      "\n",
      "QMoveTW(d)\n",
      "\n",
      "QMoveBO(d)\n",
      "\n",
      "QMoveP3(d)\n",
      "\n",
      "MaxMove(d)\n",
      "\n",
      "Figure 14: MAXQ graph for Parr’s maze task.\n",
      "\n",
      "63\n",
      "\n",
      "\f",
      "-100\n",
      "\n",
      "-150\n",
      "\n",
      "-200\n",
      "\n",
      "-250\n",
      "\n",
      "-300\n",
      "\n",
      "Hand-coded hierarchical policy\n",
      "\n",
      "-350\n",
      "\n",
      "MAXQ Q Learning\n",
      "\n",
      "Flat Q Learning\n",
      "\n",
      " \n",
      "\n",
      "l\n",
      "a\n",
      "i\n",
      "r\n",
      "T\n",
      " \n",
      "r\n",
      "e\n",
      "P\n",
      "d\n",
      "r\n",
      "a\n",
      "w\n",
      "e\n",
      "R\n",
      "n\n",
      "a\n",
      "e\n",
      "\n",
      " \n",
      "\n",
      "M\n",
      "\n",
      "-400\n",
      "\n",
      "-450\n",
      "\n",
      "-500\n",
      "\n",
      "0\n",
      "\n",
      "1e+06\n",
      "\n",
      "2e+06\n",
      "\n",
      "3e+06\n",
      "\n",
      "Primitive Steps\n",
      "\n",
      "4e+06\n",
      "\n",
      "5e+06\n",
      "\n",
      "6e+06\n",
      "\n",
      "Figure 15: Comparison of Flat Q learning and MAXQ-Q learning in the Parr maze task.\n",
      "\n",
      "64\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "from pdfminer3.layout import LAParams, LTTextBox\n",
    "from pdfminer3.pdfpage import PDFPage\n",
    "from pdfminer3.pdfinterp import PDFResourceManager\n",
    "from pdfminer3.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer3.converter import PDFPageAggregator\n",
    "from pdfminer3.converter import TextConverter\n",
    "import io\n",
    "\n",
    "resource_manager = PDFResourceManager()\n",
    "fake_file_handle = io.StringIO()\n",
    "converter = TextConverter(resource_manager, fake_file_handle, laparams=LAParams())\n",
    "page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    "\n",
    "with open('C:\\\\Users\\\\Al\\\\Documents\\\\ByteSizeArxiv\\\\library/9905014v1.pdf', 'rb') as fh:\n",
    "\n",
    "    for page in PDFPage.get_pages(fh,\n",
    "                                  caching=True,\n",
    "                                  check_extractable=True):\n",
    "        page_interpreter.process_page(page)\n",
    "\n",
    "    text = fake_file_handle.getvalue()\n",
    "\n",
    "# close open handles\n",
    "converter.close()\n",
    "fake_file_handle.close()\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
