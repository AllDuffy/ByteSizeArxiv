For use downloading, preprocessing, and ideally summarizing arxiv articles as they are posted.
Use DL&PP to download and preprocess 
tokenizeText to tokenize
run new make data to pack the tokenized data into jsons within tars
unzip the tars (removing this wasteful zipping unzipping later) and follow instructions under "train your own models" here:https://github.com/ChenRocks/fast_abs_rl