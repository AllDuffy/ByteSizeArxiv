{
    "id": "C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\trainTokenized\\0601044v1",
    "article": [
        "this paper is an experimental study of methodologies for evolutionary computations inspired by common practices in the machine learning and pattern recognition communities . more specifically using genetic programming for supervised learning we aim at evaluating both the e\ufb00ect of using a three data sets methodology and the e\ufb00ect of minimizing the classifiers complexity . our experiments show that these approaches preserve the performances of gp while significantly reducing the size of the best of run solutions which is in accordance with occam s razor principle . the structure of the paper goes as follow . section starts with a high level description of the tested approaches and their justifications . a presentation of relevant work follows in section . thereafter the methodology used in the experiments is detailed in section . finally section presents the experimental results obtained on six binary classification data sets and section concludes the paper . introduction gp is particularly suited for problems that can be assimilated to learning tasks with the minimization of the error between the obtained and desired outputs for a limited number of test cases the training data using a ml terminology . indeed the classical gp examples of symbolic regression boolean multiplexer and artificial ant are only simple instances of well known learning problems . in the early years of gp these problems were tackled using a single data set reporting results on the same data set that was used to evaluate the fitnesses during the evolution . this was justifiable by the fact that these are toy problems used only to illustrate the potential of gp . in the ml community it is recognized that such methodology is \ufb02awed given that the learning algorithm can overfit the data used during the training and perform poorly on unseen data of the same application domain . hence it is important to report results on a set of data that was not used during the learning stage . this is what we call in this paper a two data sets methodology with a training set used by the learning algorithm and a test set used to report the performance of the algorithm on unseen data which is a good indicator of the algorithm s generalization capability . even though this methodology has been widely accepted and applied in the ml and pr communities for a long time the ec community still lags behind by publishing papers that are reporting results on data sets that were used during the evolution phase . this methodological problem has already been spotted and should be less and less common in the future . the two data sets methodology prevents reporting \ufb02awed results of learning algorithms that overfit the training set . but this does not prevent by itself overfitting the training set . a common approach is to add a third data set the validation set which helps the learning algorithm to measure its generalization capability . this validation set is useful to interrupt the learning algorithm when overfitting occurs and or select a configuration of the learning machine that maximizes the generalization performances . this third data set is commonly used to train classifiers such as back propagation neural networks and can be easily applied to ec based learning . but this approach has an important drawback it removes a significant amount of data from the training set which can be harmful to the learning process . indeed the richer the training set the more representative it can be of the real data distribution and the more the learning algorithm can be expected to converge toward robust solutions . in the light of these considerations an objective of this paper is to investigate the e\ufb00ect of a validation set to select the best of run individuals for a gp based learning application . another concern of the ml and pr communities is to develop learning algorithms that generate simple solutions . an argument behind this is the occam s razor principle which states that between solutions of comparable quality the simplest solutions must be preferred . another argument is the minimum description length principle which states that the best model is the one that minimizes the amount of information needed to encode the model and the data given the model . preference for simpler solutions and overfitting avoidance are closely related it is more likely that a complex solution incorporates specific information from the training set thus overfitting the training set compared to a simpler solution . but as mentioned in this argumentation should be taken with care as too much emphasis on minimizing complexity can prevent the discovery of more complex yet more accurate solutions . there is a strong link between the minimization of complexity in gp based learning and the control of code bloat that is an exaggerated growth of program size in the course of gp runs . even though complexity and code bloat are not exactly the same phenomenon as some kind of bloat is generated by neutral pieces of code that have no e\ufb00ect on the actual complexity of the solutions most of the mechanisms proposed to control it can also be used to minimize the complexity of solutions obtained by gp based learning . this paper is a study of gp viewed as a learning algorithm . more specifically we investigate two techniques to increase the generalization performance and decrease the complexity of the models use of a validation set to select best of run individuals that generalize well and use of lexicographic parsimony pressure to reduce the complexity of the generated models . these techniques are tested using a gp encoding for binary classification problems with vectors taken from the learning sets as terminals and mathematical operations to manipulate these vectors as branches . this approach is tested on six di\ufb00erent data sets from the uci ml repository . even if the proposed techniques are tested in a specific context we argue that they can be extended to the frequent situations where gp is used as a learning algorithm . related work some gp learning applications have made use of a three data sets methodology but without making a thorough analysis of its e\ufb00ects . panait and luke conducted some experiments on di\ufb00erent approaches to increase the robustness of the solutions generated by gp using a three data sets methodology to evaluate the efficiency of each approach . rowland and kushchu conducted studies on generalization in ec and gp . both of their argumentations converge toward the testing of solutions in previously unseen situations for improving robustness . because of the bloat phenomenon typical in gp parsimony pressure has been more widely studied . in particular several papers have produced interesting results around the idea of using a parsimony pressure to increase the generalization capability of gp evolved solutions . however a counter argumentation is given in where solutions biased toward low complexity have in some circumstances increased generalization error . this is in accordance with the argumentation given in which states that less complex solutions are not always more robust . table . gp primitives used to build the classifiers . name args . description add sub mul addition fadd x x. subtraction fsub x x. multiplication fmul xx . div protected division fdiv x x x. otherwise . mxf mnf abs maximum value fmxf max . minimum value fmnf min . absolute value fabs x. x x x otherwise . sln saturated symmetric linear function fsln sum mea mxv miv l e x i xi . ixi card . sum of vector s components fsum mean of vector s components fmea p maximum of vector s components fmxv maxi xi . minimum of vector s components fmiv mini xi . l norm of the vector fl ephemeral random vector generated by copying the value of a ranpp domly selected training set data . vector with the value of the data to classify . i x i. p methodology the experiments conducted in this work are based on a gp setup specialized for binary classification problems . the data processed by the primitives are vectors of two possible sizes either of size one or of size n the feature set size . table presents the set of primitives used to build the programs . three main families of primitives were used the mathematical function primitives the vector to scalar primitives and the vectorial terminals . the mathematical function primitives with two arguments are defined to deal with arguments of di\ufb00erent sizes by applying the function to each component of the n sized arguments when necessary repeatedly using the value of the scalar arguments . more formally if f denotes the function associated to the primitive presented in table the output of these primitives is a scalar if both arguments are scalars a size n vector t if the first argument is a scalar and the second a vector a size n vector t if the first argument is a vector and the second a scalar a size n vector t if both arguments are vectors . table . description of uci data sets used for the experimentations . of data set size features application domain bcw cmc wisconcin s breast cancer . benign and . malignant . contraceptive method choice . not using contraception and . using contraception . german credit approval approved and not approved . ionosphere radar signal . without structure detected and . with a structure detected . pima indians diabetes . tested negative and . tested positive for diabetes . spam e mail . non junk e mail and . junk e mail . ger ion pid spa on the other hand the vector to scalar primitives are defined to convert a vector argument of size n into a scalar output . when the argument is a scalar it is returned as output value as is without modification except for the l primitive which returns the absolute value of the input scalar . finally the vectorial terminals are always vectors of size n with either randomly selected data of the training set used as constants or the value of the data to classify used as the variable of the problem . the data evaluated is classified according to the output of the gp tree that is assigned to the first class for an output value positive or zero otherwise assigned to the second class . if necessary the output of the gp program is converted into a scalar beforehand by a summation of each vector s components as does the primitive sum . in order to test the e\ufb00ect of using a validation set and applying some parsimony pressure gp will be tested on common binary classification data sets taken from the machine learning repository at uci . the selected data set are presented in table . the selection of these data sets was guided by the following main criteria select appropriate sets for binary classification select appropriate sets for folds cross validation that is data sets without predefined separated training and testing sets and select sets of relatively large size or high dimensionality . the first two criteria were chosen in order to fit into our general methodology to avoid special data manipulations while the last criterion was postulated in an attempt to select not too easy data sets that should help to generate discriminant results . before the experiments each data set was randomly divided into folds of equal size taking care to balance the number of data of each class between the folds . a folds cross validation has been conducted using the data in folds as the training set for an evolution reporting the test set error rate on the remaining fold . for each tested configuration the process is repeated times for each fold for a total of evolutions per configuration . the reported results consist in the means for these evolutions . our experimentations are conducted on four di\ufb00erent configurations . baseline the fitness measure consists in minimizing the error rate on the complete training set . the best of run individual is simply the individual of the evolution with the lowest error rate on the training set with the smallest individual selected in cases of ties . with validation for each evolution the training set is randomly divided into two data sets the fitness evaluation data set with of the training data and the validation set with the remaining . the class distribution of the data is well balanced between the sets . the fitness measure consists in minimizing the error rate on the fitness evaluation set . at each generation a two objective sort is conducted in order to extract a set of non dominated individuals with regards to the lowest fitness evaluation set error rate and the smallest individuals . these non dominated individuals are then evaluated on the validation set with the best of run individual selected as the one of these with the smallest error rate on the validation set ties being solved by choosing the smallest individual . with parsimony pressure a lexicographic parsimony pressure is applied to the evolution by minimizing the error rate on the complete training set using the individual size as second point of comparison in cases of identical error rates . as with the baseline configuration the best of run individual is the individual of the evolution with the lowest error rate on the training set with the smallest individual selected in cases of ties . with validation and parsimony pressure a mix of the two previous configurations by separating the training set into two sets the fitness evaluation set and the validation set and making use of the lexicographic parsimony pressure . the fitness evaluation set is used to compute the error rate that guides the evolution while the validation set is used only to select the best of run individual . the selection of this best of run individual is identical to the with validation configuration by extracting a pareto front of the non dominated individuals of the current generation . at each generation all these non dominated individuals are tested on the validation set . the best of run individual is selected as the solution that minimizes the validation error rate breaking ties by preferring the smallest individuals . thus for the second and fourth settings the pareto front is extracted at each generation for testing against the validation set . this is motivated by two main reasons it is important to reduce the number of solutions tested against the validation set in order not to select best of run solutions that are just by chance performing well on the validation set and it is desirable to test on the validation set a range of solutions with di\ufb00erent accuracy size trade o\ufb00s . it should be stressed that tournament selection is used in all evolutions with lexicographic ranking for the third and fourth configurations . strictly speaking this is not a pareto domination based multi objective selection algorithm . table presents the gp parameters used during the experiments . no special tweaking of these parameter values was done which correspond in most cases table . tableau of the gp evolutions . parameter description and parameter values terminals and branches see table . population size stop criterion one panmictic population of individuals . evolution ends after generations . replacement strategy genetic operations applied following generational scheme . selection tournaments selection with participants . fitness measure without parsimony pressure minimize the error rate . standard mutation replace a subtree with a new randomly generated one . exchange a primitive with another of the same arity . replace a branch with one of its children and remove the branch mutated and the other children s subtrees . ephemerals mutation randomly select a new ephemeral random vector . copy without modification an existing individual . data normalization the data of the di\ufb00erent sets are scaled in along the di\ufb00erent dimensions . to the default values of the software tool used . the experimentations have been implemented using the gp facilities of the open beagle framework . results table presents the detailed results obtained by testing the four configurations presented in the previous section using the six data sets of table . the error rates and tree sizes that are reported consist in the mean and standard deviation values of the best of run individuals for the runs . the e\ufb00ort consists in a measure of the computations done during the evolutions . it is calculated by summing the number of gp primitives evaluated during the runs . more precisely for configurations without validation the e\ufb00ort is computed by counting in the number of primitives in each individual times the training set size for all evaluated individuals during the run . for configurations with validation the size of the individuals on pareto front times the note that the notion of e\ufb00ort presented here is di\ufb00erent from the one defined by koza in . table . error rates tree sizes and e\ufb00ort for the evolution of gp based classifiers using the uci data sets . results in italic are not statistically di\ufb00erent from those of the baseline configuration according to a confidence two tailed student s t test . results in bold are more than smaller than the corresponding baseline results . train set rate valid . set rate test set rate tree size mean std . mean error dev . std . mean std . mean std . mean stdev . size dev . dev . e\ufb00ort error dev . approach error bcw cmc ger ion pid spa . baseline validation . parsimony . both . baseline validation . parsimony . both . baseline validation . parsimony . both . baseline validation . parsimony . both . baseline validation . parsimony . both . baseline validation . parsimony . both . fig . one way analysis of variance box plots of the best of run solutions test set error rates . the center box is bounded by the first and third quartiles of the data distribution with the median as the central line in the box . the notches surrounding the median show the confidence interval of this median . the whiskers above and below the boxes represent the spread of the data value within . times the interquartile range with the symbol showing outliers . e t a r r o r r e t e s t s e t. e t a r r o r r e t e s t s e t. e t a r r o r r e t e s t s e t. e t a r r o r r e t e s t s e t. e t a r r o r r e t e s t s e t. e t a r r o r r e t e s t s e t. baseline validation parsimony both baseline validation parsimony both baseline validation parsimony both bcw cmc ger baseline validation parsimony both baseline validation parsimony both baseline validation parsimony both ion pid spa validation set size is also taken into account . italic results in table are not statistically di\ufb00erent from the corresponding baseline result hence all other results are statistically distinct from the baseline . figure presents the box plots that stem from a one way analysis of variance conducted on the test set error rates . looking at the results it seems that no approach is clearly superior to the others in term of test set accuracy . but taking a closer look we can see that the approach using both the validation set and parsimony pressure reduces the variance of the test set error rates for the bcw ger pid and spa data sets having a comparable or slightly worse variance for the two other sets . this is an important result as getting reproducible and stable solutions is often more interesting than finding only infrequently a marginally better individual . taking a closer look at the error rates on the di\ufb00erent sets in table important di\ufb00erences can be noted between the train and validation set rates on one hand and the test set rates on the other hand . the di\ufb00erences between the train and test rates can be explained by an overfitting of the training data . but it is surprising to see the importance of the di\ufb00erences between the validation and fig . one way analysis of variance box plots of the best of run solutions tree sizes . baseline validation parsimony both baseline validation parsimony both baseline validation parsimony both bcw cmc ger i e z s e e r t n o i t u o s t s e b l i e z s e e r t n o i t u o s t s e b l i e z s e e r t n o i t u o s t s e b l i e z s e e r t n o i t u o s t s e b l i e z s e e r t n o i t u o s t s e b l i e z s e e r t n o i t u o s t s e b l baseline validation parsimony both baseline validation parsimony both baseline validation parsimony both ion pid spa test rates . this may indicate that because too many solutions are still tested against the validation set at each generation the risk of selecting solutions that fit the validation set by chance is not negligible . figure presents the one way anova box plots for the best of run tree sizes . this time it seems clear that the tested methods significantly reduce the best ofrun individual tree sizes for all tested data sets . it is interesting to note that the configurations with a validation set have generated significantly smaller best ofrun individual tree sizes compared with the parsimony pressure only approach . this is expected given that the validation set is directly used in the best of run individual selection process while the parsimony pressure is used only to limit the tree sizes during the runs . also the important size reduction of the bestof run solutions especially noticeable with the combination of validation and parsimony pressure is valuable when simplicity or comprehensibility is necessary for the application at hand . finally taking a look at the mean e\ufb00ort in table the reduction goes up to with the validation and parsimony pressure approach compared to the baseline e\ufb00ort . conclusion in this paper methodologies were investigated to improve gp as a learning algorithm . more specifically using the gp based setup for binary classification the use of a validation set for selecting best of run individuals was tested in order to pick solutions that generalize well . the e\ufb00ect of a lexicographic parsimony pressure was also tested in order to avoid unnecessary complexity in the evolved solutions . experimental results indicate that the use of a validation set improves a little the stability of the best of run solutions on the test sets by maintaining accuracy while slightly reducing variance in most cases . this is important given the stochastic nature of gp which can introduce important variations of the results from one run to another . moreover it was shown that mild parsimony pressure applied during evolutions can sustain performance in general while e\ufb00ectively reducing both solution size and e\ufb00ort . the combination of these two approaches apparently gives the best of both worlds by reducing the variance of test set errors simplifying drastically the complexity best of run solutions and cutting down e\ufb00ort by half . as future work still using a gp based learning setup it is planned to develop new stopping criteria based on the di\ufb00erence between training and validation set error rates . it is also planned to study the e\ufb00ect of changing the test cases during the course of the evolution for gp based learning using methods such as competitive co evolution and boosting . this work was supported by postdoctoral fellowships from the ercim and the fqrnt to c. gagn e. acknowledgments"
    ],
    "abstract": [
        "fitness functions based on test cases are very common in genetic programming . this process can be assimilated to a learning task with the inference of models from a limited number of samples . this paper is an investigation on two methods to improve generalization in gp based learning the selection of the best of run individuals using a three data sets methodology and the application of parsimony pressure in order to reduce the complexity of the solutions . results using gp in a binary classification setup show that while the accuracy on the test sets is preserved with less variances compared to baseline results the mean tree size obtained with the tested methods is significantly reduced ."
    ],
    "extracted": [
        0
    ],
    "score": [
        0.6949152542372882
    ]
}