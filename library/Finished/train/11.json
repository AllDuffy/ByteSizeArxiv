{
    "id": "C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\trainTokenized\\0510038v4",
    "article": [
        "at which jackson uses in the proof of gives us an alternate bound to theorem . lemma . let c be the concept class consisting of s way majority of r way cn b and any distribution d over n there parity of b literals . then for any f exists a fourier basis element \u03c7\u03b1 such that \u03c9 . ed proof . assume f is a majority of h. hs each of which is a r way parity of b literals . then lemma . implies that there exists hi such that s. let hi be parity of the b literals \u2113 . \u2113r . observation . gives ed s ed ed l max \u03b1 ed also note that for j. r we have the following l \u03b1 by lemma . p \u2113 j b by corollary . m ln b. b m p therefore for some constant c we have l from which we obtain max\u03b1 ed \u03c9 . q r j l o combining this result with that of corollary . we obtain the following result theorem . the concept class c consisting of s way majority of r way parity of b literals can be learned in time poly using the ghs algorithm . as an immediate corollary we obtain the following close analogue of theorem . theorem . the concept class c consisting of s way majority of r way parity of b literals where s poly r o is efficiently learnable using the ghs algorithm . locating sensitive elements and learning with ghs on a restricted grid in this section we consider an extension of the ghs algorithm which lets us achieve slightly better bounds when we are dealing only with basic b literals . following an idea from the new algorithm works by identifying a subset of sensitive elements from for each of the n dimensions . definition . a value \u03c3 is called i sensitive with respect to f n if there exist values c c. ci such that ci . cn f c. ci f \u03c3 ci . cn . a value \u03c3 is called sensitive with respect to f if \u03c3 is i sensitive for some i. if there is no i sensitive value with respect to f we say index i is trivial . the main idea is to run ghs over a restricted subset of the original domain n which is the grid formed by the sensitive values and a few more additional values and therefore lower the algorithm s complexity . denotes the smallest value in li which is larger than xi . a refinement of s is a grid in n of the is therefore defined to be form l l lemma . let s be a grid l ln in n such that each l s denote the set of indices for which li let s i i refinement s l l n such that l xi l n where each li \u2113 . \u03ba then s admits a i xi li n i. li and \u03c4 set l i for all r. \u2113 xi if r l i xi r j end if end for if l i lmax end if do xi \u03c4 then r r \u03c4 xi xi l i r xi xi \u2113 b \u03ba\u2113 . up to and including the largest do while or lmax the end of the algorithm every l i contains either element which is it is easy to verify that it satisfies property as well . \u03ba together give that the number of corners in s property and the bound is at most \u03ba . it is easy to see from the algorithm that the area covered by each corner in s is at most . therefore any \u01eb fraction of the corners in s cover an area of at most \u03ba again using the bound on s i bn s i \u01eb\u03ba bn \u03ba \u01eb e \u01ebbn \u01ebbn . bn c this gives property . the following lemma is easy and useful similar statements are given in . note that the lemma critically relies on the b literals being basic . lemma . let f n ity of basic b literals . then for each index sensitive values with respect to f. be expressed as an s way majority of parn there are at most s i i proof . a literal \u2113 on variable xi induces two i sensitive values . the lemma follows directly from our assumption that for each variable xi each of the s parity gates has no more than one incoming literal which depends on xi . algorithm is our extension of the ghs algorithm . it essentially works by repeatedly running ghs on the target function f but restricted to a small grid . to upper bound the number of steps in each of these invocations we will be referring to the result of theorem . . after each execution of ghs the hypothesis defined over the grid is extended to n in a natural way and is tested for \u01eb accuracy . if h is not \u01eb accurate then a point where h is incorrect is used to identify a new sensitive value and this value is used to refine the grid for the next iteration . the bound on the number of sensitive values from lemma . lets us bound the number of iterations . our theorem about algorithm s performance is the following . lmax . xi l. ln l the output of refinement algorithm with input s. l n. if li xi t algorithm an improved algorithm for learning majority of parity of basic b literals . l loop s l s one can express s l xi xi . let xi end if perform random membership queries until an element found such that f n such that find an index f. n is f. x f this requires o membership queries using binary search . li end loop li . theorem . let concept class c consist of s way majority of r way parity of basic b literals such that s poly and each f cn b has at most \u03ba non trivial indices and at most \u2113 i sensitive values for each i. n. then c is efficiently learnable if r o. x i xi . xn proof . we assume b \u03c9 without loss of generality . otherwise one immediately obtains the result with a direct application of ghs through theorem . . s. by lemma . there are at most \u03ba\u2113 o we clearly have \u03ba sensitive values . we will show that the algorithm finds a new sensitive value at each iteration and terminates before all sensitive values are found . therefore the number n and \u2113 of iterations will be upper bounded by o. we will also show that each iteration runs in poly steps . this will establish the desired result . let us first establish that step takes at most poly steps . to observe s without any trouble . due to the construction of algorithm for every non trivial index i of f l i has fixed cardinality lmax . therefore ghs could be invoked over the restriction of f onto the grid f if f is s way majority of r way parity of basic b literals then the function s could be expressed as t way maobtained by restricting it onto the grid f jority of u way parity of basic l literals where t o. due to theorem . running ghs over a grid with alphabet size o in each time if the dimension of the rectangles non trivial index takes poly . the key idea here is that running ghs over this \u03ba\u2113 size are r o log alphabet lets us replace the b in theorem . with \u03ba\u2113 . r and l s u to check whether if h \u01eb approximates f at step we may draw o log uniform random examples and use the membership oracle to empirically estimate h s accuracy on these examples . standard bounds on sampling show that if the true error rate of h is less than \u01eb then the empirical error rate on such a sample will be less than \u01eb with probability \u03b4 . observe that if all the sensitive values are recovered by the algorithm h will \u01eb approximate f with high probability . s property of the refinement guarantees indeed since g approximates f that misclassifying the function at \u01eb fraction of the corners could at most incur an overall error of \u01eb \u01eb . this is because when all the sensitive elements are recovered for every corner in s h either agrees with f or disagrees with f in the entire region covered by that corner . thus h will be an \u01eb approximator to f with high probability . this establishes that the algorithm must terminate within o iterations of the outer loop . locating another sensitive value occurs at steps and . note that h is not an \u01eb approximator to f because the algorithm moved beyond step . even if we were to correct all the mistakes in g this would alter at most \u01eb fraction of the corners in the grid s and therefore \u01eb fraction of the values in h again due to the th property of the refinement and the way h is generated . therefore for at least \u01eb fraction of the domain we ought to have f. thus we have observed that steps take at most poly steps as we note that we have been somewhat cavalier in our treatment of the failure probabilities for various events . these include the possibility of getting an inaccurate estimate of h s error rate in step or not finding a suitable element soon enough in step or having the ghs algorithm fail to return a good hypothesis in one of its executions . a standard analysis shows that all these failure probabilities can be made suitably small so that the overall failure probability is at most \u03b4 within the claimed runtime . applications to learning unions of rectangles in this section we apply the results we have obtained in sections and to obtain results on learning unions of rectangles and related classes . learning majorities and unions of many low dimensional rectangles the following lemma will let us apply our algorithm for learning majority of parity of b literals to learn majority of and of b literals lemma . let f be expressible as an s way majority of r way and of boolean literals . then f is also expressible as a o way majority of r way parity of boolean literals . such that each x satisfies at most one fi then the function or satisfies l o. this fact lets us apply the argument behind theorem . without modification and we obtain corollary . . note that only the rectangles connected to the same or gate must be disjoint in order to invoke corollary . . conclusions and future work for future work besides the obvious goals of strengthening our positive results we feel that it would be interesting to explore the limitations of current techniques for learning unions of rectangles over n. at this point we can not rule out the possibility that the generalized harmonic sieve algorithm is in fact a poly time algorithm for learning unions of s arbitrary rectangles over n. can evidence for or against this possibility be given for example can one show that the representational power of the hypotheses which the generalized harmonic sieve algorithm produces is or is not sufficient to express high accuracy approximators to arbitrary unions of s rectangles over n we thank the anonymous journal referees whose helpful suggestions improved the presentation of this paper . acknowledgement"
    ],
    "abstract": [
        "we consider the problem of learning unions of rectangles over the domain ^ n in the uniform distribution membership query learning setting where both b and n are large . we obtain poly time algorithms for the following classes poly way majority of o dimensional rectangles . union of poly many o frac log ^ ^ dimensional rectangles . poly way majority of poly or of disjoint o dimensional rectangles . our main algorithmic tool is an extension of jackson s boosting and fourier based harmonic sieve algorithm to the domain ^ n building on work of . other ingredients used to obtain the results stated above are techniques from exact learning and ideas from recent work on learning augmented ac ^ circuits and on representing boolean functions as thresholds of parities ."
    ],
    "extracted": [
        0
    ],
    "score": [
        0.44360902255639095
    ]
}