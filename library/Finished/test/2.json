{
    "id": "C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\testTokenized\\0009001v3",
    "article": [
        "introduction the asymptotic nature of kolmogorov complexity calculus renders it significantly less useful in practical applications such as inference by the minimum description length principle . in the classical mdl approach this problem is solved by replacing kolmogorov complexity with a phenomenological complexity measure just before performing the actual inference . such a measure can be chosen to suit a particular application whereas the general form of the mdl constructions can be considered as a consequence of e mail a.soklakov rhul.ac.uk andrei n. soklakov the asymptotic properties of kolmogorov complexity . here we propose a di\ufb00erent approach . we argue that kolmogorov complexity can become more practical if we restrict the class of reference computers . computer science is not the only field which can benefit from the proposed research . there is a growing interest in using kolmogorov complexity as a fundamental physical concept . this includes applications in thermodynamics theory of chaos physics of computation and many other areas of modern theoretical physics . it is however very difficult to use kolmogorov complexity in any concrete physical setting or indeed in any concrete application . for that we need a much more detailed calculus that can be applied to particular cases of reference computers . the main aim of this article is to stimulate further research in developing such a practical complexity calculus . this article is organized as follows . in section we review some basic definitions . in section we present the main conceptual arguments of the paper . in section we give an example of how one can build a restricted class of computers in a natural way . considering one of the central equalities of the standard complexity calculus we give an illustration of how the error terms may be reduced . basic definitions let x be the set of finite binary strings where \u03bb is the string of length . a set of strings y x with the property that no string in y is a prefix of another is called an instantaneous code . a prefix computer is a partial recursive function c y x x. for each p y and for each d x the output of the computation is either undefined or given by c x. kolmogorov complexity of a string \u03b1 given a data string d relative to a computer c is defined as the length kc of the shortest program that makes c compute \u03b1 given data d kc min where p denotes the length of the program p. since this complexity measure depends strongly on the reference computer it is important to find an optimal computer u such that the complexity of any string relative to u is not much higher that the complexity of the same string consult for further references . consult for further references . andrei n. soklakov relative to any other computer c. mathematically a computer u is called optimal if c \u03bac such that \u03b1 d ku kc \u03bac where \u03bac is a constant depending on c but not on \u03b1 or d. it turns out that the set of prefix computers contains such a u and moreover it can be constructed so that any prefix computer can be simulated by u for further details consult . such a u is called a universal prefix computer and its choice is not unique . using some particular universal prefix computer u as a reference the conditional kolmogorov complexity of \u03b1 given \u03b2 is defined as ku . the above definitions are generalized for the case of many strings as follows . we choose and fix a particular recursive bijection b x x x for use i be a set of n strings \u03b1i x. for throughout the rest of this paper . let n k n we define h\u03b1 \u03b1 . \u03b1ki b and h\u03b1i \u03b1 . we can now define ku ku . for any two universal prefix computers u and u we have by definition ku ku \u03ba where \u03ba is a constant that depends only on u and u and not on \u03b1 or \u03b2 . most of the research on kolmogorov complexity is focused on the asymptotic case of nearly random long strings when \u03ba can be neglected in comparison to the value of the complexity . in such cases kolmogorov complexity becomes an asymptotically absolute measure of the complexity of individual strings . for this reason many fundamental properties of kolmogorov complexity are established up to an error term which is asymptotically small compared to the complexity of strings involved . for instance the standard analysis of the prefix kolmogorov complexity gives ku ku ku where is an error term which grows logarithmically with the complexity of the considered strings . this is an example of an asymptotic property that all kolmogorov measures of complexity have irrespective of the choice of the reference computer . of course it is important to know that all kolmogorov measures of complexity share many of their asymptotic properties . for any given reference computer however kolmogorov complexity is a well defined function on all binary strings . even from a purely mathematical viewpoint it is interesting to study the properties of such functions beyond the asymptotics . as for the applied viewpoint consider by analogy mathematical analysis . this theory would be much less useful if we studied only asymptotic properties of functions . andrei n. soklakov main arguments without significant knowledge about the reference computer kolmogorov complexity can be considered only up to an additive error term o. error terms even as small as o make it impossible to use occam s razor to discriminate between simple hypotheses . the importance of this problem becomes apparent once we recognize that the domain of simple hypotheses is absolutely crucial in our every day life as well as in fundamental science . indeed it is often the case that after extensive analysis the greatest scientific discoveries can be expressed in a form so simple that they are readily understood by even school children . humans can relatively easily discriminate between di\ufb00erent hypotheses even when the kolmogorov complexities involved are rather small . this gives them an enormous advantage over the present day theoretical models . a good example is kepler s theory of planetary motion . in what was a major breakthrough in theoretical astronomy at the time kepler introduced elliptical orbits as a better alternative to the complicated copernican planetary model of superimposed epicycles . at the level of accuracy provided by brahe s experiments the original copernican model had to be refined by introducing additional epicycles the keplerian theory appeared to be simpler and therefore better by occam s razor . this apparently obvious fact can not be established using the standard formalism of kolmogorov complexity whereas kepler s theory can be simpler relative to some type of computers the copernican model can be simpler relative to some other type of reference computers . much simpler examples can be found in tests that are designed by humans to test their own intelligence . a typical problem in such tests is to find the next element in a sequence of symbols . for example if the first four elements of a sequence are an intelligent person is supposed to see the simplest pattern and predict as the next element of the sequence . as in the previous example all humans would agree that predicting would correspond to the choice of the simplest hypothesis whereas the standard formalism of kolmogorov complexity can not be used to justify this . it seems entirely plausible that the ultimate theory of artificial intelligence and in particular inductive inference can achieve human like results only if the building blocks of the theory such as kolmogorov complexity are made sensitive to small variations in the complexity of hypothesis . the o ambiguity in the classical definition of kolmogorov complexity and the error terms like in eq . is the price we pay for having an unrestricted class of reference computers . every human perceives complexity with respect to their own built in reference computer the brain . as in the case of abstract reference computers human brains are not identical . however they are similar andrei n. soklakov enough to allow for a sharper discrimination between individual theories on the basis of their complexity . this suggests that further progress in applications of kolmogorov complexity to the theory of induction can be made possible if we find a natural way of restricting the class of reference computers . we see from this discussion that some restrictions on the class of reference computers are needed . it is desirable however to have a complexity theory which would be as general as possible . as a compromise we can try to group all possible reference computers into restricted classes . although we may want to study all such classes we can argue that due to biological technological and other limitations only one class of reference computers is physically available to us . a definition of this realistic class of reference computers would be the crucial link between the abstract theory of kolmogorov complexity and the practical theories of induction and computer learning . what kind of restriction of the class of reference computers can be seen as natural it appears natural to assume that given some particular level of technology one can build more powerful computers only at the expense of a more complex internal design . in section we use this observation to construct an example of a natural restriction of the class of reference computers . roughly speaking this restriction entails the requirement that switching to a more complex reference computer should always be accompanied by an equivalent reduction of program lengths . using some particular universal computer u as a reference we define the complexity of a computer ws from the set given data d as ku . we then construct a particular set of computers such that the sum of the complexity of a computer and the length of a program for it is the same for all equivalent programs and for all computers in the set . this gives us a tradeo\ufb00 between computer complexity and program lengths similar to what one would expect in the real world where we face various practical limitations . together with the original reference computer u computers form a naturally restricted class . it is natural to define a computer w which is universal for this class by setting w ws where u is included by defining w\u03bb u. using any such w as a reference we can see that in principle even error terms logarithmic in complexity can be removed from the standard complexity calculus . in particular we prove that for any triple of simple strings \u03b1 \u03b2 \u03b3 we have kw kw kw const where the constant depends only on the reference machine w. apart from subtleties associated with the operation of combining strings two programs p and p for computers c and c are called equivalent i\ufb00 c c. andrei n. soklakov into pairs this is analogous to eq . with the important di\ufb00erence that the error term is replaced by a constant . in the standard complexity calculus the above equation holds only up to an error term which grows logarithmically with the complexity of the considered strings . as we explained earlier this is unacceptable if we want to analyze the complexity of simple strings . the error terms are especially troublesome if we want to use the complexity calculus as a part of inductive inference based on the mdl principle . in such cases we are interested in the position of the minimum rather than on the approximated value of complexity . the error term can significantly shift the position of the minimum even when mistakes on the value of complexity are minor . this can introduce uncontrollable mistakes in the inference results . in our case however equation is exact in the sense that the constant does not in\ufb02uence the position of critical points so it can be safely ignored in applications such as induction by the mdl principle . example as we explained in section a natural restriction of the class of reference computers can make kolmogorov complexity more useful in applications such as inference and computer learning . in this section we consider one possible way of making such a restriction . we show that in the important case of simple strings the proposed restriction e\ufb00ectively removes the error term in eq . which has important applications in physics . definition fix \u03b4 n. a set of strings s\u03b4 x is called \u03b4 simple i\ufb00 for any two strings \u03b1 \u03b3 s\u03b4 we have \u03b1 \u03b4 \u03b3 \u03b4 and h\u03b1 \u03b3i \u03b4 where denotes the string length . following chaitin consider a list of infinitely many requirements hrk lki for the construction of a computer . each requirement hrk lki requests that a program of length lk be assigned to the result rk if the computer is given data d. the requirements are said to satisfy the kraft inequality if pk lk for such requirements there exists an instantaneous code characterized by the set of string lengths . a computer c is said to satisfy the requirements if there are precisely as many programs p of length l such that c r as there are pairs hr li in the list of requirements . fix a universal computer u which can be constructed from an e\ufb00ectively given list of requirements . consider the set of all programs andrei n. soklakov for u such that the output of computation u is defined . since b is a bijection we can write u hrk ski where rk and sk are strings from x. moreover because u is a universal computer any pair of strings h\u03b1 \u03b3i can be generated this way . in what follows we consider only those pk for which sk \u03bb . for every fixed s from the set we construct a list of requirements hrk pk ku \u03bas di k. where pk is the length of the program pk and \u03bas d is some constant . it was shown that the constant \u03bas d can be chosen large enough such that these requirements satisfy the kraft inequality . fix any \u03b4 n and consider a sublist of requirements hrk pk ku \u03bas di where s\u03b4 is the set of \u03b4 simple strings . for any s s\u03b4 we can find \u03ba max then choose \u03bas rk d s\u03b4 rk d s\u03b4 . hrk pk ku \u03bai for any fixed s s\u03b4 these requirements satisfy the kraft inequality by construction . furthermore since s\u03b4 is finite and b is recursive these requirements can be e\ufb00ectively given . this means that for any s s\u03b4 there is a computer ws that satisfies these requirements consult for further details . for each value of s s\u03b4 we use to construct one ws . we define w\u03bb u and form the set wu . this set contains the original computer u as a somewhat special element . having the computer u at our disposal it would take at least ku bits to specify any other ws from the set wu given data d. we can now see that requirements are designed larger ku will have in such a way that more complex computers i.e. shorter programs lk pk ku \u03ba . this is exactly the property that we wanted to use as a natural restriction that defines a realistic class of computers . in what follows we restrict our attention to the set wu . we define a computer w which is universal for the set wu i.e. which is designed to simulate any computer ws wu w ws . theorem for any \u03b1 d s\u03b4 and for any \u03b3 s\u03b4 we have kw kw kw \u03ba . andrei n. soklakov proof consider the program pk which causes ws wu to produce the result rk s\u03b4 given data d ws rk . by definition of ws the length of pk satisfies the requirement s s\u03b4 and d s\u03b4 pk pk ku \u03ba where pk is the program for u such that u hrk ski sk \u03bb . we define the set k which can contain more than one element since some of the pairs can coincide . from the construction of ws we note that requirements associate exactly one program pk with the corresponding program pk . in other words there is a one to one correspondence between programs pk and pk . this means that the set k coincides with the set k. since u d and s are fixed and using the identity k k we have from eq . min k k pk min k k pk ku \u03ba s s\u03b4 . by definition of w we have w ws rk s \u03bb . this means by definition of kolmogorov complexity that kw mini k pi s \u03bb . similarly from eq . we have ku mini k pi and therefore eq . becomes kw ku ku \u03ba . because w u we have for instance ku kw . using this observation to transform both terms at the right hand side of eq . and choosing s sk we have eq . as required . note that since u is an arbitrary prefix computer the above analysis provides a grouping of all possible reference computers into naturally restricted classes . acknowledgments it is my pleasure to acknowledge many helpful suggestions by jens g. jensen a.s. johnson and yuri kalnishkan . andrei n. soklakov"
    ],
    "abstract": [
        "given a reference computer kolmogorov complexity is a well defined function on all binary strings . in the standard approach however only the asymptotic properties of such functions are considered because they do not depend on the reference computer . we argue that this approach can be more useful if it is refined to include an important practical case of simple binary strings . kolmogorov complexity calculus may be developed for this case if we restrict the class of available reference computers . the interesting problem is to define a class of computers which is restricted in a way modeling the real life situation where only a limited class of computers is physically available to us . we give an example of what such a natural restriction might look like mathematically and show that under such restrictions some error terms even logarithmic in complexity can disappear from the standard complexity calculus . keywords kolmogorov complexity algorithmic information theory ."
    ]
}