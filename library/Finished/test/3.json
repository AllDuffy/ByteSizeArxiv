{
    "id": "C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\testTokenized\\0009007v1",
    "article": [
        "keywords classification learning uncertainty evaluation comparison multiple models cost sensitive learning skewed distributions to appear in machine learning journal introduction traditionally classification systems have been built by experimenting with many di\ufb00erent classifiers comparing their performance and choosing the best . experimenting with di\ufb00erent induction algorithms parameter settings and training regimes yields a large number of classifiers to be evaluated and compared . unfortunately comparison often is difficult in real world environments because key parameters of the target environment are not known . the optimal cost benefit tradeo\ufb00s and the target class priors seldom are known precisely and often are subject to change . for example in fraud detection we can not ignore misclassification costs or the skewed class distribution nor can we assume that our estimates are precise or static . we need a method for the management comparison and application of multiple classifiers that is robust in imprecise and changing environments . we describe the roc convex hull method which combines techniques from roc analysis decision analysis and computational geometry . the roc convex hull decouples classifier performance from specific class and cost distributions and may be used to specify the subset of methods that are potentially optimal under any combination of cost assumptions and class distribution assumptions . the rocch method is efficient so it facilitates the comparison of a large number of classifiers . it minimizes the management of classifier performance data because it can specify exactly those classifiers that are potentially optimal and it is incremental easily incorporating new and varied classifiers without having to reevaluate all prior classifiers . we demonstrate that it is possible and desirable to avoid complete commitment to a single best classifier during system construction . instead the rocch can be used to build from the available classifiers a hybrid classification system that will perform best under any target cost benefit and class distributions . target conditions can then be specified at run time . moreover in cases where precise information is still unavailable when the system is run the hybrid system can be tuned easily based on feedback from its actual performance . the paper is structured as follows . first we sketch brie\ufb02y the traditional approach to building such systems in order to demonstrate that it is brittle under the types of imprecision common in realworld problems . we then introduce and describe the rocch and its properties for comparing and visualizing classifier performance in imprecise environments . in the following sections we formalize the notion of a robust classification system and show that the rocch is an elegant method for constructing one automatically . the solution is elegant because the resulting hybrid classifier is robust for a wide variety of problem formulations including the optimization of metrics such as accuracy expected cost lift precision recall and workforce utilization and it is efficient to build to store and to update . we then show that the hybrid actually can do better than the best known classifier in certain situations . finally by citing results from empirical studies we provide evidence that this type of system indeed is needed . an example a systems building team wants to create a system that will take a large number of instances and identify those for which an action should be taken . the instances could be potential cases of fraudulent account behavior of faulty equipment of responsive customers of interesting science etc. we consider problems for which the best method for classifying or ranking instances is not well defined so the system builders may consider machine learning methods neural networks casebased systems and hand crafted knowledge bases as potential classification models . ignoring for the moment issues of efficiency the foremost question facing the system builders is which of the available models performs best at classification traditionally an experimental approach has been taken to answer this question because the distribution of instances can be sampled if it is not known a priori . the standard approach is to estimate the error rate of each model statistically and then to choose the model with the lowest error rate . this strategy is common in machine learning pattern recognition data mining expert systems and medical diagnosis . in some cases other measures such as cost or benefit are used as well . applied statistics provides methods such as cross validation and the bootstrap for estimating model error rates and recent studies have compared the e\ufb00ectiveness of di\ufb00erent methods . unfortunately this experimental approach is brittle under two types of imprecision that are common in real world environments . specifically costs and benefits usually are not known precisely and target class distributions often are known only approximately as well . this observation has been made by many authors and is in fact the concern of a large subfield of decision analysis . imprecision also arises because the environment may change between the time the system is conceived and the time it is used and even as it is used . for example levels of fraud and levels of customer responsiveness change continually over time and from place to place . basic terminology in this paper we address two class problems . formally each instance i is mapped to one element of the set of positive and negative classes . a classification model is a mapping from instances to predicted classes . some classification models produce a continuous output to which di\ufb00erent thresholds may be applied to predict class membership . to distinguish between the actual class and the predicted class of an instance we will use the labels for the classifications produced by a model . for our discussion let c be a two place error cost function where c is the cost of a false positive error and c is the cost of a false negative error . we represent class distributions by the classes prior probabilities p and p p. for this paper we consider error costs to include benefits not realized and ignore the costs of correct classifications . e t a r e v i t i s o p e u r t. c c c fp . c c c c c c fp . false positive rates fp . figure three classifiers under three di\ufb00erent neyman pearson decision criteria the true positive rate or hit rate of a classifier is t p p positives correctly classified total positives the false positive rate or false alarm rate of a classifier is f p p negatives incorrectly classified total negatives the traditional experimental approach is brittle because it chooses one model as best with respect to a specific set of cost functions and class distribution . if the target conditions change this system may no longer perform optimally or even acceptably . as an example assume that we have a maximum false positive rate f p that must not be exceeded . we want to find the classifier with the highest possible true positive rate t p that does not exceed the f p limit . this is the neyman pearson decision criterion . three classifiers under three such f p limits are shown in figure . a di\ufb00erent classifier is best for each f p limit any system built with a single best classifier is brittle if the f p requirement can change . evaluating and visualizing classifier performance . classifier comparison decision analysis and roc analysis most prior work on building classifiers uses classification accuracy as the primary evaluation metric . the use of accuracy assumes that the class priors in the target environment will be constant and relatively balanced . in the real world this rarely is the case . classifiers often are used to sift through a large population of normal or uninteresting entities in order to find a relatively small number of unusual ones for example looking for defrauded accounts among a large population of customers screening medical tests for rare diseases and checking an assembly line for defective parts . because the unusual or interesting class is rare among the general population the class distribution is very skewed . as the class distribution becomes more skewed evaluation based on accuracy breaks down . consider a domain where the classes appear in a ratio . a simple rule always classify as . e t a r e v i t i s o p e u r t classifier classifier classifier . false positive rate figure roc graph of three classifiers the maximum likelihood class gives a. accuracy . this accuracy may be quite difficult for an induction algorithm to beat though the simple rule presumably is unacceptable if a non trivial solution is sought . skews of are common in fraud detection and skews exceeding have been reported in other applications . evaluation by classification accuracy also assumes equal error costs c c. in the real world classifications lead to actions which have consequences . actions can be as diverse as denying a credit charge discarding a manufactured part moving a control surface on an airplane or informing a patient of a cancer diagnosis . the consequences may be grave and performing an in mushroom incorrect action may be very costly . rarely are the costs of mistakes equivalent . classification for example judging a poisonous mushroom to be edible is far worse than judging an edible mushroom to be poisonous . indeed it is hard to imagine a domain in which a classification system may be indi\ufb00erent to whether it makes a false positive or a false negative error . in such cases accuracy maximization should be replaced with cost minimization . the problems of unequal error costs and uneven class distributions are related . it has been suggested that for training high cost instances can be compensated for by increasing their prevalence in an instance set . unfortunately little work has been published on either problem . there exist several dozen articles in which techniques for cost sensitive learning are suggested but few studies evaluate and compare them . the literature provides even less guidance in situations where distributions are imprecise or can change . given an estimate of p the posterior probability of an instance s class membership decision analysis gives us a way to produce cost sensitive classifications . classifier error frequencies can be used to approximate such probabilities . for an instance i the decision to emit a positive classification from a particular classifier is c p c regardless of whether a classifier produces probabilistic or binary classifications its normalized cost on a test set can be evaluated empirically as cost f p c c most published work on cost sensitive classification uses an equation such as this to rank classifiers . given a set of classifiers a set of examples and a precise cost function each classifier s cost is computed and the minimum cost classifier is chosen . however as discussed above such analyses assume that the distributions are precisely known and static . more general comparisons can be made with receiver operating characteristic analysis a classic methodology from signal detection theory that is common in medical diagnosis and has recently begun to be used more generally in ai classifier work . roc graphs depict tradeo\ufb00s between hit rate and false alarm rate . we use the term roc space to denote the coordinate system used for visualizing classifier performance . in roc space t p is represented on the y axis and f p is represented on the x axis . each classifier is represented by the point in roc space corresponding to its pair . for models that produce a continuous output e.g. posterior probabilities t p and f p vary together as a threshold on the output is varied between its extremes the resulting curve is called the roc curve . an roc curve illustrates the error tradeo\ufb00s available with a given model . figure shows a graph of three typical roc curves in fact these are the complete roc curves of the classifiers shown in figure . for orientation several points on an roc graph should be noted . the lower left point represents the strategy of never alarming the upper right point represents the strategy of always alarming the point represents perfect classification and the line y x represents the strategy of randomly guessing the class . informally one point in roc space is better than another if it is to the northwest . an roc graph allows an informal visual comparison of a set of classifiers . roc graphs illustrate the behavior of a classifier without regard to class distribution or error cost and so they decouple classification performance from these factors . unfortunately while an roc graph is a valuable visualization technique it does a poor job of aiding the choice of classifiers . only when one classifier clearly dominates another over the entire performance space can it be declared better . the roc convex hull method in this section we combine decision analysis with roc analysis and adapt them for comparing the performance of a set of learned classifiers . the method is based on three high level principles . first roc space is used to separate classification performance from class and cost distribution information . second decision analytic information is projected onto the roc space . third the convex hull in roc space is used to identify the subset of classifiers that are potentially optimal . . . iso performance lines by separating classification performance from class and cost distribution assumptions the decision goal can be projected onto roc space for a neat visualization . specifically the expected cost of applying the classifier represented by a point in roc space is p c p f p c therefore two points and have the same performance if t p t p f p f p cp cp this equation defines the slope of an iso performance line . that is all classifiers corresponding to points on the line have the same expected cost . each set of class and cost distributions defines a family of iso performance lines . lines more northwest are better because they correspond to classifiers with lower expected cost . . . the roc convex hull because in most real world cases the target distributions are not known precisely it is valuable to be able to identify those classifiers that potentially are optimal . each possible set of distributions d convex hull a c. b e t a r e v i t i s o p e u r t. false positive rate figure the roc convex hull identifies potentially optimal classifiers . defines a family of iso performance lines and for a given family the optimal methods are those that lie on the most northwest iso performance line . thus a classifier is optimal for some conditions if and only if it lies on the northwest boundary of the convex hull of the set of points in roc space . we discuss this in detail in section . we call the convex hull of the set of points in roc space the roc convex hull of the corresponding set of classifiers . figure shows four roc curves with the roc convex hull drawn as the border between the shaded and unshaded areas . d is clearly not optimal . perhaps surprisingly b can never be optimal either because none of the points of its roc curve lies on the convex hull . we can also remove from consideration any points of a and c that do not lie on the hull . consider these classifiers under two distribution scenarios . in each negative examples outnumber positives by . in scenario a false positive and false negative errors have equal cost . in scenario b a false negative is times as expensive as a false positive . each scenario defines a family of iso performance lines . the lines corresponding to scenario a have slope those for b have slope . figure shows the convex hull and two iso performance lines \u03b1 and \u03b2 . line \u03b1 is the best line with slope that intersects the convex hull line \u03b2 is the best line with slope that intersects the convex hull . each line identifies the optimal classifier under the given distribution . figure shows the three roc curves from our initial example with the convex hull drawn . . . generating the roc convex hull the roc convex hull method selects the potentially optimal classifiers based on the roc convex hull and iso performance lines . for each classifier plot t p and f p in roc space . for continuous output classifiers vary a threshold over the output range and plot the roc curve . table shows an algorithm for producing such an roc curve in a single pass . the convex hull of a set of points is the smallest convex set that contains the points . there is a subtle complication to producing roc curves from ranked test set data which is re\ufb02ected in the algorithm shown in table . specifically consecutive examples with the same score can give overly optimistic or overly pessimistic roc curves depending on the ordering of positive and negative examples . the roc curve generating algorithm shown here waits until all examples with the same score have been tallied before computing the next point of the roc curve . the result is a segment that bisects the area that would have resulted from the most optimistic and most pessimistic orderings . \u03b2 c \u03b1 a e t a r e v i t i s o p e u r t. false positive rate figure lines \u03b1 and \u03b2 show the optimal classifier under di\ufb00erent sets of conditions . find the convex hull of the set of points representing the predictive behavior of all classifiers of interest for example by using the quickhull algorithm . for each set of class and cost distributions of interest find the slope of the corresponding iso performance lines . for each set of class and cost distributions the optimal classifier will be the point on the convex hull that intersects the iso performance line with largest t p intercept . ranges of slopes specify hull segments . figures and demonstrate how the subset of classifiers that are potentially optimal can be identified and how classifiers can be compared under di\ufb00erent cost and class distributions . . . comparing a variety of classifiers the roc convex hull method accommodates both binary and continuous classifiers . binary classifiers are represented by individual points in roc space . continuous classifiers produce numeric outputs to which thresholds can be applied yielding a series of pairs forming an roc curve . each point may or may not contribute to the roc convex hull . figure depicts the binary classifiers e f and g added to the previous hull . e may be optimal under some circumstances because it extends the convex hull . classifiers f and g never will be optimal because they do not extend the hull . new classifiers can be added incrementally to an rocch analysis as demonstrated in figure by the addition of classifiers e f and g. each new classifier either extends the existing hull or it does not . in the former case the hull must be updated accordingly but in the latter case the new classifier can be ignored . therefore the method does not require saving every classifier for re analysis under di\ufb00erent conditions only those points on the convex hull . recall that each point is a classifier and might take up considerable space . further the management of knowledge about many classifiers and their statistics from many di\ufb00erent runs of learning programs can be a substantial undertaking . classifiers not on the rocch can never be optimal so they need not be saved . every classifier that does lie on the convex hull must be saved . in section . we demonstrate the rocch in use managing the results of many learning experiments . e t a r e v i t i s o p e u r t classifier classifier classifier convex hull . false positive rate figure roc curves with convex hull . . changing distributions and costs class and cost distributions that change over time necessitate the reevaluation of classifier choice . in fraud detection costs change based on workforce and reimbursement issues the amount of fraud changes monthly . with the roc convex hull method comparing under a new distribution involves only calculating the slope of the corresponding iso performance lines and intersecting them with the hull as shown in figure . the roc convex hull method scales gracefully to any degree of precision in specifying the cost and class distributions . if nothing is known about a distribution the roc convex hull shows all classifiers that may be optimal under any conditions . figure showed that given classifiers a b c and d only a and c can ever be optimal . with complete information the method identifies the optimal classifier . in figure we saw that classifier a is optimal under scenario a and classifier c is optimal under scenario b. next we will see that with less precise information the roc convex hull can show the subset of possibly optimal classifiers . . . sensitivity analysis imprecise distribution information defines a range of slopes for iso performance lines . this range of slopes intersects a segment of the roc convex hull which facilitates sensitivity analysis . for example if the segment defined by a range of slopes corresponds to a single point in roc space or a small threshold range for a single classifier then there is no sensitivity to the distribution assumptions in question . consider a scenario similar to a and b in that negative examples are times as prevalent as positive ones . in this scenario consider the cost of dealing with a false alarm to be between and and the cost of missing a positive example to be between and . these conditions define a range of slopes for iso performance lines . figure a depicts this range of slopes and the corresponding segment of the roc convex hull . the figure shows that the choice of classifier is insensitive to changes within this range . figure b depicts a scenario with a wider range of slopes m. the figure shows that under this scenario the choice of classifier is very sensitive to the distribution . classifiers a c and e each are optimal for some subrange . m table algorithm for generating an roc curve from a set of ranked examples . given e list of tuples hi pi where i labeled example p numeric ranking assigned to i by the classifier p n count of positive and negative examples in e respectively . output r list of points on the roc curve . t count f count plast r hi sort e in decreasing order by p values while do current tp tally current fp tally last score seen list of roc points remove tuple hi pi from head of e if then add point to end of r end if if then t count t count else end if f count f count end while add point to end of r i is a negative example building robust classifiers up to this point we have concentrated on the use of the rocch for visualizing and evaluating sets of classifiers . the rocch helps to delay classifier selection as long as possible yet provides a rich performance comparison . however once system building incorporates a particular classifier the problem of brittleness resurfaces . this is important because the delay between system building and deployment may be large and because many systems must survive for years . in fact in many domains a precise static specification of future costs and class distributions is not just unlikely it is impossible . we address this brittleness by using the rocch to produce robust classifiers defined as satisfying the following . under any target cost and class distributions a robust classifier will perform at least as well as the best classifier for those conditions . our statements about optimality are practical the best classifier may not be the bayes optimal classifier but it is at least as good as any known classifier . srinivasan calls this fapp optimal . stating that a classifier is robust is stronger than stating that it is optimal for a specific set of conditions . a robust classifier is optimal under all possible conditions . in principle classification brittleness could be overcome by saving all possible classifiers and then performing an automated run time comparison under the desired target conditions . however such a system is not feasible because of time and space limitations there are myriad possible classification models arising from the many di\ufb00erent learning methods under their many di\ufb00erent parameter settings . storing all the classifiers is not feasible and tuning the system by comparing classifiers on the \ufb02y under di\ufb00erent e g a c f e t a r e v i t i s o p e u r t. false positive rate figure classifier e may be optimal for some conditions because it extends the roc convex hull . f and g can not be optimal they are not on the hull nor do they extend it . conditions is not feasible . fortunately doing so is not necessary . moreover we will show that it is sometimes possible to do better than any of these classifiers . rocch hybrid classifiers we now show that robust hybrid classifiers can be built using the rocch . definition let i be the space of possible instances and let c be the space of sets of classification models . let a \u00b5 hybrid classifier comprise a set of classification models c c and a function \u00b5 i \u211c c. a \u00b5 hybrid classifier takes as input an instance i i for classification and a number x \u211c . as output it produces the classification produced by \u00b5 . things will get more involved later but for the time being consider that each set of cost and class distributions defines a value for x which is used to select the best classifier for those conditions . to build a \u00b5 hybrid classifier we must define \u00b5 and the set c. we would like c to include only those models that perform optimally under some conditions since these will be stored by the system and we would like \u00b5 to be general enough to apply to a variety of problem formulations . the models comprising the rocch can be combined to form a \u00b5 hybrid classifier that is an elegant robust classifier . definition the rocch hybrid is a \u00b5 hybrid classifier where c is the set of classifiers that form the rocch and \u00b5 makes classifications using the classifier on the rocch with f p x. note that for the moment the rocch hybrid is defined only for f p values corresponding to rocch vertices . robust classification our definition of robust classifiers was intentionally vague about what it means for one classifier to be better than another because di\ufb00erent situations call for di\ufb00erent comparison frameworks . we . false positive rate . a. low sensitivity e a e a. e t a r e v i t i s o p e u r t. e t a r e v i t i s o p e u r t c c. false positive rate b. high sensitivity figure sensitivity analysis using the roc convex hull low sensitivity high sensitivity now continue with minimizing expected cost because the process of proving that the rocch hybrid minimizes expected cost for any cost and class distributions provides a deep understanding of why and how the rocch hybrid works . later we generalize to a wide variety of comparison frameworks . the rocch hybrid can be seen as an application of multi criteria optimization to classifier design and construction . the classifiers on the rocch are edgeworth pareto optimal with respect to tp fp and the objective functions we discuss . multi criteria optimization was used previously in machine learning by tcheng lambert lu and rendell for the selection of inductive bias . alternatively the rocch can be seen as an application of the theory of games and statistical decisions for which convex sets represent optimal strategies . edgeworth pareto optimality is the century old notion that in a multidimensional space of criteria optimal performance is the frontier of achievable performance in this space . in cases where performance is a linear combination of the criteria the optimality frontier is the convex hull . . . minimizing expected cost from above the expected cost of applying a classifier is ec p c p f p c for a particular set of cost and class distributions the slope of the corresponding iso performance lines is mec cp cp every set of conditions will define an mec . we now can show that the rocch hybrid is robust for problems where the best classifier is the classifier with the minimum expected cost . the slope of the rocch is an important tool in our argument . the rocch is a piecewise linear concave down curve . therefore as x increases the slope of the rocch is monotonically nonincreasing with k discrete values where k is the number of rocch component classifiers including the degenerate classifiers that define the rocch endpoints . where there will be no confusion we use phrases such as points in roc space as a shorthand for the more cumbersome classifiers corresponding to points in roc space . for this subsection unless otherwise noted points on the rocch refer to vertices of the rocch . definition for any real number m the point where the slope of the rocch is m is one of the endpoints of the segment of the rocch with slope m if such a segment exists . otherwise it is the vertex for which the left adjacent segment has slope greater than m and the right adjacent segment has slope less than m. for completeness the leftmost endpoint of the rocch is considered to be attached to a segment with infinite slope and the rightmost endpoint of the rocch is considered to be attached to a segment with zero slope . note that every m defines at least one point on the rocch . lemma for any set of cost and class distributions there is a point on the rocch with minimum expected cost . proof assume that for some conditions there exists a point c with smaller expected cost than any point on the rocch . by equations and a point has the same expected cost as a point if t p t p f p f p mec therefore for conditions corresponding to mec all points with equal expected cost form an isoperformance line in roc space with slope mec . also by and points on lines with larger y intercept have lower expected cost . now point c is not on the rocch so it is either above the curve or below the curve . if it is above the curve then the rocch is not a convex set enclosing all points which is a contradiction . if it is below the curve then the iso performance line through c also contains a point p that is on the rocch . if this iso performance line intersects no rocch vertex then consider the vertices at the endpoints of the rocch segment containing p one of these vertices must intersect a better iso performance line than does c. in either case since all points on an iso performance line have the same expected cost point c does not have smaller expected cost than all points on the rocch which is also a contradiction . although it is not necessary for our purposes here it can be shown that all of the minimum expected cost classifiers are on the rocch . definition an iso performance line with slope m is an m iso performance line . lemma for any cost and class distributions that translate to mec a point on the rocch has minimum expected cost only if the slope of the rocch at that point is mec . proof suppose that there is a point d on the rocch where the slope is not mec but the point does have minimum expected cost . by definition either the segment to the left of d has slope less than mec or the segment to the right of d has slope greater than mec . for case consider point n the vertex of the rocch that neighbors d to the left and consider the mec iso performance lines ld and ln through d and n. because n is to the left of d and the line connecting them has slope less than mec the y intercept of ln will be greater than the y intercept of ld . this means that n will have lower expected cost than d which is a contradiction . the argument for is analogous . lemma if the slope of the rocch at a point is mec then the point has minimum expected cost . proof if this point is the only point where the slope of the rocch is mec then the proof follows directly from lemma and lemma . if there are multiple such points then by definition they are connected by an mec iso performance line so they have the same expected cost and once again the proof follows directly from lemma and lemma . it is straightforward now to show that the rocch hybrid is robust for the problem of minimizing expected cost . theorem the rocch hybrid minimizes expected cost for any cost distribution and any class distribution . proof because the rocch hybrid is composed of the classifiers corresponding to the points on the rocch this follows directly from lemmas and . now we have shown that the rocch hybrid is robust when the goal is to provide the minimum expected cost classification . this result is important even for accuracy maximization because the preferred classifier may be di\ufb00erent for di\ufb00erent target class distributions . this rarely is taken into account in experimental comparisons of classifiers . corollary the rocch hybrid minimizes error rate for any target class distribution . proof error rate minimization is cost minimization with uniform error costs . robust classification for other common metrics showing that the rocch hybrid is robust not only helps us with understanding the rocch method generally it also shows us how the rocch hybrid will pick the best classifier in order to produce the best classifications which we will return to later . if we ignore the need to specify how to pick the best component classifier we can show that the rocch applies more generally . f p then there exists a point on the rocch with an f value at least as high as theorem for any classifier evaluation metric f if f t p and f that of any known classifier . proof assume that there exists a classifier co not on the rocch with an f value higher than that of any point on the rocch . co is either above or below the rocch . in case the rocch is not a convex set enclosing all the points which is a contradiction . in case let co be represented in roc space by . because co is below the rocch there exist points call one on the rocch with t pp t po and f pp f po . however by the restriction on the partial derivatives for any such point f f which again is a contradiction . there are two complications to the more general use of the rocch both of which are illustrated by the decision criterion from our very first example . recall that the neyman pearson criterion specifies a maximum acceptable f p rate . standard roc analysis uses roc curves to select a single parameterized classification model the parameter allows the user to select the operating point for a decision making task usually a threshold on a probabilistic output that will allow for optimal decision making . under the neyman pearson criterion selecting the single best model from a set is easy plot the roc curves draw a vertical line at the desired maximum f p and pick the model whose curve has the largest t p at the intersection with this line . classifier classifier classifier hull neyman pearson e t a r e v i t i s o p e u r t. false positive rate figure the roc convex hull used to select a classifier under the neyman pearson criterion with the rocch hybrid making the best classifications under the neyman pearson criterion is not so straightforward . for minimizing expected cost it was sufficient for the rocch hybrid to choose a vertex from the rocch for any mec value . for problem formulations such as the neymanpearson criterion the performance statistics at a non vertex point on the rocch may be preferable . fortunately with a slight extension the rocch hybrid can yield a classifier with these performance statistics . theorem an rocch hybrid can achieve the t p f p tradeo\ufb00 represented by any point on the rocch not just the vertices . proof extend \u00b5 to non vertex points as follows . pick the point p on the rocch with f p x. let t px be the t p value of this point . if is an rocch vertex use the corresponding classifier . if it is not a vertex call the left endpoint of the hull segment on which p lies cl and the right endpoint cr . let d be the distance between cl and cr and let p be the distance between cl and p. make classifications as follows . for each input instance \ufb02ip a weighted coin and choose the answer given by classifier cr with probability p d and that given by classifier cl with probability p d. it is straightforward to show that f p and t p for this classifier will be x and t px . the second complication is that as illustrated by the neyman pearson criterion many practical classifier comparison frameworks include constrained optimization problems . arbitrarily constrained optimizations are problematic for the rocch hybrid . given total freedom it is possible to devise constraints on classifier performance such that even with the restriction on the partial derivatives an interior point scores higher than any acceptable point on the hull . for example two linear constraints can enclose a subset of the interior and exclude the entire rocch there will be no acceptable points on the rocch . however many realistic constraints do not thwart the optimality of the rocch hybrid . theorem for any classifier evaluation metric f if f t p and f f p and no constraint on classifier performance eliminates any point on the rocch without also eliminating all higher scoring interior points then the rocch hybrid can perform at least as well as any known classifier . proof follows directly from theorem and theorem . linear constraints on classifiers f p t p performance are common for real world problems so the following is useful . corollary for any classifier evaluation metric f if t p and f f f p and there is a single constraint on classifier performance of the form a t p b f p c with a and b non negative then the rocch hybrid can perform at least as well as any known classifier . proof the single constraint eliminates from contention all points that do not fall to the left of or below a line with non positive slope . by the restriction on the partial derivatives such a constraint will not eliminate a point on the rocch without also eliminating all interior points with higher f values . thus the proof follows directly from theorem . so finally we have the following corollary for the neyman pearson criterion the rocch hybrid can perform at least as well as that of any known classifier . proof for the neyman pearson criterion the evaluation metric is f t p that is a higher t p is better . the constraint on classifier performance is f p f pmax . these satisfy the conditions for corollary and therefore this corollary follows . all the foregoing e\ufb00ort may seem misplaced for a simple criterion like neyman pearson . however there are many other realistic problem formulations . for example consider the decision support problem of optimizing workforce utilization in which a workforce is available that can process a fixed number of cases . too few cases will under utilize the workforce but too many cases will leave some cases unattended . if the workforce can handle k cases the system should present the best possible set of k cases . this is similar to the neyman pearson criterion but with an absolute cuto\ufb00 instead of a percentage cuto\ufb00 . theorem for workforce utilization the rocch hybrid will provide the best set of k cases for any choice of k. proof the decision criterion is to maximize t p subject to the constraint the theorem therefore follows from corollary . t p p f p n k in fact many screening problems such as are found in marketing and information retrieval use exactly this linear constraint . it follows that for maximizing lift precision or recall subject to absolute or percentage cuto\ufb00s on case presentation the rocch hybrid will provide the best set of cases . as with minimizing expected cost imprecision in the environment forces us to favor a robust solution for these other comparison frameworks . for many real world problems the precise desired cuto\ufb00 will be unknown or will change . what is worse for a fixed cuto\ufb00 merely changing the size of the universe of cases may change the preferred classifier because it will change the constraint line . the rocch hybrid provides a robust solution because it gives the optimal subset of cases for any constraint line . for example for document retrieval the rocch hybrid will yield the best n documents for any n for any prior class distribution and for any target corpus size . ranking cases an apparent solution to the problem of robust classification is to use a model that ranks cases and just work down the ranked list . this approach appears to sidestep the brittleness demonstrated with binary classifiers since the choice of a cuto\ufb00 point can be deferred to classification time . however choosing the best ranking model is still problematic . for most practical situations choosing the best ranking model is equivalent to choosing which classifier is best for the cuto\ufb00 that will be used . rb ra random n cases e t a r e v i t i s o p e u r t. false positive rate figure the roc curves of the two ranking classifiers ra and rb described in section . . an example will illustrate this . consider two ranking functions ra and rb applied to a classbalanced set of cases . assume ra is able to recognize a common aspect unique to positive cases that occurs in of the population and it ranks these highest . assume rb is able to recognize a common aspect unique to negative cases occurring in of the population and it ranks these lowest . so ra ranks the highest correctly and performs randomly on the remainder while rb ranks the lowest correctly and performs randomly on the remainder . which model is better the answer depends entirely upon how far down the list the system will go before it stops that if fewer than cases are to be selected then ra should be is upon what cuto\ufb00 will be used . used whereas rb is better if more than cases will be selected . figure shows the roc curves corresponding to these two classifiers and the point corresponding to n where the curves cross in roc space . the rocch method can be used to organize such ranking models as we have seen . recall that roc curves are formed from case rankings by moving the cuto\ufb00 from one extreme to the other . the rocch hybrid comprises the ranking models that are best for all possible conditions . whole curve metrics in situations where either the target cost distribution or class distribution is completely unknown some researchers advocate choosing the classifier that maximizes a single number metric representing the average performance over the entire curve . a common whole curve metric is auc the area under the curve . the auc is equivalent to the probability that a randomly chosen positive instance will be rated higher than a negative instance and thereby is also estimated by the wilcoxon test of ranks . a criticism of auc is that for specific target conditions the classifier with the maximum auc may be suboptimal . indeed this criticism may be made of any single number metric . fortunately not only is the rocch hybrid optimal for any specific target conditions it has the maximum auc there is no classifier with auc larger than that of the rocch hybrid . using the rocch hybrid to use the rocch hybrid for classification we need to translate environmental conditions to x values to plug into \u00b5 . for minimizing expected cost equation shows how to translate conditions to mec . for any mec by lemma we want the f p value of the point where the slope of the rocch is mec which is straightforward to calculate . for the neyman pearson criterion the conditions are defined as f p values . for workforce utilization with conditions corresponding to a cuto\ufb00 k the f p value is found by intersecting the line t p p f p n k with the rocch . we have argued that target conditions are rarely known . it may be confusing that we now seem to require exact knowledge of these conditions . the rocch hybrid gives us two important capabilities . first the need for precise knowledge of target conditions is deferred until run time . second in the absence of precise knowledge even at run time the system can be optimized easily with minimal feedback . by using the rocch hybrid information on target conditions is not needed to train and compare classifiers . this is important because of imprecision caused by temporal geographic or other di\ufb00erences that may exist between training and use . for example building a system for a real world problem introduces a non trivial delay between the time data are gathered and the time the learned models will be used . the problem is exacerbated in domains where error costs or class distributions change over time even with slow drift a brittle model may become suboptimal quickly . in many such scenarios costs and class distributions can be specified at run time with reasonable precision by sampling from the current population and used to ensure that the rocch hybrid always performs optimally . in some cases even at run time these quantities are not known exactly . a further benefit of the rocch hybrid is that it can be tuned easily to yield optimal performance with only minimal feedback from the environment . conceptually the rocch hybrid has one knob that varies x in \u00b5 from one extreme to the other . for any knob setting the rocch hybrid will give the optimal t p f p tradeo\ufb00 for the target conditions corresponding to that setting . turning the knob to the right increases t p turning the knob to the left decreases f p. because of the monotonicity of the rocch hybrid simple hill climbing can guarantee optimal performance . for example if the system produces too many false alarms turn the knob to the left if the system is presenting too few cases turn the knob to the right . beating the component classifiers perhaps surprisingly in many realistic situations an rocch hybrid system can do better than any of its component classifiers . consider the neyman pearson decision criterion . the rocch may intersect the f p line above the highest component roc curve . this occurs when the f p line intersects the rocch between vertices therefore there is no component classifier that actually produces these particular statistics as in figure . by theorem the rocch hybrid can achieve any t p on the hull . only a small number of f p values correspond to hull vertices . the same holds for other common problem formulations such as workforce utilization lift maximization precision maximization and recall maximization . time and space efficiency we have argued that the rocch hybrid is robust for a wide variety of problem formulations . it is also efficient to build to store and to update . the time efficiency of building the rocch hybrid depends first on the efficiency of building the component models which varies widely by model type . some models built by machine learning methods can be built in seconds . hand built models can take years to build . however we presume that this is work that would be done anyway . the rocch hybrid can be built with whatever methods are available be there two or two thousand . as described below as new classifiers become available the rocch hybrid can be updated incrementally . the time efficiency depends also on the efficiency of the experimental evaluation of the classifiers . once again we presume that this is work that would be done anyway . finally the time efficiency of the rocch hybrid depends on the efficiency of building the rocch which can be done in o time using the quickhull algorithm where n is the number of classifiers . the rocch is space efficient too because it comprises only classifiers that might be optimal under some target conditions . the number of classifiers that must be stored can be reduced if bounds can be placed on the potential target conditions . as described above ranges of conditions define segments of the rocch . thus the rocch hybrid may need only a subset of c. adding new classifiers to the rocch hybrid also is efficient . adding a classifier to the rocch will either extend the hull adding to the rocch hybrid or conclude that the new classifiers are not superior to the existing classifiers in any portion of roc space and can be discarded . the run time complexity of the rocch hybrid is never worse than that of the in situations where run time complexity is crucial the rocch should be component classifiers . constructed without prohibitively expensive classification models . it then will find the best subset of the computationally efficient models . empirical demonstration of need robust classification is of fundamental interest because it weakens two very strong assumptions the availability of precise knowledge of costs and of class distributions . however might it not be that existing classifiers already are robust for example if a given classifier is optimal under one set of conditions might it not be optimal under all it is beyond the scope of this paper to o\ufb00er an in depth experimental study answering this question . however we can provide solid evidence that the answer is no by referring to the results of two prior studies . one is a comprehensive roc analysis of medical domains recently conducted by andrew bradley . the other is a published roc analysis of uci database domains that we undertook last year with ron kohavi . note that a classifier dominates if its roc curve completely defines the rocch . therefore if there exist more than a trivially few domains where no single classifier dominates then techniques like the rocch hybrid are essential if robust classifiers are desired . bradley s study bradley studied six medical data sets noting that unfortunately we rarely know what the individual misclassification costs are . he plotted the roc curves of six classifier learning algorithms . on not one of these data sets was there a dominating classifier . this means that for each domain there exist di\ufb00erent sets of conditions for which di\ufb00erent classifiers are preferable . in fact the running example in the present article is based on the three best classifiers from bradley s results on the heart bleeding data his results for the full set of six classifiers can be found in figure . classifiers constructed for the cleveland heart disease data are shown in figure . bradley s results show clearly that for many domains the classifier that maximizes any single metric be it accuracy cost or the area under the roc curve will be the best for some cost and class distributions and will not be the best for others . we have shown that the rocch hybrid will be the best for all . our study in the study we performed with ron kohavi we chose ten datasets from the uci repository each of which contains at least instances but for which the accuracy for decision trees was less than . for each domain we induced classifiers for the minority class . we selected several induction algorithms from mlc a decision tree learner naive bayes with discretization k nearest neighbor for several k values and bagged mc . mc is similar to c. probabilistic predictions are made by using a laplace correction at the leaves . nb discretizes the data based on entropy minimization and then builds the bradley s purpose was not to answer this question fortunately his published results do anyway . e t a r e v i t i s o p e u r t. bayes k nn mlp c. msc perceptron . false positive rate figure bradley s classifier results for the heart bleeding data . naive bayes model . ibk votes the closest k neighbors each neighbor votes with a weight equal to one over its distance from the test instance . some of the roc curves are shown in figure . for only one of these ten domains was there an absolute dominator . in general very few of the runs performed had dominating classifiers . some cases are very close for example adult and waveform . in other cases a curve that dominates in one area of roc space is dominated in another . these results also support the need for methods like the rocch hybrid which produce robust classifiers . as examples of what expected cost minimizing rocch hybrids would look like internally table shows the component classifiers that make up the rocch for the four uci domains of figure . for example in the road domain naive bayes would be chosen for any target conditions corresponding to a slope less than . and bagged mc would be chosen for slopes greater than . . they perform equally well at . . limitations and future work there are limitations to the rocch method as we have presented it here . we have defined it here only for two class problems . srinivasan shows that it can be extended to multiple dimensions . it should be noted that the dimensionality of the roc hyperspace grows quadratically in the number of classes so both efficiency and visualization capability are called into question . we have assumed constant error costs for a given type of error e.g. all false positives cost the same . for some problems di\ufb00erent errors of the same type have di\ufb00erent costs . in many cases such a problem can be transformed for evaluation into an equivalent problem with uniform intra type error costs by duplicating instances in proportion to their costs . we also have assumed for this paper that the estimates of the classifiers performance statistics are very good . as mentioned above much work has addressed the production of good estimates for simple performance statistics such as error rate . much less work has addressed the production of good roc curve estimates . as with simpler statistics care should be taken to avoid over fitting the training data and to ensure that di\ufb00erences between roc curves are meaningful . one solution is to use cross validation with averaging of roc curves which is the procedure used to produce the roc curves in section . . to our knowledge the issue is e t a r e v i t i s o p e u r t. bayes k nn mlp c. msc perceptron . false positive rate figure bradley s classifier results for the cleveland heart disease data open of how best to produce confidence bands appropriate to a particular problem . those shown in section . are appropriate for the neyman pearson decision criterion . also we have addressed predictive performance and computational performance . these are not the only concerns in choosing a classification model . what if comprehensibility is important the easy answer is that for any particular setting the rocch hybrid is as comprehensible as the underlying model it is using . however this answer falls short if the rocch hybrid is interpolating between two models or if one wants to understand the multiple model system as a whole . although roc analysis and the rocch method were specifically designed for classification domains we have extended them to activity monitoring domains . such domains involve monitoring the behavior of a population of entities for interesting events requiring action . these problems are substantially di\ufb00erent from standard classification because timeliness of classification is important and dependencies exist among instances both factors complicate evaluation . this work is fundamentally di\ufb00erent from other recent machine learning work on combining multiple models . that work combines models in order to boost performance for a fixed cost and class distribution . the rocch hybrid combines models for robustness across di\ufb00erent cost and class distributions . in principle these methods should be independent multiple model classifiers are candidates for extending the rocch . however it may be that some multiple model classifiers achieve increased performance for a specific set of conditions by interpolating along edges of the rocch . cherikh uses roc analysis to study decision making where the decisions of multiple models are present . unlike our work the goal is to find optimal combinations of models for specific conditions . however it seems that the two methods may be combined profitably well chosen combinations of models should extend the rocch yielding a better robust classifier . the rocch method also complements research on cost sensitive learning . existing cost sensitive learning methods are brittle with respect to imprecise cost knowledge . thus the rocch is an essential evaluation tool . furthermore cost sensitive learning may be used to find better components for the rocch hybrid by searching explicitly for classifiers that extend the rocch . false positive a. vehicle false positive b. crx e v i t i s o p e u r t e v i t i s o p e u r t. e v i t i s o p e u r t e v i t i s o p e u r t. mc nb ib ib ib bag mc mc nb ib ib ib bag mc mc nb ib ib ib bag mc mc nb ib ib ib bag mc . false positive c. roadgrass false positive d. satimage figure smoothed roc curves from uci database domains conclusion the roc convex hull method is a robust efficient solution to the problem of comparing multiple classifiers in imprecise and changing environments . it is intuitive can compare classifiers both in general and under specific distribution assumptions and provides crisp visualizations . it minimizes the management of classifier performance data by selecting exactly those classifiers that are potentially optimal thus only these need to be saved in preparation for changing conditions . moreover due to its incremental nature new classifiers can be incorporated easily e.g. when trying a new parameter setting . the rocch hybrid performs optimally under any target conditions for many realistic problem formulations including the optimization of metrics such as accuracy expected cost lift precision recall and workforce utilization . it is efficient to build in terms of time and space and can be updated incrementally . furthermore it can sometimes classify better than any known model . therefore we conclude that it is an elegant robust classification system . we believe that this work has important implications for both machine learning applications and machine learning research . for applications it helps free system designers table locally dominating classifiers for four uci domains domain vehicle road crx satimage slope range dominator bagged mc nb bagged mc . bagged mc nb bagged mc nb . nb bagged mc ib ib ib ib bagged mc . from the need to choose comparison metrics before precise knowledge of key evaluation parameters is available . indeed such knowledge may never be available yet robust systems still can be built . for machine learning research it frees researchers from the need to have precise class and cost in particular work on distribution information in order to study important related phenomena . cost sensitive learning has been impeded by the difficulty of specifying costs and by the tenuous nature of conclusions based on a single cost metric . researchers need not be held back by either . cost sensitive learning can be studied generally without specifying costs precisely . the same goes for research on learning with highly skewed distributions . which methods are e\ufb00ective for which levels of distribution skew the rocch will provide a detailed answer . recently drummond and holte have demonstrated an intriguing dual to the rocch . their cost curves represent expected costs explicitly rather than as slopes of iso performance lines and thereby provide an insightful alternative perspective for visualization . note an implementation of the rocch method in perl is publicly available . the code and related papers may be found at http www.hpl.hp.com personal tom_fawcett rocch . acknowledgments much of this work was done while the authors were employed at the bell atlantic science and technology center . we thank the many with whom we have discussed roc analysis and classifier comparison especially rob holte george john ron kohavi ron rymon and peter turney . we thank andrew bradley for supplying data from his analysis ."
    ],
    "abstract": [
        "in real world environments it usually is difficult to specify target operating conditions precisely for example target misclassification costs . this uncertainty makes building robust classification systems problematic . we show that it is possible to build a hybrid classifier that will perform at least as well as the best available classifier for any target conditions . in some cases the performance of the hybrid actually can surpass that of the best known classifier . this robust performance extends across a wide variety of comparison frameworks including the optimization of metrics such as accuracy expected cost lift precision recall and workforce utilization . the hybrid also is efficient to build to store and to update . the hybrid is based on a method for the comparison of classifier performance that is robust to imprecise class distributions and misclassification costs . the roc convex hull method combines techniques from roc analysis decision analysis and computational geometry and adapts them to the particulars of analyzing learned classifiers . the method is efficient and incremental minimizes the management of classifier performance data and allows for clear visual comparisons and sensitivity analyses . finally we point to empirical evidence that a robust hybrid classifier indeed is needed for many real world problems ."
    ]
}