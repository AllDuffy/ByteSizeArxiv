{
    "id": "C:\\Users\\Al\\Documents\\ByteSizeArxiv\\library\\valTokenized\\0309015v1",
    "article": [
        "bayesian networks and the causal markov condition learning statistical dependencies among a set of n random variables x. xn is an important tool of scientific research . formally the task of learning those dependencies is to obtain some information about the joint probability measure p where p de . a useful way to represent such notes the probability of the event x x. xn xn information in a graphical way is given by the concept of bayesian networks . although one may consider bayesian networks merely as a way of encoding statistical dependencies into a graph the concept is better understood if a causal interpretation is given to the graph . recall that every joint probability p can be factorized as p p n yj x. xj are the conditional probabilities given the values x. xj where p p are given . once determined once the transition probabilities p xj we have found a hypothetical graph with corresponding transition probabilities that seems to be in good agreement with the observed data we would like to judge whether we have really found a good model or whether the good agreement is rather caused by over fitting our limited amount of data . in upper bounds on the required learning bayesian networks using statistical learning theory sample size for learning the probabilities of all k tuples with a certain accuracy and reliability are given . under the assumption that the true probability measure is markovian relative to a simple graph this will give the joint measure on the n variables up to a certain accuracy . here we do not make any prior assumptions on the underlying joint probabilities . merely the fact that we have found a simple model that does explain data shall give the accuracy and reliability of our guess . for each node xj the number of free parameters increases exponentially with the number kj of parents of xj . therefore it seems to be a reasonable concept to bound the number of free parameters of the available probability measures by considering graphs with small in degree in order to avoid over fitting . however this is a heuristic argument . in the context of learning theory vapnik has argued that a small number of free parameters of the set of available functions to fit observed data is neither sufficient nor necessary to avoid over fitting . he showed the so called vapnikchervonenkis dimension of a set of functions to be decisive . but we will show that it does make sense from the point of view of learning theory to consider graphs with small in degree since we can derive upper bounds on the vc dimension of the set of corresponding probability measures . in section we formulate the criterion for judging whether a hypothetical measure fits well the observed data and give a meaning on what defines a good guess of statistical dependencies i.e. we define a risk functional quantifying the goodness of fit . in section we rephrase the concept of vc dimension and explain the general idea to use it for obtaining reliability bounds when an unknown function is to be learned . in our case the unknown function is the joint probability distribution on n random variables . therefore we derive in section bounds on the vc dimension of sets of joint distributions corresponding to given graphs and sets of graphs . we show how to obtain reliability bounds for the estimated distribution . in section we show how to apply structural risk minimization principle in order to learn baeysian networks reliably . in section we implement the minimization as a convex optimization problem . selection criterion for hypothetical networks assume the data are given by l n tuples x x. xl . using prior knowledge on the underlying causal structure we might prefer a specific graph pg describes the observed g. it should have the property that a probability distribution in pg we use the following data already very well . in order to find the best distribution in approach . consider the observed relative frequencies h formally as a \u03c9n and minimize probability measure over the set of possible n tuples \u03c9 \u03c9 the kullback leibler relative entropy \u03c9 k h ln p h ln h xx \u03c9 xx \u03c9 which is equivalent to the minimization of remp h ln p ln p. xx l xi l d. janzing and d. herrmann over all p pg . by the law of large numbers remp converges to r p ln p xx \u03c9 where p is the true probability measure on \u03c9 . note that r yields for p p r p ln p s xx \u03c9 i.e. the entropy of p. it measures the quality of the hypothesis concerning the statistical dependencies since it measures whether those events that have been predicted to be rather unlikely by the hypothetical measure do really occur rarely . therefore a low value of r does not only mean that the kullback leibler distance between p and the true measure p is low but it also implies that the entropy of p is low . this means that we have found strong statistical dependencies . they may for instance indicate strong causal in\ufb02uences among the variables . this justifies to consider r as a criterion that measures whether the hypothetical measure p is not only good in the sense that its deviation from p is small but also that we have found a law with high predictive power . the minimization above is quite convenient since the factorization in eq . corresponds to a sum of the logarithms of the conditional probabilities . it is clear that this minimization does not make sense if g gc is the complete acyclic graph for a given order . since all pgc we would clearly obtain p h a fatal over fit . this example measures are in shows intuitively that the minimization above leads to over fitting when g has too many arrows . in order to consider this problem from a perspective of statistical learning theory we rephrase the essential concepts in the next section . risk estimation by statistical learning theory as explained above a major problem in inferring the true probability measure p from the set of training data is over fitting . it is not sufficient that remp is small we rather would like to have r small . abstractly speaking the problem reads given a family of negative functions consider the data points xx . xl and choose f\u03b1 in such a way that one can expect with high confidence that is small . in this general setting the specific form of f\u03b1 is not relevant the problem is simply to choose a function f\u03b1 from a family such that its expectation value is maximal . statistical learning theory tells the following . if the family is small enough with respect to a specific measure we can say with high confidence that for all \u03b1 the risk r deviates from the empirical risk r f\u03b1 xx \u03c9 remp f\u03b1 l xj l only by a small amount . to make this precise we brie\ufb02y explain the notion of vc dimension . first we introduce it only for two valued functions . learning bayesian networks using statistical learning theory definition . let \u03bb be an index set of arbitrary cardinality . let \u03b1 \u03b1 be a set of indicator functions on \u03c9 . then the v c dimension of \u03b1 \u03bb is the largest natural number l such that there exists l points x x. xl \u03c9 with the property that for every indicator function \u03c7 there exists a function f\u03b1 such that its restriction to the definition of vc dimension of arbitrary real valued functions relies on the vc di mension of sets of indicator functions definition . let \u03b1 \u03bb be a family of real valued functions on a set \u03c9 . then the vc dimension of \u03b1 \u03bb is the vc dimension of the family of the indicator functions f\u03b1 \u00b5 ir \u03b1 \u03bb . here \u03c7\u00b5 is defined by \u03c7\u00b5 for c \u00b5 and \u03c7\u00b5 \u03c7\u00b5 \u00b5 . for c the following theorem is a corollary from the statements in theorem . let be a set of measurable real valued functions on \u03c9 bounded below and above by a and b respectively . let h be the vc dimension of the set . then for any training data x x. xl we have with probability at least \u03b7 r remp \u03c6a b with for all functions f\u03b1 . \u03c6a b r h l ln note that the reliability bound is uniform on the family i.e. with probability \u03b7 the di\ufb00erence between remp and r is for all f\u03b1 bounded by the second term in eq . in the following section we will give bounds on the vc dimension of certain sets of joint probability distributions of n variables . the vc dimension associated with a graph or a set of graphs the factorization of markovian joint distributions in eq . is decisive for the upper bound on the vc dimension of pg . note that the vc dimension of the families and p pg p pg coincide . note furthermore that pg contains also all distributions that are markovian relative to a graph g whenever g was obtained from g by deleting some arrows . in this pg are considered . sense one considers always a set of graphs when general distributions in let mj the number of elements of \u03c9j . we find \u03c9j d. janzing and d. herrmann theorem . let rj be the indices of the set pj of parents of xj with respect to a given graph g. then the vc dimension of pg is at most ng mi . xj n yi proof . we show that the logarithms of all probability distributions in pg can be written as a linear functional in a common ng dimensional vector space . for each set j we define . n j. jk and for all the other values . then the logarithm of the probability of x can be obtianed by j is for the entry that corresponds to the restriction of x to pj of . j proof . we extend the proof of theorem . the definition of each space vj given there depends on one particuliar choice of the parents of xj . now we have a vector space v i j corresponding to each possible choice of parents of xj given by one specific subset i for each node j. we define \u02c6v i v i j. j n one checks easily that n is the dimension of \u02c6v . note furthermore that also the definition of each cx j in the proof of theorem depends on one specific choice i of the parents of xj . hence we obtain now a di\ufb00erent vector cx i for each i. in analogy to the proof of theorem we assign a vector \u02c6cx to each n tuple x by j \u02c6cx i cx i. j let p be an arbitrary probability measure in \u02c6 p. the proof of theorem assigns a vector f v to this measure . note that there is a canonical embedding of the vector space v introduced in the proof of theorem into the space \u02c6v defined here since each vj defined there corresponds to one specific v i j here . with this embedding we have ln p \u02c6cx h f i. hence the logarithms of probabilities can be written as an inner product in a vector space of dimension n. this completes the proof . if no specific order on the random variables is given a priori the vc dimension of all graphs with a fixed in degree is bounded as follows theorem . let some graph g with in degree . then the vc dimension of p be the set of probability measures that are markovian relative to p is at most n mi xj yi j where the sum runs over all subsets j of . n. the proof follows from the observation that each p p is a factor log linear model i.e. a probability distribution with the property that its logarithm can be written as a sum of functions each depending on at most variables . then the bound of lemma in applies . the following corollary from theorem shows explicitly how to use the bounds on the vc dimensions in order to get reliability bounds on the estimated risk functional . note that d. janzing and d. herrmann it is therefore necessary to restrict one s attention to sets of probability measures which are \u03bb for each \u03bb be the set of joint distributions bounded below . explicitly we define let p with the property that p p \u03bb for all n tuples in \u03c9 . note that we do not assume that the true probability measure p satisfies this requirement . only the hypothetical measure p has to be bounded . then the bounds a and b in theorem are and ln \u03bb respectively . we conclude corollary . let \u03bb be a set of joint distributions with vc dimension h. then for any training data x x. xl we have with probability at least p p \u03b7 r remp \u03c6\u03bb with \u03c6\u03bb r h l ln uniformly for all p. setting p \u03bb g we obtain reliability bounds on the estimated probability measure \u03bb provided that the graph g has been chosen in advance . with we obtain reliability bounds if the hypothetical measures are restricted to those that factorize to a simple graph . p p p p however the prior restriction to a specific \u03bb and a specific graph or to graphs with small in degree is not acceptable . an appropriate way to learn bayesian networks should also consider complex graphs provided that sufficiently large sampling strongly indicate a more complicated dependency among the variables . similarly one should not a priori exclude probabilities that are smaller than a specific value \u03bb . for large sample size data may give strong evidence that some probabilities are indeed small . on the other hand the estimation in corollary seems to require prior restrictions . this problem is solved by structural risk minimization principle in statistical learning theory . it uses a hierarchy of increasing sets of hypothetical functions . then a function g from a larger set is only preferred compared to a function f from a smaller set if not only remp remp but also the bound on r is smaller than the bound on r. we explain this principle in the following section . now we brie\ufb02y summarize the estimations for the vc dimension of some interesting set of graphs . here we assume that l is the maximum over all values mj . for the vc dimension of a given graph g with in degree we have this follows from theorem since for the vc dimension of all graphs with in degree which respect a given order on the nodes we have n l. h l. mi yi l h n xj j. learning bayesian networks using statistical learning theory this is due to theorem since the second sum in eq . runs over for the vc dimension of the set of all graphs with in degree we have this follows from theorem since the sum in eq . runs over j h n l. n terms . terms . this seems to suggest that in general a small in degree reduces the vc dimension con siderably whereas prior knowledge on the causal order is less relevant . structural risk minimization before we apply structural risk minimization to the problem of learning probabilities we brie\ufb02y sketch the general idea . consider the case that an arbitrary function on a set \u03c9 is to be learned . define a sequence k n of families fk of functions . the idea is that the sequence defines a hirarchy of more and more complex families of functions and the less complex ones are a priori preferred . let k in be any sequence of non negative numbers k pk . these values express to what extent one tends to prefer functions from with fk with lower k. let hk be the vc dimension of fk . then one has with probability \u03b7 that for each function f p k fk s r remp \u03c6 where \u03c6 is the confidence term in eq . this is a standard union bound argument . note that the sequence on pk may be chosen in such way that it expresses prior probabilities to the choice of a certain class fk . but it should be emphasized that the reliability bound in eq . does not rely on this interpretation . p \u03bbm be the set of probability measures bounded from below by \u03bbm . let here we define a hirarchy of probability measures which takes into account two aspects of a measure we prefer measures which are markovian relative to a simple graph and measures with high cut o\ufb00 value \u03bb . let m in be a sequence of positive values converging to zero . pr be let r sets of probability measures . they may for instance correspond to an enumeration of all directed acyclic graphs on n nodes . they may also correspond to graphs with in degree \u03bbm for small m and small k. r. then we prefer probability measures in we may express this by defgining probabilities qk m which are decreasing in k and m. in analogy to the bound above we obtain p. pk p d. janzing and d. herrmann theorem . let k k with k in or k. r an arbitrary set of families of joint distributions on the n random variables . let k m define an arbitrary probability measure on k pk . then we know with probability \u03b7 for all k in . let hk be the vcin and all r m r remp \u03c6\u03bb dimension of p \u03bbm pk p holds with \u03c6\u03bbm ln \u03bbmr l hk ln the structural risk minimization principle works as follows . for a given number k m choose pk m p \u03bbm pk such that remp is minimal . then choose k m such that remp \u03c6\u03bbm is minimal . the following example gives an idea how to apply this principle . given n binary variables . then our upper bound on the vc dimension of the set of graphs with in degree is n. h qk m k m. let pk be the set of joint distributions which are markovian relative to a graph with in in degree k. set furthermore \u03bbm m and choose the prior probability measure on in as for p pk p \u03bbm we obtain \u03c6\u03bbm m ln r l nk ln ln ln the confidence term grows exponentially in k with o and with o whenever the other parameters are fixed . hence the required sample size grows quickly with the in degree whereas the number of random variables is less decisive . also the cut o\ufb00 value \u03bb of the probabilities is less decisive since the required sample size grows only with o although we have defined the cut o\ufb00 values \u03bbm in such a way that they decrease exponentially in m. convex optimization for bayesian networks the number of directed acyclic graphs with constant in degree and n nodes increases polynomially in n. therefore it is realistic to assume that for all graphs with small indegree the optimization can be carried out for each graph . hence we may restrict our attention to finding the optimal probability measure that is markovian relative to a given graph g and bounded by a given value \u03bb from below . let vj be defined as in the proof of theorem i.e. the set of real valued functions on \u03c9rj . learning bayesian networks using statistical learning theory let xi be the i th observed n tuple . let xi its parents . then the task is to find a vector rj its restriction to the variable xj and all that minimizes subject to the following constraints f jfj jvj v remp l xi l xj n fj for each j the sum of the conditional probabilities p over all xj for all tuples \u03c9 \u03c9pj . formally this means \u03c9j has to be z\u03c9 exp xxj \u03c9j for \u03c9 \u03c9pj . no probability p is less than \u03bb . we can achieve this by stating the stronger \u03c9 is less than \u03bb n. this is equivalent constraint that no transition probability p xj to g\u03c9 j xj fj ln \u03bb . n the optimization is rather similar to that one in with the decisive di\ufb00erence that the normalization can be performed for each node separately here whereas the normalization condition for the joint measure on n variables involves a sum over all possible n tuples i.e. a number growing exponentially in n. here the computational complexity grows only polynomially in n for constant k. the number of constraints grows linearly in n but exponentially in k. the number of terms in the sum grows also exponentially in k. but since we assume that k is small we consider the optimization as computationally tractable . due to the convexity of the constraints it is a usual linear programming problem that can be efficiently solved . conclusions we have presented a method for estimating the joint distribution of a large number of random variables from sparse data . the statistical dependencies among the variables are explained by bayesian networks such that networks with simple graphs are preferred . we provide reliability bounds without restricting the set of joint distribution under consideration . we have shown that the set of probability measures that are markovian relative to simple graphs have low vc dimension . this guarantees reliable estimation in the sense of statistical learning theory whenever the observed data is explained well by those simple measures . if no simple bayesian network fits the data the method does not allow reliable estimation . furthermore we have shown that finding the optimal distribution within a class of distributions is a convex optimization problem . since the number of simple graphs is not too large the whole estimation can be performed efficiently . d. janzing and d. herrmann"
    ],
    "abstract": [
        "to learn dependencies among random variables requires exponentially large sample size in the number of observed random variables if any arbitrary joint probability distribution can occur . we consider the case that sparse data strongly suggest that the probabilities can be described by a simple bayesian network i.e. by a graph with small in degree delta . then this simple law will also explain further data with high confidence . this is shown by calculating bounds on the vc dimension of the set of those probability measures that correspond to simple graphs . this allows to select networks by structural risk minimization and gives reliability bounds on the error of the estimated joint measure without any prior assumptions on the set of possible joint measures . the complexity for searching the optimal bayesian networks of in degree delta increases only polynomially in the number of random varibales for constant delta and the optimal joint measure associated with a given graph can be found by convex optimization ."
    ],
    "extracted": [
        0
    ],
    "score": [
        0.5988023952095808
    ]
}